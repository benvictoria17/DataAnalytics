title,score,id,url,comms_num,created,body,timestamp
STEM Career Change,5,swvi7j,https://www.reddit.com/r/datascience/comments/swvi7j/stem_career_change/,6,1645341433.0,"I’m currently working as a field biologist for fisheries research, and am looking to transfer into a more data-science oriented career field. I’ve grown tired of the field work side and love the data side, while most of my coworkers are the opposite.

I have a M.S. in Environmental Science, with coursework in single and multivariate stats, although I don’t use very much complicated math in my job. I have more experience than most of my early-career coworkers with R, and do use it at work, but am light years behind the statisticians in my office. No experience in Python, SQL, or any other data science software. 

My questions would be:

1. What skills would I need to gain / build on before making the switch? 

2. What’s a reasonable entry salary? Biologists don’t make great money so almost anything would be an increase haha.  

3. Are online courses / certifications worth it? The amount of marketing I see for those is insane. 

I luckily have access to large amounts of data and free time to learn new skills at my job, so I just want to make sure I’m on the right path. Thanks in advance!",2022-02-20 09:17:13
Comment,79,hxct3v5,,0,1645130086.0,DataScientologists,2022-02-17 22:34:46
Comment,1,hxcsshc,,0,1645129964.0,Sounds like you'll need some sort of fuzzy matching. You can get confidence scores here as well.,2022-02-17 22:32:44
Comment,2,hxcva4l,,0,1645130920.0,"Best of both worlds. Work in DS without working in DS, hehe.",2022-02-17 22:48:40
Comment,1,hxcuqf2,,0,1645130711.0,"Hi u/Ok_Acanthisitta5478, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 12 karma.",2022-02-17 22:45:11
Comment,1,hxcupfq,,0,1645130701.0,"So I have the opportunity to officially enter the ""data field"" for a large retail company. So name recognition. However it's a lateral move in pay. But it's good exposure to big data which I haven't had yet. Thoughts?",2022-02-17 22:45:01
Comment,3,hxd36hw,,0,1645133910.0,"> You should know that nested loops has exponential complexity.

Minor nitpick: the nested loops themselves have polynomial complexity, not exponential (i.e. O(N\^M) for M loops, not O(M\^N)). What is exponential is the relationship between time complexity and the number of nested loops. I'm sure this is what you meant, but the wording is slightly off.",2022-02-17 23:38:30
Comment,2,hxd2xtj,,0,1645133820.0,Though it's mainly taught in ECE these days.,2022-02-17 23:37:00
Comment,2,hxd20t1,,0,1645133478.0,"/u/Morodin_88  read my mind.  

You can be a great programmer but SW engineering goes beyond that.   

With DS as with SW engineering you'd want to think end-to-end starting with strategy around what the DS folks should be doing.   Then there should be thought/discipline given to requirements, design, data (that whole space really), solid piplines, versioning (of code and data + lineage), testing, metrics, etc. etc.   

In my company there is way less discipline in the DS space than there is in typical SW engineering spaces.  

There are a whole set of tools coming around to manage many of the areas in the DS space.",2022-02-17 23:31:18
Comment,2,hxd0f0e,,0,1645132871.0,"Agreed... ITT a bunch of people trying to justify why they write bad code and another group that doesn't know software engineering isn't the same thing as writing good code. 

I can write good code but I'm a horrible software engineer... This is why I advise DS minded people to idk try and build a simple app / website and learn what SWE is about.",2022-02-17 23:21:11
Comment,2,hxd035y,,0,1645132750.0,Would love to see something similar for other problem types,2022-02-17 23:19:10
Comment,2,hxczspb,,0,1645132638.0,"I am a beginner, would like to learn more about this domain. Could you please share few of your works. And I would be happy to work, learn and grow under your guidance.",2022-02-17 23:17:18
Comment,1,hxczgpm,,0,1645132510.0,"Hi u/AnalysisParalysis93, I removed your submission for the following removal reasons:

* **Videos are not allowed.** Submissions from youtu.be are not allowed on r/datascience.",2022-02-17 23:15:10
Comment,41,hxcyeec,,0,1645132106.0,"Possibly adapted from [Google's Rules of ML](https://developers.google.com/machine-learning/guides/rules-of-ml)

> do machine learning like the great engineer you are, not like the great machine learning expert you aren’t

The rest of the doc is a great read!",2022-02-17 23:08:26
Comment,1,hxcxocn,,0,1645131826.0,\*You must be able to write good code. Not the same thing as being a good software engineer. Leetcoding is masturbation after 4-5 years as a data scientist,2022-02-17 23:03:46
Comment,2,hxcxjyf,,0,1645131779.0,Just starting to learn from researchers in this area. Maybe in a year or so.,2022-02-17 23:02:59
Beast practices or frameworks for defining success metrics?,9,rc6wjp,https://www.reddit.com/r/datascience/comments/rc6wjp/beast_practices_or_frameworks_for_defining/,2,1639015248.0,"I'd love to learn what framework folks use for defining feature success metrics. At a high level, I usually bucket my metrics under these areas: engagement, health, and Satisfaction. Revenue is usually not a focus for my team so I exclude. Within each category info through an exercise to understand what success would look like, example under engagement - metrics to understand how many people are using the feature (slice by various dimensions) over time etc

. Does anyone have a framework or approach they can share?",2021-12-09 04:00:48
Data Scientist VS Product/Project manager role,86,rc5knh,https://www.reddit.com/r/datascience/comments/rc5knh/data_scientist_vs_productproject_manager_role/,53,1639011149.0,"Hey everyone, I am currently a Sr. Analyst and love all the math and ML behind machine learning(still learning), I see my fresher friends jumping into product manager roles and earning 2X their previous salaries, I am a quiet introverted nerd and maybe that's the reason I would think 10X before jumping to the PM track but what do you guys think? Which has a good progression in roles and salaries? Is it Product manager or Data Scientist?",2021-12-09 02:52:29
Is exact position title important?,8,rc324k,https://www.reddit.com/r/datascience/comments/rc324k/is_exact_position_title_important/,21,1639003524.0,"I am in the data science team and my current position is jr.data scientist. Before getting this position, I applied and interviewed for ""data scientist"" position at this current company, but at the end when they extended the offer, i was given ""jr."" just because i was lacking experience level needed for ""data scientist"" in their goddamn hr system. (even though i was interviewed for exactly this position). I tried to negotiate but it didnt work. I accepted the position nonetheless and felt like this was bait and switch so now want to start applying again starting next year. Would me leaving out ""jr."" part in my resume make a difference there? How could companies know?",2021-12-09 00:45:24
Comment,1,hxpg1l9,,0,1645367642.0,"Mid career really, sorry about the confusing title.",2022-02-20 16:34:02
Comment,-3,hxotmmb,,0,1645352607.0,I'm learning and wanted to do something unique..maybe like a project...best resource or guide for simple feed forward networks?,2022-02-20 12:23:27
Comment,2,hxfeljc,,0,1645177093.0,"""No. Next, please.""",2022-02-18 11:38:13
Comment,1,hxfe00y,,0,1645176610.0,"Hi u/Josso_l, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 3 karma.",2022-02-18 11:30:10
Comment,1,hxfdh7u,,0,1645176184.0,"Also a building ""i think"" should be flexible to withstand an earthquake.",2022-02-18 11:23:04
Comment,20,hxfci90,,0,1645175395.0,"You will need to write and maintain a list of those issues basically, and what do you believe is the way to mitigate each point (there can be a lot of tradeoffs), and then transform this list into code to filter that data.

Fully automation from the beginning is not possible, since the definition of 'bad data' is very much domain-dependent/problem-specific. For example, you mention some outliers. In some analyses, you should exclude them. But in other analyses, they are very useful (they can point to instrumentation failure or bad training for those entering the data or for fraudulent behavior).",2022-02-18 11:09:55
Comment,1,hxfc5mc,,0,1645175111.0,"Hi u/sydneysweeney69, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 3 karma.",2022-02-18 11:05:11
Comment,0,hxfc3ly,,0,1645175065.0,"I was thinking more like using machine learning for automated forex and trading.

also just investing in general not analysis and science.

and also selling the soul to a billion dollar corp.",2022-02-18 11:04:25
Comment,4,hxfc07d,,0,1645174988.0,"If your goal is to get rich by doing data analysis/science, then yes, that s a 0.0000001% chance or so to make it happen in this way.",2022-02-18 11:03:08
Comment,1,hxfboo5,,0,1645174729.0,"Geophysics grad student here. I strongly doubt any building can withstand a magnitude 9 especially when the epicenter is near the building. That being said, the rock strata around the building also plays a role in amplifying the vibrations. Yes, the building might not get uprooted, but the shaking could very well shake off building materials near the top of the building, thus making it unsafe to live in.",2022-02-18 10:58:49
Comment,-2,hxfbizl,,0,1645174600.0,im only 5.5 =(,2022-02-18 10:56:40
Comment,3,hxfbiba,,0,1645174586.0,Better chance at shooting a ball through hoops or throwing the pigskin,2022-02-18 10:56:26
Comment,2,hxfb7qd,,0,1645174343.0,Build me a dashboard tracking the amount of fights with your boss. I should be able to have colors showing me the distribution of topics that you fight over. I need it by tomorrow.,2022-02-18 10:52:23
Comment,1,hxfat1e,,0,1645174014.0,"Hi, I'm currently doing some analysis on formula 1 data (race data mainly) but I'm interested by what you mean when you talk about the race ratings, could you expand?",2022-02-18 10:46:54
Comment,1,hxfanlc,,0,1645173890.0,"Yeah although I haven't seen any CV person call themselves data scientist.
Computer vision engineer/scientist, CV developer, Software developer, machine learning engineer whatever. 

Worked in medical CV myself and last decade in speech and don't do that either because I usually don't do general DS work. And because, as you said, DS can mean anything. I am generally more likely to work in C++ or Rust than in R or with Databricks, Tableau or similar.
Yes, I also did a few small DSy projects but still avoid calling me DS ;).",2022-02-18 10:44:50
Comment,-2,hxfaj6j,,0,1645173792.0,like an investment firm started by a financial data scientist?,2022-02-18 10:43:12
Comment,3,hxfaf99,,0,1645173702.0,the only way would can make that sort of money is by starting a business,2022-02-18 10:41:42
Comment,-1,hxfa2o0,,0,1645173416.0,That's because your opinion is ill informed and garbage quite frankly,2022-02-18 10:36:56
Comment,0,hxfa0px,,0,1645173371.0,"That's one specific task with clinical trial data for submission related work. What about about using medical images for clinical prediction, that's based on data obtained in trials. Or proteomics. You really don't have a clue what you're talking about",2022-02-18 10:36:11
Comment,6,hxf9jgx,,0,1645172981.0,"Lmao, your best bet is marrying rich",2022-02-18 10:29:41
Comment,3,hxf9cn2,,0,1645172827.0,Holy shit this is good,2022-02-18 10:27:07
Comment,9,hxf95dk,,0,1645172662.0,Nope. Have you tried being born wealthy?,2022-02-18 10:24:22
Comment,1,hxf8u6y,,0,1645172410.0,"Hi u/Sad_Campaign713, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 4 karma.",2022-02-18 10:20:10
Comment,9,hxf8oze,,0,1645172296.0,Never. Why runs after Money. Live life fully,2022-02-18 10:18:16
Comment,1,hxf8flm,,0,1645172087.0,"lol anyone can become a Data Scientist, I was an Animator, now a Data Scientist.",2022-02-18 10:14:47
Comment,1,hxf7zab,,0,1645171731.0,You're welcome! Yeah I had the same feeling after working for a big company in the aerospace industry for several years,2022-02-18 10:08:51
Comment,5,hxf7uu2,,0,1645171636.0,"To add on to the list of projects, I'd recommend looking at doing some data analysis in an area which you find interesting on a personal level. This way it makes it easier for you to describe the project to a future employer, and you have a lot of ""area specific competence"" which will aid your research. 

An example could be gaming? I saw one post of a guy who did an analysis on cheaters in Rust.  Or perhaps you like ice hockey and want to see what factors contribute to a team going to the playoffs? I myself did an analysis on Formula 1 races and I did a comprehensive analysis on what makes people rate a specific race higher than others. Everything was done in a notebook and I could do some data storytelling to my analysis in my interviews. Good luck!",2022-02-18 10:07:16
Comment,1,hxf4x3r,,0,1645169411.0,"Hi u/leighscullyyang, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 5 karma.",2022-02-18 09:30:11
Comment,1,hxf49yb,,0,1645168942.0,"This is an interesting problem. I'm curious if the following approach would make sense in this context:

* Cluster the entire dataset and identify an optimal number of clusters for the documents (i.e. using internal validation)
* Look at where your labeled data fall into those clusters
* If there is one or a few clusters for which you do not have any labeled data, sample a reasonable number of points from those clusters and manually label them
* Treat the problem as a classification analysis from hereon

Don't think this fully solves the problem, but may be a decent workaround. You'd likely have some low-pop classes that don't justify a separate cluster and therefore wouldn't be captured, but this would hopefully only be a small number of the documents. We can also increase the number of clusters to potentially find a few more of these low-pop classes as well.

Hopefully that helps. Feel free to ignore if it doesn't make sense :)",2022-02-18 09:22:22
Comment,2,hxf439l,,0,1645168810.0,"Saving this for future reference, thanks for sharing!",2022-02-18 09:20:10
Comment,2,hxf3us6,,0,1645168643.0,That's a great approach! Much better than doing a lot of Kaggle or whatever tasks that require too much time do dig through for any Senior DS on the hiring side.,2022-02-18 09:17:23
Comment,1,hxf2tf2,,0,1645167889.0,"Speaking as a person who does big data, a thorough understanding of memory management is a pretty nice skill to have in order to write efficient code that chugs through a system that generates roughly 100GB daily for nearly the past 10 years. The ability to train models in insanely large historical datasets like what I work with daily. The ability to ETL historical datasets that have gone through various iterations and forms throughout the years as the data lake evolved. Etc.

I guess the point of my rambling is that data science itself is so huge that depending whatever specialization you eventually take may require vastly different skillsets.",2022-02-18 09:04:49
Comment,1,hxf1p6v,,0,1645167102.0,"As a DE it would be sooooo nice if the DS’s I worked with were capable of deploying to prod. Instead I’m just given a series of bioinformatics scripts spanning multiple hpc clusters resulting in some obscure file in some obscure host that no one has access to and an associated notebook that *would* work only within some hyper specific anaconda env. And then I have to figure out how to automate the scripts, ETL and warehouse it so it actually confirms to our already agreed-upon structure. 

Anyway that’s why I’m going back to software dev",2022-02-18 08:51:42
Comment,-1,hxf0ipy,,0,1645166277.0,"> You know what needs to stop? It's not statistics either.

The vast hordes argue the Software Eng angle. I have seen more people worried about ""whitespace"" than good statistics. Statistics is underrated.",2022-02-18 08:37:57
Comment,1,hxezun4,,0,1645165816.0,You're assuming your work produces entirely a net benefit. It could very well do a lot of harm and you may never know. I think you're being small minded,2022-02-18 08:30:16
Comment,1,hxeyqcm,,0,1645165077.0,I feel like you called out this sub,2022-02-18 08:17:57
Comment,1,hxeymo0,,0,1645165008.0,Half right half wrong. Remember DS = Stats + programming,2022-02-18 08:16:48
Comment,1,hxexm0x,,0,1645164344.0,"If one is not good at neither, can I still work as D.S guys???? Asking for a friend",2022-02-18 08:05:44
Comment,2,hxewslz,,0,1645163836.0,Great answer here!,2022-02-18 07:57:16
Comment,1,hxewlf9,,0,1645163711.0,"Hi u/tweety123177, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 15 karma.",2022-02-18 07:55:11
Comment,1,hxewdo0,,0,1645163576.0,"Related to MLOps and SWE. I feel like my creativity is better much utilized here unlike in DS where I just keep doing data quality checks to please the stakeholders, it's very frustrating",2022-02-18 07:52:56
Comment,1,hxetb38,,0,1645161742.0,Strong fundamental is good. But refusing to learn new technology is naive. Strong fundamentals helps to grasp new tech easily.,2022-02-18 07:22:22
Comment,32,hxesxro,,0,1645161531.0,"This is literally spot on 😂😂 

Then the next post is something like: 

<today, I sat down to cry for 45 minutes because I had to let another highly qualified candidate know they didn't get the job. That's the dark side of this industry. But I stood up, wiped my tears, splashed water on my face and called the next candidate-- the lucky one. I could hear the joy in his voice. He began to cry and pray and shit himself. The phone burst like a party popper into my eardrum and I lost all hearing. There's two sides to this industry. And I love every second of it. The good AND the bad.>",2022-02-18 07:18:51
Comment,1,hxesr8m,,0,1645161425.0,"The thing is, in terms of opportunity, you can get a lot further if you can bootstrap the environment as well as making models. Most even large companies can't really provide a statistician with a good environment out of the box. Sadly :(",2022-02-18 07:17:05
Comment,2,hxesec3,,0,1645161217.0,"There's also the opposite: we can't use open data because we can't trust it.


> but if don't normalise on census data then we're basically just creating a measure of population density...

NO OPEN DATA, only this aging CRM system export and last month's sales figures",2022-02-18 07:13:37
Comment,4,hxesbui,,0,1645161177.0,[X] -T,2022-02-18 07:12:57
Comment,46,hxervl1,,0,1645160918.0,"You mean you don't like the stock standard linkedin post that goes like this:

<Today a woman walked into a job interview wearing a tshirt with vomit on it. Said vomit was from her crying 1 year old baby in her arms <more sobstory diatribe>... she was a domestic violence survivor ... <more bs> but she was insanely qualified and obviously committed. I took a chance on her even though she was dressed inappropriately (this is the part where everyone should clap and cheer for me because I'm such a fucking humanitarian). Today, she's the CEO of Yahoo. Moral of the story: look how amazing I am.>",2022-02-18 07:08:38
Comment,1,hxera4g,,0,1645160585.0,I know someone who writes great codes but develops poor forecasting models. I write not so great code but my models have much  better performance in production and higher customer approval ratings. So 🤷‍♂️,2022-02-18 07:03:05
Comment,14,hxeqhnv,,0,1645160151.0,"I like the other answer with the data pipeline but I’ll give my own answer as well. Note: this is kinda long but you really only need one great project instead of 3 half assed ones.

Get data (clean or messy) from either a google research or scrape your own but that’s an extra step, write a script to clean data, perform some ml (nothing crazy), test thoroughly and document this process since it’s better to tell an interviewer how you evaluated the model instead of the actual results, and output the prediction to some kind of web app or email or something that makes it more user friendly (flask and stream lit are your friends here)

An example is like let’s say there’s a website that takes as input a picture of you, and returns to you its estimated age. Bad example but you get the point. This is what the end product should look like. You have a trained model in the background that takes input, and returns its output back to the browser. This can go a long way since you can demo very quickly during an interview. 

Also, focus more on getting a skeleton pipeline first. Then focus on each step. 

And last but not least, pick the idea (face age example) first so you can find relevant data you need. Don’t do covid data, pick something you like. I did basketball for mine.",2022-02-18 06:55:51
Comment,2,hxeq538,,0,1645159960.0,"Yes!

I'm a data scientist, and I need to configure clusters, figure out how many cores, memory, etc., in order to submit my Spark jobs. I'm also aware of costs, because I work for a company, and Engineering has a budget just like everyone else.

It's amazing how many of these comments are completely detached from reality. Maybe things are different for me at a tech startup, but I need to wear different hats, and IMHO that's what makes a DS valuable beyond the fundamentals.",2022-02-18 06:52:40
Comment,3,hxeq3cf,,0,1645159934.0,Inverted or transposed?,2022-02-18 06:52:14
Comment,2,hxeq1ve,,0,1645159912.0,"To be a data scientist, you must first master the secrets of entropy and the universe.",2022-02-18 06:51:52
Comment,3,hxepqqx,,0,1645159744.0,"The term you're looking for is ""software defined data integration""",2022-02-18 06:49:04
Comment,2,hxeom8t,,0,1645159143.0,"Agreed.

Maybe we should just respond to these types of posts. I feel like engagement overall is much lower on LinkedIn, so they're bound to notice. Heck, maybe even feel shame if an actual senior data scientist laughs at them and calls them out on their bullshit.",2022-02-18 06:39:03
Comment,1,hxeoi1s,,0,1645159081.0,"> My third thought is ""that looks about as easy as doing the same stuff in matlab.""

As I asked, please try it and show me. Please look at the image at the end first to make sure you understand what the actual result is. The groupby operations are going to be ugly in MATLAB, and the final plot, one line of Python code, is easily dozens of lines of MATLAB code at least. You will probably need to create an entire GUI to reproduce that one line.

> I have no idea how easy or hard any one of these is in Python. 

Trivially easy.

First, `aviinfo` is deprecated and will be removed from MATLAB, so better not to use that.  The replacement `videoreader` does not appear to dump all metadata in a single command.

But here is how I would do this in Python:

    import json
    from pathlib import Path
    import pandas as pd
    import imageio as iio

    vid_data = pd.DataFrame(Path('Videos').rglob('*.mp4'), columns=['path'])

    # This could be one line, I am making it easier to read
    vid_data['name'] = vid_data['path'].apply(lambda x: x.name)
    vid_data['size'] = vid_data['path'].apply(lambda x: x.stat().st_size)
    vid_data['date'] = vid_data['path'].apply(lambda x: x.stat().st_mtime).astype('datetime64[s]')

    vid_data['matches'] = vid_data[['name', 'date', 'size']].isin(vid_data2[['name', 'date', 'size']].to_dict()).all(axis=1)
    vid_data['changed'] = ~vid_data['matches'] & vid_data['name'].isin(vid_data2['name'])

    vid_data_good = vid_data[~vid_data.matches]
    vid_data_good['vidinfo'] = vid_data_good['path'].apply(lambda x: json.dumps(iio.get_reader(x).get_meta_data()))

    vid_data_good.to_sql('new_files', db)

I'll admit I am cheating a tiny bit. Imageio is part of anaconda, but to read video requires one additional package installed that isn't part of anaconda: imageio-ffmpeg. But this has *zero* dependencies, requires zero work to get working, and cannot cause any of the conflicts or other issues you describe. It merely exists to avoid forcing people to install ffmpeg if they don't want it.

If that really bothers you so much you can use `cv2.VideoCapture` to get the metadata, too, and it is installed by default. But it doesn't give everything in one command (note again that MATLAB's `videoreader` doesn't either), so I pretty much always use imageio.

Note also that there are other ways to work with the paths. You can use `glob` to get the paths as strings, then `os.path.getmtime` and `os.path.getsize`. Python has actually had the sort of recursive searching you just showed forever, MATLAB only got it within the last couple of years.

I prefer pathlib for working with paths, since it combines nearly all path operations in an extremely simple interface, one MATLAB doesn't have. So I could do `(targdir / 'subdir').rglob('*.mp4')` if I wanted to search the directory ""subdir"". MATLAB has nothing like PathLib, which makes working with paths much more of a chore in MATLAB. 

For more complicated directory searches, Python has `os.walk`, which loops over files recursively, and lets you interactively cut out subdirectories you don't want as you go. It is extremely useful for more complicated directory processing, and is something MATLAB doesn't have anything similar to.",2022-02-18 06:38:01
Comment,1,hxemaaz,,0,1645157937.0,"I am not a software engineer. I am a data scientist. There is a difference, and you need not be a software engineer to be a good data scientist.",2022-02-18 06:18:57
Comment,9,hxelvna,,0,1645157728.0,"I'll boldly recommend an article I recently wrote on portfolio products.

 https://link.medium.com/1V6zXJiQJnb

I also have another article I wrote on design aspects to consider, which you can find through my profile. The design part makes a difference. Do good work, and then make it look good in a portfolio. That's where some people ruin their end game. Make your portfolio products shine.",2022-02-18 06:15:28
Comment,1,hxel8y2,,0,1645157408.0,Oh wow!,2022-02-18 06:10:08
Comment,1,hxek30f,,0,1645156835.0,Why not both? They mastered literally different skills,2022-02-18 06:00:35
Comment,2,hxejhh0,,0,1645156538.0,"You know what you are correct, had to go lookup a few definitions around what is and isn't statistical and I gave a bad example.",2022-02-18 05:55:38
Comment,1,hxejfiv,,0,1645156511.0,"Hi u/metrotic2, I removed your submission for the following removal reasons:

* **Videos are not allowed.** Submissions from youtu.be are not allowed on r/datascience.",2022-02-18 05:55:11
Comment,1,hxejcde,,0,1645156469.0,">If you squint just a little, the lines between head hunting and whaling begin to blur. At least at C-level.

I don't know what half these words mean",2022-02-18 05:54:29
Comment,108,hxehstl,,0,1645155722.0,"Build a data pipeline from a source, into a database, and then from the database to visualization software like power bi or tableau. Essentially connect YouTube tutorial to YouTube tutorial and then film 10 minute videos of yourself explaining it to a person that doesn’t know anything about tech (act like you’re talking to a decision maker). Post videos at top of portfolio site and spam portfolio site with your resume. My videos got instant compliments because they could see behavior and knowledge… and it saves you from being put on the spot as much, hopefully.",2022-02-18 05:42:02
Comment,1,hxehkh4,,0,1645155611.0,"Hi u/tweety123177, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 15 karma.",2022-02-18 05:40:11
Comment,3,hxehhha,,0,1645155571.0,"Oh god, I thought BOW meant this was actually going to start with unigram IR models. There was NLP outside of RNNs in the 80s and 90s. Thanks for making me feel old.",2022-02-18 05:39:31
Comment,1,hxeh483,,0,1645155391.0,"Yes, the scary thing is they know more than you would be comfortable knowing. I work at a fortune 100 company and have met some exec researchers. 

If you squint just a little, the lines between head hunting and whaling begin to blur. At least at C-level.",2022-02-18 05:36:31
Comment,0,hxegpuf,,0,1645155199.0,"Hard disagree with any philosophy of the form “in order to be good at B, you must first be a master of A”. The typical life coach advice of “work on your fundamentals” being the quintessential example of terrible advice.

No no no. The reason you are good at A at all is because you are a master of B and it overlaps into A, not the other way around.

In other words, going deep on something builds stronger fundamentals. And the relationship is one sided: focusing on fundamentals doesn’t take you deeper. And in most cases you really don’t learn the fundamentals as well because you learned them out of context.

Correlation isn’t causation, ironic for a data scientist to get so wrong.

All building fundamentals explicitly does is, well, build fundamentals.

TC 450  
Data scientist / generalist at Google

Edit: another extremely common example of implementing this bad philosophy into bad specific advice is “learn linear algebra before you start learning machine learning”",2022-02-18 05:33:19
Comment,2,hxegj7n,,0,1645155112.0,"This is kind of my whole point. And the point of the original post... Re-usable, reproducible code isn't just a swe skillset. Good fundamental design is a core fundetal skill for all ds professionals...",2022-02-18 05:31:52
Comment,1,hxegbn2,,0,1645155011.0,"Hi u/tweety123177, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 15 karma.",2022-02-18 05:30:11
Comment,1,hxefozo,,0,1645154710.0,"Hi u/tweety123177, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 15 karma.",2022-02-18 05:25:10
Comment,7,hxefjv6,,0,1645154642.0,Need similar advice. Commenting for visibility,2022-02-18 05:24:02
Comment,0,hxef0i2,,0,1645154386.0,"False, to be a good Data Scientist you need to be good at basic math and statistics. Everything else is just compensating.",2022-02-18 05:19:46
Comment,1,hxeebgh,,0,1645154058.0,I agree with this,2022-02-18 05:14:18
Comment,1,hxedxlz,,0,1645153874.0,"Devils advocate here (also mech eng not data scientist) - could he not be getting at the fact that there are heaps of people with technical skills but this doesn’t mean they can apply them well. 

For example I have the belief that most engineers i work with are great problem solvers, but half the time they’re solving the wrong problems. 

Saying that, based on the OP I doubt he’s considered this.",2022-02-18 05:11:14
Comment,2,hxedpdj,,0,1645153766.0,"Well, I'm not saying I market myself or that you should market yourself. But if you don't know these people personally, you at least have to show up in their searches...",2022-02-18 05:09:26
Comment,1,hxedbw4,,0,1645153590.0,"I see your perspective, but real head hunting isn’t on LinkedIn. The finest diamonds never marketed themselves or sought to be discovered, yet they were sought and were found, and their value were appraised beyond the rest.",2022-02-18 05:06:30
Comment,2,hxebc8z,,0,1645152688.0,"Sure a statistician might be crazy good at analyzing results and blow the engineer out of the water. A software engineer might be able to do MLOps in circles around the statistician and write libraries for his company. A good department will have some of both working together, no one can do everything alone and if you think you can, you’re lying to yourself (or in a small enough role to where it doesn’t matter).

Just hope whatever company you get hired by knows this too",2022-02-18 04:51:28
Comment,2,hxearbh,,0,1645152430.0,"Lol I like this comment, probably the truest thing I’ve seen in this thread. But also kinda rough in interviews if you can’t stand out in either",2022-02-18 04:47:10
Comment,0,hxeac2f,,0,1645152241.0,You can extrapolate the outcome based on the input. We know that truly strong fundamentals yield distinguished performance which are demonstrated and evidenced through CL&I.,2022-02-18 04:44:01
Comment,1,hxe9lrr,,0,1645151916.0,"To be a great X, you have to be a great student. Tools, tech, and methods will always change. Your ability to learn fast, fail smart, adapt to adversity, and clothe yourself in humility is the formula for success in any role.

This is the fundamentals forest that everyone is missing for the skill trees.",2022-02-18 04:38:36
Comment,1,hxe8q18,,0,1645151522.0,"Hi, 


I am currently working my first job out of college in the asset management field. I am very interested in doing something like this type of work but am unsure of how to navigate a good start. My degree was in a applied economics major with a few data oriented aspects. There was one of the later courses that was supposed to have us use R to work with data sets but due to COVID, the classwork changed. 


I do not have much else in terms of this field but am eager to learn more. I do not think that my current career path is for me. I saw a few certificate courses that are offered by the universities in my state and was wondering if they were worth it.",2022-02-18 04:32:02
Comment,5,hxe8oh4,,0,1645151504.0,"The value I see is being contacted by HRs and head hunters, but that's about it",2022-02-18 04:31:44
Comment,1,hxe8bg6,,0,1645151339.0,This,2022-02-18 04:28:59
Comment,2,hxe84cf,,0,1645151250.0,Reason why I deleted mine. Everybody loves to promote themselves on that platform. Worried about what someone else is doing in their career. No value IMHO.,2022-02-18 04:27:30
Comment,1,hxe82a9,,0,1645151224.0,Ooh! are you still working on edunet or other projects in the edm space?,2022-02-18 04:27:04
Comment,1,hxe4jck,,0,1645149624.0,"Coming to this thread very late, but felt compelled to reply to this comment.

I've not once in my life regretted prioritizing my hobbies and interests over my career. My career is, and always will be, way down low on my priority list.  We all need money to survive, yes. But our wealth-centric, hyper-capitalistic society has corrupted our thinking. At the end of the day, most of our careers are completely meaningless and do nothing beneficial for society. All we're really doing is increasing corporate wealth and power (this isn't the case for all jobs, obviously, but for many it is, especially for we private sector data scientists).

There is nothing wrong with prioritizing your hobbies over your career.",2022-02-18 04:00:24
Comment,2,hxe4a4m,,0,1645149506.0,"My god this is so true. I manage and work with 7-8 data scientists. They can regurgitate Bayesian statistics back to you, but have no idea how to write a simple unit test. Their lack of understanding the fundamentals of the language they write in is painfully obvious. 

“But I know pandas well!!“

No.. you know how to trial and error your way through the problem at hand with no knowledge of how unoptimized and clunky your code is. 

Fundamentals are key to being a good data scientist AND data engineer. Anyone can learn to drive a car — not everyone understand how a car really works.",2022-02-18 03:58:26
Comment,3,hxe3lac,,0,1645149193.0,This is a problem I'm having at work. One team is staffed by bootcamp grads who are good at analyzing data. The trouble comes when they try to play software developer in production systems.,2022-02-18 03:53:13
Comment,1,hxe3emh,,0,1645149108.0,That's the other thing I'm not moving to a tech area for another year or two.,2022-02-18 03:51:48
Comment,1,hxe1z1u,,0,1645148466.0,"No worries, everybody was a beginner when they started. Most of my papers are applied papers. You may find these easier than the theoretical ones. You can see the titles from my google scholar page (https://scholar.google.com/citations?user=_oWyQ2UAAAAJ&hl=en). Please let me know if you feel interest in any of the papers. I would love to share. Also, may be we can get connected if you need any guidance. Please, PM me if show your further interest.",2022-02-18 03:41:06
Comment,2,hxe1qhj,,0,1645148355.0,"You can go through some of the titles from my google scholar page (https://scholar.google.com/citations?user=_oWyQ2UAAAAJ&hl=en). Please let me know if you feel interest in any of the papers. I would love to share. Also, may be we can get connected if you need any guidance in this domain. Please, PM me if show your further interest.",2022-02-18 03:39:15
Comment,2,hxe1kli,,0,1645148280.0,"Yes, most of my papers are applied papers. You may find these easier than the theoretical ones. You can see the titles from my google scholar page (https://scholar.google.com/citations?user=_oWyQ2UAAAAJ&hl=en). Please let me know if you feel interest in any of the papers. I would love to share. Also, may be we can get connected if you need any guidance. Please, PM me if show your further interest.",2022-02-18 03:38:00
Comment,1,hxe0kvg,,0,1645147829.0,May I ask what topics are you studying/upskilling for? What do you plan to do after? Asking because I would like to avoid SHs management as well :D,2022-02-18 03:30:29
Comment,1,hxe0f3q,,0,1645147756.0,"Sort of. I switched from marketing analytics for a real estate company to product analytics at a tech company. At the end of the day, it’s still mostly web analytics just from a different angle. But a tech company is going to value web/product analytics a lot more than real estate.",2022-02-18 03:29:16
Comment,1,hxe0dw0,,0,1645147740.0,Masters and upskilling on the side,2022-02-18 03:29:00
Comment,1,hxe07bn,,0,1645147659.0,Was it the same type of work just a better company?,2022-02-18 03:27:39
Comment,1,hxe061h,,0,1645147642.0,"Well, one should probably rather be aware to check data type sizes for a given language or system. 
Most languages and 64 bit systems define float and int as 4 byte (atm) and provide an explicit double. Python is an exception... but numpy and torch floats are also 4 bytes/single (and also offer float64 or double, and float16/single).",2022-02-18 03:27:22
Comment,1,hxdzts1,,0,1645147487.0,"Ha, saw this a moment ago on my linkedIn as well",2022-02-18 03:24:47
Comment,1,hxdzmms,,0,1645147397.0,"I switched jobs within the same team (marketing to marketing analytics) and kept the same pay. 

But after a couple of years of experience in the analytics role, plus upskilling via the first few classes in a part-time MSDS program, I got a new job at another company, same level different industry, significant pay bump. 

Depending on what you’re coming from, data & analytics could pay a lot more over time as you upskill. Probably very industry and job dependent though.",2022-02-18 03:23:17
Comment,1,hxdywas,,0,1645147067.0,What do you do now?,2022-02-18 03:17:47
Comment,2,hxdy1ib,,0,1645146676.0,"This is going to help me a lot. After working in IT for several years now, I really want to transition to something else more interesting. Thank you!",2022-02-18 03:11:16
Comment,1,hxdxwx3,,0,1645146619.0,Thanks!,2022-02-18 03:10:19
Comment,2,hxdw7ig,,0,1645145853.0,I quit data science to avoid stakeholder management.,2022-02-18 02:57:33
Comment,1,hxdupzo,,0,1645145189.0,This is the type of bad advice the Chief Data Scientist would give the team at my _last_ company - you know because I left to go somewhere that values growth,2022-02-18 02:46:29
Comment,1,hxduko4,,0,1645145123.0,"I have no idea if the task you chose is tilted in Python's favor. My first thought on looking at all of that is ""do that in sql"". My second thought is ""that's a nice clean dataset, but what about stuff I actually need to do on a regular basis."" My third thought is ""that looks about as easy as doing the same stuff in matlab.""

The kinds of operations I'm thinking of aren't things you do with a nice clean dataset, so offering an example workflow on a public dataset won't get my point across. Instead, here's a sequence of basic operations I might do when handed a hard drive full of data. I have no idea how easy or hard any one of these is in Python. If not a single one of them turns out to be obnoxiously complicated, I might not literally eat my hat, but I will be surprised and I might start to see your point of view. Installing nonstandard packages counts as obscene.

A = struct2table(dir(""X:\my_folder\**\*.avi"")); % to find all avi files within my_folder and its subfolders, plus size and date modified for each

A.date = datetime(A.date); % to convert to datetime for easy chronological sorting, date matching with other data

[A.matched, A.matchindex] = ismember(A(:,{'name','bytes','date'}), B(:,{'name','bytes','date'}, 'rows'); % to check files against a list of other files and find the easily spotted duplicates

A.changed = ~A.matched & ismember(A.name,B.name); % flag partial matches to investigate; has someone been manually renaming or editing files? 

C = A(~A.matched,:);

C.vidinfo = arrayfun(@(X) jsonencode(aviinfo(X)), C.folder+""\""+C.name, 'UniformOutput', false); % get frame dimensions, num frames, encoding, etc for each video, convert to JSON

sqlwrite(db, 'new_files', C); % stick it in the 'base

The above assumes I have a table ""B"" with similar columns in my workspace to compare against, and an open database connection ""db"" in autocommit mode.",2022-02-18 02:45:23
Comment,3,hxdtu8l,,0,1645144793.0,"So for me I had 3 on LinkedIn. This was 3 months ago. There were so python questions regarding packages I was familiar with such as pytorch, tensorflow, pandas, etc. The main thing that they all hit on was the business case. With this I was given a business question and a ""this is what I want to know"" statement and I walked the interviewer through the steps as I thought they should be done. Steps including what techniques, processes, and pointing out assumptions and unknowns in the problem.

Hope this helps.",2022-02-18 02:39:53
Comment,1,hxdpcvz,,0,1645142822.0,"I am a recent graduate from natural sciences and new to the market, trying my best to study the pointless Leetcode problems, review ML concepts while prepping project skills. It’s all too overwhelming at once and I thought about giving up multiple times.
Recently, I attempted a ridiculous “coding challenge” where you have 90 minutes to solve 5 Leetcode easy and 12 hard / time consuming MCQ, all for a random e-commerce startup. So, yah, I guess it f* is.",2022-02-18 02:07:02
Comment,1,hxdnzsr,,0,1645142231.0,"So your take on this is that all banks are wrong, and you know better... ? Surely you must know that p̂ = 0 or p̂ = 1 never occurs in practice anyway.

&#x200B;

Furthermore, we don't need to lose an infinite amount of money on a loan before using LL becomes reasonable. That's just ridiculous. Is using MSE absurd as well, given Xβ is unbounded hence so is (Y - Xβ)^(2) ... ? The fact that we heavily penalize gross misclassifications is the very reason why they seldom occur when we deploy our models.

&#x200B;

At this point it's rather clear you're arguing out of bad faith. Idk what's up with you and your irrational dislike of statisticians, but I give up. Have a nice day.",2022-02-18 01:57:11
Comment,1,hxdnua8,,0,1645142166.0,"Their loss, I guess.",2022-02-18 01:56:06
Comment,4,hxdnfyd,,0,1645141994.0,Me too 😂😭,2022-02-18 01:53:14
Comment,1,hxdn1g0,,0,1645141823.0,"If you drop out, be sure to have gotten the right intuition from your classes.  I see many machine learning engineers being very adapt with code, but no feeling for statistical uncertainty.",2022-02-18 01:50:23
Comment,1,hxdm7e3,,0,1645141466.0,"Currently I have 1 year of experience under my belt. By the time my program would start in 2023 it will be 1.5 years. I do think I would be doing part time so I can continue working but I haven't given it too much thought yet, 80 hrs of work/school sounds awful but might be doable to get it done faster (1.5 vs 2.5 years).",2022-02-18 01:44:26
Comment,3,hxdl61m,,0,1645141023.0,"I have never worked somewhere that had primary/foreign keys in our databases.  If I am lucky the tables would be partitioned by date.

So I will ask the question: do you need to do this?  Is the time spent setting this up worth it for how much you will use it?",2022-02-18 01:37:03
Comment,2,hxdl3r1,,0,1645140996.0,That's awesome. Congrats!,2022-02-18 01:36:36
Comment,1,hxdk6jm,,0,1645140611.0,I will happily do it to increase my salary 5x.,2022-02-18 01:30:11
Comment,1,hxdj0sq,,0,1645140127.0,If only we had a software engineer...,2022-02-18 01:22:07
Comment,3,hxditud,,0,1645140046.0,"Get rid of the skills section altogether. It's like in movies; show don't tell. Show me how you have used data visualization with python through a project you have done. 

I would also make separate academic and professional experience sections. To me it is jarring to go from data analyst to random course information. 

In your work experience you really need to highlight results. Give me a story about an ad-hoc report that was interesting or had high value. 

Often it is said that you put your best feature as your top line. I would put education first (including course work from ASU). 

How open are you to onsite work as well?  I know the temptation is to apply for remote but that is a really crowded area. Remote positions at the company I work for are getting 20X the applicants compared to onsite.",2022-02-18 01:20:46
Comment,1,hxdhauf,,0,1645139411.0,"Hi u/Sushi_Lad, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 12 karma.",2022-02-18 01:10:11
Comment,3,hxdh4k2,,0,1645139338.0,"The amount of papers that get published every year in this field is crazy. I read a 2018 paper today called ""Bidirectional Attention Flow For Machine Comprehension"" which presented a model that gave state of the art performance in language comprehension tasks. That model is now ranked #52 in performance. Insanity.",2022-02-18 01:08:58
Comment,1,hxdgbdi,,0,1645139003.0,You're right. It should be huge data. Which is a whole different animal in its own. Even with an MS in data I've a hard time getting data scientist interviews. And it's probably my work expirence and no name places. So this would give me both of that. And I may have to suck it up. Some of the subs can get to your head. Then before you know it you're demanding 200k first year out of school in Nebraska 😂,2022-02-18 01:03:23
Comment,3,hxdg7r2,,0,1645138962.0,Would also like to know,2022-02-18 01:02:42
Comment,20,hxdfzo7,,0,1645138869.0,"This is code for ""they're mediocre at both"".",2022-02-18 01:01:09
Comment,7,hxdf2c8,,0,1645138499.0,"Hmmm, this feature needs more engineering...",2022-02-18 00:54:59
Comment,1,hxdeb6g,,0,1645138197.0,"u/the75th

Yea this is also what I feel but theres a huge problem that in the industry, Biostatisticians are almost exclusively doing boring SAS stuff for clinical trials and dealing with regulatory guidelines. Its not fully technical like ML or stats is ironically even though its titled “biostatistician”. Just do a LI search for Biostatistician and you unfortunately end up seeing how the field is percieved by outsiders as “regulatory FDA monkey” stuff

The people doing that sort of work are titled as “ML research scientists”, or “bioinformaticians”, and not “biostatisticians”. Its honestly all artificial-id consider them statisticians too but the market labels biostatisticians when essentially the job function is glorified medical writing. The most complex stats I did in a Biostat role was a univariate linear mixed model. 

Thats sort of why even with a Biostat degree I went to DS p>>n omics and now I want to transition out of tabular data cause I am getting bored of computing millions of p values, and rebranding myself as an ML/AI person even as a statistician.",2022-02-18 00:49:57
Comment,1,hxde7nk,,0,1645138158.0,"Some suggestions:

* Under Skills, just write Python + packages you know, then SQL, then maybe the Microsoft bullet point. The rest you have listed don't seem very informative, unless the job posting specifically asks for those skills.
* Move your course experience to a separate section, e.g. ""Projects"".
* Start with a (past tense) verb in all your bullet points. I think the content in the bullet points is pretty good though.
* Fix your line spacing under Course Certificates.",2022-02-18 00:49:18
Comment,1,hxddl1w,,0,1645137909.0,"Most (good) statisticians doing the same analysis again would have also written a function. Statisticians also don’t use excel/and work in legit languages like R/Python too, except for regulatory work in SAS but even as a statistician-trained DS myself I hesitate in calling the regulatory clinical trial stuff as “stats”.",2022-02-18 00:45:09
Comment,1,hxdd89l,,0,1645137770.0,Still not an exponential assymptote like log likelihood. You would need to lose infinite money on a loan before that becomes reasonable,2022-02-18 00:42:50
Comment,1,hxdcy5o,,0,1645137657.0,"You build one regression per course. 

Then you have to figure out which takes precedence over the other in the event that both suggest their respective course.",2022-02-18 00:40:57
Comment,1,hxdcx7f,,0,1645137647.0,"Out of curiosity, how many years of experience do you currently have? You might be a great candidate if you have practical experience and want to build further on it. I am guessing you are looking for part-time programs instead of going full time?",2022-02-18 00:40:47
Comment,2,hxdc0fa,,0,1645137286.0,"Just to sell the position a bit more; The nice thing about large retail companies is that they have a lot of data which makes analysis possible. It can be hard if your first data job is where you have to either try to scrounge data or be told to work magic on trash. This could be a great opportunity. 

My second thought is one that I have seen come up somewhat often for people transitioning from other careers. You may have to take a lateral pay move as not all data scientists are making $200k+ with no prior experience that subs like this can make seem like is the norm.",2022-02-18 00:34:46
Comment,1,hxdbqis,,0,1645137176.0,Tale as old as time.,2022-02-18 00:32:56
Comment,6,hxdb32x,,0,1645136919.0,Datascientolosoftwarengitisticachinelearnalysists?,2022-02-18 00:28:39
Comment,7,hxdaqnf,,0,1645136784.0,Datascientolosoftwarengineerists?,2022-02-18 00:26:24
Comment,6,hxdamg1,,0,1645136738.0,*You may never leave*,2022-02-18 00:25:38
Comment,14,hxda8w3,,0,1645136591.0,Oh god. I'm part of a cult.,2022-02-18 00:23:11
Comment,1,hxda4lc,,0,1645136545.0,true that 😊,2022-02-18 00:22:25
Comment,1,hxd9u54,,0,1645136433.0,"Thank you for the reply! New to this so forgive if this is a dumb question. For Logistic regression would I use it to predict if a customer will take another training course? 
I don’t know how I would use it to predict what courses they are most likely to take.",2022-02-18 00:20:33
Comment,1,hxd8fo6,,0,1645135887.0,"I think it depends on how much you like astronomy, programming, and math!",2022-02-18 00:11:27
Comment,1,hxd88jl,,0,1645135810.0,"Hi u/Advanced-Cable-6947, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 1 karma.",2022-02-18 00:10:10
Comment,1,hxd853s,,0,1645135773.0,Thank you!,2022-02-18 00:09:33
Comment,5,hxd7yc0,,0,1645135699.0,"The optimization method is not what determines if its statistical or not. You can use GD to minimize say y=x^2 if you wanted to which would only be calculus-there is no random component. 

The stats comes in the formulation of the negative log-likelihood function itself that you are minimizing. Basically how you go from n data points (xi,yi) where xi is itself a vector to setting up the optimization problem. You assume a certain distribution, take the log and sum it and then obtain the log likelihood of the data given parameters.

ML just doesn’t assume a parametric form for y=f(x). Its nonparametric/nonlinear stats. All the other assumptions are still baked into the loss function (and potentially some regularization terms). When you use a ConvNet, you are assuming that pixels nearby are correlated for example, which enables parameter sharing.

A “non statistical” model would be something like a diff eq that describes the system deterministically. Neural nets are still formulated based on maximization of log-likelihood and therefore are statistical models.",2022-02-18 00:08:19
Comment,1,hxd6p22,,0,1645135211.0,"Hi u/Advanced-Cable-6947, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 1 karma.",2022-02-18 00:00:11
Comment,1,hxd665m,,0,1645135015.0,"I was hoping to get more pay basically. But holding out for a better position may never come and I just need to put the time into a true data position at a big place. More money is probably the only thing holding me up. It's local and hybrid/remote. So maybe I should just suck it up. And there's a bonus system so technically more but not enough to sneeze at. 

Career goals, I'm finishing up my MS now and the various modeling was a lot of fun. The heavy statistics made me realize I don't know shit and got a lot better at that. So maybe I should just take this, study for another year then look toward senior or data science positions. And truth be told, I probably need to cut my chops more with sql and python",2022-02-17 23:56:55
Comment,1,hxd4xhp,,0,1645134555.0,I got my first analytics job via a lateral move. Why wouldn’t you take this job? What are your career goals?,2022-02-17 23:49:15
Comment,1,hxd4pb6,,0,1645134472.0,Imo that seems really expensive and haven't heard from anyone personally that came out of that program. Is there a particular role/company that you're interested in? And will having this particular degree help you get that job?,2022-02-17 23:47:52
Comment,3,hxd4bc0,,0,1645134327.0,Is there anything in particular that got you interested?,2022-02-17 23:45:27
Comment,1,hxd48yd,,0,1645134303.0,The Chrysler Building is only so tall...,2022-02-17 23:45:03
Comment,2,hxd425e,,0,1645134233.0,"Market basket ignore time dependency and order. That may not work for your courses since you may have sequential levels. 

Simple logistic regression can work when previously taken courses are included, but still ignores time between courses.

Not sure, your problem has a few aspects: non sequential courses and predicting when a customer might want to take one, sequential courses and predicting that, non sequential but multiple context dependency courses and predicting when.",2022-02-17 23:43:53
Comment,11,hxd41zw,,0,1645134231.0,"As someone who went to graduate school and did research in machine learning, I can say that one of the biggest misconceptions that people have is that being a machine learning expert and being a good engineer are mutually exclusive. The basis of good research is also good engineering.",2022-02-17 23:43:51
Comment,3,hxd41ha,,0,1645134225.0,"For me, it was absolutely worth it. Having an advanced degree let me apply for so many more positions and I got several more callbacks for interviews. The salary boost was definitely worth it and paid for itself in the first year.",2022-02-17 23:43:45
Comment,2,hxd3toq,,0,1645134146.0,Maybe the feeling is that it's asking for too much.,2022-02-17 23:42:26
Has anybody ever tried to create a model to predict football matches results?,0,sxal34,https://www.reddit.com/r/datascience/comments/sxal34/has_anybody_ever_tried_to_create_a_model_to/,2,1645389013.0,"Data of past matches, goals, assists, home team, away team, faults, n of shots etc.. are easily available online. However I have searched in this subreddit but found very few (and old) posts about the topic. 

I would really love to create one to predict the outcome of Bundesliga matches. Doing one right now just for fun 
and atm a crossvalidated model with Decision Trees gives me 59% correct predictions (win, draw, loss) with a simulated ROI of 29% (well.. at least in the simulation…).

Has anybody tried to do sport prediction models with some success? (positive ROI on sport bets?)
What are the challenges and obstacles in doing something like this? Is anybody interested in the topic?",2022-02-20 22:30:13
Is there anywhere that I can find how to use a TI-84 for different formulas in Elementary Statistics?,0,s2gx1o,https://www.reddit.com/r/datascience/comments/s2gx1o/is_there_anywhere_that_i_can_find_how_to_use_a/,0,1642021508.0,"I'm trying to put a cheat sheet together, and I'm wondering if there is an online resource anywhere that has a list of common statistics formulas and how to solve them by calculator. I appreciate any help, I have a final on Friday and I'm nervous!",2022-01-12 23:05:08
Mid-level data scientist and struggling with interview anxiety.,58,s1qqot,https://www.reddit.com/r/datascience/comments/s1qqot/midlevel_data_scientist_and_struggling_with/,32,1641943188.0,"Sorry, it's another. rant. about. DS. interviews. from a mid-level data scientist.

I have a master's and almost 5 years of experience in DS (ML and analytics) in a mid-sized company. Over the holidays I wanted to start looking for a new position so I started cold applying for Senior Data Scientist roles and turned on #opentowork on Linkedin. 

When I got back from the holidays, I had emails back from almost every application I've sent in, in addition to recruiters messaging me on LinkedIn. I thought, shit this is awesome and should be an easy switch, especially in the current job market... So just last week and this week, I went through \~10 recruiter phone calls, with all of them translating into a hiring manager interview or a technical screen which are scheduled for this week and next week. 

But, this is where imposter syndrome kicks in. Because DS interviews are known to differ from company to company, and even within teams of the same company, I figured it'd be best to ask the recruiters how I can best prepare for each of HM interview or tech screen. Some tell me Statistics, others tell me SQL, others tell me Python, and others tell me ML concepts. Sometimes they tell me it's all of the above. Yes, a data scientist should be fluent in most of these, especially with my level of experience, but if you ask me random textbook questions, how am I supposed to pull it out of my ass? What if I haven't used an algorithm in years? Some expect that I come prepared to answer Leetcode questions for an interview that's happening next week. Some don't even feel inclined to reply to my emails. 

I don't know how you all make the time to interview and actually get competitive job offers. I feel so underqualified and incompetent, even with years of experience in this field. To be transparent, I think I'm so scared of embarrassing myself in an interview. I'd love to hear from mid-level or senior level data scientists, how do you deal with interview anxiety, imposter syndrome or whatever this is called.",2022-01-12 01:19:48
"I'm a recent grad looking for a job as a Data Analyst, I've done 60 applications with no interview yet. How's my cover letter and resume looking? (the CL is more of a template which I edit with the specific phrases in the job listing) Is it possible to land a ~50k a year job with my experience?",200,rculhm,https://www.reddit.com/gallery/rculhm,140,1639093407.0,,2021-12-10 01:43:27
A Very Quick Career Progression to Lead Data Scientist,8,rcoun5,https://www.reddit.com/r/datascience/comments/rcoun5/a_very_quick_career_progression_to_lead_data/,11,1639077341.0,"Hi everyone, 

I have a question that might seem strange. I had started to work as a data scientist in a technology company in a niche industry. Within a year, I become the lead data scientist thanks to my strong quantitative background and strong intuition, which helps a lot in communication with the top-level management.

I have a very good level of knowledge in Introduction to Statistical Learning and Elements of Statistical Learning. I am working on deep learning as well.

However, I might have missed the progression in model deployment and data engineering skills. Furthermore, using only R might also contribute to the (potential) problem.

Do you think that it is a crucial problem? Does it have an impact on my career progression? Should I go over it? If yes, then how? Are there any better aspects to focus on?

Thanks.",2021-12-09 21:15:41
What to get a data scientist for Christmas?,243,rck4mf,https://www.reddit.com/r/datascience/comments/rck4mf/what_to_get_a_data_scientist_for_christmas/,186,1639064056.0,"**edit: this is not a joke question. I feel like these answers are funny but I don’t understand them, maybe I’ll print them all on a shirt for him to read as a gift.",2021-12-09 17:34:16
Do you like R (vs python) for data science? & How many years of experience do you have?,0,rcfiqw,https://www.reddit.com/r/datascience/comments/rcfiqw/do_you_like_r_vs_python_for_data_science_how_many/,11,1639048321.0,"I'm curious if R popularity is correlated with years of experience in data science...

[View Poll](https://www.reddit.com/poll/rcfiqw)",2021-12-09 13:12:01
From Descriptive to Prescriptive Analytics,8,rcf5yp,https://www.reddit.com/r/datascience/comments/rcf5yp/from_descriptive_to_prescriptive_analytics/,6,1639046778.0," Hi, guys! I currently work for a BI platform as a project manager. Recently, we have been contacted by a potential client who asked us to come up with a simple optimization solution based on the concept of prescriptive analytics (see the pic below). He gave us an example of the company that existed a few years ago which did just that (the name - **MondoBrain**): a business user can upload a dataset (e.g. excel file) and then with the help of fairly easy interface optimize the KPI he is interested in. Our CEO doesn't really believe in the idea but asked us to do the research - he thinks there is nothing simple about optimization, because if it was simple, everybody would be doing it. I get the appeal of this idea: it's simple, supposed to be fairly affordable, no need to write code or be a professional DS.

I have a few questions for you:

1. How do you understand the term ""Prescriptive Analytics""?
2. Do you think it is possible to create a simple optimization solution?
3. Do you know any companies that might be doing that already? (I don't mean big companies like IBM or AIMMS because of course they are investing heavily in AI and ML; and their solutions are complex)
4. If you have had actual experince of working with products based on Prescriptive Analytics, please share.

P.S. the companies we researched: **RapidMiner** \- searches for optimal points in feature space, using a predictive model for target variable; the results are single points; no significance level in out-of-box version, outlier detection can be used to filter results.

**Gurobi Optimization** \- based on mathematical programming, different models that could be written in any language. Expensive and complicated, but shows real results across different industries.

Wanted to thank everyone in advance for sharing their expertise!

&#x200B;

https://preview.redd.it/f6mtih6yxh481.png?width=1826&format=png&auto=webp&s=b0af6813ae493fa25d46d66f94340c89f511e36a

 [Varen-Technologies-MondoBrain-Product-Sheet.pdf (varentech.com)](https://www.varentech.com/wp-content/uploads/2017/06/Varen-Technologies-MondoBrain-Product-Sheet.pdf)",2021-12-09 12:46:18
What are your favourite data related quotes?,29,rcf3f0,https://www.reddit.com/r/datascience/comments/rcf3f0/what_are_your_favourite_data_related_quotes/,42,1639046445.0,What are your favourite data related quotes?,2021-12-09 12:40:45
How do I turn my menial inventory management into data sciency project?,12,rcepd6,https://www.reddit.com/r/datascience/comments/rcepd6/how_do_i_turn_my_menial_inventory_management_into/,8,1639044717.0,"I have about thousand items to track monthly. Average product movement is 200 items per week.

How do I bake in some analysis into it? Yeah sure I can see the typical metrics like which items are fast moving etc.

Looking for some ideas on how to make it little more ""nuance"".

I understand some things are not worth the hassle of putting to much mind into.",2021-12-09 12:11:57
What application can I use to track data changes?,9,rcbkrp,https://www.reddit.com/r/datascience/comments/rcbkrp/what_application_can_i_use_to_track_data_changes/,8,1639031092.0,"So I’m currently on an internship and got allocated an assignment to find an application (open source preferably) that is able to log data changes and also handle auto data documentation and versioning.

We tried DVC but it doesn’t do much on the part of documenting changes made to the data.

Any help would be greatly appreciated! (I dread going to my boss with another application that doesn’t work 🥲)",2021-12-09 08:24:52
Got $900 CAD scammed out of desperation while searching for an entry-level data analyst job,179,rcbdp7,https://www.reddit.com/r/datascience/comments/rcbdp7/got_900_cad_scammed_out_of_desperation_while/,107,1639030328.0,"So yesterday I received an email that says my resume seems to be a good fit for the company as a data analyst which turns out to be a company that pretended to be ""AthletesCAN"" (a real company that has a website that appears in the top Google search) . I did a bit of the research and found out that for some reason I cannot find any job posting in Glassdoor, LinkedIn, and indeed. I had a hunch that it may be a scam but I was blinded by desperation, thinking it was probably a start-up company, which may not have job posting updated.

So the ""HR lady"", who went by the name ""Georgina Truman"", has a LinkedIn profile associated with the real company and appears to be a real person, and she texted me about the interview held on Dec 8 2021. Seeing that everything about her on the surface seems to be legit, I got tricked thinking that ""HR lady"" = Georgina Truman. Then she sent me an email, from a different email that approached me last time, required me to add her in Skype with the provided Skype cid.  I then searched up her name on Skype and there were more than 5 results with the same profile picture, same name, but different Skype cid. I thought ""It must be for security/privacy reason that she had so many Skype account"" I thought, so I got confused by a little bit but still asked her to send me the current Skype cid that she was using. She then added me directly and started talking about the scheduling of the interview.

&#x200B;

So just 30 mins before the interview, I was doing a written form of interview with another company that has different interview questions posted on the website under [this domain name](https://www.jotform.com/). This written form of interview is a little bit unusual experience that makes me think the next session that I had with the HR lady was normal, because she said it was gonna be a text based Q and A interview on Skype chat.  About 30 mins after the interview, she informed me that I got hired, and she will need me to print, sign and scan the offer letter.

&#x200B;

After that, she sent me a $1k CAD check and asked me to scan it with my RBC app, saying that it is for purchasing some ""training material/software"" as well as some home office upgrade/improvement. I scanned the check and $1k got deposited, and I was blinded by my inner happiness and thought ""Money is at my hand now, it is probably not a scam"". Then she proceeded to tell me to immediately go out and buy Apple gift cards from the stores on a list that she said the company has made deals with. Thinking that if not being ""proactive"" with the job my offer will get rescinded,  I immediately followed her exact instructions and went out shopping ASAP. When I tried to purchase the first gift card with the debit, it could not proceed(turns out it was due to the protection of fraudulent transaction due to check bounce back), so I thought ""maybe $500 is the limit this debit card can handle"", so I proceeded with the credit card and also purchased the rest of the $400 Apple gift card. 1 hour from the last purchase when I was trying to figure what happened with my locked online banking and debit card, and the truth revealed....

&#x200B;

I was too naïve, desperate for job(being jobless for more than half a year, having credit cards almost reaching the limit), and fell for this obvious trap that I for some reason kept finding reasons to justify my thought process.  Don't be like me, and pay extra attention to the job offers whenever they ask you to spend your money after depositing a check to you.

Hopefully I can get a job within a month to start paying back the credit card debt before it reaches the max limit.

&#x200B;


EDIT (2021 Dec 09):

Another potential scam here(I did not fall into this one):

So I got an email with an offer letter that told me to add ""Lindsey Blake"" in Telegram to proceed with the training session of ""Massive Insights."" She called herself ""IT and Setup specialist from Massive Insights"" And I checked that she was an employee until six months ago and now is with the new company.

If she is not doing a part time job in ""Massive Insights"" or there is no another employee who happens to bear the name of ""Lindsey Blake"" working in ""Massive Insights"", then it is probably another identity theft trying to scam people.",2021-12-09 08:12:08
Comment,1,hxo5jq6,,0,1645334575.0,I believe they are used in reinforcement learning but I could be mistaken.,2022-02-20 07:22:55
Comment,2,hxii5uc,,0,1645227847.0,And it's higher level implementation: Hvplot. Absolutely amazing and 100% the best. Highly underappreciated and underrated,2022-02-19 01:44:07
Comment,3,hxihaem,,0,1645227464.0,"dentist - [https://money.usnews.com/careers/best-jobs/dentist/salary](https://money.usnews.com/careers/best-jobs/dentist/salary)data scientist - [https://money.usnews.com/careers/best-jobs/data-scientist](https://money.usnews.com/careers/best-jobs/data-scientist)

Geographical location plays a major role, but you can see there's a $60k difference in mean salaries between dentist and data scientist.

You can see from [annual salary thread](https://www.reddit.com/r/datascience/comments/re46xx/official_2021_end_of_year_salary_sharing_thread/), most do not break $150k. Of those that does, they are usually in norcal, long tenure, or by stock compensation. If you're not in ""major states"", you may not even break $100k.

It's true that data scientist has a much higher ROI so lifetime earning wise, DS is likely better.

That's assuming you do end up becoming a data scientist. When you finish a master degree in data science, there is a significance chance that you will not be a data scientist. When you finish dentist school, you will become a dentist.

(obviously I'm a data scientist and not a dentist so my understanding of the dentist side is not going to be so accurate).",2022-02-19 01:37:44
Comment,2,hxiefut,,0,1645226226.0,What? Proof pm me please,2022-02-19 01:17:06
Comment,1,hxi9j9c,,0,1645224142.0,This article was written by a known sex offender FYI,2022-02-19 00:42:22
Comment,1,hxi91yl,,0,1645223943.0,Basically you need a for loop to plot multiple traces.  So if you vary the market color/size/style in a categorical manner this is the only way.  Seaborn can handle this without the loop though.,2022-02-19 00:39:03
Comment,2,hxi7mfd,,0,1645223356.0,"“I am not comfortable traveling due to COVID concerns so won’t be able to make the outing” should be good enough. 

If your manager isn’t ok with that, you can go to HR. Or save the hassle and just go ahead and quit.",2022-02-19 00:29:16
Comment,1,hxi7197,,0,1645223115.0,"I will say this: a small company with a great culture is one of the best jobs you're going to find. Sure, there are downsides - and you've highlighted the right ones - but those are not hard to overcome.

If you're struggling with mentoring/feedback, look for mentoring opportunities elsewhere. If salary/benefits are low, do keep in mind that sometimes higher pay comes with shittier work.

Large companies have their benefits, but I will argue they have an order of magnitudes more problems. 

* It's easy to get caught in a role where you spend 80% of your time dealing with processes/people instead of being able to focus on DS.
* It's easy to find really, really toxic people who are untouchable.
* It's easy to find coworkers that just straight up suck at their job.
* Everything is difficult. Need permission to a system? May take a month. Need a new laptop? May take 3 months. 
* HR's fundamental job is to prevent compensation from becoming too big a line item for the company. So there is an entire function full of people saying dumb shit like ""money is not the reason why people work here"". 
* Making any type of progress normally involves displacing deeply entrenched behaviors
* Also, resolving even the most minor of problems often requires lifting the carpet to find literal cadavers hiding underneath. ""We want to calculate average sales price"", oh cool, let me explain to you all of the 8473 exceptions that we have for calculating sales price that are all rooted in logic developed by someone who has since died. Good luck.
* Making any type of substantial change required literally 20 meetings. Like, anything that would move the needle - 20 meetings minimum. Maybe 50, who the fuck knows. 

Now, here's the one thing I will say: if you are *ever* going to work at a large company, then eventually you'll want to take that plunge to learn some of the skillsets you need to survive in those environments. But - and this is just my personal opinions - large companies come with more bad than good most of the time.

Having said that - the one big challenge of small companies is that all it takes is for the cofounder(s) to have a change in philosophy that you don't agree with, and the culture can go out the window in a minute.",2022-02-19 00:25:15
Comment,2,hxi6do5,,0,1645222849.0,"this is awesome, thanks",2022-02-19 00:20:49
Comment,2,hxi62i2,,0,1645222723.0,I had a similar background to you. Feel free to PM me and I can discuss what preparation I think may have helped my resume.,2022-02-19 00:18:43
Comment,2,hxi5q38,,0,1645222585.0,Something something bootstraps.,2022-02-19 00:16:25
Comment,1,hxi5ond,,0,1645222570.0,Plotly > seaborne > matplotlib,2022-02-19 00:16:10
Comment,1,hxi4t99,,0,1645222211.0,"Hi u/simp4cleandata, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 1 karma.",2022-02-19 00:10:11
Comment,8,hxi44ei,,0,1645221928.0,"Agreed. I am a decade-long hater of matplotlib which I consider to be a stain on Python's library ecosystem. Unless you're doing something very complicated, plotly all the way.",2022-02-19 00:05:28
Comment,3,hxi41px,,0,1645221899.0,"I switched to ADS a couple years ago and never looked back. I like it more than SSMS. For example, you can click a drop down on each column to get a list of the values, much like a pivot table",2022-02-19 00:04:59
Comment,1,hxi3z7u,,0,1645221872.0,"You can do all this in Minitab now at a fraction of the cost, might be a while since you’ve used it.",2022-02-19 00:04:32
Comment,3,hxi3ub1,,0,1645221817.0,I would ask their department that deals with placements. They'll be able to give you a better idea of what their ranges look like.,2022-02-19 00:03:37
Comment,1,hxi2wzs,,0,1645221445.0,"I am mainly just wanting to know how useful the masters would be in terms of landing be a solid job,",2022-02-18 23:57:25
Comment,1,hxi25iz,,0,1645221140.0,"I am currently confused if I should pursue a field of data science or just go to dental school. I've gotten accepted to both dental school and a online masters of data science program at a good school. The dental schools I've gotten into are pretty expensive and looking at about 400-550k in debt.  
The masters is not very expensive and is just 10 courses so can finish in 1.5 years. Main thing is that idk if dental school is worth it I'm going to end up with a 150k salary which i could achieve in data science as well without as much debt and effort. I do like dentistry but I cant say im in love with it.  


My main goal in life is to be able to enjoy my free time and have time for my hobbies while having a stress free life that includes my work.

  
Any thoughts or advice would be appreciated.",2022-02-18 23:52:20
Comment,1,hxi23xc,,0,1645221122.0,"That's way too broad of a question without knowing exactly what your math/stats/coding background is. You may be new to data science, but depending on how much experience you have with the building blocks the answer will change. Dramatically.",2022-02-18 23:52:02
Comment,1,hxi1ree,,0,1645220985.0,It's just called the masters of data science (online). Yeah there is no research. I was just wondering what kind of salary I could expect and what type of positions. My undergrad degree was in bio so pretty new to this field haha.,2022-02-18 23:49:45
Comment,1,hxi1m88,,0,1645220929.0,I love plotly express. The documentation is amazing it’s simple to use and everything comes out looking great,2022-02-18 23:48:49
Comment,1,hxi1eia,,0,1645220845.0,pandas = yes,2022-02-18 23:47:25
Comment,2,hxi07f4,,0,1645220368.0,"Geom_col() maybe? You're just going to have a ton of labels on the x-axis and may need to change orientation, spacing, etc.

Maybe even using geom_map() and doing a US map and have them colorized by fccavg?",2022-02-18 23:39:28
Comment,3,hxi05jt,,0,1645220347.0,"Which Masters of Data Science from UT? There are several programs at UT that could sort of match that criteria, so a bit more info would help.

Generally speaking: your prospects after a MS in DS are going to be somewhat dictated by what your undergrad was. If you're someone that already came in with 4 years of computer science experience, or 4 years of stats then your prospects after graduation will look very different vs. coming from 4 years of no math whatsoever. And then everything in between.

What jobs will it open up? It all depends - how well do you interview? How well are you able to demonstrate your skills through personal projects? Do you land an internship?

I would say generally speaking, an MS in DS that doesn't involve research will most likely not be the type of job that lands you a super cutting edge DS job. It's more likely to land you an entry level DS job doing more generic DC work. 

Something worth looking at: ask the school what their grad prospects look like. What are their grad's employment rates post program, and then look some of them up on linkedin.",2022-02-18 23:39:07
Comment,2,hxhzwm1,,0,1645220247.0,"Looks like they're states, so I'd guess 50-52 depending if Puerto Rico and Guam are included or not",2022-02-18 23:37:27
Comment,1,hxhze4r,,0,1645220039.0,"Yeah, no way in hell I’m going back into debt for an MS.",2022-02-18 23:33:59
Comment,2,hxhyer0,,0,1645219649.0,"In my case, the problems are more big picture. The company has a team of software developers who implement major projects. Being able to understand a problem, think of a solution, describe the solution in technical language, and work with a developer to implement is a different skill set than knowing how to build a good model.

There are some hard skills that are handy in this process. You mention version control, which is a skill that will never hurt to know really well. I also suggest learning a few different programming languages. You don't need to be an expert by any means, in fact you can be functionally illiterate. Building a website using HTML+CSS+Javascript will teach you some of the realities that a dev will encounter when building an app based on your fancy deep learning model. Coding a complicated project in R will teach you about functional programming. Etc.",2022-02-18 23:27:29
Comment,-3,hxhyd0u,,0,1645219630.0,Quitting a job without having a job lined up is a terrible decision.,2022-02-18 23:27:10
Comment,1,hxhy0zr,,0,1645219498.0,How much was your salary after you got the masters?,2022-02-18 23:24:58
Comment,1,hxhxtxv,,0,1645219419.0,"How useful would a masters of data science from UT Austin be? Also I'm relatively new to the field as i just got my bachelors so would like more insight about the career, work/life balance, competition, and salary expectations? My undergrad degree is kind of useless so I'm wondering if this could open doors to enter a career that could offer 6 figs upon completing the masters.  
Also what kinds of jobs could you do with this degree?",2022-02-18 23:23:39
Comment,2,hxhxmir,,0,1645219337.0,"There isn’t. Most DS’s come from varying fields and programs. If there are “top” schools it’s basically the same as any other technical discipline. CMU, Stanford, MIT, etc.",2022-02-18 23:22:17
Comment,1,hxhxdnk,,0,1645219240.0,One of my favorites is Altair. You can do quite a bit with it straight out of the box and the syntax for everything is very straightforward.,2022-02-18 23:20:40
Comment,1,hxhxbyf,,0,1645219222.0,Just quit two weeks after the visit. That’s perfectly normal.,2022-02-18 23:20:22
Comment,1,hxhxb1o,,0,1645219212.0,"What are the top schools for DS, anyway?",2022-02-18 23:20:12
Comment,1,hxhx67x,,0,1645219161.0,A masters might be beneficial for some roles/promotions. But work experience is way more valuable. I would hire a DS with ~3 YEO over a DS with a master’s and 9 months of experience.,2022-02-18 23:19:21
Comment,1,hxhwjby,,0,1645218911.0,"Hi u/tweety123177, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 15 karma.",2022-02-18 23:15:11
Comment,0,hxhwb9v,,0,1645218822.0,Its plug and play basically. And also a great dashboarding tool that our customers can understand. I still do the the data prep and calculations in R and Python though because that part is horrible in powerbi. So I basically take the strengths of both: prep and calcs in R/Python and visualizations in powerbi. Best of both worlds,2022-02-18 23:13:42
Comment,2,hxhve75,,0,1645218453.0,"I need to move away from python though because the idea is the end user refreshes the dashboard, and all the data mashing and wrangling is done inside in power BI. Clients can't rely on somebody to arrange the data in python before entering power BI. We're selling a once click dashboard. I think DAX is my only option in that case?",2022-02-18 23:07:33
Comment,1,hxhv2fd,,0,1645218322.0,Hey now… hardy handshake with direct eye contact is the only fundamental…. That’s how those yokels used to get jobs right?,2022-02-18 23:05:22
Comment,2,hxhux81,,0,1645218265.0,What makes it easier and flexible? Trying to see why to switch to power bi from bokeh,2022-02-18 23:04:25
Comment,1,hxhu9ns,,0,1645218011.0,"Hi u/KarlaNour96, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 7 karma.",2022-02-18 23:00:11
Comment,1,hxhu9mj,,0,1645218011.0,"Biggest kudos I got from my new employer is that they loved these short 10 minute YouTube videos I made where I explained a data pipeline i constructed. Was a good display of workplace behavior and knowledge. Make a simple portfolio site if you don’t have one. Put the videos at the top of the site and put the link to your portfolio at the top of your resume/cv. Job searching is a multimedia project nowadays. I also made a bot that applied for me on LinkedIn, but that’s a little advanced lol.",2022-02-18 23:00:11
Comment,21,hxhtkde,,0,1645217730.0,"If you want EDA to be faster and more fun, becoming fluent in data visualization libraries might be your best bet. Complete automation runs against the spirit of EDA—the whole point is to have a human in the loop.",2022-02-18 22:55:30
Comment,1,hxhtiwo,,0,1645217714.0,What was your undergrad,2022-02-18 22:55:14
Comment,13,hxhsc85,,0,1645217248.0,"I hate DAX. Here’s how I cope. 
1. A better designed model means less DAX. 
2. Think of DAX as working on subsets of a table.
3. Use DAX studio to help visualize your functions.
4. If possible, I use pyodbc to load sql data, pandas to transform, and pandas to export csv for PowerBI usage.
5. Most users don’t understand dashboards and would prefer 2 sentences to describe a chart anyway",2022-02-18 22:47:28
Comment,1,hxhrf8h,,0,1645216882.0,"Somehow I read this as once you get the offer ""you should always frame it"" 

As someone trying to enter from another field and not having much luck yet, I'm like hell yes I'm going to frame my first offer letter.",2022-02-18 22:41:22
Comment,3,hxhqq3i,,0,1645216601.0,"Plotly + Dash, IMHO is the way of the future for python visualization. Frankly I'm shocked I scrolled almost 20 comments down and didn't see anyone talking about dash.",2022-02-18 22:36:41
Comment,1,hxhqijm,,0,1645216517.0,"You should have a standard ETL protocol to randomly select a sample, normalize it and develop a model.

Is it truly bad data? Is it truly an outlier? Maybe it’s a trend your just missing.",2022-02-18 22:35:17
Comment,1,hxhqgfw,,0,1645216494.0,"I like them both.  I wouldnt personally try to learn one more than the other.  FWIW, there is also next gen seaborn [API](http://seaborn.pydata.org/nextgen/) that I am excited for.",2022-02-18 22:34:54
Comment,1,hxhq7xo,,0,1645216398.0,Email = in writing. You have an offer in writing and you should always frame it that way from now on. And just be patient lol. You’re working with slow moving titans.,2022-02-18 22:33:18
Comment,1,hxhppxz,,0,1645216195.0,I've never used a for loop with matplotlib. I'm usually working with a gui or an excel workbook though.,2022-02-18 22:29:55
Comment,1,hxhpht9,,0,1645216106.0,I think they made that to be similar to R because people were using ggplot then had to use python or something.,2022-02-18 22:28:26
Comment,1,hxhp0lh,,0,1645215910.0,"Hi u/cz1xrnvz, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 1 karma.",2022-02-18 22:25:10
Comment,1,hxhotvt,,0,1645215835.0,"Currently Bokeh and Plotly.

Bokeh for my instrumentation and publishing needs. Plotly express for quick things and special plots that can't be found in Bokeh.

Happens that I have a rant today with Bokeh: I wish I could inherit bokeh's figure class and make my customized classes according to publication Journals... or I don't understand Python's OOP.",2022-02-18 22:23:55
Comment,1,hxhoev5,,0,1645215668.0,"Plotly. Form the engineering view, it can work with web frameworks to return visualization plots as part of the HTML. 
As long as plotly.js is included on frontend, interactive visualizations can be easily made available. 

I found this way more easier to work with Chart.js in JavaScript or D3 itself.",2022-02-18 22:21:08
Comment,1,hxhnqpo,,0,1645215401.0,"Serious question. Is getting a masters in DS even worth it? I mean, what’s the average cost? Even making 6 figures, it does not seem worth it. Or is additional education actually valuable in DS?",2022-02-18 22:16:41
Comment,2,hxhmf8c,,0,1645214870.0,You’re an intern. Not exactly at the top of their to-do list. Don’t worry about it.,2022-02-18 22:07:50
Comment,1,hxhm7g4,,0,1645214781.0,You said you have a large dataset?  You could use Spark. https://towardsdatascience.com/create-your-first-etl-pipeline-in-apache-spark-and-python-ec3d12e2c169,2022-02-18 22:06:21
Comment,1,hxhm775,,0,1645214778.0,Ty for the link to the book! Will read it on a 6 hour plane ride back home today!,2022-02-18 22:06:18
Comment,1,hxhm11a,,0,1645214711.0,"Hi u/Brilliant-remove, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 8 karma.",2022-02-18 22:05:11
Comment,1,hxhm0u1,,0,1645214708.0,Plotnine because I am used to R and ggplot and I don’t want to learn a new visualization tool every 2 years,2022-02-18 22:05:08
Comment,1,hxhlrmf,,0,1645214607.0,"Right and wrong at the same time.. Strong fundamentals are key, precisely because they make upskilling and learning new technologies so much easier",2022-02-18 22:03:27
Comment,2,hxhlcxx,,0,1645214443.0,How many categories do you have in broadbandSST?,2022-02-18 22:00:43
Comment,5,hxhkjpg,,0,1645214124.0,"Yeah Altair (Vega-Lite.js) just extended Wilkinson’s  Grammar of Graphics to include Interactivity.

https://idl.cs.washington.edu/files/2017-VegaLite-InfoVis.pdf

I also find this way of programming charts very intuitive.",2022-02-18 21:55:24
Comment,1,hxhkht5,,0,1645214103.0,I like seaborn and plotly.  Works for my data needs,2022-02-18 21:55:03
Comment,1,hxhk31r,,0,1645213940.0,Have you ever tried using D3.js or [Plot](https://observablehq.com/@observablehq/plot?collection=@observablehq/plot)? It is JavaScript but if you are rewrite anyways these libraries can be even more flexible than Altair in my opinion. But I do a lot of front end work so I like using JavaScript.,2022-02-18 21:52:20
Comment,1,hxhk2kt,,0,1645213935.0,I appreciate man! Thanks!,2022-02-18 21:52:15
Comment,7,hxhjlsm,,0,1645213751.0,"If you like grammar of graphics altair has a similar syntax. Also if you know a little JavaScript Observable’s [Plot](https://observablehq.com/@observablehq/plot?collection=@observablehq/plot) is pretty dope. Also uses grammar of graphics as its theoretical basis, and it is built on top of D3.js. It is still really new, but I find it is more flexible than altair (vega-lite), but I can’t put my finger on why that is.",2022-02-18 21:49:11
Comment,2,hxhidic,,0,1645213257.0,"If you know JavaScript (even if you don’t) Observable’s [Plot](https://observablehq.com/@observablehq/plot?collection=@observablehq/plot) is pretty cool.

I use D3.js for more complex stuff. But I am a fan of any visualization library that uses grammar of graphics so ggplot2, vega-lite, altair, etc.",2022-02-18 21:40:57
Comment,1,hxhi9bq,,0,1645213210.0,"Hi u/flappy123177, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 1 karma.",2022-02-18 21:40:10
Comment,1,hxhhqao,,0,1645212998.0,"> linear regression is the answer to every single problem in the world when it's not. This is the statistician pov and it's weird af.

&#x200B;

Idk why this is repeated time and time again on this sub. Mathematical statistics is an awesome field that encompasses so much more than linear models... You're probably just interacting with people who took a few introductory courses hence your gripe.",2022-02-18 21:36:38
Comment,6,hxhhkx0,,0,1645212938.0,"Don’t burn the bridge , a good reference after your MS is worth the extra albeit painful effort.

Tell them today what your plans are, truth is they’ll likely be happy for you going to school work of your likings and wish you well.",2022-02-18 21:35:38
Comment,0,hxhhjg5,,0,1645212922.0,Python is not suited for data visualization,2022-02-18 21:35:22
Comment,1,hxhh5gx,,0,1645212768.0,"So far plotly is my fav. Matpotlib is really strong for data analysis (object oriented approach is nice).

But plotly plays with Flask and Django, so analytical web apps are better with plotly.

I personally am not a big fan of Seaborn. I may be missing something, but it's so abstract that I feel limited when I use it. I've always just switched back to Matplotlib for the increased control.",2022-02-18 21:32:48
Comment,1,hxhh4l0,,0,1645212759.0,"I dont remember specifics unfortunately but the interviewer pulled up a business and it's hours of operation that also included its typical flow of guests. This was then spread out to a week / a month. And questions dealth with how I would approach different predictive scenarios, analysis, etc.

 I wish I remembered more for u but after I got out of the job search I data dumped pretty much everything.",2022-02-18 21:32:39
Comment,2,hxhh0ax,,0,1645212710.0,"The project you mentioned seems good for a DS portfolio. Similar projects will only benefit you. Nowadays, the post of DS varies a lot from company to another. A DS in a company may be doing the  job of a Data Analyst, and a DS in another company may be doing DS tasks + DE + SWE. So it's really depending on the situation. 

If I were to give advice it would be: 

1. Refine your basics in statistics, ML, DL, Python, algorithms, etc. You can check Andrew Ng's material on Coursera and [Deeplearning.ai](https://Deeplearning.ai), it's interesting
2. Pick a DS subfield that interests you and start reading and researching it. For me it's NLP. You can also work on a personal product-oriented project. This will allow you to pick up skills and knowledge on your journey.",2022-02-18 21:31:50
Comment,1,hxhga27,,0,1645212421.0,"This is super helpful thanks! 
May I ask what kind of questions they asked for the business case if you still remember?",2022-02-18 21:27:01
Comment,10,hxhf06j,,0,1645211919.0,"Yup, I'm a big fan of Holoviews. Being able to export graphs to html and send to business users (without having to host a server or worry about Tableau licenses is a big plus). They seem to be wowed by having mouseover annotations or being able to zoom/drag, even though that is mostly fluff to me (but if they like it, who am I to argue). But having sliders/dropdowns in HoloMaps is really nice. That's not to say that Tableau/PowerBI/whatever don't have a place for enterprise use cases... but if I'm just emailing some sort of adhoc analysis, Holoviews is phenomenal.

I also much prefer the API to matplotlib, and the Holoviews reference gallery is much more intuitive. The downside is that it's not very pythonic in that there can be tons of ways to do things (give it a pandas Dataframe, or a list of tuples, or a Holoviews dataset object, etc.). I just stick to always using pandas dataframed and I generally don't have to look up code for making lines/bars/scatterplots (which was never the case for matplotlib if it had been more than a few weeks since I made a plot)",2022-02-18 21:18:39
Comment,1,hxhezo0,,0,1645211914.0,"Hi, What would be the initial steps to move into data science/ML if I have a PhD in theoretical physics? Do the MOOCs count or showcasing the Github projects is a better strategy?",2022-02-18 21:18:34
Comment,1,hxhekhz,,0,1645211744.0,Thank you! Feedback on both the app and the template is very welcome (also feel free to DM me!),2022-02-18 21:15:44
Comment,2,hxhcz9v,,0,1645211120.0,I'm not sure about them being paid out but I do have vacation days. I don't know if it would be possible for me to now apply for a vacation when my manager has told me that he expects me there.,2022-02-18 21:05:20
Comment,4,hxhcydl,,0,1645211111.0,"Is going the masters part-time while continuing to work full-time an option? You’ll have an easier time getting a job with a MS + a few years of experience than an MS + less than a year. 

Otherwise if you’re set on quitting, go with option 2. What’s the worst that can happen, your boss fires you?",2022-02-18 21:05:11
Comment,1,hxhcjpy,,0,1645210949.0,I use plotly alot. It gives more flexibility and customisation with better graphical representation.,2022-02-18 21:02:29
Comment,6,hxhcdg5,,0,1645210881.0,"I'm also an R trained scientist learning python and God I miss ggplot2. Matplotlib is as capable as ggplot2, but it's not as intuitive.",2022-02-18 21:01:21
Comment,1,hxhbh8u,,0,1645210532.0,Leaflet if you're doing anything with location data.,2022-02-18 20:55:32
Comment,2,hxhbfvx,,0,1645210517.0,"Oh shit that may be why, looks like R matches col to color indeed behind the scenes and I never knew. Didn’t think of that. Thanks!",2022-02-18 20:55:17
Comment,1,hxhbfpz,,0,1645210515.0,Streamlit with plotly,2022-02-18 20:55:15
Comment,1,hxhaniv,,0,1645210211.0,"Hi u/tweety123177, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 15 karma.",2022-02-18 20:50:11
Comment,2,hxhamk5,,0,1645210200.0,Bokeh,2022-02-18 20:50:00
Comment,2,hxh9x74,,0,1645209923.0,"Do you mean when you do something like geom_line(mapping=aes(x, y, color=z))? Hm, haven't run into that one. Is col and alias for color in R?",2022-02-18 20:45:23
Comment,1,hxh9g4q,,0,1645209739.0,Same,2022-02-18 20:42:19
Comment,2,hxh9bkh,,0,1645209690.0,"I have found this to be a two-edged sword. Yes, you remove outliers, but if you focus on quantiles, you will inevitably remove a certain percentage of data. What I have found to work better is using q0.01-c*mean, q0.99+c*mean (or similar). In any case, this highly depends on business backgrounds. Obviously, removing the top 1% of cash flows doesn't make sense, but excluding negative sale values makes sense.",2022-02-18 20:41:30
Comment,1,hxh8neb,,0,1645209431.0,"You may get something out of the 80000hours org, which had a lot of insightfuk work re this line of thinking",2022-02-18 20:37:11
Comment,3,hxh8jid,,0,1645209388.0,Damn that looks very similar to ggplot in R. Nicely done Seaborn package devs,2022-02-18 20:36:28
Comment,1,hxh8en9,,0,1645209337.0,If I want quick and dirty then it's [pandas plotting](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html). If I want it pretty then it's [Altair](https://altair-viz.github.io/). It's beautiful and so well maintained.,2022-02-18 20:35:37
Comment,1,hxh8cla,,0,1645209316.0,Thank you for the thoughtful response,2022-02-18 20:35:16
Comment,5,hxh728z,,0,1645208826.0,Try posting in the sticky.,2022-02-18 20:27:06
Comment,1,hxh5q61,,0,1645208317.0,"I really like echarts, plotly, seaborn, and the original matplotlib. All of these have benefits and drawbacks.",2022-02-18 20:18:37
Comment,1,hxh5jqj,,0,1645208249.0,"Awesome, thanks for the reply",2022-02-18 20:17:29
Comment,2,hxh5exs,,0,1645208197.0,I usually use plotly or the built in plotting tool in geopandas for map plots. I've also used echarts as well.,2022-02-18 20:16:37
Comment,1,hxh542n,,0,1645208081.0,"In our GPU enabled dataframe, we use matplotlib, plotly, seaborn.  Then we modify them to output raytraced charts.  It's probably overkill but it makes the charts beautiful (see [https://row64.com/Gallery/](https://row64.com/Gallery/) for examples).",2022-02-18 20:14:41
Comment,2,hxh4nmm,,0,1645207904.0,I have had issues with plotnine though like sometimes col=… in the aes() in plotnine didnt color my group like it would in R,2022-02-18 20:11:44
Comment,4,hxh2ys7,,0,1645207259.0,"For some complex plots you need that extra configurability matplotlib offers, however, Seaborn helps reduce your plot code footprint when producing the basic plots we use all the time.",2022-02-18 20:00:59
Comment,3,hxh2as7,,0,1645207007.0,Agreed. It’s kind of a pain in the ass to use.,2022-02-18 19:56:47
Comment,1,hxh25ib,,0,1645206952.0,"Yeah this is similar to my experience with a large pharma company. Took awhile to get the offer in, and then after that did all of the onboarding stuff. I actually didn't get my computer and other materials until a week after I started.",2022-02-18 19:55:52
Comment,2,hxh0rw8,,0,1645206434.0,"Do you have vacation days? Will they be paid out when you leave? If not, then it might be worth using them for the dates of the outing.",2022-02-18 19:47:14
Comment,3,hxh0jbn,,0,1645206346.0,"This is just way too overdetailed in the transformers department, and lacking very basic things pre-NNs (n-grams, maxent models, HMMs, CRFs, averaged perceptron...). Heck, even Word2Vec deserves some love (skipgrams, cbows, GloVE, fasttext...). Just admit it's a transformers-only timeline instead.",2022-02-18 19:45:46
Comment,3,hxh0dib,,0,1645206286.0,"Not sure what other people's experiences are like, but mine have been around a monthish for the larger companies I've worked at.  They haven't sent you any kind of onboarding info or requested any other identifying info from you?",2022-02-18 19:44:46
Comment,4,hxgzqes,,0,1645206044.0,"It depends what you are aiming to do with it. For quick sql queries, table/view admin and stored procedures I prefer SSMS. For any real analysis I write the basic SQL query in SSMS then copy it into pyodbc and work in python, which it sounds like you would be more comfortable with anyway.",2022-02-18 19:40:44
Comment,1,hxgz1xw,,0,1645205786.0,"Agree. First I use [pandas plot](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html) to quickly prototype, then I rewrite using [altair](https://altair-viz.github.io/gallery/). However, for image based plots I still use matplotlib.",2022-02-18 19:36:26
Comment,1,hxgyunp,,0,1645205709.0,What about those who make maps with python?,2022-02-18 19:35:09
Comment,2,hxgyu8w,,0,1645205705.0,Kimberly Fessel has a series of fantastic tutorials on youtube for seaborn. Give it a try.,2022-02-18 19:35:05
Comment,1,hxgyjsx,,0,1645205598.0,it mentioned that it only works with rds medium instances. i am having the micro indtance . would it still work ?,2022-02-18 19:33:18
Comment,6,hxgybgf,,0,1645205511.0,Removing as much as physical file dependencies as possible since collaborating otj (atleast whatever’s easy to),2022-02-18 19:31:51
Comment,2,hxgy4eu,,0,1645205439.0,I'm currently going Python to csv to tableau for dashboards I share.  Is there a reason you're using gsheet?  (Just looking to optimize my flow),2022-02-18 19:30:39
Comment,1,hxgx45u,,0,1645205059.0,"seaborn

its just the quickest way to get what i need. time-series with standard error- one liner. Facetplot for categories - 2 liner. good-looking heatmap - 1liner...

If i want an interactive dashboard i wouldnt use python anyway, but tableau or powerBI",2022-02-18 19:24:19
Comment,2,hxgwq91,,0,1645204913.0,"Depending on the thread, ideally yes of course",2022-02-18 19:21:53
Comment,1,hxgwi4x,,0,1645204829.0,Plotly and bokeh,2022-02-18 19:20:29
Comment,2,hxgvwvr,,0,1645204609.0,"Seaborn gets me to 80% of where I want to go with 20% of the effort.

Although tbh I'd rather just export the data and do it in ggplot...",2022-02-18 19:16:49
Comment,4,hxgvl8u,,0,1645204487.0,Don’t even get me started on matplotlib.  For loops just to get all the data on the plot at once?  Like I get it but it’s super clunky if you’ve never used it before.  That said there are a lot of nice example on the website you can just paste your code into which is what I end up doing most of the time.  Seaborn is nice though.,2022-02-18 19:14:47
Comment,3,hxguyx1,,0,1645204250.0,"Why even bother including bag of words and tf-idf if you're going to ignore all the other important stuff that happened before 2013?

And honestly, most of these are just currently popular research papers that will be forgotten in 10 years. Transformers, BERT, and GPT are all historically relevant, but almost nothing else in this graphic post-transformers will be.",2022-02-18 19:10:50
Comment,11,hxguxv9,,0,1645204239.0,"Your comment somehow *underestimated* the capabilities of Seaborn. I would call Seaborn statisticians' plotting library because almost every Seaborn plot API has statistical functionalities  built in. Matplotlib is great for raw plotting. Seaborn offers much more. 

For example - 

    x = [7.5, 7.5, 17.5]
    y = [393.198, 351.352, 351.352]


    plt.plot(x,y) 

vs

    sns.lineplot(x=x,y=y)

They both are similar but plot different things because Seaborn has much more functionalities and depending on the parameters will plot differently.

Another great thing about Seaborn is that it plays very nicely with Pandas dataframes.",2022-02-18 19:10:39
Comment,1,hxgu3v3,,0,1645203920.0,Plotly....can be easily integrated in dashboards and everything...visuals are good and can be easily configured,2022-02-18 19:05:20
Comment,6,hxgsqlp,,0,1645203396.0,Seriously. If adhoc especially. I lose my curious state of mind when I hit the mind fuck brick wall of perfecting charts.  Also EDA is 100% better on tableau kind of drag and drop GUI. The whole point is to perform maximum experiments in the same limited time. Use all the tools you can intelligently. No shame in utilising whatever subscriptions you have,2022-02-18 18:56:36
Comment,9,hxgsl17,,0,1645203339.0,"I have an irrational distaste for matplotlib. Everything seems harder than it should be. It's actually quicker for me to interface with R's base plot, from python, to make a plot, than it is to make the plot I want in matplotlib. That thing seems way overengineered.

Seaborn is a bit better. Plotly has a similar problem of having way too many ways of doing the same thing, and docs are a bit all over the place.

I need to try plotnine.

I come from an R background though, so my brain is just very trained on how base plots and ggplot2 do things.",2022-02-18 18:55:39
Comment,2,hxgsdou,,0,1645203261.0,I haven’t been able to find an IDE other than jupyter notebook for seaborn and plotly.  Kind of tiresome using my browser for it,2022-02-18 18:54:21
Comment,1,hxgrzvf,,0,1645203118.0,PostgreSQL and vscode,2022-02-18 18:51:58
Comment,8,hxgrbw1,,0,1645202868.0,"100%, I'm not sold on any visual/GUI tools for typical data science workflows (ETL, data transformation, modeling), but for visualization it's SO much easier to get things how you want them to look & with a professional shine to them with Tableau (or any BI tool, but Tableau is the prettiest).",2022-02-18 18:47:48
Comment,1,hxgqwty,,0,1645202710.0,"Hi u/Last-Entertainer-811, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 6 karma.",2022-02-18 18:45:10
Comment,1,hxgqgz4,,0,1645202545.0,Ahh yes visually looking like quite a lot of green in the bottom post but that’s just because your story was biased in showing green to build a story. Nice job,2022-02-18 18:42:25
Comment,1,hxgqai3,,0,1645202478.0,Has been posted multiple times and ‘memes’ are limited to Monday.,2022-02-18 18:41:18
Comment,8,hxgpu5c,,0,1645202306.0,"I love Seaborn for this reason. 99% of the work I do just sticks with Seaborn functionality, but you can dig into an axis object or whatever and update the underlying pyplot easily.",2022-02-18 18:38:26
Comment,3,hxgpj46,,0,1645202192.0,Plotly Dash is really cool. I prefer Seaborn over matplotlib anyday.,2022-02-18 18:36:32
Comment,6,hxgpclk,,0,1645202125.0,underrated. i find their concatenation/compound chart syntax very pleasing,2022-02-18 18:35:25
Comment,1,hxgpckd,,0,1645202125.0,I mostly use matplotlib and seaborn. But i am little curious about plotly as i heard it also creates interactive graphs. Is it worth learning?,2022-02-18 18:35:25
Comment,1,hxgpcb1,,0,1645202122.0,I love plotly but matplotlib with seaborn is my go to at work because is basically knew by all the people I work with and make it easier to collaborate,2022-02-18 18:35:22
Comment,1,hxgp8dd,,0,1645202081.0,"Thanks, just saw it in the comments below, will check it out",2022-02-18 18:34:41
Comment,1,hxgp5q9,,0,1645202053.0,"We have a lot of data that needs to be organized in a very particular way in order to run the python model we are assembling. My initial thought was restoring/rebuilding the relationships that at least used to exist to ensure that everything is organized across the whole system.

Do you have any suggestions for how to best organize so many tables while being mindful of things like double/under counting? I am relatively new to my position and any advice is welcome.",2022-02-18 18:34:13
Comment,1,hxgowhy,,0,1645201956.0,"This is why automatic anomaly detection is important. This requires a deep understanding of the data so you know what to check for and what qualifies as an anomaly. Your script can kick off a warning when it finds a problem. 

However you will never be able to catch everything. You can do things to reduce problems that are caused by outliers, using more robust models that are less sensitive to outliers is typically my first choice, but ultimately you are just going to have to accept some.",2022-02-18 18:32:36
Comment,1,hxgokcz,,0,1645201828.0,"But, isnt a bad Idea to train using misslabelled data ?? How can I be sure, after that, that my model prediction is better than the real classification. I mean... predicted may be different than true label due to my model (i.e my model didnt give me the right prediction)",2022-02-18 18:30:28
Comment,1,hxgodbj,,0,1645201753.0,Can u go into deep how bad data could indicate fraudulent and give an example,2022-02-18 18:29:13
Comment,33,hxgo8mm,,0,1645201703.0,Plotly > matplotlib. Not even close in my opinion.,2022-02-18 18:28:23
Comment,3,hxgo3oq,,0,1645201652.0,Reported for misinformation,2022-02-18 18:27:32
Comment,1,hxgn6sn,,0,1645201303.0,you train a classifier based on the labelled data and use the classifier to identify mislabelled data via loss or confusion to do clean your data. iterate this as many times as you want to get desired results,2022-02-18 18:21:43
Comment,5,hxgls22,,0,1645200764.0,You should rephrase your question into „what’s your favorite matplolib wrapper?“,2022-02-18 18:12:44
Comment,3,hxglezr,,0,1645200625.0,"> Dataspell

Thank you for reminding me what this is called. I just saw Datalore recently and was super confused: I thought this was supposed to be a local IDE, not some Colab knockoff! JetBrains gotta rename these things more distinctly.",2022-02-18 18:10:25
Comment,10,hxgl06x,,0,1645200469.0,"Yes, in fact that's it main benefit over pyplot. It assumes a workflow based on pandas rather than numpy arrays.

Let's say you have a dataframe with ""time"", ""score"", and ""player"" columns and you want to plot score against time for each player, using different colours for them.

    import seaborn as sns
    ax=sns.lineplot(data=df, x=""time"", y=""score"", hue=""player"")

And we're done. A nicely formatted plot, a legend, everything in one line.",2022-02-18 18:07:49
Comment,3,hxgjxha,,0,1645200052.0,Bokeh has been my go to - it has the right balance of versatility and usability for me. It can do anything and the plots looks good. Also adding interactive tools is easy and makes data exploration faster.,2022-02-18 18:00:52
Comment,1,hxgj7jn,,0,1645199773.0,"Matplotlib is a quick and dirty option to see what your data looks like , when presenting to others and want something a bit more fancy plotly is the way to go !",2022-02-18 17:56:13
Comment,13,hxgj0pe,,0,1645199699.0,"I don't think you need to ""learn"" a visualization library, especially if you've already made some visualizations with both of them.

You need to know what kinds of plots you can (and should, or more important: shouldn't - looking at you, pie charts!) create with what kind of data and what they tell you.

If you know that (e.g. the first thing you'd want to do with a 1d numpy array is look at the distribution, so some kind of histogram might be nice), it's straightforward enough to look up the syntax.

That being said, the combination of dash and plotly is great for dynamic visualizations and webapps, but seaborn makes graphs that are, out of the box, very pretty and I personally enjoy looking at pretty graphs that I made *very much*...",2022-02-18 17:54:59
Comment,3,hxgixtx,,0,1645199667.0,"I'm going to check this out, thanks. I have struggled to ""get"" matplotlib in a way that makes it easy to integrate. I haven't practiced too much with it since I have data visualization platforms that my org likes to use (and Jupyter notebooks scare people over 45)",2022-02-18 17:54:27
Comment,2,hxgirfi,,0,1645199597.0,Dbt cloud has a free pricing tier https://www.getdbt.com/pricing/,2022-02-18 17:53:17
Comment,16,hxgilvu,,0,1645199536.0,"1. Bokeh, probably the best for me
2. Matplotlib. Anyone trying to go hard core into visualisation should learn about the different layers not just pyplot 
3. Plotly",2022-02-18 17:52:16
Comment,1,hxgibe5,,0,1645199425.0,"Hi. hope your doing well. how was Finland so far? people, culture, payment, etc. ? I'm from middle east. and am looking for a place other than US to continue my education. how do you evaluate their behavior to us?",2022-02-18 17:50:25
Comment,1,hxgia33,,0,1645199411.0,"Hi u/strawberrykiwishake, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 8 karma.",2022-02-18 17:50:11
Comment,2,hxghqwc,,0,1645199201.0,"Sweet. I will look into it. Does it play well with pandas? Forgive my ignorance, I went to classes in high school for programming when Java was popular, learned some C++, web dev, visual basic, and some programming language I've never heard of before or since that was supposed to be big. I've done a lot more with C and starting to get into python just for work, and work is busy, so I haven't had much time to actually look into much beyond solving issues at hand.",2022-02-18 17:46:41
Comment,3,hxghh5p,,0,1645199095.0,altair is greaty but I think its the same thing as plotly?,2022-02-18 17:44:55
Comment,5,hxgh526,,0,1645198962.0,Log paper. Beats excel!,2022-02-18 17:42:42
Comment,3,hxgh1ur,,0,1645198926.0,"Urgh, I gave some private lessons to a high school math teenager. Excel vis was a pain. A histogram with more than 1 group is impossible to make, while I know the syntax in Python and R.",2022-02-18 17:42:06
Comment,3,hxgh1b5,,0,1645198921.0,Oh God lol.,2022-02-18 17:42:01
Comment,7,hxggyua,,0,1645198894.0,"You can use ggplot2 in Python, check out the package plotnine",2022-02-18 17:41:34
Comment,15,hxggqv1,,0,1645198806.0,"I like [Holoviews](https://holoviews.org/) a lot! I spend a ton of time working in pandas dataframes/jupyter notebooks so having a library that interfaces nicely is a must. If I need more flexibility I'll go back to pyplot, but for quick charting I usually use Holoviews as my go to.",2022-02-18 17:40:06
Comment,10,hxggqs5,,0,1645198806.0,Seaborn uses and returns pyplot axis objects. So if your application integrates nicely with pyplot then it should be just fine.,2022-02-18 17:40:06
Comment,3,hxggm8f,,0,1645198756.0,"Streamlit + altair IMO, although I know thats a bit of a cheat answer. Letting users play with data is a lot more powerful than guessing what charts they want to see.",2022-02-18 17:39:16
Comment,1,hxggiff,,0,1645198715.0,"Plotly and Seaborn are my go to, simple yet effective in getting my point across.",2022-02-18 17:38:35
Comment,5,hxgg3uq,,0,1645198555.0,"Plotly is really great, but I am still waiting for support for it in Dataspell.",2022-02-18 17:35:55
Comment,18,hxgfaov,,0,1645198231.0,I like Seaborn because is so colorful and very easy to use and you can make a lot of different types of graphs just with one function and with not much code.,2022-02-18 17:30:31
Comment,20,hxgf7xs,,0,1645198201.0,"I can’t either lol. I imagine that as i continue using Python more (currently R is the language I do most of my data work in), I’ll still turn to R for data visualization.",2022-02-18 17:30:01
Comment,10,hxgengu,,0,1645197973.0,I know this says Python but I really love ggplot2 in R-learned it before any Python viz libraries but Seaborn felt like the one that translates roughly to ggplot in R thus far.,2022-02-18 17:26:13
Comment,3,hxge8l5,,0,1645197806.0,"1. matplotlib (via pandas.plot) while in hurry
2. plotly when I have time (not a fan of syntax though)",2022-02-18 17:23:26
Comment,11,hxgdlkv,,0,1645197549.0,Plotly because it's flexible and interactive.,2022-02-18 17:19:09
Comment,30,hxgdl98,,0,1645197546.0,altair,2022-02-18 17:19:06
Comment,24,hxgcx9w,,0,1645197271.0,Good call. Plotly express all the way for exploration. One line and you can have an animated interactive plot. No contest for me.,2022-02-18 17:14:31
Comment,1,hxgciqw,,0,1645197108.0,Matplotlib,2022-02-18 17:11:48
Comment,1,hxgbw2m,,0,1645196848.0,"Apache is good kit, based in Python I believe but it’s a gui based setup. Long story short learning any (alternative scripting language) python as a skill is probably worth three times more time you can put into it than most anything dealing with data right now… other than sql.

Interfaces come and go companies make something free is now expensive but if you know Apache or Python and SQL you can do stuff that it’s so awesome",2022-02-18 17:07:28
Comment,1,hxgbf84,,0,1645196653.0,"gotcha. yeah i was hoping there was some tooling which made it easier instead of starting from scratch. i came across dbt , apache spark etc. even aws seems have aws glue and aws data pipeline. just hard to know which one to pick. i am currently trying to do a specific work (and have to learn in parallel )",2022-02-18 17:04:13
Comment,106,hxgbcpu,,0,1645196623.0,Plotnine cause I can't let go of ggplot :(. Ggplots consistent grammar with tidy data is so easy to work with v,2022-02-18 17:03:43
Comment,12,hxgbajv,,0,1645196598.0,"Thanks, I'll probably give it a look see this weekend. I've literally just been using it for a few calculators for work. Excel graphs require tweaking that I can't do on my phone and I don't want to lug my laptop around everywhere.

Would seaborn be as easily integrated into a tkinter/gtk gui application?",2022-02-18 17:03:18
Comment,1,hxgat54,,0,1645196397.0,Thanks. I think when I tried building a pipeline I used some orchestrating software that was overly complex and was giving me trouble. I’ll try yours.,2022-02-18 16:59:57
Comment,91,hxgac73,,0,1645196198.0,"Give seaborn a go!

Seaborn is really just a set of convenience functions which make pyplot plots for you. If you're using dataframes and like their style, then it's basically just making pyplot easier to use.

I'm a pyplot fan but often find that seaborn will either do everything I was going to do very easily or at least be a good jumping off point, giving me a plot I can do final tweaks too.",2022-02-18 16:56:38
Comment,7,hxg9q8m,,0,1645195940.0,Yeah look for plotnine,2022-02-18 16:52:20
Comment,6,hxg9kzj,,0,1645195877.0,You can use ggplot in python?,2022-02-18 16:51:17
Comment,5,hxg9euu,,0,1645195806.0,Matplotlib is nice since it works with Pandas by default but I personally like Altair a lot more. Cleaner looking and similar to ggplot2.,2022-02-18 16:50:06
Comment,95,hxg9d2j,,0,1645195785.0,Plotly is really nice.,2022-02-18 16:49:45
Comment,1,hxg9cwm,,0,1645195783.0,"I don't use python a lot and I'm still a student, but I personally prefer plotly",2022-02-18 16:49:43
Comment,10,hxg8z7c,,0,1645195619.0,Matplotlib,2022-02-18 16:46:59
Comment,-4,hxg8jaz,,0,1645195429.0,Export the data and visualization in powerbi. So much easier and flexible,2022-02-18 16:43:49
Comment,1,hxg818k,,0,1645195210.0,"Hi u/RegularImaginary9283, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 1 karma.",2022-02-18 16:40:10
Comment,1,hxg7xtj,,0,1645195169.0,That may be an possibility... Inside each class try to find and remove the bad data ?,2022-02-18 16:39:29
Comment,13,hxg7rcv,,0,1645195092.0,Seaborn is just beautiful by default. Pyplot is my go to for quick vis though. It’s simple and barren by default so I can swiftly see my data. But you really need to make big changes to it if you’re presenting it to clients lol.,2022-02-18 16:38:12
Comment,2,hxg7oy6,,0,1645195063.0,What are the best practices they are missing? Testing? Version control? Non-global variables? (I'm in a boot camp and worried about turning out like your coworkers),2022-02-18 16:37:43
Comment,121,hxg7iir,,0,1645194986.0,"I dunno. Matplotlib.pyplot is a pain, but it's the only one I know so far and I haven't run into anything I couldn't do with it yet.",2022-02-18 16:36:26
Comment,14,hxg768t,,0,1645194838.0,Bokeh and ggplot,2022-02-18 16:33:58
Comment,1,hxg75mb,,0,1645194830.0,"Yes, just like 0% is less than 1% , and 0% of a trillion is not much",2022-02-18 16:33:50
Comment,4,hxg6krl,,0,1645194572.0,"If taking this path, be sure to evaluate the effects filtering this data out. Some situations can handle chopping off the tail tips whereas others can’t.",2022-02-18 16:29:32
Comment,1,hxg6f3u,,0,1645194502.0,"You asked for open source and free ways to build in in a data science forum, I would highly reccomend you buy a book on scripting in python or another language.

I’m not sure I understand your question or what you are referencing by “non constrained” are you looking for one single tool that does this or?",2022-02-18 16:28:22
Comment,1,hxg5z6v,,0,1645194303.0,"In a non constrained context I can simply get the first result. My dataset is large, I am looking for something free and not too cumbersome to create , can work with large datasets and allows good transformation. Python can build anything and everything which seemed like a significant learning curve to do the pipeline instead of getting to a business outcome.",2022-02-18 16:25:03
Comment,2,hxg5fmz,,0,1645194055.0,"got it, thank you",2022-02-18 16:20:55
Comment,1,hxg4w0e,,0,1645193810.0,"So these are certainly not stupid questions but they have been answered many times in at least the last 3 to 6 months definitely was over the last couple of years. Look back over the thread for any specifics but it seems like you’ve already got a good start.

You could apply for the job see what you get, but you start by putting your fingers on the keyboard and building stuff and then pushing it to GitHub.

Start by building tools that you think are cool or would help to solve a certain problem and expanding from there.",2022-02-18 16:16:50
Comment,18,hxg4tky,,0,1645193780.0,"Python to gsheet to Tableau 
Because it’s literally nightmarish to micro edit ax plot kind of syntax. Atleast for me.",2022-02-18 16:16:20
Comment,1,hxg4mbq,,0,1645193685.0,getting paid 1% on a billion dollar asset is more than getting paid 100% on a 100k asset no?,2022-02-18 16:14:45
Comment,2,hxg4lw5,,0,1645193680.0,"pyjanitor

sort of.",2022-02-18 16:14:40
Comment,2,hxg4fk2,,0,1645193600.0,"If you googled “AWS ETL RDS pipeline for data with python” what comes up? It does come with the assumption that do you know Python, or another scripting language.",2022-02-18 16:13:20
Comment,23,hxg4ean,,0,1645193584.0,"I personally love bokeh, but there's always some love to go around for matplotlib and seaborn.",2022-02-18 16:13:04
Comment,3,hxg448o,,0,1645193456.0,"You would write your jobs in sql or Python (typically, you could use whatever) and then use airflow to orchestrate them.",2022-02-18 16:10:56
Comment,1,hxg3947,,0,1645193052.0,Well they are out there ;),2022-02-18 16:04:12
Comment,2,hxg32lm,,0,1645192968.0,This is the kind of person I’m interested in,2022-02-18 16:02:48
Comment,1,hxg2ggv,,0,1645192682.0,"Maybe you need to hire someone who was a scientist, like a physicist, who also did a more social science like economics, who then gained experience as a management consultant for a few years, whilst getting a management degree, worked as a data analyst for a few years and obtained further formal training in postgraduate level statistics and computer science. Maybe also showed leadership and communication skills by holding leadership positions or did teaching in school or something like that. Yeah, someone like that.",2022-02-18 15:58:02
Comment,1,hxg23bq,,0,1645192511.0,"Hi u/RP_m_13, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 25 karma.",2022-02-18 15:55:11
Comment,1,hxg1ln3,,0,1645192281.0,"thanks . Haven’t explored it, let me give that try. Guessing they have some usability under free tier",2022-02-18 15:51:21
Comment,2,hxg1ifr,,0,1645192238.0, it seemed like a pipeline stitching tool rather than transform / load  tool . i was assuming they need to be built somewhere else and then stitched via airflow . is that incorrect ?,2022-02-18 15:50:38
Comment,1,hxg17ss,,0,1645192097.0,"My unpopular hottake...

BI ""skills"" aren't skills at all.

Excel, SQL, Tableau... these don't need training. You should be advanced level from the start, and these skills shouldn't belong in resumes. It's equivalent to ""proficient in MS Outlook and Word"".",2022-02-18 15:48:17
Comment,2,hxg0xwi,,0,1645191967.0,Pyodbc to database. Simply connect database to visualization software. Focus was on displaying ability to move data around and visualize it. I wasn’t really concerned about specific platform or software since different companies use different software for things.,2022-02-18 15:46:07
Comment,2,hxg06nz,,0,1645191608.0,"Admittedly when I hear “clinical trial data” I usually think of the submissions and Biostat regulatory stuff, which is what I meant ironically is an example of something that does not have much statistics and obviously no software eng, its more non technical/writing/regulatory based. 

Otherwise yea if you are jus analyzing the image and omics data as a DS and it happened to be generated as a side thing from the trial then you are right—there isn’t much software eng and it is more stats+bioinformatics based.",2022-02-18 15:40:08
Comment,1,hxg039x,,0,1645191561.0,"The thing is, at least for ML and statistical modeling, errors are easier to detect in the engineering workflow.  It’s much less obvious to know you’re implementing improper design without a good foundation in statistical inference.",2022-02-18 15:39:21
Comment,0,hxfz62q,,0,1645191101.0,"It's not Biostats doing it, it's Data Scientists. But the original post in this thread was saying ""come back to me when you've deployed some large time series model...."", implying that that's what a DS is. Whereas in my group we are data scientists but don't deploy anything for the most but research things like medical imaging, machine learning on clinical data etc..",2022-02-18 15:31:41
Comment,1,hxfyqqd,,0,1645190888.0,Negativity and blasphemy from HR? Usually those types are pumping the positivity whether they buy into it or not.,2022-02-18 15:28:08
Comment,2,hxfyltf,,0,1645190817.0,I wonder if you could use cosine distance to figure out the mostly likely misclassified comments based on dis-similarity. Just a thought,2022-02-18 15:26:57
Comment,2,hxfyeh6,,0,1645190712.0,"Do you have access to other resources in AWS? Step function and AWS batch would be two choices.

If not, you can write a python script, and run it like a cron job.",2022-02-18 15:25:12
Comment,2,hxfxpi6,,0,1645190352.0,"This kind of data may be from a trial, I didn’t say it wasn’t, but the analysis is not done by people with the Biostat title, they usually have other titles like ML engineer, Bioinfo, or DS, even if the degree itself may be in Biostat. When I said working in “clinical trials” I did not mean analyzing omics and image data that was collected for patients in trial.

Biostat is mostly the submissions in most jobs. Are the Biostatisticians by title doing image processing where you are? Because thats not common as you can see in various searches. 

Most “Biostat” positions are not doing hardcore stat like signal processing, ML, Bayesian probabilistic programming on image data generated from trials. Its not just technical data analysis 

I also analyze omics data from trials but I am a data scientist by title, though my degree is Biostat. Biostat title colleagues are not doing any of this and are working in solely SAS and doing submissions, they don’t get to use real stats languages like R or Python",2022-02-18 15:19:12
Comment,2,hxfxnjd,,0,1645190323.0,"Traverse looks sick! Thanks for sharing, and great app!",2022-02-18 15:18:43
Comment,5,hxfxmp7,,0,1645190311.0,Airflow is pretty standard for batch jobs. I’d go with that.,2022-02-18 15:18:31
Comment,2,hxfx97s,,0,1645190115.0,"For a course grounded more in an inferential and foundational statistics-based approach, try EdX - UC San Diego’s Probability and Statistics in Data Science using Python.  
For a more applied approach, taught in R, you can try MIT’s “Data Analysis for Social Scientists” on EDX. This is a good fit if you don’t have a strong statistical background or already know R.",2022-02-18 15:15:15
Comment,2,hxfx4o1,,0,1645190048.0,Wrote an article on how to create [kick-ass portfolio projects](https://www.nicksingh.com/posts/guide-to-creating-kick-ass-data-science-ml-portfolio-projects) (which includes the story of how I landed at Facebook)!,2022-02-18 15:14:08
Comment,1,hxfwt90,,0,1645189879.0,Dataware Scientineers?,2022-02-18 15:11:19
Comment,0,hxfwkpv,,0,1645189751.0,"Where do you think they get the images from? Clinical trials. I work in a pharmaceutical company, with this data. People in my group are working with the FDA on an imagining project.",2022-02-18 15:09:11
Comment,0,hxfw8m8,,0,1645189569.0,I work for a pharmaceutical company and I am not statistician....,2022-02-18 15:06:09
Comment,2,hxfvzv9,,0,1645189439.0,"This is great! I’m actually looking to transition into data science from the hospitality industry and have been following a similar path. I’ve been out of school for a while now, so I’m reteaching myself algebra 2 with plans to move up into Calc and Stats and am simultaneously auditing an MITx Intro to Computer Science using Python course.

Definitely adding this to the curriculum!",2022-02-18 15:03:59
Comment,2,hxfvh6b,,0,1645189157.0,You could cut out data that's outside of the 1st and 99th percentile if that's mostly likely erroneous,2022-02-18 14:59:17
Comment,1,hxfua67,,0,1645188486.0,basketballreference.com,2022-02-18 14:48:06
Comment,1,hxfu6cw,,0,1645188424.0,Apache airflow?,2022-02-18 14:47:04
Comment,1,hxftwz4,,0,1645188273.0,"Damn that's a good one, wish I did this when I was first trying to break in to the field.",2022-02-18 14:44:33
Comment,1,hxfsfb5,,0,1645187391.0,"I was only briefly in CV but it might be because much of the field originated from engineering disciplines. Then later it became a more CSy field with lots of C++ and OpenCV and all that and just recently became more and more about statistics and ML.

In speech it's probably even more noticable. I had a friend having to go to the EE departement with his habilitation treatise because the CS faculty said ""that's not CS"" (even though he mostly did ML, had a CS background and probably can't tell apart voltage from current).
Many of my colleagues come from an EE or physics background (I also did my PhD at a telecommunication research center even though I am a complete CS person :) ).

But the more the fields are eaten by deep learning and friends I guess the more we will see more data sciency roles (whatever that means exactly)",2022-02-18 14:29:51
Comment,1,hxfrstl,,0,1645187008.0,"Year one is a free trial if I remember correctly. I think you need to sign up with your school email id.

I did my certification using the free version.",2022-02-18 14:23:28
Comment,2,hxfrnti,,0,1645186920.0,need something free as it’s for my personal project. alteryx is expensive isnt it,2022-02-18 14:22:00
Comment,1,hxfrjiu,,0,1645186845.0,"Yes. I'm doing that and using the output from that process to determine where I have good name matches already. I'm asking if there's an established method of combining that scoring with the address comparisons. I have something that tests well now, but I'm making it up as I go along. Prefer going with an established method if one exists, as this feels like a common enough task that someone out there might have experience in the domain.

Not a lot of interest in this post, so I'll assume that this isn't the right place to ask.",2022-02-18 14:20:45
Comment,1,hxfrfst,,0,1645186782.0,"I tried nba.com but was hard to scrape. Then I looked up how to scrape nba data and someone wrote an article and linked a site where scraping was much easier. It was current enough for me where it shows running total of all stats. Used beautiful soup btw. 

It did not include per game stats but All I wanted was averages per year.",2022-02-18 14:19:42
Comment,-3,hxfrcb7,,0,1645186721.0,Alteryx,2022-02-18 14:18:41
Comment,3,hxfqv1u,,0,1645186419.0,"Yep. Adding to it, I've seen some people apply checks for everything they know that can be a problem. And go for an initial iteration. Then use the evaluation to guess where the problem could be. And trace it back from there.  

For example good accuracy, precision but poor recall was traced back to noisy data points that existed in both categories (essentially same looking records having different output columns).

Edit: In this case the problem turned out to be business-exceptions made by one of the senior stakeholders on the client side.",2022-02-18 14:13:39
Comment,1,hxfq6tb,,0,1645185985.0,"Never. I've interviewed and know  people working as biostatisticians at J&J, Pfizer and Moderna. Biostats / clinical stuff was a lot of regulatory work, t tests ad survival analysis. If you want someone to do that hire a god damn statistician that was my point.

Usually if there's image data etc they'll call it some flavour of bio-informatics...",2022-02-18 14:06:25
Comment,1,hxfpxlj,,0,1645185815.0,"That's interesting. 

From studying multiple CV courses at graduate level I get the sense that it's a very different and rich domain you can spend your entire life specialising in. Not everything needs DL either, right kernel for edge detection or segmentation might solve your problem right away.

ML engineer is common for CV people indeed. At the job I'm starting in september I'll be called ""data scientist"" and some projects are 100 % computer vision related (e.g. sorting garbage or classifying goods).",2022-02-18 14:03:35
Comment,1,hxfp2qf,,0,1645185239.0,">and also selling the soul to a billion dollar corp.

this is the best way, but they will pay you that less than 1% of the OP goal.

&#x200B;

To use ML for trading is possible, but it will take you months of work before you get just a decent infrastructure, few more months to find working strategies...and you will be against quite big competitors!",2022-02-18 13:53:59
Comment,1,hxfow92,,0,1645185116.0,Cool! Can you share your portfolio by any chance?,2022-02-18 13:51:56
Comment,5,hxfney6,,0,1645184081.0,my favourite part is copying and pasting a segment of the post into the search bar and finding that 30 other linkedin influencers/HR Managers/Entrepreneurs have posted the exact same thing.,2022-02-18 13:34:41
Comment,1,hxfncsk,,0,1645184038.0,"I will be messaging you in 3 days on [**2022-02-21 11:33:08 UTC**](http://www.wolframalpha.com/input/?i=2022-02-21%2011:33:08%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/datascience/comments/svfms3/probability_and_statistics_courses_for_ds/hxfna82/?context=3)

[**3 OTHERS CLICKED THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Fdatascience%2Fcomments%2Fsvfms3%2Fprobability_and_statistics_courses_for_ds%2Fhxfna82%2F%5D%0A%0ARemindMe%21%202022-02-21%2011%3A33%3A08%20UTC) to send a PM to also be reminded and to reduce spam.

^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%20svfms3)

*****

|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|
|-|-|-|-|",2022-02-18 13:33:58
Comment,1,hxfna82,,0,1645183988.0,!RemindMe 3 days,2022-02-18 13:33:08
Comment,1,hxfma0y,,0,1645183247.0,Yeh I don't understand why this kind of 'influencing'  is so popular. Each one of these type of linkedin posts are equally cringy (checkout r/linkedinlunatics) and yet all of them have hundreds to 10s of thousands of reactions.,2022-02-18 13:20:47
Comment,1,hxfkl10,,0,1645181939.0,"Obligatory, oh how the turntables",2022-02-18 12:58:59
Comment,1,hxfjjee,,0,1645181107.0,"The code is in the 'about' in the app, however I didnt realise it's currently crashing. Also in a couple of other comments here: [https://github.com/nite/covid-19](https://github.com/nite/covid-19) . Feel free to DM me, would be interested to hear what you're building!",2022-02-18 12:45:07
Comment,1,hxfjgnx,,0,1645181044.0,"You probably know more than me on this point, I just used the default of ""density"" since I am not a data scientist myself. But good to know there exist an alternative approach, thanks!",2022-02-18 12:44:04
Comment,1,hxfj9su,,0,1645180892.0,"I think one of the issues is sometimes it becomes impossible to follow those practices especially in proportion to the ad hoc visualizations and data wrangling that has to be done on moments notice or just in general. When the data you are given is constantly in different formats and from many different sources for each project it gets hard to modularize it. Or when you have to do a bunch of data quality checks specific to the data given. 

Too many times previous data wrangling code that I saved expecting the data to be in that format has broke.",2022-02-18 12:41:32
Comment,2,hxfj9oe,,0,1645180889.0,"Amazing job, thanks for sharing!",2022-02-18 12:41:29
Comment,0,hxfiuzm,,0,1645180561.0,"If you don’t mind, what basketball data did you look at ? And where’s a great source to get reliable (basketball) sports data?",2022-02-18 12:36:01
Comment,1,hxfiuh4,,0,1645180550.0,"I'm an undergraduate studying electronics engineering [on my last year currently] I have been interested on data science for some time and I'm really into mathematics [assume that I have the knowledge/mathematical maturity of a standard math undergraduate]

Can you please tell me about data science in electronics? What do people working on DS in the field of electronics do day to day? Is it mathematically intensive in some sense?

In electronics, I'm mostly interested in microprocessors & communication

I'm looking for guidance & educational resources that can help. Thanks!",2022-02-18 12:35:50
Comment,1,hxfioa3,,0,1645180416.0,"Do you not use Databricks? A lot of this is in drop down menus there, where you select the cluster. And then of course you just need to benchmark your code (if its a repetitive loop just do a small part of it first) and get an estimate of the completion time to submit the job. Not many SWE skills are needed, but without Databricks you probably do need more to spin up the cluster to begin with. I guess larger companies have the resources for it",2022-02-18 12:33:36
Comment,1,hxfh6yk,,0,1645179202.0,"There’s a racing community online which lets their users rate the races, and then they compile it to give each race a “score”. You can find their data here https://www.racefans.net/rate-the-race/",2022-02-18 12:13:22
Comment,1,hxfh61r,,0,1645179181.0,"Yeah this isn't true at all. It's a technology field. Fundamentals are great but if you aren't keeping up with technology or ahead of the trends you'll be out of the career as fast as you got in.

20+ years of experience... 

Technology field is ever changing... Every 3-5 years you better be updating your skills. If not in 10 years you'll be over paid to do a dying job. 15 years you'll be starting your career over... Wondering what happened.",2022-02-18 12:13:01
Comment,1,hxffdfo,,0,1645177716.0,🤦‍♀️,2022-02-18 11:48:36
Comment,2,hxff45m,,0,1645177505.0,"Medical image and proteomics data is not clinical trial and would fall into bioinformatics. Like I said look at job descriptions on LI—most jobs titled “biostat” do not deal with that stuff. For medical imaging you are looking at pretty niche ML eng or research jobs and for proteomics it is DS and Bioinfo jobs within Biotech. “Biostat” is the actual trial itself, and thats the regulated analyses for submissions not the other stuff.

Im going by the terms used in industry btw, in academia those thigs may be a part of “biostat”.

Here is an example even within a tech company, IBM: Check out this job at IBM: Senior Statistician - Watson Health https://www.linkedin.com/jobs/view/2903475683

Do you even see a single actual statistical/data analysis method mentioned? Any actual modeling? No, those are in data science and ML jobs there.

Another— Check out this job at IQVIA: Principal Biostatistician https://www.linkedin.com/jobs/view/2844868067

Again, no stats method actually mentioned and no mention of real stat languages like R.",2022-02-18 11:45:05
Comment,1,hxff3i2,,0,1645177490.0,/r/LinkedInLunatics,2022-02-18 11:44:50
I have 500k lines machine read-able US medical charges data. How much is that worth?,0,sxqser,https://www.reddit.com/r/datascience/comments/sxqser/i_have_500k_lines_machine_readable_us_medical/,12,1645440825.0,"I was planning to use this data for some project, but I found something better to work on. Looking to sell this, but don't know what the right price is!",2022-02-21 12:53:45
Apache Airflow Tutorial Series for Beginners,13,sxoeyb,https://www.reddit.com/r/datascience/comments/sxoeyb/apache_airflow_tutorial_series_for_beginners/,0,1645431518.0,"Hey there,

I have been using Airflow for a couple of years in my work. I think it is a great tool for data pipeline or ETL management. Therefore, I have created this tutorial series to help folks like you want to learn Apache Airflow. So far, there are 12 episodes uploaded, and more will come.

If you are interested, you can watch the whole playlist on [YouTube](https://www.youtube.com/watch?v=z7xyNOF8tak&list=PLwFJcsJ61oujAqYpMp1kdUBcPG0sE0QMT). If you think it is helpful, consider subscribing to my [youtube channel](https://www.youtube.com/c/coder2j) and star my [GitHub repository](https://github.com/coder2j/airflow-docker). Comment what topics you want to see or discuss about Airflow in the next episode.

Updated Tutorial Episode

1. [Introduction and Local Installation](https://youtu.be/z7xyNOF8tak)
2. [Get Airflow running in Docker](https://youtu.be/J6azvFhndLg)
3. [Airflow Core Concepts in 5 mins](https://youtu.be/mtJHMdoi_Gg)
4. [Airflow Task Lifecycle and Basic Architecture](https://youtu.be/UFsCvWjQT4w)
5. [Airflow DAG with BashOperator](https://youtu.be/CLkzXrjrFKg)
6. [Airflow DAG with PythonOperator and XComs](https://youtu.be/IumQX-mm20Y)
7. [Airflow TaskFlow API](https://youtu.be/9y0mqWsok_4)
8. [Airflow Catchup and Backfill](https://youtu.be/OXOiUeHOQ-0)
9. [Schedule Airflow DAG with Cron Expression](https://youtu.be/tpuovQFUByk)
10. [Airflow Connection and PostgresOperator](https://youtu.be/S1eapG6gjLU)
11. [Add Python Dependencies via Airflow Docker Image Extending and Customizing](https://youtu.be/0UepvC9X4HY)
12. [AWS S3 Key Sensor Operator](https://youtu.be/vuxrhipJMCk)",2022-02-21 10:18:38
MS in Data Science VS MS in Applied Data management and Analytics,1,sxocsf,https://www.reddit.com/r/datascience/comments/sxocsf/ms_in_data_science_vs_ms_in_applied_data/,4,1645431271.0,"I'm an undergraduate student currently. If I had choice between these two, what shall I go ahead with?
Maybe the working professionals can guide me a little into it.

MS in Computational Data Science* 
https://science.iupui.edu/academics/degrees-and-programs/_degrees/computational-data-science-computer-information-science-ms-iupui-cdsms.html

MS in Applied Data management and Analytics
https://et.iupui.edu/departments/cigt/programs/cit/grad/mstechdata/plan",2022-02-21 10:14:31
Object Oriented Data Visualization,2,sxm4j8,https://www.reddit.com/r/datascience/comments/sxm4j8/object_oriented_data_visualization/,1,1645423051.0,"Is there a tutorial/ resource out there that teaches matplotlib with the object oriented api only? I’ve been trying to practice some visualization but most resources switch back and forth. I’m coming from an R background and looking for something that follows close logic to ggplot. 

Thanks!",2022-02-21 07:57:31
How important is academic research in terms of hiring/pay?,3,sxlvqn,https://www.reddit.com/r/datascience/comments/sxlvqn/how_important_is_academic_research_in_terms_of/,8,1645422221.0,"Howdy data wranglers, I'm currently a student and I may have the opportunity to work in our AI lab here. It seems like a great educational opportunity but admittedly I'm unsure how that translates to real-world success. 

I'm currently doing my undergrad and we're hoping to publish one paper at the end of this semester so even if I don't work in the lab I will have most likely had my name on at least one paper. I will be doing my M.S. in Data Science but it's a practicum-based program so I won't really be doing research through that. Part of me is thinking it may be a good way to distinguish myself from other applicants but part of me thinks industry experience (if possible) would be more important. I do have an interest in academia, but I really mostly care about my potential career prospects. Just curious of the opinions from people who have already been through the whole university -> industry transition.",2022-02-21 07:43:41
"How to handle forecasting case studies, especially in the context of using ML?",4,sxij21,https://www.reddit.com/r/datascience/comments/sxij21/how_to_handle_forecasting_case_studies_especially/,2,1645411392.0,"


So I am interviewing with some companies that do a lot of forecasting with ML so I'm preparing myself. 

So I have taken a time series analysis class (so I know box Jenkins, arma, arima, sarima, garch etc.) And I'm familiar with frequency domain methods and dealing with speech signals.  

Assuming I'm dealing with some forecasting using some time series data( outside of like stock/options data or typical signal processing stuff like speech , eeg, etc); Something like these problems
https://otexts.com/fpp2/case-studies.html

Is there a good step by step process(like box jenkins)for dealing with them before running an ML algorithm ?
Thanks in advance.

Edit: also any examples would be nice too",2022-02-21 04:43:12
Learning from Twitter,3,sxbn4d,https://www.reddit.com/r/datascience/comments/sxbn4d/learning_from_twitter/,2,1645391814.0,"If at all, how do you use Twitter for learning purposes?   
I am not a social media user but I finally decided to create a ""professional"" Twitter to be used only for learning, growth, professional development. I started following some people that I knew did work in areas of interest, which led to more and more suggestions. I'm currently following 71 people, all of who seem to be very active in sharing work, techniques, visualization, etc. 

I'm at a loss on how to use this app. How do you extract anything meaningful from it? There's no way I can read through all the posts, short of spending all day scrolling through it. And by the time I've reached ""the bottom"", there are more tweets! It's been 24 hours and I'm already exhausted.   


I definitely want to try to make it work because I've already found many missed and upcoming opportunities that I wouldn't have found otherwise and I can see that people are forming genuine professional relationships, in a way that you can't do on LinkedIn.",2022-02-20 23:16:54
Question about standard error and null distribution?,0,sxaxgh,https://www.reddit.com/r/datascience/comments/sxaxgh/question_about_standard_error_and_null/,11,1645389938.0,"From what I understand 

I am supposed to collect a sample 

Then i need to calculate a true statistic to the sample And then use it calculate a standard error based on the type of the true statistic

Next I will use standard error to build a null distribution to test my null hypothesis 

And some how I can successfully reject the null sometimes:

how I was able to do that when the null distribution was made by value closely related to my sample.
 which seemingly means, that any sample I use will always be within the null distribution and I will always fail to reject the null?",2022-02-20 22:45:38
In and out migration by county?,0,sxatit,https://www.reddit.com/r/datascience/comments/sxatit/in_and_out_migration_by_county/,2,1645389636.0,"I'm looking for a way to better analyise the migration to and from counties in the United States.  I have found that there is [ACS data](https://www.census.gov/data/tables/2019/demo/geographic-mobility/county-to-county-migration-2015-2019.html) (5-year) and  [IRS data](https://www.irs.gov/statistics/soi-tax-stats-migration-data) (yearly) on migration, but am curious if there are any other data sources that might be more accurate in determining these numbers. 

Also are there any ways to determine demographic information (job type, status, income, etc.) about these individuals so that we can get a better sense of who it is that is moving to these areas?",2022-02-20 22:40:36
Is It Ok To Do 0-1 Scaling Then Divide By The Standard Deviation?,11,swshng,https://www.reddit.com/r/datascience/comments/swshng/is_it_ok_to_do_01_scaling_then_divide_by_the/,1,1645330544.0,"Rookie here tryna learn and I read over normalization so I had a question google couldn't answer

If am understanding stuff correctly, if I have a df I can first do 0-1 scaling on it to get equal ranges while preserving the data series's original means and standard deviations and then once I divide the 0-1 scaled data by the standard deviation, I would get a variance that is 1 across all data series.

Therefore my brain concludes that doing 0-1 scaling then dividing by standard deviation leads to a data set that shares range and standard deviation thus making it better to be used in models such as SVMs, Naive Bayes, KMeans Clustering, and other Forest Based Models. Is my reasoning flawed or is there merit behind my idea (and if possible can someone refer me to any papers/articles on this if you are aware of something) Thanks!",2022-02-20 06:15:44
Jujutsu – A Git-compatible DVCS that is both simple and powerful,1,swg5g1,https://github.com/martinvonz/jj,0,1645294335.0,,2022-02-19 20:12:15
Comment,0,hxszh80,,0,1645426039.0,"No, it did not say that. It said if you haven't read PRML or Murphy or ESL or **something on that level** then you don't have a deep understanding. I edited it because I realised not everyone likes to learn exclusively from textbooks like me as opposed to courses, lectures or research papers. Am I not allowed to edit my comment when I realise that I didn't get the point I was trying to make across properly? Also eric\_he clearly says in his comment that his problem is with me ""raising the gates too high"" i.e. he thinks these textbooks are too high of a bar. The point is I'm setting a bar at what I think a deep level of understanding should mean and those textbooks require a level of mathematical maturity that I think is a good height to set the bar. If you think the bar should be lower then I fundamentally disagree. If you set the bar any lower you are basically treating models as black boxes.",2022-02-21 08:47:19
Comment,0,hxsvjwi,,0,1645423457.0,The target audience for textbooks at this level include advanced undergraduates. If you're not able to get at least an advanced undergraduate level understanding of statistical machine learning then no I don't think you have a deep level of understanding of it.,2022-02-21 08:04:17
Comment,7,hxshevc,,0,1645415452.0,"I'm doing a BSc where I can choose basically whatever I want from CS, math, stats. This is the best option IMO. I think there are probably less masters programs like this, but I know of at least one at a good university where you can pick from a wide range of courses in math, stats, CS, etc.",2022-02-21 05:50:52
Comment,-1,hxsgw6x,,0,1645415190.0,"I would argue if you don't have the mathematical maturity and are not on the level of being able to understand the majority of the content in textbooks like Murphy, Pattern Recognition and Machine Learning, Elements of Statistical Learning then you do not have a deep level of understanding of statistical machine learning.",2022-02-21 05:46:30
Comment,2,hxsg9oi,,0,1645414875.0,How does Murphy's book use sigma algebras? I've read PRML and sigma algebras never came up.,2022-02-21 05:41:15
Comment,3,hxknl27,,0,1645276249.0,"I wonder as well, as far as a Jupyter notebook is no more than a python script including comments to provide jupyter directives. 
There is no reason that renaming or copying the contents to .py file couldn’t expected results.
Obviously, while experimenting with Jupyter you probably added a lot of outputs that are no more expected.",2022-02-19 15:10:49
Comment,17,hxknblv,,0,1645276087.0,I hear people at faang with job scientist title don’t get to do any really data science tho. It’s more of a data analyst role. That’s a no go for me,2022-02-19 15:08:07
Comment,0,hxkn8vk,,0,1645276042.0,"I use a Lenovo Thinkpad, granted I'm still just a student. My entire IT department used them at a previous job, including the programmers.",2022-02-19 15:07:22
Comment,1,hxkn125,,0,1645275911.0,"Hi u/Representative_Two37, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 1 karma.",2022-02-19 15:05:11
Comment,3,hxkmm0u,,0,1645275657.0,"In our case, a few really strong people left - to be replaced by the same number of really strong hires.

The only real loss ends up being continuity and team velocity during the transition. That is still bad.

But I wouldn't characterize it as a loss of talent in aggregate. Just a lot of reshuffling.

Some people say this kind of shuffling is part of why the San Francisco tech scene keeps being innovative. I wouldn't rule that hypothesis out, so at least in the data science field ""the great resignation"" might end up being good for good employers as well in the long run. Provided they survive the transient challenges.",2022-02-19 15:00:57
Comment,66,hxkleft,,0,1645274882.0,"The general sentiment is that jupyter notebooks are only good for experimentaion and prototyping. For any production level work, you need to put your code in python scripts.

How we/I use it at work is we play around with some data, do some initial modeling, and then if it looks like this is something worth putting in production, I would create a python module and use that. One optimization I do in jupyter is try to write as many functions as possible so that later i can copy-paste easily inside python module.

If you really want to use jupyter for your production jobs etc, you can look at ploomber

https://github.com/ploomber/ploomber",2022-02-19 14:48:02
Comment,15,hxklb11,,0,1645274823.0,Fine for data exploration and development. Not good for production or deployment.,2022-02-19 14:47:03
Comment,2,hxkjthd,,0,1645273839.0,"Yeah, because its a breeze to connect it to AutoML, lol",2022-02-19 14:30:39
Comment,16,hxkjrq5,,0,1645273804.0,"That's been happening a lot at my employer. People are hustling for senior titles and then move in a few months for better pay elsewhere. Management have started restructuring the organisation to combat sudden grade inflation and plug growing holes in the middle of the hierarchy, but I've noticed them really low balling new hires to the point that all the senior leads are graduates over teams of senior engineers and there's a bizarre inverted skill level to rank relationship as churn continues to accelerate.",2022-02-19 14:30:04
Comment,2,hxkjl4n,,0,1645273676.0,"Started a meadery, and moved back to academia to do a post-doc. I know I don't want to stay in academia but the post-doc is in a really great lab, and is well funded so it gives me time to figure out what my next move is.",2022-02-19 14:27:56
Comment,2,hxkiyc3,,0,1645273224.0,"all of them

source: my IT experience was of much more interest to interviewers than my math degree.",2022-02-19 14:20:24
Comment,10,hxkitj3,,0,1645273130.0,"It's not a resignation, it's a reshuffle. Most of them went to work at other companies. Calling it a ""resignation"" reflects a myopic perspective.",2022-02-19 14:18:50
Comment,2,hxki1s1,,0,1645272557.0,Called the glass ceiling in Germany. Invisible border you can only overcome by changing employers.,2022-02-19 14:09:17
Comment,3,hxkgmv5,,0,1645271475.0,lolwut?,2022-02-19 13:51:15
Comment,4,hxkesqd,,0,1645269988.0,Personally I went from just “having a job” which was mind numbing busy work - to finding and landing a job using tech I enjoyed and in an interesting field. The WFH model really opened up possibilities that were previously much more difficult to find.,2022-02-19 13:26:28
Comment,2,hxkdw8a,,0,1645269232.0,"[Lets-plot](https://lets-plot.org), a ggplot2 port by JetBrains that creates interactive graphs.",2022-02-19 13:13:52
Comment,1,hxkbp6h,,0,1645267387.0,"\> I've asked the question for [https://www.reddit.com/r/datascience/comments/steeoo/how\_do\_deal\_with\_exploding\_model\_numbers/](https://www.reddit.com/r/datascience/comments/steeoo/how_do_deal_with_exploding_model_numbers/) on the bottom-up approach of predicting per-sku level, but it seems like this will be quite a lot of work especially for MVP.

It is genuinely a pretty complicated topic. For sure though you'd probably want to setup a naive baseline forecast consisting of some statistical model applied to each SKU independently (even as simple as average sales of last week extrapolated etc etc). Take a look at Table 2 of the [M4 writeup](https://www.sciencedirect.com/science/article/pii/S0169207019301128) and go up the list until you reach a level of naive forecast that you think is applicable to your data.

This of course misses all the cross-correlations and shared information across SKUs, but you are asking for an MVP after all. Lots of the naive approaches applied to individual SKUs will also be embarrassingly parallel which is a plus point.

It's not necessarily an approach that you want to genuinely use as a production forecast, especially in the case where you have lots of very under-sampled SKUs. But it sounds like you're a little overwhelmed by options and want to get something out of the door quickly. In any case, having a naive baseline for comparing improvements against is always useful.",2022-02-19 12:43:07
Comment,1,hxkbce5,,0,1645267097.0,look on kaggle or [data.world](https://data.world) or drivendata,2022-02-19 12:38:17
Comment,14,hxk9hde,,0,1645265538.0,"Right? I was like “uhhh my whole team has been openly talking about hopping for pay, boss is that you?” in a similar midwestern corporate job.",2022-02-19 12:12:18
Comment,30,hxk86qd,,0,1645264453.0,"Was a Business Intelligence Engineer for 5+ years at a FAANG company making $180K, but shit was hitting the fan repeatedly and work life balance was horrible. Got a Principal Business Intelligence Engineer role at a well funded startup for $270K that's 100% remote and has unlimited PTO. Very happy with the move so far.

Despite the shite environment, if you're at a non-FAANG company and want that big name on your resume, now is the time. They are desperate for talent, the bar is certainly lower, and they are willing to pay! Just get ready to grind hard. After you hit 2 years, recruiters from other big companies will approach you on LinkedIn, and that's your opportunity to jump to something better. Good luck!",2022-02-19 11:54:13
Comment,6,hxk7lkp,,0,1645263962.0,yeah the pay and market for swe is so much better. I regret not doing CS in undergrad.,2022-02-19 11:46:02
Comment,1,hxk76e9,,0,1645263610.0,"Hi u/Darkstar_Aman, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 5 karma.",2022-02-19 11:40:10
Comment,8,hxk71ch,,0,1645263490.0,"Yeah, this basically happened to me a few weeks ago.  I always go in with a gameplan because its easy to have it go the other direction and say something that shoots yourself in the foot but I almost accepted a verbal offer without even looking at the benefits lol",2022-02-19 11:38:10
Comment,6,hxk6bzi,,0,1645262903.0,"Many of the people I know who have exited have no plans of returning.   I know quite a few who are in their 40s who have decided to live on $5k monthly.   They have had to make some lifestyle changes (i.e. some people I know have moved from the bay area to Petaluma / Napa), but nothing too serious.   I often wonder if they are the smart ones.",2022-02-19 11:28:23
Comment,11,hxk658x,,0,1645262744.0,From an outsiders point of view it seems Caterpillar is very advanced for their industry.  They even sponsor kaggle competitions.,2022-02-19 11:25:44
Comment,1,hxk620p,,0,1645262669.0,I really like their hyperparameter tuning. It’s really easy to use and their UI is good too.,2022-02-19 11:24:29
Comment,9,hxk4rkp,,0,1645261596.0,"Our entire department got poached for at least £10k more than we were earning before. 

Salaries in our small city just can't compete with remote work for places based in any of the big cities, let alone London rates.",2022-02-19 11:06:36
Comment,1,hxk4h3p,,0,1645261366.0,"Matplotlib.. nothing fancy but there's tons of documentation, community on stackoverflow etc who can help you out, so you can achieve pretty much any visualization you can think of",2022-02-19 11:02:46
Comment,1,hxk4g5s,,0,1645261346.0,"Even when I actually use pyplot, I still load seaborn with the default theme at the top. It just looks so much nicer.",2022-02-19 11:02:26
Comment,2,hxk3pax,,0,1645260733.0,Hmmm I guess it is important to balance the idealistic side of things and the realistic side. This managing of expectations actually helped me to shift my perspective towards my job applications. Thank you so much!,2022-02-19 10:52:13
Comment,4,hxk3kxn,,0,1645260628.0,This sounds like State Farm in Bloomington.,2022-02-19 10:50:28
Comment,1,hxk3afh,,0,1645260393.0,"Rstudio, use both",2022-02-19 10:46:33
Comment,1,hxk2twt,,0,1645260011.0,"Hi u/ylazz001, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 1 karma.",2022-02-19 10:40:11
Comment,2,hxk2a32,,0,1645259555.0,"Snap. We’ve had a severe exodus of SWE roles, where people have jumped to remote companies & doubled their pay. Waiting to see if it gets addressed this year.",2022-02-19 10:32:35
Comment,5,hxk1ujb,,0,1645259214.0,I didn't expect to see a Bokeh fan here. Bokeh is 2016ish imo,2022-02-19 10:26:54
Comment,4,hxk1ngs,,0,1645259054.0,You're not wrong.,2022-02-19 10:24:14
Comment,1,hxk1baz,,0,1645258780.0,"Is this the, how many cows are there in the US type of question?",2022-02-19 10:19:40
Comment,1,hxk17qu,,0,1645258702.0,I was camp anti fancy tools but made my peace with “it depends…”,2022-02-19 10:18:22
Comment,1,hxk148m,,0,1645258628.0,"This is the answer, I tried learning matplotlib and seaborn but the end result is just not as nice as something I can whip up in tableau public",2022-02-19 10:17:08
Comment,25,hxk0z13,,0,1645258509.0,Writing unit tests should always 100% be required for anyone writing any type of code. Writing tests is cheap when compared to finding issues with your code in production.,2022-02-19 10:15:09
Comment,1,hxk0c9i,,0,1645258014.0, Plotnine cuz I love ggplot,2022-02-19 10:06:54
Comment,2,hxk0akk,,0,1645257977.0,"""Wednesday""",2022-02-19 10:06:17
Comment,9,hxk04lh,,0,1645257844.0,"Yep. Pay rarely increases as much while in a job as getting a new one somewhere else, even if it is just doing the same stuff.",2022-02-19 10:04:04
Comment,1,hxjzyz8,,0,1645257724.0,"Domain expertise, end to end knowledge, knowledge of project scopes, probably good at managing your own workload, and so could oversee others
Same reasons SE can move easily to PM after mid to senior levels. Sit in on enough scrum weeklys and quarterlys you get the drift",2022-02-19 10:02:04
Comment,22,hxjz22o,,0,1645257018.0,"I planned on pushing and negotiating for compensation with my new job, but their starting offer was already past my, ""Maybe I can convince them to up the pay to..."" stretch goal, so I, after speaking with some family and friends - who all talked me out of going after another 5K, I just took their first offer.

West coast companies hiring remote roles from the Midwest is a pretty big win-win for the companies, and the Midwesterners.",2022-02-19 09:50:18
Comment,5,hxjyzeh,,0,1645256960.0,I took another job for 20% more.,2022-02-19 09:49:20
Comment,5,hxjyssc,,0,1645256818.0,"I'm in the Midwest. I've spent my entire career to date working in the auto industry.

March 1st, I'm starting with a California and London company in recruiting, and at a large pay bump for what looks to be far less stressful work. It's remote only, which to my extroverted self is a downside, but it's still a lot better than what I was dealing with in this pandemic era.",2022-02-19 09:46:58
Comment,1,hxjx656,,0,1645255562.0,Then don't use it? I didn't type that comment out to suggest it. I don't use it for anything anyone else will even see for the most part. I just use it to visualize quick things for work because excels graphing sucks.,2022-02-19 09:26:02
Comment,2,hxjw1yj,,0,1645254716.0,Many hospitals (including my own in the midwest) are hiring remote now so we've lost a few to big name healthcare systems in the coasts. I'll be doing the same soon.,2022-02-19 09:11:56
Comment,1,hxjvss3,,0,1645254524.0,Lol,2022-02-19 09:08:44
Comment,5,hxjvgsa,,0,1645254274.0,"I relaxed and soul searched a while, then went back to academia for another masters for fun, and am only now starting to entertain recruiters again. Can't say the majority did this, but I think there really was an abnormal bump in grad school enrollment, so I'm not the only one...",2022-02-19 09:04:34
Comment,1,hxjv3zm,,0,1645254010.0,"Hi u/GaNdAlF207, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 16 karma.",2022-02-19 09:00:10
Comment,1,hxjupjc,,0,1645253710.0,"Hi u/fight_capitalism, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 2 karma.",2022-02-19 08:55:10
Comment,1,hxjueul,,0,1645253493.0,"I will be messaging you in 1 day on [**2022-02-20 06:50:26 UTC**](http://www.wolframalpha.com/input/?i=2022-02-20%2006:50:26%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/datascience/comments/svrcxe/any_python_users_here_completely_confused_by_dax/hxjubiq/?context=3)

[**1 OTHERS CLICKED THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Fdatascience%2Fcomments%2Fsvrcxe%2Fany_python_users_here_completely_confused_by_dax%2Fhxjubiq%2F%5D%0A%0ARemindMe%21%202022-02-20%2006%3A50%3A26%20UTC) to send a PM to also be reminded and to reduce spam.

^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%20svrcxe)

*****

|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|
|-|-|-|-|",2022-02-19 08:51:33
Comment,2,hxjubiq,,0,1645253426.0,RemindMe! 1 day,2022-02-19 08:50:26
Comment,4,hxjtp7v,,0,1645252976.0,pandas_profiling and sweetviz,2022-02-19 08:42:56
Comment,6,hxjtgm8,,0,1645252807.0,"*Hey what resources*

*Are u watching on feature*

*Preprocessing and gen?*

\- Madrigal1100

---

^(I detect haikus. And sometimes, successfully.) ^[Learn&#32;more&#32;about&#32;me.](https://www.reddit.com/r/haikusbot/)

^(Opt out of replies: ""haikusbot opt out"" | Delete my comment: ""haikusbot delete"")",2022-02-19 08:40:07
Comment,0,hxjtfjf,,0,1645252786.0,Hey what resources are u watching on feature preprocessing and gen?,2022-02-19 08:39:46
Comment,4,hxjtcms,,0,1645252728.0,One persons trash is another persons treasure.,2022-02-19 08:38:48
Comment,50,hxjt2j4,,0,1645252526.0,"Writing good code that has [minimal code smells](https://en.wikipedia.org/wiki/Code_smell), [anti-patterns](https://en.wikipedia.org/wiki/Anti-pattern),  and follows standard practice (e.g. [PEP-8 style guide](https://www.python.org/dev/peps/pep-0008/)).

Learning technologies like Docker/pipenv, source control tools, and cloud services like AWS.

Bonus points if you can write unit tests. But I don't think this is required unless you want to get into deployment too.",2022-02-19 08:35:26
Comment,9,hxjt151,,0,1645252500.0,"I'll go out and say that both United Rentals and Caterpillar are both fucking awesome companies to work for. Didn't think I'd wind up in construction, but yeah, it's been pretty great.",2022-02-19 08:35:00
Comment,4,hxjsrgn,,0,1645252311.0,"Similar, but in BA/DA role. I was essentially forced into a ""voluntary"" termination with severance (non-economy related) at a large tech/retail firm. I became an accidental part of the big resignation, and decided to take time off and decide what I was going to do next since I felt burned (out) from my position.

To answer the question more succinctly, I'm taking another go at freelance work. I don't need to immediately have the same pay level I had to remain financially stable if it also makes me being mentally stable with better hours and/or stress levels.",2022-02-19 08:31:51
Comment,3,hxjrlyr,,0,1645251496.0,"Don't apologize, this is awsome! And exactly why I check out threads like this.

I love the ux of plotly express in jupyter notebooks but also deal with very large timeseries and it's caused crashes in the past. So i just switched back to matplotlib, but sorely miss the interactivity and ux of px.

With this extension I'm now able to switch back to px. Thank you!

Also, have you though about a module level function that can wrap every figure returned from a plotly express in FigureResampler? If working with large datasets it would be convenient to just have it applied by default. I'd be happy to submit a PR if you're interested.",2022-02-19 08:18:16
Comment,1,hxjqfdy,,0,1645250688.0,Geom col and then u need to set the appropriate positions by doing some dplyr arrange and then pull(1) to get the descending order of states,2022-02-19 08:04:48
Comment,1,hxjqaig,,0,1645250598.0,"Tell them in advance, ask for a reference letter, and buy a gaming laptop with the money you make.",2022-02-19 08:03:18
Comment,2,hxjpw7s,,0,1645250335.0,Plt seems kinda ugly to me. I dont like it,2022-02-19 07:58:55
Comment,1,hxjpaqn,,0,1645249935.0,Idk - I do want to be a statistician and have a masters in Stats. I find it impossible to do any stats at work and keep ending up doing cloud deployments despite zero interest/ relevant skills.,2022-02-19 07:52:15
Comment,1,hxjp5cd,,0,1645249838.0,Plotly and seaborn for me too. Depends on the job. Plotly is so hackable... I've built some insane dash apps that shouldn't be possible.,2022-02-19 07:50:38
Comment,3,hxjp1m6,,0,1645249770.0,Try plotnine.  It’s basically ggplot for Python,2022-02-19 07:49:30
Comment,1,hxjoxgm,,0,1645249695.0,At the same it does feel like more and more that the deployment and infrastructure are taking more attention to the extent that asking what the business benefits are and whether the model is suitable to deliver them gets pushed out.,2022-02-19 07:48:15
Comment,1,hxjovzf,,0,1645249669.0,Second this.  I should probably move to sea one or matplotlib but plotnine is awesome.,2022-02-19 07:47:49
Comment,38,hxjn7e1,,0,1645248596.0,"> while my employer historically could use the low cost of living as a way of keeping salaries down, these remote jobs are generally offering west coast salaries

This is absolutely happening. With remote work, companies are able to tap into talent across the whole country, and the west coast salaries are very attractive for people in the midwest. Companies with remote work that want top talent aren't going to care that their employee is in San Jose vs. San Antonio.

The companies in the midwest can't offer their salaries to anyone outside of the midwest, though, which is going to be a big problem for them. I think the brain drain hasn't hit the suits just yet and they are holding on hope that everything will ""return to normal"". Between remote options and rapid inflation, there are going to be a lot of people who will continue to leave.

My most recent interview in the midwest gave me an offer that was low enough that leaving after a couple years (or outright refusing) is an absolute no brainer, and I told them as much during the interview and negotiation phase.",2022-02-19 07:29:56
Comment,1,hxjm5r4,,0,1645247957.0,"I like Plotly (Express) as it is fast and interactive. It also is easily integrated into Plotly Dash, which makes it very versatile imo",2022-02-19 07:19:17
Comment,1,hxjm4oi,,0,1645247938.0,"So much this! 

I just couldn't bring myself to learn matplotlib, bokeh, seaborn, etc.",2022-02-19 07:18:58
Comment,1,hxjlw3q,,0,1645247792.0,Thx,2022-02-19 07:16:32
Comment,14,hxjlg5m,,0,1645247522.0,"Only tangentially related but it's super interesting to me that literally no one on my 12 person team has resigned in the 1.5 years that I've been there, despite them all being very qualified, somewhat underpaid until a ""market realignment"" 2 months ago, and all working/living in NYC. Out of the original 8 members I was the last to join and first to leave.",2022-02-19 07:12:02
Comment,8,hxjlbwg,,0,1645247452.0,Software engineering,2022-02-19 07:10:52
Comment,1,hxjl36k,,0,1645247306.0,Cufflinks.,2022-02-19 07:08:26
Comment,5,hxjk9nt,,0,1645246809.0,SWE?,2022-02-19 07:00:09
Comment,7,hxjjukt,,0,1645246561.0,How's it going with that? I've been contemplating doing the same.,2022-02-19 06:56:01
Comment,2,hxjjl4v,,0,1645246403.0,"It really seems to vary, we get posts in here and similar subs complaining how hard it is to land an entry level role in data whether it’s data scientist or data analyst. But I have no idea what kind of background/degrees those folks have, if they did any internships, how many applications they’ve submitted, etc. 

But it sounds pretty saturated at the entry level. Data Science and Analytics jobs have been pretty hyped for the past 10 years, there are tons of new masters and bachelors programs (and certificates which are pretty useless) in DS/analytics, so tons of new grads trying to land jobs. 

And to be frank, this isn’t an entry level field. Unlike software engineering, where there is a bit more work that’s straightforward and repetitive, data science and analytics isn’t always as straightforward and you need to have enough knowledge/context/experience to fill in the blanks or anticipate problems/questions, and figure out the solution. 

On top of that, while many companies are recognizing that they need data folks, they are still very early in building out data teams, and you need experienced folks to build those teams. You can’t start hiring entry level folks until your team has grown to 10-20 people and most data teams aren’t there yet.  

Salaries are all over the place but I think $50-80k is normal for a data analyst depending on industry and location. You can find some entry level DA folks in our annual salary thread (link below), and also Harnham is a recruiting firm specializing in data & analytics roles and they release an annual salary survey that seems accurate (easily found via Google). https://www.reddit.com/r/datascience/comments/re46xx/official_2021_end_of_year_salary_sharing_thread/",2022-02-19 06:53:23
Comment,4,hxjiu40,,0,1645245967.0,But but but my manager wants an automated pipeline for EDA,2022-02-19 06:46:07
Comment,2,hxjidpg,,0,1645245706.0,"You have a real point there. What to do when you have wrong data in your database? It's a bit frustrating because you lose some important information :( 

I recommend trying two things: talk to see if you can get a new and clean database (probably won't happen) or you can erase the data points that you found are erroneous, to avoid training with erroneous data.

About the model, I haven't studied in deep about text classification, but I'm not so sure about how you apply the concept of distance in this case. 

From what I studied I think you should change your data type before. For example, count how many times words have appeared in a message, choose the words that appear the most, and with that information apply the model.

I hope you the best!",2022-02-19 06:41:46
Comment,1,hxjhwkq,,0,1645245432.0,"Is it a big company? Do they have recruiters specializing in “early careers”? If so reach out to them. 

Otherwise I would target people who are/were interns there, they will probably be more likely to respond. 

And whoever you do message, make it personal. Why *that* specific company? What about it stands out? Keep in mind these folks probably get tons of cold messages from people asking for something (and many have probably turned off alerts or ignore messages from strangers), so you’ll get a better response rate if your message is sincere and personal.",2022-02-19 06:37:12
Comment,1,hxjgxud,,0,1645244889.0,Seaborn because those graphs are so clean,2022-02-19 06:28:09
Comment,1,hxjgn5f,,0,1645244724.0,"So next year I want to get a data science internship a specific company. Is okay if I message current data science employees at that company on LinkedIn just to ask about the internship and to maybe build a connection? I really would like an internship at this company, so I want to get in contact with some people working there currently.",2022-02-19 06:25:24
Comment,36,hxjgg92,,0,1645244618.0,"We lost people to Amazon, SalesForce, ServiceNow, DropBox, and some smaller startup-ish tech companies.",2022-02-19 06:23:38
Comment,1,hxje4b6,,0,1645243358.0,Ggplot,2022-02-19 06:02:38
Comment,62,hxjdpdj,,0,1645243133.0,Bought an f250 a 28ft trailer a bobcat and a mini excavator and started a landscaping company,2022-02-19 05:58:53
Comment,26,hxjdn7w,,0,1645243102.0,"Had to take a look at your comment history to verify that you weren't one of my coworkers. Point for point, this is exactly what we're experiencing as well.",2022-02-19 05:58:22
Comment,24,hxjd3fk,,0,1645242802.0,Off-topic but what sorts of SWE skills are really useful for DS? I'm a grad student hoping to go into data science in a couple of years (hopefully).,2022-02-19 05:53:22
Comment,1,hxjcrhe,,0,1645242627.0,"Depends on context

- Client side rendering: Altair. It is a wrapper for vega-lite, a really slick JS viz packages

- Seaborn & Matplotlib for paper plotting

- plotnine is really nice",2022-02-19 05:50:27
Comment,31,hxjan0o,,0,1645241515.0,Moved to a faang company for a 40% base increase and a much better job all around.,2022-02-19 05:31:55
Comment,65,hxj9bef,,0,1645240834.0,"This is 100% it, at least in the Midwest",2022-02-19 05:20:34
Comment,1,hxj8g6t,,0,1645240392.0,Big fan of Plotly and Seaborn,2022-02-19 05:13:12
Comment,71,hxj6rfm,,0,1645239536.0,I took a mammoth title bump for pretty mediocre pay. So 18 months later I'll move for better pay at the same title,2022-02-19 04:58:56
Comment,1,hxj5dgz,,0,1645238845.0,I use Panel with bokeh: https://panel.holoviz.org,2022-02-19 04:47:25
Comment,17,hxj3u32,,0,1645238097.0,"Went from a newly minted IPO Fintech company as an IC to an old traditional company with like 50k employees as a DS manager. Much better work life balance, less stress, and fully remote.",2022-02-19 04:34:57
Comment,1,hxj2l3c,,0,1645237488.0,Is it easy to land a data analyst role? How much do they pay?,2022-02-19 04:24:48
Comment,1,hxj09we,,0,1645236361.0,Gotcha. I usually just work with one line per plot and the markers aren't really necessary. It's all temporary stuff for the most part anyway.,2022-02-19 04:06:01
Comment,1,hxiz73b,,0,1645235839.0,They both follow the grammar of graphics and are built on top of D3 at least.,2022-02-19 03:57:19
Comment,0,hxiyxn7,,0,1645235711.0,"Plotly also follows the grammar of graphics like Altair and ggplot, etc.",2022-02-19 03:55:11
Comment,2,hxiypll,,0,1645235602.0,"The field is just hyper competitive to enter. I am guessing you have some sort of pre-med undergraduate which could make your chances of landing a role as a fresh masters degree student somewhat rough over someone with a software engineering background. You might have to start as a data analyst and build up experience first. 

Another issue is that the data science field is ever changing. To really stay up to date and keep upskilling it might cut into your free time as well.",2022-02-19 03:53:22
Comment,2,hxixoy8,,0,1645235106.0,"If you’re just writing queries, stored procs, etc, ADS has a nicer UI and is more lightweight than SSMS. There are also heaps of extensions you can get very easily. You should be able to do most things with ADS. 

You’ll only need SSMS for more Dba related tasks I think.",2022-02-19 03:45:06
Comment,244,hxixoqs,,0,1645235103.0,"I work at a company that historically had very little turnover year over year. We have pretty good benefits and depending on the team generally good work life balance. One reason that turnover was so low was that a lot of the data science team was from the local area generally. Being in the Midwest this could naturally limit corporate choices for employees. 

With the rise of remote work these folks are no longer tied to my current company so we have seen a surge of talent exiting. Additionally, while my employer historically could use the low cost of living as a way of keeping salaries down, these remote jobs are generally offering west coast salaries talking with folks that have left. A lot of us are in wait and see mode to see what compensation increases look like this year. 

One final issue I have also seen is that we have started to hire more and more computer science majors as software skills become more important in data science. The issue is that we are losing these new hires after a couple of years to SWE jobs. The reality of corporate data science often doesn't align with the expectations of new college grads.  Likewise, the pay for SWE generally tends to be greater as well.",2022-02-19 03:45:03
Comment,1,hxiw8wl,,0,1645234396.0,Matplotlib is the single best tool you'll only need. Frankly speaking the syntax and technicalities may be hard at first but once you get used to it the possibilities are really endless.,2022-02-19 03:33:16
Comment,3,hxivsm8,,0,1645234177.0,"> Does require a python install on the local dev machine, and on a gateway

I know about this feature and the limitations. Adding python in is an extra moving part. This is a one click solution we're trying to build. Or even zero click - it will refresh itself overnight. They just need to open and look at it.",2022-02-19 03:29:37
Comment,56,hxiuuvw,,0,1645233720.0,"Most people I know joined FAANG and/or companies that provided better benefits (job security, WLB, WFH etc) and compensation. 

I also found a “better” job, but with tradeoffs (outstanding job security, less than market compensation and no WFH).",2022-02-19 03:22:00
Comment,44,hxiumjk,,0,1645233605.0,To different employers,2022-02-19 03:20:05
Comment,0,hxiul2g,,0,1645233585.0,Precisely this. The whole point of EDA is to maximise information to noise ratio,2022-02-19 03:19:45
Comment,1,hxis4st,,0,1645232407.0,Math+Stats bachelors but no work or internships prior to MS,2022-02-19 03:00:07
Comment,1,hxiqlxw,,0,1645231682.0,did you have a relevant bachelors degree or any work experience prior to your masters?,2022-02-19 02:48:02
Comment,1,hxiqexe,,0,1645231590.0,">annual salary thread

What do you mean there is a chance you wont be a data scientist?",2022-02-19 02:46:30
Comment,1,hxip4es,,0,1645230984.0,"You can run python scripts as part of the query in powerBI. Does require a python install on the local dev machine, and on a gateway if you’re refreshing using one",2022-02-19 02:36:24
Comment,2,hxiog8x,,0,1645230679.0,Hmm.. I'm a seaborn guy but I'm gonna have to give this a shot for the stuff that's not quite worth a tableau dashboard,2022-02-19 02:31:19
Comment,1,hxiobb9,,0,1645230617.0,Neat,2022-02-19 02:30:17
Comment,1,hxin5kj,,0,1645230085.0,Seaborn is the best tool,2022-02-19 02:21:25
Comment,1,hximb9o,,0,1645229702.0,"Seaborn. I use pandas data frames for 95% of my work so it's the easiest thing to make plots with.  

I've had to make a few dashboards and plotly is the go-to there. 

Different tools for different use cases. If I need something quick, it's seaborn. If I need it to be interactive/when dealing with 3D plots, it's plotly.",2022-02-19 02:15:02
Comment,1,hxim3nl,,0,1645229604.0,Seaborn is my favorite for data exploration. It requires the least amount of looking stuff up because of how intuitive it is. For actual visualizations that go into reports I probably use something more powerful 20% of the time,2022-02-19 02:13:24
Comment,7,hxiltwv,,0,1645229481.0,"It is!

Only drawback imo is that it gets really slow when a lot of datapoints are visualized.

As my research group works mainly with large time series data, we developed an extension that solves this problem.

For large sequences (scatter plots) [Plotly Resampler](https://github.com/predict-idlab/plotly-resampler) enables to visualize tons of datapoints (through adaptive resampling).

Sorry for the shilling, but plotly with plotly-resampler truly is my daily driver :)",2022-02-19 02:11:21
Comment,1,hxils5s,,0,1645229459.0,"Do you know what geom function produces a visualization like this one? I belive this one will tie in nicely with what I want to show.

[https://jabberwocking.com/wp-content/uploads/2021/08/blog\_covid\_deaths\_2021.jpg](https://jabberwocking.com/wp-content/uploads/2021/08/blog_covid_deaths_2021.jpg)",2022-02-19 02:10:59
Comment,3,hxilm60,,0,1645229383.0,This is quite a testimonial! I am going to have to try holoviews,2022-02-19 02:09:43
Comment,1,hxiljx2,,0,1645229354.0,"Yes, that is correct. There are 51 States in this dataset",2022-02-19 02:09:14
Comment,1,hxil04t,,0,1645229109.0,:D,2022-02-19 02:05:09
Comment,1,hxiki4g,,0,1645228888.0,"It gets you in the door, but in my experience after working in this field for 10 years is that hands-on/work experience and some self-teaching go much further and these people are more agile learners.  The main benefit is that you can start at a higher position with a Masters.",2022-02-19 02:01:28
Comment,6,hxijgrq,,0,1645228426.0,"Precisely this. The whole point of EDA is to understand the data and be able to explain design decisions later. Interpretability of decisions made with data will be a thing in the not too distant future so I recommend practicing now.

Using ""Well your honor I `import win` then `win.awesome('my/data')` and that's why our bank kept denying loans to qualified minorities. I didn't do it."" won't fly anymore.

This is why there is intense research being done currently to improve the interpretability of neural nets because the biases within them are elusive and problematic when, you know, [Facebook was labeling black people as primates](https://www.npr.org/2021/09/04/1034368231/facebook-apologizes-ai-labels-black-men-primates-racial-bias)...",2022-02-19 01:53:46
Comment,1,hxiixft,,0,1645228186.0,"120 base, and 140 with bonus",2022-02-19 01:49:46
Comment,1,hxiihzd,,0,1645227996.0,"I like plotly but really want to learn a little more JS for how to make reactive pages on the web, tried using Dash but imo it was either too much of a pain or limiting so using plotly with Flask currently",2022-02-19 01:46:36
how to visualize the decision boundary of a random forest classifier in 3d,1,sxyxco,https://www.reddit.com/r/datascience/comments/sxyxco/how_to_visualize_the_decision_boundary_of_a/,0,1645464044.0,I would appreciate any advice because I have not found any helpful sources. I want to visualize the decision boundary of a random forest classifier projected on the first three PCs,2022-02-21 19:20:44
Reporting Tool Transition,0,sxy520,/r/dataengineering/comments/sxy1qw/reporting_tool_transition/,0,1645462175.0,,2022-02-21 18:49:35
Tiny ML Air Writing Recognition with Nicla Sense ME,0,sxxuj7,https://www.hackster.io/kate-vasilenko/tiny-ml-air-writing-recognition-with-nicla-sense-me-ae6a11,0,1645461447.0,,2022-02-21 18:37:27
Stop resampling data in classification problems.,76,sxtppd,https://www.reddit.com/r/datascience/comments/sxtppd/stop_resampling_data_in_classification_problems/,35,1645450678.0,"Resampling is a widely recommended solution to class imbalance among data scientists.  Resampling also is an awful idea.

Resampling is a take on case-control study designs, in which cases/controls are sampled in ways which do not respect the underlying frequency distribution for either cases or controls. When using logistic regression, [the effects are estimated in an unbiased way](https://stats.stackexchange.com/questions/558942/why-is-it-that-if-you-undersample-or-oversample-you-have-to-calibrate-your-outpu/558950#558950) but the intercept is biased.  

Additionally, [we probably don't want to be doing classification](https://www.fharrell.com/post/classification/) anyway, we mostly want to be accurately predicting risks for the outcome (risk of churn, risk of click through, whatever).  Ensuring our risk estimates are accurate vis a vis calibration and proper scoring rules allows for an appropriate risk threshold to be selected for decision making.  When you resample, all you're doing is forcing the model's probabilities to change in order to make your arbitrary decision boundary look appropriate.  You're putting the cart before the horse.

[Approaches like SMOTE do not help](https://twitter.com/MaartenvSmeden/status/1495668297630633985) (although who the hell would think that all observations within a convex subset of the feature space would all be for one class?  The idea itself is incredibly suspect to me, but I digress).

TL;DR:  Don't resample when classes are imbalanced.  If you have too few observations of one class, ask yourself if the problem is in need of ML.  Otherwise, ensure your probability predictions are calibrated and select an appropriate decision boundary.

Here is another [good post](https://stats.stackexchange.com/questions/357466/are-unbalanced-datasets-problematic-and-how-does-oversampling-purport-to-he) should you care.",2022-02-21 15:37:58
How do promotions work at your company?,2,sxpqq9,https://www.reddit.com/r/datascience/comments/sxpqq9/how_do_promotions_work_at_your_company/,4,1645436787.0,"I found out that in order to promote someone from data analyst to Snr data analyst, positions need to be available... and adhoc converting a role to Snr is very difficult and can take months.

How difficult is it to promote someone at your company? What processes do you need to follow? Is there an establish promotion HR workflow.",2022-02-21 11:46:27
Analyzing 911 narratives,4,sxf5y1,https://www.reddit.com/r/datascience/comments/sxf5y1/analyzing_911_narratives/,5,1645401469.0,"Hi all!

I work in a 911 center as an analyst. I'm looking to start categorizing certain calls that kind of get tossed into an ""Other"" emergency type. All of our calls have comments that our call takers type as well as after incident reports that contain narratives from personnel in the field. Many of these calls really shouldn't be ""Other"" and should have been categorized as one of our other emergency types.

I've been using Term Extraction from Microsoft SQL Server Data Tools to get the top nouns and phrases from these calls but was wondering what other ways I could approach this problem?",2022-02-21 01:57:49
I no longer believe that an MS in Statistics is an appropriate route for becoming a Data Scientist.,414,sx9o1g,https://www.reddit.com/r/datascience/comments/sx9o1g/i_no_longer_believe_that_an_ms_in_statistics_is/,148,1645386631.0,"When I was working as a data scientist (with a BS), I believed somewhat strongly that Statistics was the proper field for training to become a data scientist--not computer science, not data science, not analytics. Statistics. 

However, now that I'm doing a statistics MS, my perspective has completely flipped. Much of what we're learning is *completely* useless for private sector data science, from my experience. So much pointless math for the sake of math. Incredibly tedious computations. Complicated proofs of irrelevant theorems. Psets that require 20 hours or more to complete, simply because the computations are so intense (page-long integrals, etc.). What's the point?

There's basically no working with data. How can you train in statistics without working with real data? There's no real world value to any of this. My skills as a data scientist/applied statistician are not improving. 

Maybe not all stats programs are like this, but wow, I sure do wish I would've taken a different route.",2022-02-20 21:50:31
So a model I created failed....now what?,25,sx7uyi,https://www.reddit.com/r/datascience/comments/sx7uyi/so_a_model_i_created_failednow_what/,19,1645381933.0,"I created a model to predict loan acceptance. We now run this campaign twice a year, once in summer, then once in winter whereas before, we'd only run it in the summer. The summer campaign model performed really well, but the winter campaign is failing.

I actually have a theory as to why it's failing. I think that the people who usually accept the loans in the summer (people paying for vacations, back to school items) are completely different than those who are likely to accept in the winter (taxes!).

My plan is to start by running some data analysis to see if the people who are accepting the loans are different from the summer (age, credit score income, etc.).

All that said, this is the first time I've had a model do poorly. I'd love to know what you all do if a model fails. Not necessarily what I should do, but if you've had a model fail, how did you investigate it? Any resources you recommend for this topic? I want to use this situation to learn something as I realized that in school they never even touched the subject.",2022-02-20 20:32:13
"What are some good resources for learning to write clean, production-quality code?",337,sx3z67,https://www.reddit.com/r/datascience/comments/sx3z67/what_are_some_good_resources_for_learning_to/,102,1645371813.0,"I just got my first big boy data science job and I want to be really good at it. Part of this means writing bomb-ass code that can be taken to others to work with. I feel pretty good about writing code, I've done it for most of my academic and industry career, but they were always in support of ad-hoc analysis or personal projects so it didn't matter if it was messy as long as it worked.

I want to learn how to write good code and start building good habits early in my career. It would be nice if a software engineer saw it, they wouldn't immediately begin mocking me for it or hating me for giving them extra work trying to clean up what I wrote.

EDIT: Looking mostly for resources for SQL and Python",2022-02-20 17:43:33
Moving from small to large companies and what to expect,8,sx26n6,https://www.reddit.com/r/datascience/comments/sx26n6/moving_from_small_to_large_companies_and_what_to/,8,1645366591.0,"
Ive worked as an IC Director of Analytics/BI for several years now between two small companies (around 150 ish employees), and my current company is beginning to crater. They fired my boss a month ago and are planning RIFs and headcount reduction.

I hit the interview scene starting in January and secured a principal data analyst role at a 1.4B company making a lot more money. This is with their “AI and Digital” business unit.

Has anyone had any experience moving up in company size but down in title? I’m reporting directly to a VP and the next level after principal is director.

Any thoughts?",2022-02-20 16:16:31
Weekly Entering & Transitioning Thread | 20 Feb 2022 - 27 Feb 2022,6,swzsmx,https://www.reddit.com/r/datascience/comments/swzsmx/weekly_entering_transitioning_thread_20_feb_2022/,38,1645358430.0,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",2022-02-20 14:00:30
Regression on Tabular Data using Deep Learning,0,swy7pf,https://www.reddit.com/r/datascience/comments/swy7pf/regression_on_tabular_data_using_deep_learning/,36,1645352197.0,"Hello, I am working on a hospital dataset to predict the cost of a diagnosis. It has around 32 columns with sex, hospital name, city, diagnosis code, Number of days stayed, etc, and finally with the cost. I can use any model as a random forest or decision tree to predict. But I wanna make something different like deep learning models to predict the cost. I know deep learning or neural networks are popular for images. But is there any way to do regressions on tabular data to predict the cost using Deep Learning",2022-02-20 12:16:37
Ideas for Modelling Price Elasticity over time periods,2,swv0oy,https://www.reddit.com/r/datascience/comments/swv0oy/ideas_for_modelling_price_elasticity_over_time/,10,1645339539.0,"Apologies if this is more appropriate for r/statistics

For my job we are planning to model price elasticities over hundreds of products to find out optimal pricing throughout the year and to see if there are price inelastic products. 

I was thinking of doing a basic regression for different price points but have been asked to factor in time periods (Seasonality etc.) and am not sure how to incorporate that into the basic regression model while making it simple for the retail division to understand it.

Is there any method or model that you would recommend? I guess another requirement is that seeing as there will be hundreds if not thousands of products being modelled, the technique should not be too time consuming and computer intensive. Most of the data I have is stored in Spark on Databricks and I work on that so that may give an idea of the limitations of my processing power.

Your ideas don’t have to be very accurate or detailed, I’m just stuck on ideas at the moment and thought this sub might be able to help me think of something.",2022-02-20 08:45:39
Are there direct applications of markov chains in industry?,45,swojo2,https://www.reddit.com/r/datascience/comments/swojo2/are_there_direct_applications_of_markov_chains_in/,29,1645318176.0,I was wondering if markov chains are ever applied directly to any business problems in industry. Anyone here ever used one in practice? Or does anyone know if they are used in a specific industry more than others?,2022-02-20 02:49:36
Failed an interview because of this stat question.,437,swh10r,https://www.reddit.com/r/datascience/comments/swh10r/failed_an_interview_because_of_this_stat_question/,166,1645296774.0,"# Update/TLDR:

This post garnered a lot more support and informative responses than I anticipated - thank you to everyone who contributed.

I thought it would be beneficial to others to summarize the key takeaways.

I compiled top-level notions for your perusal, however, I would still suggest going through the comments as there are a lot of very informative and thought-provoking discussions on these topics.

&#x200B;

**Interview Question:**

>"" What if you run another test for another problem, alpha = .05 and you get a p-value = .04999 and subsequently you run it once more and get a p-value of .05001?""

The question was surrounded around the idea of accepting/rejecting the null hypothesis.  I believe the interviewer was looking for - How I would interpret the results. Why the p-value changed.  Not much additional information or context was given. 

**Suggested Answers:**

* u/bolivlake \- [The Difference Between “Significant” and “Not Significant” is not Itself Statistically Significant](http://www.stat.columbia.edu/~gelman/research/published/signif4.pdf)

&#x200B;

* u/LilyTheBet \- Implementing a Bayesian A/B test might yield more transparent results and more practical in business decision making ([https://www.evanmiller.org/bayesian-ab-testing.html](https://www.evanmiller.org/bayesian-ab-testing.html))

&#x200B;

* u/glauskies \- Practical significance vs statistical significance. A lot of companies look for practical significance. There are cases where you can reject the null but the alternate hypothesis does not lead to any real-world impact.

&#x200B;

* u/dmlane \- I think the key thing the interviewer wanted to see is that you wouldn’t draw different conclusions from the two experiments.

&#x200B;

* u/Cheaptat \- Possible follow-up questions: how expensive would the change this test is designed to measure be? Was the average impact positive for the business, even if questionably measurable? What would the potential drawback of implementing it be? They may well have wanted you to state some assumptions (reasonable ones, perhaps a few key archetypes) and explain what you’d have done.

&#x200B;

* u/seesplease \- Assuming the null hypothesis is true, you have a 1/20 chance of getting a p-value below 0.05. If you test the same hypothesis twice and a p-value around 0.05 both times with an effect size in the same direction, you just witnessed a \~1/400 event assuming the null is true! Therefore, you should reject the null.

&#x200B;

* u/robml  u/-lawnder  \-Bonferroni's Correction. Common practice to avoid data snooping is that you divide the alpha threshold by the number of tests you conduct. So say I conduct 5 tests with an alpha of 0.05, I would test for an individual alpha of 0.01 to try and curtail any random significance.You divide alpha by the number of tests you do. That's your new alpha.

&#x200B;

* u/Coco_Dirichlet \- Note - If you calculate marginal effects/first differences, for some values of X there could be a significant effect on Y.

&#x200B;

* u/spyke252 \- I think they were specifically trying to test knowledge of what p-hacking is in order to avoid it!

&#x200B;

* u/dcfan105 \- an attempt to test if you'd recognize the problem with making a decision based on whether a single probability is below some arbitrary alpha value. Even if we assume that everything else in the study was solid - large sample size, potential confounding variables controlled for, etc., a p value *that* close the alpha value is clearly not very strong evidence, *especially* if a subsequent p value was just slightly above alpha.

&#x200B;

* u/quantpsychguy \- if you ran the test once and got 0.049 and then again and got 0.051, I'm seeing that the data is changing. It might represent drift of the variables (or may just be due to incomplete data you're testing on).

&#x200B;

* u/oldmangandalfstyle \- understanding to be that p-values are useless outside the context of the coefficient/difference. P-values asymptotically approach zero, so in large samples they are worthless. And also the difference between 0.049 and 0.051 is literally nothing meaningful to me outside the context of the effect size. It’s critical to understand that a p-value is strictly a conditional probability that the null is true given the observed relationship. So if it’s just a probability, and not a hard stop heuristic, how does that change your perspective of its utility?

&#x200B;

* u/24BitEraMan \- It might also be that you are attributing a perfectly fine answer to them deciding not to hire you, when they already knew who they wanted to hire and were simply looking for anything to tell you no.

&#x200B;

\-----

&#x200B;

**Original Post:**

Long story short, after weeks of interviewing, made it to the final rounds, and got rejected because of this very basic question:

Interviewer: Given you run an A/B test and the alpha is .05 and you get a p-value = .01 what do you do (in regards to accepting/rejecting h0 )?

Me: I would reject the null hypothesis.

Interviewer: Ok... what if you run another test for another problem, alpha = .05 and you get a p-value = .04999 and subsequently you run it once more and get a p-value of .05001 ?

Me: If the first test resulted in a p-value of .04999 and the alpha is .05 I would again reject the null hypothesis. I'm not sure I would keep running tests unless I was not confident with the power analysis and or how the tests were being conducted.

Interviewer: What else could it be?

Me: I would really need to understand what went into the test, what is the goal, are we picking the proper variables to test, are we addressing possible confounders? Did we choose the appropriate risk (alpha/beta) , is our sample size large enough, did we sample correctly (simple,random,independent), was our test run long enough?

Anyways he was not satisfied with my answer and wasn't giving me any follow-up questions to maybe steer me into the answer he was looking for and basically ended it there.

I will add I don't have a background in stats so go easy on me, I thought my answers were more or less on the right track and for some reason he was really trying to throw red herrings at me and play ""gotchas"".

Would love to know if I completely missed something obvious, and it was completely valid to reject me. :) Trying to do better next time.

I appreciate all your help.",2022-02-19 20:52:54
Seeking Guidance on Multi-GPU setup and Parallelization,1,swgqgt,https://www.reddit.com/r/datascience/comments/swgqgt/seeking_guidance_on_multigpu_setup_and/,1,1645295937.0," Hi there, 

I am a medical student conducting some computer vision research and so forgive me if I am a bit off on the technical details. I am in a unique position where I currently have access to two machines: one with a 3080Ti and one with a 3090. I also happen to have an extra 3080Ti on hand.  
 

Currently, I am only performing the following tasks:  
 1.) inference using a CV model on a lot of video data

2.) Training basic NLP models

3.) Some sim racing (although this is obviously less of a hardware priority)

I understand enough (I think) to know that NVLink doesn’t actually matter that much unless you have a GPU cluster, and SLI doesn’t really work across different GPUs? I am basically at the crossroads of how to better parallelize across these 3 GPUs for an optimal setup. Lately I’ve been on the data parallelization route when it comes to inference by splitting my data across machines. I am wondering however, is it worth trading a 3080Ti up for a 3090 to build a dual 3090 NVLink system? Not sure if the model I am using can take advantage of parallelization, but even if it cannot, how often is model parallelization across multi-gpu’s easily accessible/possible?  
 

Additionally, are there any other advantages of this dual 3090 setup in other regards? For sim racing graphics, handling multi-monitors, data pre-processing, handling large datasets, etc….

This is all assuming that doing any other configuration outside of a dual 3090 NVLink setup is not worth it because of efficiency losses of mixing two different GPU’s (which I am also not sure how applicable this is). Also on the first machine with 3080Ti I have a X570 motherboard which I believe would only be able to run a second GPU at 8 PCIe lanes. (I’ve read that this doesn’t actually matter but am unclear about this).

Clearly, I need a little bit of guidance and am just hoping to have a somewhat clearer understanding before I go mess around with a bunch of hardware! Any resources, advice, thoughts would be much appreciated!  
 

Thanks!!!",2022-02-19 20:38:57
If you could have access to any dataset in the world what would it be?,14,swehdo,https://www.reddit.com/r/datascience/comments/swehdo/if_you_could_have_access_to_any_dataset_in_the/,23,1645289873.0,,2022-02-19 18:57:53
Discussion: How would you approach a time series problem with spatial components (Spatio-Temporal Forecasting),12,swe9ll,https://www.reddit.com/r/datascience/comments/swe9ll/discussion_how_would_you_approach_a_time_series/,10,1645289279.0,"As the title already describes I am interest in how you would approach a spatio-temporal forecasting problem.   
I am a data science student, currently doing a project where I want to use time and space features to predict demand.  
In detail: I would like to forecast demand such as taxi demand for a given location and time as for example described in the following [medium article](https://medium.com/analytics-vidhya/new-york-yellow-taxi-demand-prediction-using-machine-learning-fc697d20ff86) using the New York-Taxi Dataset as example.  


I researched the topic a lot and found ton on information ranging from classical approaches which are pure statistical such as ARIMA to using simple and deep machine learning models. Also it seems like there has been a lot of improvement made in the last years since I found a lot of papers dealing with the NYC Taxi Demand Prediction using different models and techniques. The most recent I read were [this one (GSTNet: Global Spatial-Temporal Network for Traffic Flow Prediction)](https://paperswithcode.com/paper/gstnet-global-spatial-temporal-network-for) were they trying to predict the taxi demand using a GSTN model as well as [this one ( Deep Multi-View Spatial-Temporal Network for Taxi Demand Prediction)](https://paperswithcode.com/paper/deep-multi-view-spatial-temporal-network-for) were they combined a CNN for the spatial aspect of the problem and a LSTM for the time problem. Both papers describing the process and achieved stunning results.  


Moreover I found the [DARTS Library by Unit 8](https://github.com/unit8co/darts) which offers a nice tool case for time series problems, however they unfortunately don't seem to include and possibilities for covering space aspects, so using this I would need to train an independent model for each cluster and totally loose and space relations between them.  


My thoughts so far are, that I would first cluster my data based on departures being close to one another. Furthermore I would like to include point of interest data, such as if there are a lot of restaurants or a lot of housing in the given area.   
Moreover I though also on including this information also in my later model.  
So besides passing information only time related, I would like to include also information about the space cluster where the departures happened.  


To round it up, I would be really interested in how you would approach such a problem and how you would make sure that time related features such as weather and space related features such a number of restaurants in the cluster are caputred by your model.  
Would you use a stacking approach to do so, or just go for some fancy model that is able to do both?  


Also if you have any more articles or papers dealing with this, please share (even if I am confident I did my research the past two weeks).",2022-02-19 18:47:59
Basic question about PCA - how to determine which fields to use?,15,sw9o5z,https://www.reddit.com/r/datascience/comments/sw9o5z/basic_question_about_pca_how_to_determine_which/,10,1645275999.0,"Hi, I'm a hobbyist and still learning. I'm trying to reduce a dataset down to 2 dimensions for visualization. I've read that PCA should be used only on columns that are correlated.

Should I determine how correlated the columns are before including them in PCA? If so, how can I check how suitable my dataset is for PCA beforehand?

My data is population data, and I don't need to include all the columns in the PCA the analysis. What is the best way to find which columns are least correlated with the rest of the columns, so I can drop those before running PCA?",2022-02-19 15:06:39
Juptyter Notebook Applications,67,sw91zu,https://www.reddit.com/r/datascience/comments/sw91zu/juptyter_notebook_applications/,35,1645273943.0,"I am fairly new with jupyter notebooks and I just wanted to know:   
How are they used in real life?

Can they be used in ETL processes?

If yes then how, and what additional tools are required for someone who has only worked with data in jupyter notebook (particularly for database connections with mongodb through pymongo)?

What should I learn except writing python in jupyter notebooks to manipulate data?",2022-02-19 14:32:23
What feature preprocessing and generation do you use in your job?,5,svwxrt,https://www.reddit.com/r/datascience/comments/svwxrt/what_feature_preprocessing_and_generation_do_you/,6,1645230922.0,"I was watching a feature preprocessing and generation and was wondering what types of techniques are common or whether there are new techniques that the video is missing. 

I appreciate any response! Thank you.",2022-02-19 02:35:22
"Where did all the talents go after the ""big resignation""?",189,svwq8o,https://www.reddit.com/r/datascience/comments/svwq8o/where_did_all_the_talents_go_after_the_big/,129,1645230282.0,"Just wondering, all the people who resigned and supposedly found a better job, where did they actually go? We hear stories everyday how hard it is to retain and hire good people nowadays, but we rarely hear the other side of the story. Let's be real, those who left their old job didn't just retire or idling at home. So where did they go? Are there suddenly a bunch of ""good"" employers popping up who snatched all the talents? Or did they go working in totally different industries?",2022-02-19 02:24:42
Favorite automated EDA tools in Python?,4,svrtvo,https://www.reddit.com/r/datascience/comments/svrtvo/favorite_automated_eda_tools_in_python/,8,1645216733.0,"I find eda is pretty polarizing. Some DSs it's their favorite part of the job. Others find it to be a chore. I tend to fall in the latter camp, so I'm looking for some cool ways to automate.",2022-02-18 22:38:53
"Any python users here completely confused by DAX? It's like hieroglyphics. Can you recommend some tips/tutorials that finally made you finally ""get it""?",7,svrcxe,https://www.reddit.com/r/datascience/comments/svrcxe/any_python_users_here_completely_confused_by_dax/,7,1645215459.0,"I started a very DAX heavy job recently. I still get to use python from time to time but it's a very Power BI centered job so I am having to tackle a lot of DAX related problems and it's getting worse and worse the more customized the requirements are for the visuals. 

I am getting by, but struggling. It just seems like a super ugly language. My eyes glaze over while following youtube tutorials and I can't crack it. 

Anybody in the same situation?",2022-02-18 22:17:39
Plotting using ggplot2,0,svqrsy,https://www.reddit.com/r/datascience/comments/svqrsy/plotting_using_ggplot2/,7,1645213972.0,"What kind of plot can I make with this data to achieve the following?

I want the state name on the x-axis (broadband$st) and its fcc\_avg on the y-axis. 

I looked into bar graphs and histograms in ggplot 2 but they don't really apply here.

&#x200B;

https://preview.redd.it/l6pb4y72cni81.png?width=316&format=png&auto=webp&s=398fa8acc4053872532f65220a56f7777e388d37",2022-02-18 21:52:52
Student Data Science Projects from the Wolfram India School 2022,6,svmomg,https://blog.wolfram.com/2022/02/17/student-data-science-projects-from-the-wolfram-india-school-2022/,0,1645203346.0,,2022-02-18 18:55:46
Azure Data Studio or SQL Server Management Studio?,2,svmlz7,https://www.reddit.com/r/datascience/comments/svmlz7/azure_data_studio_or_sql_server_management_studio/,4,1645203172.0,"I'm working on a project where I'm doing data analysis on some client information through their database. They have Azure Data Studio and SSMS and I was wondering which would be more beneficial for my situation. I'm expecting it to be primarily analysis with very little admin-type work, but I did have to help with creating the data model with my senior, parsing the source data to fit the model, and work with the existing database team to integrate with their current system (not really sure if that counts lol). A lot of my team uses SSMS because it's what their used to but both apps are new. From initial impressions and what I've read online so far, it looks like ADS is more user-friendly and primarily an analysis tool with the IDE and features, while SSMS is more admin-focused but I'm not sure if I'm coming up to that conclusion through biases.

Prior to this I mainly used MySQL Workbench and in turn MySQL for college projects for general database learning, but I can't imagine there being a large leap of difference (feel free to tell me if I'm wrong). Other than that, I'm more experienced with Python and using different libraries to do basic queries to extract data. As you  can see, I'm still fairly new to this so thanks in advance for any advice!",2022-02-18 18:52:52
What's your favorite data visualization tool for Python and why ?,283,sviwma,https://www.reddit.com/r/datascience/comments/sviwma/whats_your_favorite_data_visualization_tool_for/,151,1645193510.0,"My current favorite ones are Seaborn and Plotly. What are your usual go-to when it comes to plotting basic charts and complex ones ?

Thanks",2022-02-18 16:11:50
Customer Voice - Topic Modeling,4,svhshf,https://www.reddit.com/r/datascience/comments/svhshf/customer_voice_topic_modeling/,11,1645190376.0,"I am working on a project to classify some messages received from our customers. Basically I have to predict -in real time- the problem of those messages (hundreds of messages are received every day).

Our SAC team have already classified all the messages we have received but I noticed that there are many messages classified to the wrong category (i.e we cant trust the current labels).

That been said, my question is, What exactly should I do now to accomplish what I need ?

My initial plan is:

1. Do some basics text cleaning
2. Vectorizing the messages using Word2Vec
3. Creating some clusters using KMenas (here I plan to create a large number of clusters and then maybe merge some of them)
4. Giving names (categories) to those clusters based on most common words
5. Predict the new data using the pre-trained Kmeans classifier.

Is this a good approach ?

Any tips / suggestions would be great here.",2022-02-18 15:19:36
New to DS. Have a large data set in AWS RDS. I want to builf an ETL data pipeline to process the RDS data and update in RDS. Can you recommend me some open source free ways to build it ?,0,svft59,https://www.reddit.com/r/datascience/comments/svft59/new_to_ds_have_a_large_data_set_in_aws_rds_i_want/,17,1645184027.0,,2022-02-18 13:33:47
What are your strategies for filtering bad data?,17,svcjlo,https://www.reddit.com/r/datascience/comments/svcjlo/what_are_your_strategies_for_filtering_bad_data/,8,1645171201.0,"Ive been building a model and analysis tool that has ~110k observations in it. Data span 6 years and is across 63 features. Today I was able to finally put my selected features into a box plot and I noticed an extreme outlier. A quick query and short investigation revealed that my data source had left a zero off one of the observations. This caused the change to be 900% instead of. 001%. No big deal I can fix that data point.

However I'm now wondering, what strategies out there I could employ during ingest to catch and fix these easy issues automatically. I can't rely on the end user to know how to get into the dB. They'll just be familiar with the front end.",2022-02-18 10:00:01
Rebuilding the relationships in a database?,5,suxssc,https://www.reddit.com/r/datascience/comments/suxssc/rebuilding_the_relationships_in_a_database/,5,1645128030.0,"I've been given an export of a client's database (.mdb) that contains many tables (300ish) with many columns (50+), but with all of the relationships between them removed. I have:  

The tables themselves  
A data dictionary  
An indication of what the primary key is but not how it is linked to other tables  

[Here is an example of what I have to work with.](https://imgur.com/a/PtOf44I)  

As you can see, NodeID (among others throughout the database) is marked as a primary key, but it contains no foreign keys. Other tables reference NodeID in various ways (NodeID, FeedingNodeID, etc) but I would have to eyeball all instances of it by hand.

Is there any way to go about rebuilding the relationships for this database, other than by hand? Any tools, programs, or techniques you would recommend?  

Any advice on how to accomplish the task or what the framework might be for accomplishing this would be greatly appreciated, thank you.",2022-02-17 22:00:30
Assigning confidence scores for address matching exercises,1,surnfs,https://www.reddit.com/r/datascience/comments/surnfs/assigning_confidence_scores_for_address_matching/,2,1645112289.0,"I'm working on a project where I compare business names and addresses across multiple data sources. Is there any established method for assigning a confidence score for this kind of comparison work? 

Some of the data is expected to be out of date, so I may have cases where the same business has moved from location 1 to location 2 and my inputs show them in different addresses. I'm dealing with that where I can by looking for nearly identical business names in the same geographic area using fuzzywuzzy (A lot of this data was entered manually and variations in business names across sources are common), which gives me Levenshtein distance scores for naming, but I need my scoring to also reflect which address fields match too so that a good string comparison score at the same physical address is prioritized above a good one in the same zip code with a non-matching address, etc.

I'm making a score up as I go along right now to reflect the confidence of a match based on how much of the address matches and how much of the business name matches so that I can prioritize as described, but would prefer to use an established method for scoring if this is already a well-solved problem. 

Google didn't yield a lot of practical advice, so asking here. TIA.",2022-02-17 17:38:09
"What is the proper way to externally validate clusters when I have only a sample of the dataset labeled, but want to cluster the entire dataset?",1,sur9xl,https://www.reddit.com/r/datascience/comments/sur9xl/what_is_the_proper_way_to_externally_validate/,3,1645111288.0,"I have a dataset of text-based documents that I want to cluster. For a sample of this dataset (~10%) I have manually annotated labels (i.e., the ground truth). I would like to cluster this dataset to ""automate"" the annotation of the remainder of dataset. The assumption is that I can not expend the resources to label the rest. I also can't build a classifier with the labeled data because the assumption is that it does not include all possible labels present in the remaining data. I see two options for this:

1. Cluster the entire dataset. Select the clustering algorithm, number of clusters, other parameters by maximizing an external cluster validation index (e.g., ARI) on the labeled sample, thus assuming if the produced clusters conform with the manual labels, the clusters for the unlabeled data should be similarly composed (similar idea of a cluster for this data). 

2. Cluster the labeled sample only. Select the algorithm and other methodological details by maximizing an external cluster validation index. Then, use that method for the entire dataset and select algorithm parameters, number of clusters using a mix of internal validation indices and qualitative review.

Does one of these methods pass the sniff test? I haven't seen this exact use case yet in literature but I'm sure it's out there, just can't seem to find it. My inclination is that number 1 makes the most sense, but can't decide if this would potentially overfit to the sample data.",2022-02-17 17:21:28
Hmmm. Something doesn't feel right.,671,sup40t,https://i.redd.it/naug7o1cdei81.png,295,1645105363.0,,2022-02-17 15:42:43
"People who’ve worked at multiple companies, how has the different levels of emphasis on data governance across those organisations influenced your enjoyment and success with DS projects?",4,suliai,https://www.reddit.com/r/datascience/comments/suliai/people_whove_worked_at_multiple_companies_how_has/,5,1645092984.0,"Hi all, 

I’m currently working in Data Governance. I’m a graduate, so it’s all very new stuff to me. I’m really curious about how influential this realm of the data world is and can be. 

The company I work at don’t seem to value it too much, and it makes what I’m doing feel quite bland and unfulfilling. I get the impression that governance is viewed as more of a burden across the organisation and people don’t seem to recognise the motives for it. There’s also weak messaging around the incentive for good governance. 

What are you personal thoughts on Data governance as data scientists? Have you witnessed any major transformations where you’ve worked? Was the benefit noticeable or practically worthless? Has good governance facilitated more enjoyable and successful projects? 

I look forward to hearing your responses.",2022-02-17 12:16:24
"Free, actionable template to learn real-world Data Science and get hired",129,sul1kf,https://www.reddit.com/r/datascience/comments/sul1kf/free_actionable_template_to_learn_realworld_data/,12,1645091118.0,"From my 3-year experience in London fintech as a data scientist working with C-level executives, and from the self-learning journey leading up to that, I’ve created a template to learn the data science skills that companies are looking for.

It’s the template I wish I had when I started learning data science and applying for jobs. You can personalize it to fit your interests and career aspirations.

&#x200B;

My own data science journey started four years ago. I was an unhappy electrical engineer in aerospace. I was looking for something less narrow and more challenging, so I self-learned everything I needed to know about data science. This was a long journey with many detours, but eventually I felt confident enough to start applying, and after a few months I was hired as a data scientist in a vibrant fintech startup in London.

It turned out real-world data science is quite different from what I had studied! I learned about databases, data cleaning, software engineering, but the most challenging was communicating my findings to business stakeholders - both verbally as well as with data visualizations that show a clear message. So I was anxious at first and learned slowly. Eventually I got the hang of it and worked for three years with very hands-on business data, providing real value to C-level decision makers.

&#x200B;

This is a template to self-learn the DS skills companies are looking for, in less time than it took me.

The template is based around 3 pillars:

* Math & Stats
* Software Engineering & Tools
* Data & Business Communication

The Math & Stats section contains a structured list of recommended topics and principles to learn, with links to relevant resources like [Khan](https://www.khanacademy.org/math/statistics-probability/modeling-distributions-of-data/normal-distributions-library/v/ck12-org-normal-distribution-problems-qualitative-sense-of-normal-distributions) [Academy](https://www.khanacademy.org/math/statistics-probability/confidence-intervals-one-sample/introduction-to-confidence-intervals/v/confidence-intervals-and-margin-of-error) [videos](https://www.khanacademy.org/math/linear-algebra/vectors-and-spaces/vectors/v/vector-introduction-linear-algebra) and the classic books like *Introduction to Statistical Learning*).

The Software Engineering & Tools sections walks through tools to learn (based around the Jupyter-Python-Pandas ecosystem), and links to [tutorials](https://www.learnpython.org/), [videos](https://www.youtube.com/watch?v=ZyhVh-qRZPA&feature=emb_title), [example notebooks](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.03-Operations-in-Pandas.ipynb) and [cheat sheets](https://startupsventurecapital.com/essential-cheat-sheets-for-machine-learning-and-deep-learning-researchers-efb6a8ebd2e5) (all created by other fantastic people, I take no credit for the linked resources) to learn Python, Pandas, Scikit-Learn and Matplotlib.

The Data & Business Communication section is the real core of the template, where both of the previous sections come together. It’s shaped after the process for a typical business data science project:

* Data collection
* Data exploration
* Data cleaning & preparation
* Machine learning modeling: here I mention some common models actually used in businesses, like linear+logistic regression, random forests and timeseries forecasting
* Model evaluation
* Reporting & data visualization: focus on creating clear plots here
* Communicating with stakeholders: this is where I go more in depth on communicating your results to business decision makers, and telling a story which a layman can understand

The study content provided in the template is minimal, but you can go as in-depth as you like with the linked resources. The idea is that you study those resources by yourself, and then write down what you learned in your own words, directly into your own copy of the template.

And of course you can modify this template to your own taste. Delete what doesn’t interest you, and add more where you want to dive deeper.

&#x200B;

I like to learn with flashcards (especially to memorize common interview questions), so I’ve added some example flashcards to help you get started - you can add your own flashcards or delete them if it isn’t for you.

&#x200B;

Here’s the full template in Traverse (my app, with integrated flashcards):

[https://traverse.link/dominiczijlstra/zadn5zj1z3lyhf04ptok99u0](https://traverse.link/dominiczijlstra/zadn5zj1z3lyhf04ptok99u0)

Here is the same template in Notion (without the flashcards, you could use Anki in parallel):

[https://dominiczijlstra.notion.site/Data-Science-Roadmap-82739cbad35c409595876263cacde0e4](https://dominiczijlstra.notion.site/Data-Science-Roadmap-82739cbad35c409595876263cacde0e4)

&#x200B;

This is the first version, so I’d love to get your feedback and suggestions here to make further improvements!",2022-02-17 11:45:18
Tukey test in python?,1,sukxj3,https://www.reddit.com/r/datascience/comments/sukxj3/tukey_test_in_python/,4,1645090642.0,"noob question, i want to perform tukey test to compare 4 numerical columns in my dataframe, let's say column names are a, b, c, d and all of them have continuous numerical values, how do i go about that, a syntax for same will be much appreciated",2022-02-17 11:37:22
Found this awesome NLP timeline from BoW to Transformers. Credit goes to Fabio Chiusano.,333,suj00s,https://i.redd.it/x2srm0rhici81.png,15,1645082882.0,,2022-02-17 09:28:02
Anybody doing independent research on NLP?,16,suifsw,https://www.reddit.com/r/datascience/comments/suifsw/anybody_doing_independent_research_on_nlp/,8,1645080783.0,"I discovered that many people in the Data Science & ML industry are doing independent research (without any formal academic supervision or collaboration with labs) and publishing papers. I'm also motivated enough to do independent research collaboration in the area of Natural Language Processing. I've got a few papers published in this domain and looking forward to publishing more.

I would love to talk to anyone who is working independently or wants to collaborate.",2022-02-17 08:53:03
I want to learn how to setup an ETL Pipeline for Marketing,2,sucb0b,https://www.reddit.com/r/datascience/comments/sucb0b/i_want_to_learn_how_to_setup_an_etl_pipeline_for/,4,1645061506.0,"Aspiring Entrepeneur/ Data Scientist specialized on Marketing ML (beginner)...

I want to be able to track and measure marketing channels, campaigns, and perform experiments on all marketing efforts but I don't even know where to start or what should I know to start collecting and processing the data. I kind of know in theory what is needed, but I want to know in practice and to be able to implement:

1. How to collect data from google analytics, facebook, email campaigns, etc, and send it to a data warehouse
2. How A/B & Multivariate testing experiments work in practice/ real life, where are perform, what is needed

I hope is not a lot to ask, but I feel a little bit lost with all this type of implementation.",2022-02-17 03:31:46
Market Basket Analysis vs. Recommendation System,1,su9yb9,https://www.reddit.com/r/datascience/comments/su9yb9/market_basket_analysis_vs_recommendation_system/,3,1645054828.0,"Hey I am new to data science - I am a data engineer. My team wants to build a proof of concept to showcase what data can be used for at our company. 
We have data for training courses our customers took for our products. 

Our goal is to try and build something that can recommend training courses to a user in a marketing email based upon what they have already taken. 

Immediately I thought of a Recommendation System though we do not have ratings on the courses from the users or a lot of demographic data. I also then thought about doing a Market Basket Analysis to recommend courses based on what courses people commonly took together. 

What would you recommend starting out with? Thank you!",2022-02-17 01:40:28
What does MVP look like for inventory/demand forecast?,1,su5922,https://www.reddit.com/r/datascience/comments/su5922/what_does_mvp_look_like_for_inventorydemand/,2,1645042555.0,"I've asked the question for https://www.reddit.com/r/datascience/comments/steeoo/how_do_deal_with_exploding_model_numbers/ on the bottom-up approach of predicting per-sku level, but it seems like this will be quite a lot of work especially for MVP. 

So while I would like to keep per-sku as an option for future iteration, I am wondering what are other quick ways to establish a baseline number with inventory forecasting?

I guess the difficulty I am having is that we are not just predicting sales, but sales of each sku, and not sure which ML model can handle it.",2022-02-16 22:15:55
I'm unsure of which database is best for my data collection use case.,1,su4bis,https://www.reddit.com/r/datascience/comments/su4bis/im_unsure_of_which_database_is_best_for_my_data/,8,1645040221.0,"So, I have to extract data for 25000 github repositories or so. I need to get the authors, commits, files and file changes for each of those.

I intend to do it in a multithreaded fashion because otherwise it will take too long. However, with foreign keys and such this will cause issues with race conditions. For instance authors in these repositories can be repeated and depending on who comes across an author first, several threads may erroneously attempt to insert at the same time causing errors in the process. I could just insert the data for the authors and repositories first but this is just going to be way too slow for 25000 repositories and it cannot be done in a multithreaded fashion. 

My only concern for this data is that it should be easily queryable after I store it. I won't be writing to it anymore after I obtain it. I went for postgres because I figured it would be easier to work with that when using pandas, but I'm wondering if going NoSQL might be better in the long run.

Need some advice with this, hopefully someone can help me.",2022-02-16 21:37:01
Help on model diagnostics - stagnant test loss,1,su2xu5,https://www.reddit.com/r/datascience/comments/su2xu5/help_on_model_diagnostics_stagnant_test_loss/,7,1645036664.0,"I am training a graph neural network on a link prediction (binary classification) task. I am uncertain why model seems to be overfitting so much, but precision and recall continue to increase. I have not reached a point where test loss is increasing, but it seems to converge to some value much higher than the training loss. I am using binary cross-entropy loss with logits. In other words a loss that function that combines a Sigmoid layer and the BCELoss.

https://preview.redd.it/u6ivr39zo8i81.png?width=2022&format=png&auto=webp&s=8838fe73c5e8bc928ea743b61275bdf28a815f6a

Any ideas on what areas to work on lowering test loss function more? Model is performing fairly well on our topline business metrics, but I would like to see test loss get much closer to training.",2022-02-16 20:37:44
How to fit a distribution to raw data and draw observations from it in R?,5,stzexn,https://www.reddit.com/r/datascience/comments/stzexn/how_to_fit_a_distribution_to_raw_data_and_draw/,9,1645027386.0,"Hi all, I have a vector of observation (clearly not normally distributed, and also not gamma, lnorm, weibull, ecc given that it includes negative values). What I would like to do is to use R to fit a distribution to such observations and subsequently draw new observation form it to use in a Montecarlo simulation. Does someone know which package I could use for this? I googled a bit but only found stuff about usinf ""fitdist"" which does not seem appropriate given that obs are not normal and include negative value, so usual distributions don't seem to fit. Thanks in advance",2022-02-16 18:03:06
"To those who used to do data science and quit… Why, and what did you shift to?",277,stys2x,https://www.reddit.com/r/datascience/comments/stys2x/to_those_who_used_to_do_data_science_and_quit_why/,225,1645025800.0,"Hello all,

I wanted to get some insight from people who have done data science successfully but quit for whatever reasons. Maybe too stressful? Maybe better job offers? Retirement? 

Any discussion would be appreciated!

Edit: Biggest collective issues here seem to be management expecting magic from data scientists given subpar data. A lot of uneducated management stick their nose in, not knowing what they’re talking about. It can get stressful. Can you handle the smoke? 💨",2022-02-16 17:36:40
Cluster Stability visualization technique,3,styl1p,https://www.reddit.com/r/datascience/comments/styl1p/cluster_stability_visualization_technique/,5,1645025290.0,"Full transparency here: my exposure to data science has been by trade, not by formal education or training. That comes with knowledge/terminology gaps, so I apologize in advance for those. If something isn't clicking with you, please feel free to ask clarifying questions and I'll do my best to answer them.

I had an idea for a visualization I wanted to see if there was something out there that does this already in python, or even more fundamentally if there are oversights in my thinking that would blow up this kind of approach from the get-go.

clustering basics: k-centroid clustering starts by selecting k random points and evaluating 'distances' from those k points across the remainder of the dataset. Each data point is then assigned to a 'cluster' based on which of these k points it is closest to.

The problem: those k points are assigned randomly. And we usually get around this by running a clustering exercise repeatedly. But since every single point gets assigned to a cluster, we can end up with points that are 'promiscuous' and end up in different clusters a lot. And I haven't found a good way of visually describing this.

The summary of the proposition: a kind of topographical map, where we first identify k points that are (basically) never in the same cluster. Then we track how frequently each of the various data points are in the same cluster as each of those k points. So if K1 and point 56,757 are in the same cluster 95% of the time, that pairing has a height of 0.95. And if K2 and point 5,251 are in the same cluster 50% of the time, that pairing has a height of 0.5.

So then we take the set of K that are most exclusive to each other, make a pair of orthogonal eigenvectors out of them and pretend that these are new axes. Then we plot the full dataset onto these new axes and then treat the frequency of how often those points are paired together as the 'height' of the relationship.

Then, I think, we have a topographical map. Setting a threshold of how frequently point-to-centroid pairs share a cluster is essentially like setting the sea level of this topographical map, and there's probably some curve that identifies how much information we lose for each 0.01 of the 'sea level' and then we can probably fit some half-dozen different kinds of optimization algorithms there to find out the 'ideal' height.

The resulting ""islands"" are your new, improved, and focused clusters, with 'promiscuous' data points underwater.",2022-02-16 17:28:10
Can correlation be used a factor?,1,stwzg8,https://www.reddit.com/r/datascience/comments/stwzg8/can_correlation_be_used_a_factor/,17,1645021088.0,"Let’s say I’m doing a product cannibalization analysis. Product X sales decrease from Year 1 to Year 2, while a new Product Y which was introduced in Year 1 experience sales growth during the Year 1 to Year 2 period. I want to calculate the product cannibalization rate which should in theory be (sales decrease of Product X)/(sales increase of Product Y) but this is assuming that all of my sales lost in Product X went to Product Y, but if I did a correlation analysis, I see that the correlation coefficient is around -0.7 instead of a perfect -1.0 negative correlation. Would I be able to apply a factor of 0.7 to my cannibalization rate since it seems only 70% of the movement in sales is tied to the products and not other factors? Am I looking at this correctly or does this not make any sense?",2022-02-16 16:18:08
What analysis is it called where you study behavior of an agent based on frequency of occurrence?,2,stsdpd,https://www.reddit.com/r/datascience/comments/stsdpd/what_analysis_is_it_called_where_you_study/,12,1645005923.0,"Say I have some network traffic data, and I see that usually user A logs in 5-10 times a week into the network. Suddenly if one day I see 50-100 logins from that user, that is suspicious activity, right? Maybe the user was hacked, etc.

What is this kind of analysis called, where there is no label column in the dataset stating that this traffic instance is normal or anomalous; but rather, we need to model what is normal vs anomalous based on frequency of occurrence?

I just want to know how or what to search for on the web, to know what kind of approaches people have been using to solve these kind of problems.",2022-02-16 12:05:23
How does your company handle project requests?,3,stsbjn,https://www.reddit.com/r/datascience/comments/stsbjn/how_does_your_company_handle_project_requests/,9,1645005707.0,"I'm rather fresh in the DS field and so is the company that I work for. We are constantly getting requests to do projects for the different departments in my company (telecoms) and the product owners often come back and say something like ""Oh, can you actually do exactly what you did but for a different group of customers"".. without realising that that means we have to start from scratch.  


Anyway, rant aside, how do you handle project requests? Do you send out a form to the business units and ask them to outline exactly what they want? I'm also wildly unfamiliar with a lot of the data that we have so sometimes it takes a long time to find out if we even have the right data. Is this normal? 

&#x200B;

Like I said, I'm fresh and still in a very junior role. Any feedback would be appreciated! :)",2022-02-16 12:01:47
Navigating the uncertainty of what you're supposed to be doing,12,stnavk,https://www.reddit.com/r/datascience/comments/stnavk/navigating_the_uncertainty_of_what_youre_supposed/,6,1644987076.0,"I've been in the ""data"" field for few years after previously training in a clinical area but never quite got the ""data scientist"" title-have been working as a statistician, then an analyst and really became advanced in my coding/programming skills over the course of the last few years. I realize I enjoy programming and could envision coding all day. My most recent job ended up being less analysis and modeling and more 'using code so I never have to do manual work again'-some of it sucked b/c but it was also rewarding to figure out how to write scripts for stuff people were doing manually for years.

However, I a pretty common theme I honestly felt in my last few jobs is that I quickly lost sight as to what I was doing because the people overseeing the projects seemed to have a lack of clear goals in their work. My work was basically centered around ad-hoc requests from people-sometimes unrealistic requests, it became repetitive and boring and everything felt like we were just doing things for the sake of doing them. 

I started applying to jobs both in my original field and data science roles in tech with the hopes I can do a job where at minimum I know what I'm supposed to be doing everyday and ended up getting got an offer at a place I originally applied for in a clinical role but ended up in a bit of a random role where I am neither doing data science (b/c they already have a team of pretty talented people who are coding, creating dashboards and modeling) or clinical work-I'm basically an in between person coming up with 'new ideas' and measures-it's really up to me to define the role. The thing is there are some clinical people who know what they are looking for when it comes to data, so it's basically right now a pipeline between them and the data team and I don't know where I fit in the puzzle. The people I work with so far are great and I do think it's nice to have the freedom of trying something new, but I feel very limited-I don't have access to the data which the data team does and they probably won't prioritize me getting access since I'm not on that team. I've been coming up with projects that aren't dashboards, but I sort of feel like I'm getting that 'doing for the sake of doing' feeling. 

I'm assuming (from some posts here) some of you have felt this way-any tips to navigate? I'm allocating some time to self-teaching and doing side projects so I still feel like I can be a part of the data world, but funnily I feel overwhelmed from being a bit underwhelmed and could use some insight how to better navigate that.

Thank you.",2022-02-16 06:51:16
How often can you use “off the self” Bayesian models in application/practice?,0,stlc5s,https://www.reddit.com/r/datascience/comments/stlc5s/how_often_can_you_use_off_the_self_bayesian/,2,1644980897.0,"I’m in a undergraduate Bayesian statistics course. Thus far we have learned three cases of conjugate Bayesian models:

Beta binomial, normal normal, gamma poisson.

I’m wondering how often these specific cases, or in other words, conjugate Bayesian models are easy to apply in practice. As in, with knowledge equipped from these three conjugate models, can I solve a wide variety of problems? Or in practice is it more about specifying custom likelihoods and mixing and matching priors and likelihoods to get what I want? 

Is just knowing these three models well enough to be dangerous with using Bayesian methods in practice? What more would I need to know?",2022-02-16 05:08:17
"New Edition of Kevin Murphy's ""Probabilistic Machine Learning"" Book (free pdf!)",17,stken0,https://www.reddit.com/r/datascience/comments/stken0/new_edition_of_kevin_murphys_probabilistic/,1,1644978173.0,"Kevin Murphy released a new edition of his ML book, and there's a free pdf: https://probml.github.io/pml-book/book1.html

There's code for the book, and it looks like he's brought it up to the state of the art.",2022-02-16 04:22:53
Azure ML - what are people's experiences?,3,stgoox,https://www.reddit.com/r/datascience/comments/stgoox/azure_ml_what_are_peoples_experiences/,9,1644967799.0,"I'm currently working on an Azure ML project, and finding it frustrating. In many ways I can see that there's aspects of a good tool there, but the detail of getting things to work together seems very challenging. My project is a migration from AZ ML Classic to the current, so while the documentation covers a lot of 'getting started' aspects which are relelvant in a greenfield scenario, in my scenario I find the documentation doesn't have the needed detail and the overall experience is fiddly.

Is this just me, or do others find the same thing? Is there a 'missing manual' for Azure ML out there somewhere and I just haven't found it, or is the MS online stuff it?",2022-02-16 01:29:59
Is there appetite for a separate space for experienced DS?,239,stfgds,https://www.reddit.com/r/datascience/comments/stfgds/is_there_appetite_for_a_separate_space_for/,58,1644964607.0,"I've been noodling on the idea for a bit. I love that we have a space for Data Scientists, but it feels like the primary audience here is folks trying to enter or transition to DS.

I really enjoy what r/ExperiencedDevs has to offer, compared to say r/cscareerquestions which feels a lot like the blind leading the blind.

The raison d'etre for the spin-off sub would be for experienced DS (maybe seniors and above?) to congregate, learn from each other, share career tips, upcoming roles in each others' teams, etc.

If the sub grows enough, we can setup verification processes (while respecting everyone's privacy) to ensure high quality.",2022-02-16 00:36:47
Question for data scientists: algorithm performance,1,stfdis,https://www.reddit.com/r/datascience/comments/stfdis/question_for_data_scientists_algorithm_performance/,6,1644964399.0,"Have to preface this by saying not sure if this is a stupid question or not. 

Do seasoned data scientists know which algorithm will perform best by examining the dataset? And how do you know? Is it just intuition? 

I'm still very very junior in terms of DS (have always been kind of a glorified data analyst/consultant role) and struggling to explain why certain algorithms perform better than others. I know there're pros and cons for each algo in terms of speed or interpretability, but in this context, I'm talking just pure performance.",2022-02-16 00:33:19
UX director/product designer here... I'm interviewing data science analyst candidates. What should I ask?,0,stf0c4,https://www.reddit.com/r/datascience/comments/stf0c4/ux_directorproduct_designer_here_im_interviewing/,6,1644963443.0,"I'm sitting in on a Data Scientist candidate interview because I'll be working closely with this person. I'd love to get a real feel for how we'd work together.

I am FAR from a data expert, but of course, data informs nearly every decision I make. Help me ask great questions, please :)",2022-02-16 00:17:23
How do deal with exploding model numbers? Especially for inventory forecasting,12,steeoo,https://www.reddit.com/r/datascience/comments/steeoo/how_do_deal_with_exploding_model_numbers/,22,1644961891.0,"In Kaggle comps, it seems like the common method of inventory forecasting is to predict per each product which is fine for smaller dataset, but how do you deal with that in real life where you have thousands of products and need to predict per store? 

This would end up with the equal thousands of predictions that need to be reconciled somehow",2022-02-15 23:51:31
How do you deal with Jupyter notebook debt?,29,sta6yp,https://www.reddit.com/r/datascience/comments/sta6yp/how_do_you_deal_with_jupyter_notebook_debt/,61,1644951065.0,"Hi all! I've been talking to many folks lately about dealing with code quality in Jupyter notebooks, and I'd like to hear the perspective of the r/datascience community. To get started, here are a few things I've heard:

1. **Allow Jupyter notebooks but refactor them before deployment.** This is the most common answer, people are allowed to use notebooks but before deployment, there is a big refactoring process where the notebook is converted into scripts or functions. One problem I see with this approach is that it's slow and error-prone, sometimes results from the original notebook cannot be reproduced.
2. **Deploy notebooks as-is.** This is an interesting approach, teams execute notebooks in production. I think it works ok for simple projects (e.g. notebooks with < 100 cells) but it gets difficult to maintain for larger projects.
3. **Ban the use of Jupyter notebooks.** Pretty strict IMO, what ends up happening is that a lot of code lives outside the git repository and gets lost there. This approach forces Jupyter users to refactor their code before merging it into the codebase.
4. **Use jupytext and write small notebooks.** This is a pretty rare answer (because many people don't know about jupytext yet). but I think it's a great solution: jupytext essentially allows you to open .py files as notebooks so can edit the code in Jupyter but version it with git without issues. The main caveat here is that although it enables code reviews, it doesn't fully solve the problem, and the notebooks/scripts may still have some hidden state. [This is my current approach; I wrote about it here.](https://ploomber.io/blog/nbs-production/)

Any other approaches?",2022-02-15 20:51:05
Companies that migrate ERP and CRM from SQL to Web API (JSON?). Why?,3,st92q8,https://www.reddit.com/r/datascience/comments/st92q8/companies_that_migrate_erp_and_crm_from_sql_to/,6,1644948208.0,"what are the advantages to have one system (ERP, CRM,…) that do no longer fetch data from a SQL Server but use an API (with JSON?). Why one company should decide to do this kind of migration? Isn’t it a disadvantage among others to not be able to query in a SQL way? What are the advantages and disadvantages to do that? In which scenarios would you recommend this kind of migration?",2022-02-15 20:03:28
How much does Econometrics come into practice in Data Science,29,st7zf5,https://www.reddit.com/r/datascience/comments/st7zf5/how_much_does_econometrics_come_into_practice_in/,18,1644945395.0,"Hi everyone,

I'm currently doing my undergrad dissertation, which requires a lot of data analysis, but from an econometric perspective - regressions, significance testing, unit root testing, serial correlation testing, heteroskedasticity, looking at the distribution of the residuals e.t.c.

I was just wondering how much that comes into play when working in a career in data? Is it more common among 'data analyst' positions rather than in 'data scientist' or 'data engineering'?

Thanks XD",2022-02-15 19:16:35
Cross Validation on Over / Under Sampling,8,st5ll7,https://www.reddit.com/r/datascience/comments/st5ll7/cross_validation_on_over_under_sampling/,12,1644939234.0,"Imagine you are tuning a random forest model and you are dealing with unbalanced classes. You want to study over / under sampling your response, or your non responses.

Do you need to do something like cross validation on the percentage of over / under sampling you are doing, or is this not required if you are sampling with replacement?",2022-02-15 17:33:54
"Has anyone here worked in the agricultural industry? If yes, what did you do?",1,st2b36,https://www.reddit.com/r/datascience/comments/st2b36/has_anyone_here_worked_in_the_agricultural/,6,1644929696.0,,2022-02-15 14:54:56
"Labeling numerical coded variables like 1=0, 2=1, 3=2 etc. acceptable?",1,st0j1v,https://www.reddit.com/r/datascience/comments/st0j1v/labeling_numerical_coded_variables_like_10_21_32/,6,1644923172.0,"Working in medical field, we regularly see datasets that contain variables with coded values. For example like this:

    Biopsy visit (standardmatvisit)  
    0 = No  
    1 = Yes
    
    Number biopsies for research, max. 3 (standardmatsamples)
    1 = 1
    2 = 2
    3 = 3

Sure, makes sense to me, that second one could be a numeric value with min/max but ok. However, then I see things like this:

    Performance status (perfstat)  
    1 = 0  
    2 = 1  
    3 = 2  
    4 = 3  
    5 = 4  
    6 = 5

Like.. why though!? I know the codes can theoretically be anything, but this is just begging for problems down the line. It doesn't happen often, but I've seen this kind of thing a couple of times now.

imho this is just bad practice. Anyone encounter this, and is it accepted in your organization?",2022-02-15 13:06:12
What’s the best time series book from a practitioner/ applied perspective?,3,sszput,https://www.reddit.com/r/datascience/comments/sszput/whats_the_best_time_series_book_from_a/,4,1644919747.0,I find lots of time series/ forecasting books are on the theoretical side with lots of formulae. Is there a time series book that’s like German/ Hill / ( Vehtari) or Kuhn/ Johnson in terms of being aimed at practitioners in terms of explaining why to do things.,2022-02-15 12:09:07
Everything should be a dashboard,117,ssz9p9,https://www.reddit.com/r/datascience/comments/ssz9p9/everything_should_be_a_dashboard/,65,1644917967.0,"TL;DR: Be careful what you wish for. 

I \*finally\* managed to move to a Data Science position within the company I work for after months of lobbying and multiple contract jobs on the side - just to have some manager involved for whom everything should be a dashboard and everything should have a clickable UI even when we have very little idea about what the data is even going to look like.

Have been fighting him about it for 2 months.

This post has 0 value outside of me venting.

Kill me.",2022-02-15 11:39:27
Side Hustle,5,ssy1j8,https://www.reddit.com/r/datascience/comments/ssy1j8/side_hustle/,19,1644912933.0,"Fellow Data Scientist/Analysts who have side hustles, what do you do as a side hustle and how did it come about ?",2022-02-15 10:15:33
AI-generated poetry about data science,697,ssqt3h,https://www.reddit.com/gallery/ssqt3h,74,1644888523.0,,2022-02-15 03:28:43
Poor mans saas hosted Alteryx?,5,ssq57c,https://www.reddit.com/r/datascience/comments/ssq57c/poor_mans_saas_hosted_alteryx/,4,1644886622.0,"Does such a thing exist? I am not a data scientist by any stretch of the defintion, but have used Alteryx at work before so its the only thing beyond excel and basic SQL that i know, hence the reference. 

What I am trying to do is pull a dataset via a REST API on a daily basis, eliminate unneeded fields, do some basic cleansing/scrubbing, de-dupe and export any net-new records to a CSV. 

I supposed i could do this in excel, but looking for something a bit more modern and affordable than Alteryx. Like an IFTTT but for Data. 

Anything like this exist?",2022-02-15 02:57:02
Retrieve instagram information of a post?,0,ssklt0,https://www.reddit.com/r/datascience/comments/ssklt0/retrieve_instagram_information_of_a_post/,2,1644870854.0,There is a way to download the data of an instagram post? Like comments. I know it can be done on twitter but im not sure about IG,2022-02-14 22:34:14
What was the stupidest thing management made you do?,6,sskc63,https://www.reddit.com/r/datascience/comments/sskc63/what_was_the_stupidest_thing_management_made_you/,18,1644870170.0,"There are great managers out there. And there are companies with amazing DS workflows and decision making processes.

But where's good, there's bad too. Tasks, comments and opinions you can't believe someone actually thought that this was a good idea. 

What was your all-time favorite facepalm moment in your career?

Disclaimer: Please don't post any offensive stuff or ""nobody outside DS understands DS, cause everyone is stupid"" type of comments. We all know that there are outstanding product owners, project leads and C-level people out there. But ""I can't believe this is happening right now"" moments are parts of the job too and I just wanna have a laugh 🙂",2022-02-14 22:22:50
"Moved into ‘data scientist’ role one year after starting my first ever job, need advice.",3,ssjtqt,https://www.reddit.com/r/datascience/comments/ssjtqt/moved_into_data_scientist_role_one_year_after/,5,1644868886.0,"Im from the UK, after a year into my first job after graduating I applied to an internal vacancy as a data scientist. The company is a materials R&D company and they are looking to apply ML and finite element analysis to develop new materials, it seems like a great opportunity for me to break into the data science career, however, the role does not involve the classic data science methods mentioned in numerous other posts on here, things such as SQL, Tablaue, pandas etc. And they do not have any of the existing infrastructure for data science as it is a completely new concept for them. 

They have agreed that I can complete courses and stuff but I feel I’m not going to get that much transferable experience if I ever wanted to break into something like big tech. Any advice would be greatly appreciated.",2022-02-14 22:01:26
Solution for importing big excel sheets with over 150k rows to mysql database using phpmyadmin?,0,ssjihm,https://www.reddit.com/r/datascience/comments/ssjihm/solution_for_importing_big_excel_sheets_with_over/,11,1644868128.0,"Hello, I have a big excel sheet with around 178k rows of sales data for different items, I wanted to import it to mysql database using Xampp and phpmyadmin but every time I try the importing just stops at around 8k rows and tells me PHP timeout occurred.

I would appreciate a solution to this problem if anything knows.",2022-02-14 21:48:48
Node2Vec Explained & Implemented in Python,2,ssiy2p,https://www.reddit.com/r/datascience/comments/ssiy2p/node2vec_explained_implemented_in_python/,1,1644866718.0,"Just wrote a new article on node2vec, a famous paper which provides a solution for transforming networks into an embedding space which holds the initial structure of the network. In the article I provide an intuitive and technical overview of the main concepts in the paper, as well as the python implementation of the algorithm. Check it out if you're interested.

[https://towardsdatascience.com/node2vec-explained-db86a319e9ab](https://towardsdatascience.com/node2vec-explained-db86a319e9ab)",2022-02-14 21:25:18
Professional resume review services?,1,sshi4p,https://www.reddit.com/r/datascience/comments/sshi4p/professional_resume_review_services/,1,1644863108.0,"I've been in the DS/Analytics space for close to 10 years now, and was wondering if any of you have run across professional resume review services specific to DS/Analytics you'd recommend + cost? My fear is a general service won't have the specialized knowledge in how to edit a more specialized technical resume in the DS/Analytics field.",2022-02-14 20:25:08
The Monte Carlo Algorithm,9,ssfgto,https://www.reddit.com/r/datascience/comments/ssfgto/the_monte_carlo_algorithm/,28,1644858120.0,"I am a self-taught Data Analyst and in my free time I spend a lot of time improving my skills. Among others I read a lot about ML topics and Algorithms and try to learn applying the knowledge I get from the books / articles I read with real use cases I have. 

I have heard of the Monte Carlo Algorithm and I get the general idea about simulations and distributions to solve some problems. But I can’t really think of a use case where I might need or use it.

DS of Reddit: do you use it and for what? what use cases make sense to use it? Why is so little discussed about it in the DS Community? ( I have read 3 books about ML and DS and I have never found any mention about it).",2022-02-14 19:02:00
Tool/script available for identifying speakers and counting speaking time in audio fragments,1,ssf2tr,https://www.reddit.com/r/datascience/comments/ssf2tr/toolscript_available_for_identifying_speakers_and/,2,1644857191.0," For a project I'm working on involving 350+ hours of audio with multiple speakers it would be highly insightful/helpful to have some stats on who is talking how much over the course of these hours. I was wondering if there already exists a tool or an adaptable script to do this automatically, by maybe identifying individual speakers and counting active minutes, instead of having to manually log all of this. It would literally save months of labor. Thanks in advance! (I'm really trying not to offend rule 9, sorry if I still did.)",2022-02-14 18:46:31
Settle an debate: Drop chance in OSRS,2,ssewwt,https://www.reddit.com/r/datascience/comments/ssewwt/settle_an_debate_drop_chance_in_osrs/,9,1644856782.0,"So in OSRS, you kill monsters. Each kill there's a chance of getting a drop. So let's say the odds are 1/128.

Now, on average, it will take 128 kills to get this drop. 

&#x200B;

But let's say you are now 350 kills into it, and you still didn't get your drop.

Are you then, from that point, more likely to get it?

So, because you have 350 kills, will you then get it sooner than 1/128?

Or will you have to start again at 0 when predicting the drop chance, which will then still be 1/128? So from then on, it should take on average 128 kills to get the drop, despite the 350 kills so far?",2022-02-14 18:39:42
"People who work in big tech: If all the users data was transferred to them, would it be as valuable? If so how?",0,ssdqwn,https://www.reddit.com/r/datascience/comments/ssdqwn/people_who_work_in_big_tech_if_all_the_users_data/,20,1644853861.0,"Not just big tech employees but anyone. Facebook, Google, etc. has collected so much data on users over the past decade or so. The value of this data from a corporate, profit-centric, perspective is clear: ux optimization, demographic targeting, ads, and so on.

Now if this data was taken from the big companies and given to the user, in a workable format, what would the best way to use it be? Would it be as valuable (probably not so from profit generation pov but from a personal happiness, general satisfaction, health point of view)? What are the insights a regular individual could get from their data? As data practitioners what would you do? How do we get there from where we are today? What are the paths? What are your thoughts? 

If we continue on the present trend of increased consolidation of data in the hands of corporations and elites that don't have out best interest in mind, the future may look bleak. Decentralize!",2022-02-14 17:51:01
Sugestions for soft skills training - senior DS pivoting into managerial / technical leadership responsibilities,0,ssd9en,https://www.reddit.com/r/datascience/comments/ssd9en/sugestions_for_soft_skills_training_senior_ds/,0,1644852568.0,"Hi all,

As per the title looking for ideas on how to blow my training budget in 2022.

I have no interest in attending conferences, I attend regular meetups, follow plenty of blogs and do enough learning oriented side-projects. Occassionally I skim through papers.

For context, I lead an experimentation team in a small/mid-sized company that is growing very fast.

I am overseeing a junior and actively hiring for a DE and a couple of other roles. I am relatively new to having to manage others and having had fairly bad previous experiences with management I really want to set the bar higher for myself.

I have received extensive agile training and feel confident wrt product ownership and development. As an IC I feel that my strength has been architecting and prototyping solutions, I can easily connect the dots (from an engineering and technical perspective) where others might struggle to. I may not always be the best person to iron out all the details as I do tend to get stuck in an endless self-imposed feature-bloat cycle, even though I should know better xD

Future aspirations include a move towards a data strategy oriented role higher up. I see such a huge problem within my company (hard to put my finger on what caused this, I haven't been around long) where we have plenty of senior people that can't set direction for themselves and their teams and don't usually have a layer of technical leadership to refer to regarding engineering solutions and also setting a direction and laying the foundations today so that we can succeed tomorrow. For example, decisions made a few years back regarding the set up and design of our databases and data-tooling ecosystem have turned out to be a huge hurdle to achieving current goals and priorities.

Open to ideas and suggestions, anything that you have found useful I'm really keen on hearing about it!",2022-02-14 17:29:28
"My model seems too accurate, what can I do to ensure it is correct?",51,ssbez3,https://www.reddit.com/r/datascience/comments/ssbez3/my_model_seems_too_accurate_what_can_i_do_to/,52,1644847508.0,"I'm predicting probabilities that a certain part will fail in the next year. I have percent failures since 2012 and I use the year 2020 as my target. I also have various quantitative and qualitative features regarding the part.

After playing the typical DS pipeline game,  I create my 80/20 train/test split and perform 5-fold cross validation using a linear regression model. The result is that my model is 99.99999.. % accurate, which seems absurd. It shouldn't be due to overfitting, so what may be causing this issue? I know additional context is probably needed, but I'm looking for some general questions I can ask about my model to potentially understand what is going on.

EDIT: I use the word ""accuracy"" fast and loose here. I'm treating the prediction of probability as a regression problem. My measure of accuracy is RMSE which is nearly zero (10e-31)

Edit2: Thanks for the comments everyone! I believe I have a good idea of what avenues to explore now.",2022-02-14 16:05:08
"""I can't trust it if I don't know how it works!""",372,ssamhy,https://i.redd.it/dn6ku8h2wsh81.png,36,1644845357.0,,2022-02-14 15:29:17
"Data Science conferences in 2022, focus in Healthcare?",6,ss8hv1,https://www.reddit.com/r/datascience/comments/ss8hv1/data_science_conferences_in_2022_focus_in/,2,1644838144.0,"Guys, 

What is your go to list of data science conferences to attend this year?

I need to find one for this year‘s development plan but I am kinda buzzed by many conferences out there about data science. If it matches to one or some preferences below, even better:

- Can be either industrial or academic 
- Located in Europe
- Wellknown or at least credible speakers
- Focus on applications in Healthcare
- In person is better


Thanks!",2022-02-14 13:29:04
Why adding variables in linear regression is the same as controlling for them?,24,ss7ver,https://www.reddit.com/r/datascience/comments/ss7ver/why_adding_variables_in_linear_regression_is_the/,19,1644835847.0,"Hello, 

I've asked the same question (with no success) in cross validated. I have heard many times this sentence, but I don't understand why this is the case. In the question I state a ""conjecture"" that I'd like to know whether is true or not (I believe it's true, because I have run several simulations and everytime I get the answer that I would expect). If anyone could shed some ligth into it I'd appreciate it a lot! 

[https://stats.stackexchange.com/questions/564195/why-adding-variable-in-linear-regression-is-the-same-as-controlling-for-it](https://stats.stackexchange.com/questions/564195/why-adding-variable-in-linear-regression-is-the-same-as-controlling-for-it)",2022-02-14 12:50:47
What are some great notebooks to learn from?,5,ss7ru6,https://www.reddit.com/r/datascience/comments/ss7ru6/what_are_some_great_notebooks_to_learn_from/,4,1644835440.0,"I'm looking for a series of notebooks or GitHub projects where I can learn some new ways to approach the cleaning, feature engineering and visualisations part of the data science workflow.

Are there some other people's project that your particularly learned from?

For reference I'm a student so even things like a box-cox transformation are rather new to me. 
I'd rather them being in python.
Finally, I'm not interested in a specific data science branch (computer vision, recommender systems or else), but rather anything is useful as I'm still discovering what's out there.",2022-02-14 12:44:00
Your Top 3 favourite Kaggle authors for notebook,0,ss1b39,https://www.reddit.com/r/datascience/comments/ss1b39/your_top_3_favourite_kaggle_authors_for_notebook/,0,1644811287.0,Who are your top 3 authors u have followed in Kaggle that provides a comprehensive explanation on their notebooks in your opinion ?,2022-02-14 06:01:27
I might have deleted a lot of stuff from a server and I'm absolutely terrified,461,ss0vh9,https://www.reddit.com/r/datascience/comments/ss0vh9/i_might_have_deleted_a_lot_of_stuff_from_a_server/,118,1644809966.0,"I work as a Machine Learning Engineer. I work out of a e2e server where most of the work stuff is stored an from where it's deployed to cloud.

Last night I was trying to work a bit and wanted to delete a bunch of subfolders (about 12) and wanted to use the command line to do it. I only recently started my job and I've never used command line before so I'm still learning.

I gave rm -rf -- /\* instead of rm -rf -- \*/ and it just started deleting everything. I manually interrupted the operation immediately after. But the server has shut down, and nobody is able to login. I think it needs a reboot from whoever has access.

This was Sunday night, which was last night. I told my manager on Slack but he hasn't responded yet.

Im absolutely terrified and I have no idea if any of it can be recovered. I've hardly been able to sleep before I wake up having a panic attack from a horrible dream.

&#x200B;

Edit: Update - I spoke to people. It looks like the reboot wasn't working because something called the ""partition file"" that is needed for reboot was deleted. But good news is that there's a daily backup that can be restored. But thanks everyone for your helpful advice.",2022-02-14 05:39:26
"What is the difference between data science, data analytics, analytics engineering and big data?",0,sruewf,https://www.reddit.com/r/datascience/comments/sruewf/what_is_the_difference_between_data_science_data/,7,1644790101.0,,2022-02-14 00:08:21
Why can't I open jupyter lab? Please help,0,srsjp8,https://www.reddit.com/r/datascience/comments/srsjp8/why_cant_i_open_jupyter_lab_please_help/,5,1644785267.0,"I have installed jupyterlab using the anaconda navigtor. After updating the anaconda navigator I am no longer able to open jupyterlab. Can someone please help??

I get the following error:

/Users/user/opt/anaconda3/lib/python3.8/site-packages/nbclassic/notebookapp.py:73: FutureWarning: The alias \`\_()\` will be deprecated. Use \`\_i18n()\` instead.  
\_(""Don't open the notebook in a browser after startup."")  
/Users/user/opt/anaconda3/lib/python3.8/site-packages/nbclassic/notebookapp.py:89: FutureWarning: The alias \`\_()\` will be deprecated. Use \`\_i18n()\` instead.  
\_(""Allow the notebook to be run from root user."")  
/Users/user/opt/anaconda3/lib/python3.8/site-packages/nbclassic/traits.py:20: FutureWarning: The alias \`\_()\` will be deprecated. Use \`\_i18n()\` instead.  
help=\_('Deprecated: Use minified JS file or not, mainly use during dev to avoid JS recompilation'),  
/Users/user/opt/anaconda3/lib/python3.8/site-packages/nbclassic/traits.py:25: FutureWarning: The alias \`\_()\` will be deprecated. Use \`\_i18n()\` instead.  
help=\_(""Supply extra arguments that will be passed to Jinja environment.""))  
/Users/user/opt/anaconda3/lib/python3.8/site-packages/nbclassic/traits.py:29: FutureWarning: The alias \`\_()\` will be deprecated. Use \`\_i18n()\` instead.  
help=\_(""Extra variables to supply to jinja templates when rendering.""),  
/Users/user/opt/anaconda3/lib/python3.8/site-packages/nbclassic/traits.py:62: FutureWarning: The alias \`\_()\` will be deprecated. Use \`\_i18n()\` instead.  
help=\_(""""""Path to search for custom.js, css"""""")  
/Users/user/opt/anaconda3/lib/python3.8/site-packages/nbclassic/traits.py:74: FutureWarning: The alias \`\_()\` will be deprecated. Use \`\_i18n()\` instead.  
help=\_(""""""Extra paths to search for serving jinja templates.  
/Users/user/opt/anaconda3/lib/python3.8/site-packages/nbclassic/traits.py:85: FutureWarning: The alias \`\_()\` will be deprecated. Use \`\_i18n()\` instead.  
help=\_(""""""extra paths to look for Javascript notebook extensions"""""")  
/Users/user/opt/anaconda3/lib/python3.8/site-packages/nbclassic/traits.py:130: FutureWarning: The alias \`\_()\` will be deprecated. Use \`\_i18n()\` instead.  
help=\_(""""""The MathJax.js configuration file that is to be used."""""")  
/Users/user/opt/anaconda3/lib/python3.8/site-packages/nbclassic/traits.py:143: FutureWarning: The alias \`\_()\` will be deprecated. Use \`\_i18n()\` instead.  
help=(\_(""Dict of Python modules to load as notebook server extensions.""  
/Users/user/opt/anaconda3/lib/python3.8/site-packages/nbclassic/notebookapp.py:122: FutureWarning: The alias \`\_()\` will be deprecated. Use \`\_i18n()\` instead.  
description = \_(""""""The Jupyter HTML Notebook.  
/Users/user/opt/anaconda3/lib/python3.8/site-packages/nbclassic/notebookapp.py:143: FutureWarning: The alias \`\_()\` will be deprecated. Use \`\_i18n()\` instead.  
help=\_(""""""Path to search for custom.js, css"""""")  
/Users/user/opt/anaconda3/lib/python3.8/site-packages/nbclassic/notebookapp.py:155: FutureWarning: The alias \`\_()\` will be deprecated. Use \`\_i18n()\` instead.  
help=\_(""""""extra paths to look for Javascript notebook extensions"""""")  
\[I 2022-02-13 20:36:52.591 ServerApp\] jupyterlab | extension was successfully linked.  
\[I 2022-02-13 20:36:52.591 ServerApp\] jupytext | extension was successfully linked.  
\[W 2022-02-13 20:36:52.771 ServerApp\] 'ExtensionManager' object has no attribute '\_extensions'  
Traceback (most recent call last):  
File ""/Users/user/opt/anaconda3/bin/jupyter-lab"", line 10, in  
sys.exit(main())  
File ""/Users/user/opt/anaconda3/lib/python3.8/site-packages/jupyter\_server/extension/application.py"", line 567, in launch\_instance  
serverapp = cls.initialize\_server(argv=args)  
File ""/Users/user/opt/anaconda3/lib/python3.8/site-packages/jupyter\_server/extension/application.py"", line 537, in initialize\_server  
serverapp.initialize(  
File ""/Users/user/opt/anaconda3/lib/python3.8/site-packages/traitlets/config/application.py"", line 88, in inner  
return method(app, \*args, \*\*kwargs)  
File ""/Users/user/opt/anaconda3/lib/python3.8/site-packages/jupyter\_server/serverapp.py"", line 2341, in initialize  
point = self.extension\_manager.extension\_points\[starter\_extension\]  
File ""/Users/user/opt/anaconda3/lib/python3.8/site-packages/jupyter\_server/extension/manager.py"", line 303, in extension\_points  
for value in self.extensions.values()  
File ""/Users/user/opt/anaconda3/lib/python3.8/site-packages/nbclassic/nbserver.py"", line 80, in extensions  
nb = self.\_extensions.get(""nbclassic"")  
AttributeError: 'ExtensionManager' object has no attribute '\_extensions'",2022-02-13 22:47:47
SQL vs Dataframe API,11,srp3vq,https://www.reddit.com/r/datascience/comments/srp3vq/sql_vs_dataframe_api/,9,1644776323.0,"Curious, what transformations are easier or less verbose with dataframe API versus SQL and vice versa?  Cumulative sums and running totals I think are easier with dataframe API 
, along with doing forward fills.  I was going to add flattening JSON, but I was pleasantly surprised by Snowflake's lateral flatten()  SQL function.  It was actually easier to grok I think versus pandas json_normalize()'s meta and record_path parameters.

Any other examples you can come up with?  This post was just born out of curiosity.  My personal philosophy is to use as much SQL as possible, then use Python or scripting as last resort.  With cloud data warehouses being more prominant, I feel like perhaps there is growing trend that there will be less reliance or usage of PySpark dataframe API in general.  Curious what examples others come up with!",2022-02-13 20:18:43
What is your Data Science superpower?,201,sroe4z,https://www.reddit.com/r/datascience/comments/sroe4z/what_is_your_data_science_superpower/,173,1644774542.0,"I've been working as a Data Scientist for 6 years now and in the first 2 or 3 years I used to feel as I if wouldn't have what it takes. My job title wasn't always Data Scientist. I had prior positions as Data Analyst and Business Intelligence Analyst. However, these titles seemed to represent my skillset rather poorly.

I have a background in cognitive neuroscience and made a PhD before going in the industry. For my PhD I developed statistical software applications, wrote interfaces for fMRIs and conducted fMRI studies (fun fact: fMRIs are designed for medical diagnostics, so if you want to do research with them you need to build custom software for handling the communication with the ""hardware""). Got into ""big data"" there, because one fMRI session can easily generate between 30-50GB raw data. Consider that studies usually have 30-50 participants and people are neither capable to hold still for an our nor do brains look the same. So getting the two images you put in your publication requires numerous preprocessing and normalization steps.

Long story short, neuroscientists don't excel at math. I tried to make up for that, but at some point I stopped, because focusing on your strength rather than your weaknesses is more beneficial imo. But I felt inferior for a long time. Don't get me wrong, I'm pretty decent with multivariate statistics and I understand the math behind most Data Science techniques pretty well, but this is simply not the domain I feel most comfortable with.

It took me a couple of years to understand that my ""superpower"" is to get stuff in production, build DS applications end-to-end and to get the C-level approval for starting in the first place (i.e. explaining why we need to do what without too much nerding around). I still build rather ""simple"" models ranging from classification to linear/logistic regressions or probability based systems. But most of the time, I leave the hardcore modelling to my teammates and when they're done, I make their stuff work. This can range from optimizing aggregates/ETL pipelines over increasing the performance of Python scripts by finding and fixing bottlenecks to integrating our algorithms seamlessly into a company's software architecture. You could argue that this is more a software engineering task, but in a lot of use cases it isn't. When you have a model that needs 20 hours for a nightly build, you can try to make it faster, but quite often the key is to reiterate and modify the features selection. For instance, you can build a feature based on all historical data, but when the underlying systems are not performing well enough, you can design a similar feature with comparable variance explanation using sampling or simply trying out another approach from a completely different angle. Since this requires deep feature design and selection knowledge, I consider it a Data Science task.

After getting a bit distracted by telling you ""my life's story"", here's what I'm curious about: Can you relate to this? And if yes: What is the Data Science task you excel in (aka your ""superpower"")?",2022-02-13 19:49:02
Can financial/crypto data actually be predicted well?,0,srn2rb,https://www.reddit.com/r/datascience/comments/srn2rb/can_financialcrypto_data_actually_be_predicted/,46,1644771259.0,"I'm a data analyst learning ML in my free time and I also dabble in crypto. I've tried using key metrics (price changes, volume, social metrics, etc) with Random forests and neural networks without much success. 

I'm considering trying a LSTM model given multiple time series but it seems that those models for financial data typically just overfit for the test data.

I know it probably isn't an appropriate question here but I just want to know if I'm going on a wild goose chase or is there some possibility of a model performing well for one week and one month forecasts?",2022-02-13 18:54:19
Discretising continuous features,16,srliqe,https://www.reddit.com/r/datascience/comments/srliqe/discretising_continuous_features/,29,1644767225.0,"Is there theory available for an either logical or mathematical way of discretising continuous data?. Im trying to fit a naive bayes model to some data but most features are magnitudes rather than tags. I can get good results but my data manipulation is subjective and biased by my models output (ie: I discretise data at my will given the models output). So is there a way to be sure like “this is how continuous data should be discretised”?. That could be a good starting point for my investigation.

Been on the job for a while, read some books but cant remember there being theory for this case.

Pd: both written explanations, links to articles and bibliography is welcome. Thank you for your time.",2022-02-13 17:47:05
Determining if model is giving FPs without ground truths.,3,srkrsp,https://www.reddit.com/r/datascience/comments/srkrsp/determining_if_model_is_giving_fps_without_ground/,1,1644765249.0,"I have a binary image classifier that’s used around my country and it seems to be giving a very high number of positive predictions localized to 2 provinces. We have nearly a million predictions to look at and I was looking for some ideas to start with, here are mine:

-  check model performance on data the model was tested on in that area to see if performance differs
- visually inspect images of lowest probability that were classified as positive for the anomalous area and a set from the non-anomalous areas to see if I can find any patterns/differences.
- cluster model embeddings in 2D and see if anything stands out

I’ve been a DS for a little while but focused on time series regression where I can get ground truths in real time. So debugging vision models is an entirely new realm for me.

Any ideas, advice, and personal experiences are very much welcomed!",2022-02-13 17:14:09
Building a Complete OCR Engine From Scratch In Python,0,srj6xd,https://www.reddit.com/r/datascience/comments/srj6xd/building_a_complete_ocr_engine_from_scratch_in/,0,1644760696.0,Ever thought of building your own OCR engine?. This article explains how you can do so step by step.,2022-02-13 15:58:16
Weekly Entering & Transitioning Thread | 13 Feb 2022 - 20 Feb 2022,13,srh5w1,https://www.reddit.com/r/datascience/comments/srh5w1/weekly_entering_transitioning_thread_13_feb_2022/,136,1644753630.0,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",2022-02-13 14:00:30
Git/cloudera cdsw,1,srgdwv,https://www.reddit.com/r/datascience/comments/srgdwv/gitcloudera_cdsw/,2,1644750554.0,"I'm an amateur (coding mainly just on pycharm and jupyter) whom just joined a company which uses git for codes storage and Ive barely started learning it. They are going to bring in cloudera cdsw soon. 

Does the latter replace the former, or are they complementary with each doing a specialized task?",2022-02-13 13:09:14
How to follow up after networking with someone?,10,srdy1y,https://www.reddit.com/r/datascience/comments/srdy1y/how_to_follow_up_after_networking_with_someone/,10,1644740661.0,"Recently I've been reaching out to some people on LinkedIn and I've had some pretty productive chats. The thing is, I never know how to continue the relationship afterwards. How do I keep the rapport so that it eventually becomes a meaningful relationship? 

Every person I've talked to has been said yes to me when I've asked if I could ever reach out to them if I had any questions, but it feels weird if the only thing we talk about is some \\ questions I may have. How do I go about actually establishing a meaningful relationship with them?

Thanks!",2022-02-13 10:24:21
I just want things to work,102,sracym,https://www.reddit.com/r/datascience/comments/sracym/i_just_want_things_to_work/,82,1644727557.0,"This isn't a technical support post, I just want to vent. 

I'm a complete beginner with a science background. I've finished about half of a Udemy course because I have a fantastic idea for a project that is both useful and relevant to my interests. 

I need geopandas for it to work, easy, I download the package and try to import it. Doesn't work, I broke the dependencies or something when I installed. Great. I had to reinstall anaconda because I was intsalling everything on root. Won't do that again. 

New environment, geopandas imports! Try to run a line of code from documentation and it breaks. Something is wrong with one of the dependencies again I spend like 2 hours trying to find out why and it seems like people have fixed this problem by importing one of the dependencies first. I tried that and I got a completely separate error message. I Google again I get another solution and now I have an error message that doesn't even appear on search results. 

Please, god, someone tell me this is normal, this level of struggling. I want to abandon this field altogether and burn my laptop. And dealing with these issues for days and I haven't even started my project yet. I don't want to deal with sorting out dependencies and packages I just want to look at bird migration damn it!!!",2022-02-13 06:45:57
Just realized that data science is literally just connect the dots,0,sr8onp,https://www.reddit.com/r/datascience/comments/sr8onp/just_realized_that_data_science_is_literally_just/,27,1644721952.0,I don’t know why some people gage keep this to be some 200 iq shit that only math PhDs can do it’s so easy,2022-02-13 05:12:32
Need some advice..,0,sr42wt,https://www.reddit.com/r/datascience/comments/sr42wt/need_some_advice/,10,1644707947.0,"I don’t know if this is the place to ask, but I need some advice. I’m currently a sophomore studying computer science, and I’m interested in possibly narrowing it down to data science instead. 

My school offers a Data Science major so I was thinking of doing that. However, I’m not the greatest at math (specifically calculus) and I just hate doing math in general. Is this a dealbreaker? 

My current path is majoring in computer science and moving on to becoming software engineer.

My two main interests are problem solving and finance, so I really want to mix the two together.  


Given this information, do you think I should stick with CS and do a software engineering or switch to data science? I’m somewhat familiar with data science but I’d like to learn more from you guys.",2022-02-13 01:19:07
Do you guys actually know how to use git?,575,squ4oq,https://www.reddit.com/r/datascience/comments/squ4oq/do_you_guys_actually_know_how_to_use_git/,211,1644680269.0,"As a data engineer, I feel like my data scientists don’t know how to use git. I swear, if it where not for us enforcing it, there would be 17 models all stored on different laptops.",2022-02-12 17:37:49
"Is it a thing to convert a messy spreadsheet into a small relational database for ease of use? Or would you use other cleaning/tidying techniques? Newbie here, advice very welcome!",4,sqtirh,https://www.reddit.com/r/datascience/comments/sqtirh/is_it_a_thing_to_convert_a_messy_spreadsheet_into/,10,1644678481.0,"Hi guys,

Newbie here, sorry if my questions are basic or don't make sense. I'll try to be as clear as I can.

I'm working on a very large, very messy (EDIT: It's not very large or messy, I am just inexperienced and it feels that way) datasheet for a college project in basic DA, and had the thought to convert it into a much more ordered SQL database for ease of use. The dataset I am using is from Kaggle, in case anyone wants to look: https://www.kaggle.com/pralabhpoudel/world-energy-consumption (It's not mine, I just picked it out because I like the topic, and I have a list of queries I want to make to see what insights might pop out for me).

Is this a silly idea? I'd kinda just like to know if this practice would be ""common"" or if it's outlandish. I don't want to get bad habits or go down silly rabbitholes this early.

Thanks for any advice!

EDIT: I should mention the project req is to demonstrate the ability to use (a) a direct file import (any format - hence excel is fine here), and (b) SQL, API or scraping....I was thinking killing 2 birds with the one stone.",2022-02-12 17:08:01
A/B testing strategies for outbound calling campaign,13,sqt4xc,https://www.reddit.com/r/datascience/comments/sqt4xc/ab_testing_strategies_for_outbound_calling/,6,1644677388.0,"Looking for advice on my current project. I am supporting a sales team responsible for direct customer outreach via outbound calling. This is a newly established team trying to enroll customers in a brand new service (launched two weeks ago.)

Currently, the sales team operates off a pre-sorted list of prospects ranked high to low according to each prospect's expected lifetime value. The sales team works down the list sequentially. We are considering other ways to rank prospects in order to increase conversion.

I am familiar with the basics of A/B testing, but I'm not sure how to implement in this context. Some challenges I've observed include...

- No existing conversion rate benchmark since the service is brand new.

- My experience with A/B testing is to test small changes one at a time. For this project, there is interest in trying various strategies, starting immediately.

- There are several variables I cannot control, including staff capacity, data quality, etc.

Any tips?",2022-02-12 16:49:48
NLP Project suggestion,1,sqsfgg,https://www.reddit.com/r/datascience/comments/sqsfgg/nlp_project_suggestion/,1,1644675159.0,"Hi,

Part of the bootcamp our 4th project is about NLP. Ideally storing it to MongoDB and from there rest is followed. Since I am new to all of these I am seeking advice to work on what is hot in the market would also make a great portfolio project. Considering I am new to the concept, I am open for your suggestions. Thank you so much.",2022-02-12 16:12:39
"ML pipeline, where to start",55,sqnydj,https://www.reddit.com/r/datascience/comments/sqnydj/ml_pipeline_where_to_start/,22,1644659001.0,"Currently I have a setup where the following steps are performed

* Python code checks a ftp server for new files of specific format
* If new data if found it is loaded to an mssql database which 
* Data is pulled back to python from views that processes the pushed data
* This occurs a couple of times
* Scikit learn model is trained on data and scores new data
* Results are pushed to production view

The whole setup is scripted in a big routine and thus if a step fails it requires manual cleanup and a retry of the load. We are notified on the result of failures/success by slack (via python). Updates are roughly done monthly due to the business logic behind.

This is obviously janky and not best practice.

Ideas on where to improve/what frameworks etc to use a more than welcome! This setup doesnt scale very well…",2022-02-12 11:43:21
Can anyone share any papers where a LSTM model out-performed a CNN and/or regression-based model? Everything I see online seems based on toy examples.,19,sqkmrz,https://www.reddit.com/r/datascience/comments/sqkmrz/can_anyone_share_any_papers_where_a_lstm_model/,12,1644646130.0,"Applying more advanced models to real solutions isn't at the ""cutting edge"" of data science, but it seems like there's a lack of literature around their actual applications.",2022-02-12 08:08:50
"For people who tried it or know someone who did or you can just give a good advice: Could be having a digital/social presence on YT and/or Instagram any benefit on my career (events, networking wise) or could it backfire?",1,sqi5e4,https://www.reddit.com/r/datascience/comments/sqi5e4/for_people_who_tried_it_or_know_someone_who_did/,7,1644637860.0,"So, we all mostly have linkedin / github and so on. And before any judgments I am not trying to be an influencer or whatever that is. I am considering doing this for specific goals and based on specific conditions. The content will mainly be about sharing my journey and demonstrate what I learned via videos etc. Def no like an x-faang content where I’d be giving tips or how to be data scientist..etc.

My condition: in my 30s, on career shift (not much though, as I do have background in Engineering however, my job roles before were managerial, and I hated every second of it), living in third world country where not much of opportunities to begin with and the idea of shifting career or not being satisfied with your job barely exist or got accepted. And yes my age too lol

Goals: I want to connect with data science community on international level. And more than just through following someone or talking in blogs..etc. I want to be exposed to more work/events opportunities abroad and I’ve seen some people that have used YT to demonstrate their abilities were able to do so.

I also, want to use it as a platform to encourage others to choose whatever they want to do in their life. Career wise or whatever! Learn something new and start over at whatever age.

And definitely hoping that it could be a source of an income one day.

With all that being said, I am concerned it could backfire on me, like companies would not be interested in hiring someone who are that active in this domain on social media. Or maybe they’d have higher expectations of me!

PS: just in case there would be any comments about 30s is not that old. We do have many jobs posts requiring someone to be no older than 29.",2022-02-12 05:51:00
About how much time did you invest in learning R or Python before you felt productive?,15,sqfs82,https://www.reddit.com/r/datascience/comments/sqfs82/about_how_much_time_did_you_invest_in_learning_r/,21,1644630635.0,"By ""productive,"" I mean that you can be given some basic spreadsheet data, screen it, clean up all different data types, run descriptive summaries, and create some basic data visualizations. I would be very appreciative if you could offer any of the following details.

* How many hours of day over what period of time
* Whether you have a coding or data background
* Any other limiting or supporting factors to consider

And, most importantly, what would you recommend to new learners? Especially new learners who do not have a coding or technical background.

I know the answers for this will be diverse. I hope to compile your stories, responses, suggestions, and ideas for new learners. Your contribution is greatly appreciated. Thanks in advance.",2022-02-12 03:50:35
How would you deliver a briefport done on a statistical analysis of 1 million data points?,0,sqdvze,https://www.reddit.com/r/datascience/comments/sqdvze/how_would_you_deliver_a_briefport_done_on_a/,2,1644625005.0,"So I just completed a multivariate regression based on a little over 1 million data points using fifteen blocks and five treatments with some solid results.

There’s clearly a top three choices and bottom five ones to avoid but other than a graphical analysis how do you generate reports?

The client never actually said how they wanted the outcome and I usually have very specific deliverable examples samples or requirements, but this guy has a masters degree in stats from a major school and I want to make a good impression.

Right now I am going to deliver him a colorized rendering of the actual regression, a simple spreadsheet, some of my Python code and a PDF of probably a page or two explaining the findings.

How would you deliver a statistical analysis and the explanation that goes along with it in layman‘s terms I mean is this just like one of those dual column research papers that I read on ARXIV and produce this in MLA format?",2022-02-12 02:16:45
"Tips on dealing with ""brain fry""?",45,sqaijg,https://www.reddit.com/r/datascience/comments/sqaijg/tips_on_dealing_with_brain_fry/,30,1644616024.0,"Hi all, I'm relatively new to the data science world and in the back half of a career transition from a completely different industry. I'm half way through a MS in Data Science program, and a few months ago, landed a new gig as a data analyst at a marketing agency. 

I'm loving my job so far. I've been learning a lot and have already applied a decent amount of things I've learned in school to my job. Work environment is good, culture is good, work/life balance is good....pretty much everything you could ask for in a new job. 

Lately, towards the end of some work days and weeks, I've been suffering from really bad ""brain fry"" - probably the best term I can come up with to describe it. I wouldn't necessarily call it burnout cause I'm enjoying my work. But some days I'll be working on a project or coding for most of the day, and by 5 PM, I just feel completely drained and exhausted from spending so much mental energy. Case in point, I'm posting this at 4:45 PM on a Friday because I'm dealing with it right now.

Just wondering if anyone else has dealt with similar things from working on big projects and if you have any tips on how to combat or avoid it. Likewise, maybe some reassurance from people with much more experience in the field who can tell me things will get better with more time and experience lol. 

Appreciate any advice!",2022-02-11 23:47:04
My new employer uses Backstop CRM to manage email campaigns to promote products. Any advice how to pull meaningful data from this thing?,1,sqa4l4,https://www.reddit.com/r/datascience/comments/sqa4l4/my_new_employer_uses_backstop_crm_to_manage_email/,1,1644614980.0,"I'm still learning the system. It seems kind of slow and unwieldy.

I'm proficient in python and know a bit of SQL. Any advice on how to deal with this clunky UI?",2022-02-11 23:29:40
Limitations of MAE / RMSE discussed in literature,17,sq9b77,https://www.reddit.com/r/datascience/comments/sq9b77/limitations_of_mae_rmse_discussed_in_literature/,6,1644612809.0,"I was reading this paper and I found that the section on error reporting was very nicely explained.

I don't know who this might be relevant for but who knows - maybe it helps one or two people:

>""Unsigned average errors (MAE or RMSE), although commonly reported and compared when discussing model performance, can sometimes underrepresent the actual errors during applications using the model.  
>  
>A better indication of the expected error (and the accepted convention) for the uncertainty in thermochemistry is given by its 95% conﬁdence interval (u95%), or twice the standard deviation (2σ), meaning only one out of every 20 values should be expected outside of the given uncertainty.  
>  
>Therefore, three main error statistics are needed to describe the spread of the errors of a method, mean absolute error (MAE), mean signed error (MSE), and 95% conﬁdence interval (u95%).  
>  
>MAE is a pure average of the magnitude of the diﬀerence between the measured (or calculated) value and its corresponding benchmark and is not easily skewed by outliers. MSE is an indication of the systematic error and is commonly reported as MSE ± 2σ since MSE is associated with the center of the 95% conﬁdence interval.""

Since (probably 🙂) not everyone gets as excited about quantum chemical calculations as I do I only quoted the relevant passages and referenced the paper at the end.   
I also liked their methodical explanation of over- /underfitting:

>""Typically in machine learning, a trade-oﬀ between bias and variance is observed, i.e., as the error on the training set (bias) decreases toward the irreducible error, the overall error on the test set (variance) increases.  
>  
>Additionally, models with a low bias and high variance are thought to be overﬁtted to the training data, since they feature low errors on the training data but high errors on the test set, while large biases indicate underﬁtting. An ideal model, neither under-nor overﬁt, will produce low errors for both the training and test sets, though minimizing these two errors simultaneously is not a simple task.  
>  
>The test set error is only calculated once, after the model is completely trained on the training data, and model hyperparameters cannot be tuned based on the performance of the test set. Cross-validation helps mitigate this problem by choosing the hyperparameters which minimize the overall validation set errors. If the data is balanced, and both the test and validation sets are representations of the full data set, this will minimize the error on the unseen test set. Analysis of these errors, shown in Table 3, gives more insight into model performance than the ﬁnal out-of-sample MAE.""

  
 Link: [https://pubs.acs.org/doi/10.1021/acs.jcim.6b00340](https://pubs.acs.org/doi/10.1021/acs.jcim.6b00340)   


\[Edit: formatted the quoted sections\]",2022-02-11 22:53:29
Is there a substitute for shap.KernelExplainer for time series forecasting?,4,sq8w48,https://www.reddit.com/r/datascience/comments/sq8w48/is_there_a_substitute_for_shapkernelexplainer_for/,1,1644611651.0,"I am working on a series of forecasting models with high dimensional input, so varying each time lag of each feature is both too computationally expensive to be feasible and unlikely to give reasonable results. Is there a way to provide user-defined ""superpixel""-esque time segments to mask for KernelExplainer or a similar tool?

I'm probably going to have write my own code for eventually but it would be very good if I could get an approximate solution put together quickly.

I'm not able to use anything that interfaces directly with TF/Pytorch as I have a lot of preprocessing steps that need to be included in the explanation.",2022-02-11 22:34:11
any useful datasets or lists of all English words? The ones I'm seeing contain many non-words,6,sq7tz9,https://www.reddit.com/r/datascience/comments/sq7tz9/any_useful_datasets_or_lists_of_all_english_words/,2,1644608781.0,"Hi, I need to do regex searches of English words in Python. I'm looking at several such as these:

[https://github.com/dwyl/english-words](https://github.com/dwyl/english-words)

[https://www-personal.umich.edu/\~jlawler/wordlist](https://www-personal.umich.edu/~jlawler/wordlist)

They contain entries such as swizz, cr, dg, ob,  podicipitiformes,  scrimshanker, and others that don't seem to be actual words. Or even if they are, they are extremely rare. Or it depends on how you define ""word"". 

Does anyone know of a ""common use"" list of English words? 

I looked at NLTK which has a variety of corpuses, but then there are many to choose from.",2022-02-11 21:46:21
Is anybody trying to start a blog on datascience?,0,sq5wfl,https://www.reddit.com/r/datascience/comments/sq5wfl/is_anybody_trying_to_start_a_blog_on_datascience/,11,1644603580.0,"Hi,

I am trying to start my personal data science blog (won't post the link).

I am motivated by multiple reasons: personal branding, learning new stuff, consolidating knowledge, improving my English writing skills and storytelling,  .... and possibly finding a good niche and likewise people.

I already did a couple of posts aiming at about 1 post per month this year. Keeping the motivation isn't easy and getting good feedback from other people doing the same would be very valuable.

How did you do at the beginning? Have you got some experiences to share?",2022-02-11 20:19:40
Does industry care about odds or probabilities in “classification” (logistic regression) tasks?,12,sq5ueo,https://www.reddit.com/r/datascience/comments/sq5ueo/does_industry_care_about_odds_or_probabilities_in/,12,1644603421.0,"I’m taking a generalized linear models course at the moment, and we have spent several weeks learning about logistic regression. One thing we learned was how the response of logistic regression, depending on if you apply the right transformations, you can talk about how your response variable in terms of odds or probabilities. You can build confidence intervals for both of these. What had me wondering was which is more useful for a business case perspective, ie for anyone whose doing logistic regression tasks often, do you guys share your results in terms of the odds ratio, or probabilities? One of my professors says it depends on the industry, in that in clinical trials odds is more useful, but I would have thought probabilities would be a more practical way of sharing results? Any thoughts on this? Do you guys interpret parameters in odds or probabilities?",2022-02-11 20:17:01
How often do you read research articles for work? For personal projects?,49,sq2wsy,https://www.reddit.com/r/datascience/comments/sq2wsy/how_often_do_you_read_research_articles_for_work/,34,1644595734.0,Curious how often people refer to research articles (not just blog posts or tutorials) for work or personal projects. Do you maintain subscriptions to any publications or just look up articles ad hoc based on your current projects?,2022-02-11 18:08:54
Tonic.ai,0,sq0rnh,https://www.reddit.com/r/datascience/comments/sq0rnh/tonicai/,0,1644589959.0,I keep seeing YouTube adds pop up for this product and it seems interesting. Has anybody used this and can give feedback on its value?,2022-02-11 16:32:39
What should data analysis & visualisation infrastructure look like for asset management?,5,spwyw3,https://www.reddit.com/r/datascience/comments/spwyw3/what_should_data_analysis_visualisation/,8,1644577657.0,"tl;dr: Tell me what you know about rolling out BI systems in a large organisation (please)

Hello! I'm an aspiring data-scientist, keen to have some help for my first project in an asset management job (for the state's portfolio of public schools).

I'm in the strategy unit, so most of the data / KPIs involved are about things like percentage of unused space in the portfolio, amount of schools compliant with various OHS or enviro regulations, proportion of defects that are addressed within a 12 month period... you get the idea.

They want me to figure out the best way to overhaul the way data visualisation reports are produced. The problem is that the data comes from a dozen databases and random other areas. However, a comprehensive database is gradually being built, which I believe uses PowerPlan & IBM Maximo.

My hypothesised plan is as follows:

Short-term fix: Build a basic strategic dashboard in Power BI where calculated values are manually entered (which will be an upgrade on their current system -manually pasting Excel graphs into PowerPoint after hounding external Units for their stats).

Long-term strategy: Build 5-10 automated 'operational dashboards' which each belong to individual Units. The data in these dashboards then feeds into the 'strategic dashboard'. The idea being that this would provide a cohesive business intelligence system that would streamline data analysis across the entire organisation.

\_ \_ \_ \_ \_ \_ \_ \_ \_

Feel free to give me any suggestions; software, structures, resources, correct me butching data jargon, whatever you like. I really need all the help I can get. Thankyou!",2022-02-11 13:07:37
Best Kaggle notebook that uses Python to perform EDA and analysis?,0,spvdsc,https://www.reddit.com/r/datascience/comments/spvdsc/best_kaggle_notebook_that_uses_python_to_perform/,1,1644571593.0,"Looking for some recommendations for notebooks that includes a comprehensive analysis / EDA performed on any subject as a reference for learning purposes

(Links to them will be helpful as well)


Appreciate it !",2022-02-11 11:26:33
What more can I do to learn more comprehensively?,2,sptou6,https://www.reddit.com/r/datascience/comments/sptou6/what_more_can_i_do_to_learn_more_comprehensively/,0,1644565045.0,"I’ve been taking Python data science and machine learning courses on Sololearn and Udemy for a little while now.  So I’m starting to get a familiarity with the process of machine learning and data science, but I don’t think I’m at a level where I could put myself in the world just yet for work.  Plus I’m a little concerned about the dev env of Jupyter notebook, because it seems like a data scientist would have more tools at their disposal to collect/clean data, and create models to train and test.

After courses like those, what are some learning resources I could get into?",2022-02-11 09:37:25
How would you explain Data Science to a 6-year old kid?,24,spszy3,https://www.reddit.com/r/datascience/comments/spszy3/how_would_you_explain_data_science_to_a_6year_old/,41,1644562601.0,,2022-02-11 08:56:41
Rejected from my first round of applications,9,spnsou,https://www.reddit.com/r/datascience/comments/spnsou/rejected_from_my_first_round_of_applications/,35,1644546476.0,"Trying to make the transition from a non-technical ph.d. program to data science. I have some solid projects on my GitHub and have done a good amount of modeling in my research, but nothing in terms of industry experience.

I feel like if I could get to the interview stage I could hold my own in terms of ML, stats, python, and SQL. Unfortunately, so far all these companies are asking for 3+ years experience and I feel like my resume is getting tossed out of hand. I have a BA in CS, but my other two degrees are in education.

Any advice on how I can get past the initial resume screen? Is adding more projects to my GitHub futile? Do I just need to go back to a coding boot camp so I can get a degree in DS?",2022-02-11 04:27:56
"Data scientists who use their skills to earn extra money aside from their main jobs or use these skills in investment, how do you do this ? How did you start ?",368,spncfr,https://www.reddit.com/r/datascience/comments/spncfr/data_scientists_who_use_their_skills_to_earn/,236,1644545202.0,,2022-02-11 04:06:42
Cable companies competitive data science,0,spm45f,https://www.reddit.com/r/datascience/comments/spm45f/cable_companies_competitive_data_science/,0,1644541737.0,Hi I was curious and working on a project to help cable companies assess competitors and new builders in their area. Any idea how do companies use data science or any recommendations for books etc.,2022-02-11 03:08:57
Experience with Great Learning programs,0,spm1tl,https://www.reddit.com/r/datascience/comments/spm1tl/experience_with_great_learning_programs/,2,1644541545.0,"I’m interested in taking the following course offered by Great Learning  it’s called: Data Science and Machine Learning: Making Data-Driven Decisions program by MIT Institute for Data, Systems, and Society (IDSS). I like this program because it’s not that long and not terribly expensive. I was trying to find reviews about it as I’ve never heard of the platform “Great Learning” before.  I’m American and native English speaker and I’m a little worried about how well I’ll be able to understand the lectures as it’s all remote and from what I’ve seen online that this “Great Learning” company is based in India so not sure if many of the lectures will be taught be native English speakers or not. 

Also im hoping not to offend anyone with my concerns about being able to understand.  I have adhd and already struggle at times with understanding other native English speakers. 

Cheers and thank you!",2022-02-11 03:05:45
What's a really good book that describes how statical concepts were developed?,35,spl3v9,https://www.reddit.com/r/datascience/comments/spl3v9/whats_a_really_good_book_that_describes_how/,19,1644539054.0,"I want a book that walks me through the thought of how statistical concepts came to be. The intuition that spawned the concept. I understand topics a lot better when I understand the context in which they were invented, and feel like there has to be others that feel the same way. Any recommendations where to start looking?",2022-02-11 02:24:14
"If you use a laptop, what kind of laptop do you use?",1,spkd8f,https://www.reddit.com/r/datascience/comments/spkd8f/if_you_use_a_laptop_what_kind_of_laptop_do_you_use/,6,1644537154.0,"Hi everyone! I’m looking to transition into Data Science and so I’m trying to learn different programs. I already work with Matlab for research. I currently have a 2018 Macbook Pro (15 inch) and I’ve found that it doesn’t work too well with Matlab. People I know who use Python love their Macbook and I also liked it when I worked with Python. However, my laptop doesn’t even have enough space to update, let alone be able to work with different programs downloaded. So I was wondering what laptops you guys use or do you use a PC? Should I bother investing in a new laptop?",2022-02-11 01:52:34
Data Scientist vs. ML Engineer vs. Data Engineer for Coding,4,spic8e,https://www.reddit.com/r/datascience/comments/spic8e/data_scientist_vs_ml_engineer_vs_data_engineer/,29,1644530499.0,"I’d love to ask what everyone here considers the best of the three career path options in the title for someone who enjoys coding more than the theory, presentation, and visualization elements of data science.

Thank you!",2022-02-11 00:01:39
Why did you choose Data Science over SWE?,30,sphwy8,https://www.reddit.com/r/datascience/comments/sphwy8/why_did_you_choose_data_science_over_swe/,39,1644529388.0,"Title. Why did you choose Data Science over SWE? I’m about to be a college grad debating which field to try breaking into (my degree is geared more towards Data Science), but I’d love to hear your personal opinions. From some YouTube videos I’ve watched, it seems like Data Science mixes business with statistics and coding (whereas SWE is majority coding) but I am interested if this generalization holds true in your real jobs. 

Thank you so much for any insight and guidance!",2022-02-10 23:43:08
Do people here stick to one industry or shop around?,3,sphjje,https://www.reddit.com/r/datascience/comments/sphjje/do_people_here_stick_to_one_industry_or_shop/,9,1644528391.0,"I have seen a few posts in this sub talking about the importance of having domain expertise. I would probably fall into the category of having good domain knowledge along with data analytics/science abilities, but by no means would I consider myself an ML guru. That being said, sometimes I feel like I am pigeonholing myself to the industry I am in. For context, this is in the real estate development and homebuilding industry, which in my experience is ripe for technological and data disruption. I am somewhat encouraged by this bit, but often think that it might be a mistake to go all in on one industry. Looking to get some thoughts from people here.",2022-02-10 23:26:31
"1 Stone, 3 Birds: Finer-Grained Encryption @ Apache Parquet - Subsurface Live Winter 2022 (Register Now - Live Online March 2/3)",0,spg13n,https://www.dremio.com/subsurface/live/winter2022/session/1-stone-3-birds-finer-grained-encryption-apache-parquet/,0,1644524408.0,,2022-02-10 22:20:08
"UK: 23 million pounds to create 2,000 scholarships in AI and data science in England",0,spfk6e,https://wire.mpelembe.net/index.php/uk-business/?rkey=2022021020220210102&filter=9768,0,1644523248.0,,2022-02-10 22:00:48
Data science theory books if I already know basic statistics?,0,spev5t,https://www.reddit.com/r/datascience/comments/spev5t/data_science_theory_books_if_i_already_know_basic/,3,1644521540.0,"What books cover topics like feature selection, Lasso, bias, variance in a relatively straightforward way ( kinda like the Statequest channel in YT)? Preferably in a business context.

I am well familiar with the usual statistical concepts like regression, Chi-square, etc., Thanks!",2022-02-10 21:32:20
How much % of your work as Data Science is spent...,159,speaxy,https://www.reddit.com/r/datascience/comments/speaxy/how_much_of_your_work_as_data_science_is_spent/,103,1644520126.0,"Question to all the people on this sub with the job title Data Scientist: how much % of your work as Data Science is spent doing actual data science / bulding and testing ML algorithms VS other stuff (data cleaning, database management, ETL processes, dashboards, ad-hoc reports, meetings, consulting... etc) ?

What are the parts of your job that you love, the ones you like, the ones you tolerate and the ones you hate?",2022-02-10 21:08:46
Recommendations for Map Visualisation Libraries?,7,spdyqv,https://www.reddit.com/r/datascience/comments/spdyqv/recommendations_for_map_visualisation_libraries/,12,1644519318.0,"Hi, 

My client wants some data visualised onto some maps of the united kingdom for some reports. (ex. stats for counties/regions/specific locations) I've looked a lot online but mostly only found libraries that are for manipulating interactive maps (googlemaps, etc) embedded on a website. 

It can be in almost any language (Python, JS, or R preferred), Thanks in advance.",2022-02-10 20:55:18
Anyone get annoyed by scrolling the notebook table horizontally and end up slightly out of the table and navigated to the previous page?,2,spdw8a,https://www.reddit.com/r/datascience/comments/spdw8a/anyone_get_annoyed_by_scrolling_the_notebook/,2,1644519144.0,This is for Databricks Notebook. Would love to see if there's any fix on this. My Google-fu on this is weak since everything is on disabling the entire chrome previous and next page which I don't want.,2022-02-10 20:52:24
Making 55k/ye + benefits as Entry Level Data Analyst,2,spcet5,https://www.reddit.com/r/datascience/comments/spcet5/making_55kye_benefits_as_entry_level_data_analyst/,5,1644515429.0,"I have a bachelor's degree in mathematics and computer science. 

I don't need much and I don't mind making less. I work remote, but here's the thing: I literally put in less than 20 hours a week if that and I have unlimited PTO. My job is super easy.

I do have a desire to strengthen my skills and I'm not sure this is exactly the route to make it better. 

I may be able to go to another place remote and make 75-80k plus a year and maybe transitioned into a data scientist role later, but I figured that will come with a much higher payload.

Should I look for a second job and at what salary? I am based in the US and I now have two years of experience in data analysis in tech.",2022-02-10 19:50:29
Lack of product sense/domain knowledge. How to improve?,9,spaanh,https://www.reddit.com/r/datascience/comments/spaanh/lack_of_product_sensedomain_knowledge_how_to/,8,1644509861.0,"I am a seasoned DS with a phd in industrial engineering.   I  interviewed a fintech company who issues credit card to low-credit population. In the second round of tech interview, the feedback is shown below:

>The feedback was that despite your lack of domain experience, where *some* guidance is expected, the role requires an independent vs task oriented mentality. This is not to say they didn't feel you have solid technical skills, it's more so that today, for these initial key roles in a young company the expectations are higher and criteria narrow.

The task was a data preprocessing to flag who's risky in terms of default on a loan. 

I am not in the fintech industry, so how can improve to become  INDEPENDENT minded?",2022-02-10 18:17:41
Suggestions for an online course to learn Tableau? I live in QC Canada but willing to take overseas courses online,1,sp98ro,https://www.reddit.com/r/datascience/comments/sp98ro/suggestions_for_an_online_course_to_learn_tableau/,3,1644507146.0,,2022-02-10 17:32:26
Does your Anaconda Navigator get stuck?,1,sp7p3e,https://www.reddit.com/r/datascience/comments/sp7p3e/does_your_anaconda_navigator_get_stuck/,10,1644502825.0,"I'm wondering if it is user error or a common issue. If I leave my anaconda navigator open overnight,  it is unusable the next morning. It will load load and load but never respond to anything. 
Is it the case for you too?",2022-02-10 16:20:25
Job Title Advice? I don't think I've crossed the line to Data Scientist yet,49,sp6btu,https://www.reddit.com/r/datascience/comments/sp6btu/job_title_advice_i_dont_think_ive_crossed_the/,21,1644498769.0,"For the last two years My company has started dipping it's toes into the water with Machine Learning. We partnered with an AutoML tool called [dotData](https://dotdata.com/) and water training I was the most the comfortable and have been leading the charge since.

Since then we've attempted 3 Machine Learning projects with one being successful and implemented (using Cluster, PCA to help organize our warehouses better).

I'm currently a Business Intelligence Analyst on a small team of 6 that's the entire data for our company. I spend probably 80% of my time writing on projects that aren't ML related. DBA type projects, ETL projects, simple Reporting or fleshing out B.I. tools/reporting.

This year we have several DS projects I'll be working on my there's still a small part of my job probably less than a third for the upcoming year. Building a classification model related to inventory discrepancies. Sales Forecasting and an Optimization project related to which order to pick together in our warehouse. I'm also currently in the OMSA program at Georgia Tech to increase my Analytics/DS knowledge.

The company is reevaluating job titles in IT since many are outdated and don't match what people are currently doing. I really enjoy Data Science and wanna eventually be a Data Scientist. I'm debating if I'm at the point I should choose that as my job title.

I know the majority of DS work isn't building models, but I feel there's a difference between 80% if your job not being models and 80% being non-DS projects. And I'm fearful if I pick that job title before I'm doing a larger amount of DS work I'll really just be an imposter and have a job title that doesn't line up with that I actually do.

What are your thoughts? Should I stick with a job title like Analyst for now? Is my work load have enough DS stuff to make the cut? Is there an inbetwen job title that better covers me?",2022-02-10 15:12:49
What is a use case for Spark on a local machine,75,sp3m6l,https://www.reddit.com/r/datascience/comments/sp3m6l/what_is_a_use_case_for_spark_on_a_local_machine/,44,1644489151.0,"If Spark is for distributing data science across clusters, is there any use for it purely on your local machine? Perhaps if you had a GPU?",2022-02-10 12:32:31
Do you run AB tests with operations at your company?,6,soznvg,https://www.reddit.com/r/datascience/comments/soznvg/do_you_run_ab_tests_with_operations_at_your/,10,1644474096.0,What are the typical experimental designs used? Do you find it hard to use a rigorous one? My experience at a startup that relies strongly on human labor has been that’s it almost impossible to run a rigorous experiment. What is your experience?,2022-02-10 08:21:36
Advice to soon be interviewer?,0,sov08l,https://www.reddit.com/r/datascience/comments/sov08l/advice_to_soon_be_interviewer/,2,1644460038.0,"I am a data scientist coming from the world of academia (2 years doing DS work as physics grad student and 1 year as postdoc) I have about 2 years industry experience in DS proper. Due to some recent resignations and opportunities seized on my part, I am in line for a managerial position. One of the first acts that will need to be done is hiring…. I’ve never done this !  Does anyone with experience have any great advice for this new adventure of mine or DS managerial advice in general?",2022-02-10 04:27:18
How does one go about model deployment in a prod environment? Always been curious.,15,sou1xu,https://www.reddit.com/r/datascience/comments/sou1xu/how_does_one_go_about_model_deployment_in_a_prod/,5,1644457408.0,What differs from software development? What are some leading tools to use? Any tips or advice to someone starting out?,2022-02-10 03:43:28
Does anyone have experience with Decibel?,0,sotupi,https://www.reddit.com/r/datascience/comments/sotupi/does_anyone_have_experience_with_decibel/,2,1644456821.0,I can't find a single reddit post on this tool and their website resources are super minimal..  have a few questions and hoping someone here might have some insight.,2022-02-10 03:33:41
My journey from a data entry job to 100K+ as a DA (3 years),11,sotpjl,https://www.reddit.com/r/datascience/comments/sotpjl/my_journey_from_a_data_entry_job_to_100k_as_a_da/,12,1644456397.0,"I want to preface this by saying I've had some personal things that set me back a bit and caused me to lose momentum after graduation. however, after graduating in 2018 with a degree in economics from a state school I applied to basically any job with data in the name. This is the first tip you have to just get a job as close to your dream as possible. Once you get it take any opportunity to do the kind of work you want your next job to be. After 3 months start looking for the next step. you probably won't find it until around 6 months to 1 yr at the first job. for me, it was a data analyst job that paid 45k. I knew it was low for the title but I didn't care AT ALL. I took it and learned as much as I could. I made sure to utilize SQL and R and excel as much as possible. Try as hard as possible to do that. it will be the single thing that gets you the real DA role you want. 95% of my colleagues in this role were not using these tools. They would barely use excel and just run SQL scripts that are pre-written. 

&#x200B;

TLDR: The saying dress for the job you want not the job you have is BS. but the equivalent for job duties is definitely real. Do what you want to do if it means going above and beyond at your shitty role then so be it. You need to leverage the opportunities you have to get better ones.",2022-02-10 03:26:37
Data Analyst & Data scientist offers,14,sorvap,https://www.reddit.com/r/datascience/comments/sorvap/data_analyst_data_scientist_offers/,24,1644451168.0,"Hi all, I got two offers, one as a data analyst (insights, visualisations...) in a start up company with 3.4 rating in glassdoor, and the other as a data scientist in a big consultancy company with 4.2 rating. The data analyst salary is £15.000 more. But I am leaning in the data scientist role since I believe I will learn more and further expand my technical skills. Do you think I am taking the right decision?",2022-02-10 01:59:28
How does your company keep track of the impactful events that have happened?,9,soqyys,https://www.reddit.com/r/datascience/comments/soqyys/how_does_your_company_keep_track_of_the_impactful/,5,1644448693.0,"I find that as a data scientist, we do a lot of work explaining what happened in a business context, what was the impact, and recommending what to do next.

The thing is, all of my team's work is decentralized and I don't really know what's happening at a high level. Is that a struggle that you have faced and have you teams solved it some how?",2022-02-10 01:18:13
Remember stories of people beating the lottery with statistics?,0,soq6q2,https://www.reddit.com/r/datascience/comments/soq6q2/remember_stories_of_people_beating_the_lottery/,31,1644446650.0,"I need one of you beautiful, programming, degenerates to help me beat a game.

There’s an NFT/crypto game I know of that looks ripe for getting an edge through data analysis/machine learning.

The website has apis and everything. Plz reply and let’s get the bag",2022-02-10 00:44:10
How do you oversample a time series without breaking the relationship of the data points?,5,sop1re,https://www.reddit.com/r/datascience/comments/sop1re/how_do_you_oversample_a_time_series_without/,4,1644443655.0,"I’m working with time series data and my target variable is multi-class categorical and the classes are severely unbalanced. 

Ex of my target class distributions 

[0] : 10
[1] : 4 
[2] : 471 
[3] : 37 
[4] : 111

So my models give zero thought to classes 0,1,3 and mostly predict class 2 and maybe a handful of predictions are class 3

So I wanted to oversample the data using SMOTE but since the data is a time series, won’t the SMOTE oversamples “break” the time relationship between the observations because it will randomly insert the the new observations? 

Does it matter in this case or is there a unique way around this?",2022-02-09 23:54:15
How long to curate data and conduct analysis?,0,sop1h3,https://www.reddit.com/r/datascience/comments/sop1h3/how_long_to_curate_data_and_conduct_analysis/,0,1644443636.0,"Hi all,


I got my first big boy job as a consultant at a Big 4 and am currently working on a workstream that  involved creating an outreach approach, collecting the data, curating the data, and creating an analysis. 


My partner and I have had to curate ~1000 open ended responses on pretty unfamiliar topics and create a meaningful analysis in about 2 weeks time on top of other typical job duties. 


I am tired, but almost at the finish line. Is this a typical timeline for something of this scale?",2022-02-09 23:53:56
Moving from structured reporting role to very open ended role,0,soozds,https://www.reddit.com/r/datascience/comments/soozds/moving_from_structured_reporting_role_to_very/,0,1644443482.0,"I've worked for over 5 years in a fairly structured data analytics/finance reporting role working with technical teams, and just got an offer to a position in state government to do 'be the data guy' and I would be the *only* data guy.  It will be very open ended, and includes things like finding and arranging for data from various persons/sources, gathering it and creating/publishing visualizations for public informational use.  The new role would include moving to a new open-source scripting platform largely on my own, which I have found daunting in the past.  This would be a bit of a pivot in my career from data/finance analytics to data management and visualization I think.  As near as I can tell this role would be light on statistics, modeling, Big Data, and cloud things.

I'm conflicted because I am very comfortable and effective in the position I am at, but also growing more and more 'bored' with each series of quarterly reports.  I'm worried because some of my weaknesses can become issues in an unstructured/solo environment where I don't have someone I can look to for answers/solutions to tough questions. Don't get me wrong, I solve my fair share of issues/problems on my own but I'm also prone to getting stumped and stuck in 'runaway brain mode' when there's too much to manage and talking to someone else that is data savvy usually helps me re-focus.

Has anyone come up to a similar crossroads before?  Suggestions/Advice/Experiences would be greatly appreciated.",2022-02-09 23:51:22
Real World Example of Machine Learning on Rails,0,soogfv,/r/SerpApi/comments/soob29/real_world_example_of_machine_learning_on_rails/,1,1644442082.0,,2022-02-09 23:28:02
question about attribution models for data scientists in the marketing realm.,3,sonu9b,https://www.reddit.com/r/datascience/comments/sonu9b/question_about_attribution_models_for_data/,5,1644440464.0,"I was reading [an article](https://www.semanticscholar.org/paper/Data-driven-multi-touch-attribution-models-Shao-Li/09c397be5c654041d55451022396b2ed26f0f56a)  about data driven multi touch attribution models. In the article, the  authors propose a couple alternatives to the first/last click models  we're so accustomed to.

On, page 2, the authors write:

>In  addition to the lack of a true data-driven MTA model,a good metric to  evaluate different MTA models is not avail-able either. Intuitively, a  good MTA model should have ahigh degree of accuracy in correctly  classifying a user aspositive (with a conversion action) or negative  (without aconversion action)

What  does it mean for an MTA model to have high accuracy in classifying  users as converters vs non-converters?Put another way, how can one use a  model, say a last touch attribution model, to predict whether a user  will convert or not convert?  
To me this doesn't make sense. I thought  attribution models tell us how many existing purchases can be  attributed to a media source. That is, they assume purchases have been  made, and then tell us what source is responsible for which purchase.  They cannot be used to forecast if a user will purchase looking at their  user journey",2022-02-09 23:01:04
What are some Alteryx use cases that can save a company money?,2,sonsnq,https://www.reddit.com/r/datascience/comments/sonsnq/what_are_some_alteryx_use_cases_that_can_save_a/,2,1644440382.0,"I recently saw a demo on Alteryx and it looks like a neat tool for a non-coder such as myself. I was wondering if anyone knows any good use cases for the tool for detecting mistakes/errors. I work for a windshield replacement company.  


One thought I had was maybe we could use the tool to detect duplicate refunds/payments to customers or maybe detecting delays (i.e. we didn't complete the work on time or parts didn't come in).",2022-02-09 22:59:42
"DS/DE/DA's with industry specific experience, especially healthcare, are you getting recruited hard right now?",91,somgs0,https://www.reddit.com/r/datascience/comments/somgs0/dsdedas_with_industry_specific_experience/,58,1644436898.0,"Often times in this sub I get the impression sub that supply far outweighs demand and jobs are very difficult to get, so I wondered if it was industry specific. 

I've been healthcare for 10+ years and lately I am getting blown up on LinkedIn. Anyone else in healthcare experiencing the same? It might be because I have experience with both Epic and Cerner which are the 2 primary EMR's in the market. Like this week someone reached out (I don't have #open to work turned on on my LinkedIn) with an insane (high) salary on a remote position. Downside was that it was contract to hire and I'm not much of a risk taker. Curious what others are feeling.",2022-02-09 22:01:38
Different results in production vs evaluation - Keras Deep Learning,1,soluof,https://www.reddit.com/r/datascience/comments/soluof/different_results_in_production_vs_evaluation/,6,1644435314.0,"I have built a cryptocurrency regression model but it performs different in real-life then the evaluation over the same period.

I am using exchange binance. In production I call my custom the predict() function each 15min just after the new data sample has closed. Since data is real-time I use the sample at index `-2` because `-1` is real-time and will still change. I also specify the timestamp of the sample I want in the predict() function so there are no mismatches.

I ran the program from 05-02-22 (DD-MM-YY) till 09-02-22 but when I evaluate over the same period it shows very different results: (BTW the model is not trained over this period)

    Real Life:
     * profits: -7.5
     * precision: 0.40
     * trades: 10
    
    Evaluation over the same period:
     * profits: 5.32
     * precision: 0.72
     * trades: 25

So I tested if there was an error in the prediction code. When I call my custom predict() function for each timestamp `[05-02-22 00:00, 05-02-22 15:00, 05-02-22 30:00, ..., 09-02-22 XX:XX]` and then evaluate the results. It is exactly the same as the evaluation results. Therefore I conclude there is no error in the predict() function which causes this.

Does anyone have any idea what could cause this?

The custom predict function (Don't know if it helps).

    # predict symbols.
    def predict(self,
    	# single symbol to predict.
    	symbol=None,
    	# the symbols to predict.
    	symbols=[],
    	# the expected timestamp.
    	timestamp=None,
    	# hide the errors.
    	hide_errors=False,
    	# use multiprocessing.
    	multiprocessing=False,
    	# max processes.
    	max_processes=15,
    ):
    
    	# by single.
    	if symbol != None:
    
    		# fetch df <-- Same function used in training & evaluation.
    		X, Y = self.fetch_symbol(symbol=symbol, lookup=False, mode=""live"")
    
    		# check empty dataframe.
    		if len(Y) == 0:
    			raise exceptions.EmptyDataFrame(f""{symbol} - Encoutered an empty dataframe."")
    
    		# slice df.
    		if timestamp == None:
    			X = X[len(X)-1:len(X)]
    			Y = Y[len(Y)-1:len(Y)]
    		else:
    			timestamp = int(Date(timestamp).to_seconds())
    			for index in [-1, -2]:
    				if int(Y.iloc[index][""timestamp""]/1000) == timestamp:
    					X = X[len(X)+index:len(X)+index+1]
    					Y = Y[len(Y)+index:len(Y)+index+1]
    					break
    			if len(Y) != 1:
    				if not hide_errors:
    					logging.log(f""&RED&Error&END&: Unable to find timestamp '{Date(timestamp)}' in the {symbol} dataframe."")
    
    		# predict.
    		timestamp = Date(Y.iloc[0][""timestamp""]/1000)
    		if multiprocessing:
    			return [[symbol, timestamp, X]]
    		prediction = float(self.model.model.predict(X)[0][0])
    		return [{
    			""timestamp"":timestamp,
    			""symbol"":symbol,
    			""prediction"":prediction,
    			#""lookup"":Y.iloc[index][""lookup""],
    		}]
    
    	# by multiple.
    	else:
    
    		# single process.
    		if not multiprocessing:
    			loader = ProgressLoader(f""Predicting {len(symbols)} symbols."", max=len(symbols), calc_finish=True, log_duration=True)
    			possibilities = []
    			for symbol in symbols:
    				try:
    					possibilities += self.predict(symbol=symbol, timestamp=timestamp)
    				except exceptions.InvalidDataFrame as e:
    					if not hide_errors:
    						logging.log(f""&RED&Error&END&: {e}"")
    				except exceptions.EmptyDataFrame as e:
    					if not hide_errors:
    						logging.log(f""&RED&Error&END&: {e}"")
    				except exceptions.InternalServerError as e:
    					if not hide_errors:
    						logging.log(f""&RED&Error&END&: {e}"")
    				loader.next()
    			loader.stop()
    			return possibilities
    
    		# multiprocessing.
    		else:
    
    			# fetch data.
    			def fetch(symbols=[], timestamp=None, hide_errors=False, id=0, memory={}):
    				data = []
    				for symbol in symbols:
    					try:
    						data += self.predict(symbol=symbol, timestamp=timestamp, hide_errors=hide_errors, multiprocessing=True)
    					except exceptions.InvalidDataFrame as e:
    						if not hide_errors:
    							logging.log(f""&RED&Error&END&: {e}"")
    					except exceptions.EmptyDataFrame as e:
    						if not hide_errors:
    							logging.log(f""&RED&Error&END&: {e}"")
    					except exceptions.InternalServerError as e:
    						if not hide_errors:
    							logging.log(f""&RED&Error&END&: {e}"")
    					except Exception as e:
    						if not hide_errors:
    							logging.log(f""&RED&Unknown Error&END&: {e}"")
    				memory[id] = data
    
    			# start processes.
    			if max_processes > len(symbols):
    				max_processes = len(symbols)
    			processes = []
    			mp_manager = __multiprocessing__.Manager()
    			memory = mp_manager.dict({})
    			divided = Array(symbols).divide(into=max_processes)
    			for id in range(max_processes):
    				p = __multiprocessing__.Process(target=fetch, args=(divided[id], timestamp, hide_errors, id, memory))
    				p.start()
    				processes.append(p)
    			for p in processes:
    				p.join()
    				p.close()
    			data = []
    			for id in range(max_processes):
    				try:
    					data += memory[id]
    				except KeyError:
    					logging.log(f""&RED&Error&END&: Failed to retrieve data from process {id}."")
    			
    			# predict on data.
    			possibilities = []
    			for symbol, timestamp, X in data:
    				prediction = float(self.model.model.predict(X)[0][0])
    				possibilities += [{
    					""timestamp"":timestamp,
    					""symbol"":symbol,
    					""prediction"":prediction,
    				}]
    			return possibilities

And how i call the function:

    neuralnet.predict(symbols=neuralnet.symbols, multiprocessing=True, timestamp=str(Date(timestamp)))

I already contacted binance support and they say that once the data is released the data will never change again. So this should also not be the problem.

Any help would be very much appreciated!

Thanks in advance.

This is all the code used in prediction an processing the predictions [https://github.com/vandenberghinc/issue-1](https://github.com/vandenberghinc/issue-1/tree/main). If you read the code you can see that some valid predictions are limited for example if there are multiple possibilites it selects the one where the highest price change is predicted. But without all this limitations it would have made only 13 trades instead of 10. I checked the logs, so that should not be the problem.",2022-02-09 21:35:14
transportation engineer to become an transportation data scientist,0,solib6,https://www.reddit.com/r/datascience/comments/solib6/transportation_engineer_to_become_an/,3,1644434390.0,"Hi am a transportation engineer. I want to change my career to transportion data scientist.
Where should I start? Am planning to self learn data science as a part time with my job.
I couldn't find any books/courses/tutorials regarding transportation data science. I don't know where to start.
What courses should i do ? I want to specialise in transportation sector 
Could you guys please help me?",2022-02-09 21:19:50
transportation engineer to become an transportation data scientist,0,soli4c,https://www.reddit.com/r/datascience/comments/soli4c/transportation_engineer_to_become_an/,0,1644434384.0,"Hi am a transportation engineer. I want to change my career to transportion data scientist.
Where should I start? Am planning to self learn data science as a part time with my job.
I couldn't find any books/courses/tutorials regarding transportation data science. I don't know where to start.
What courses should i do ? I want to specialise in transportation sector 
Could you guys please help me?",2022-02-09 21:19:44
Social Project Index Visualization,0,sok9bg,https://www.reddit.com/r/datascience/comments/sok9bg/social_project_index_visualization/,3,1644431045.0,"Hi,

I am in the progress of doing a practice project for data visualization and came across this super interesting visualization on the Social Progress Index website.

Would anyone happen to know how what language and packages they used to create this?

I appreciate your help.

[https://www.socialprogress.org/?code=USA](https://www.socialprogress.org/?code=USA)

&#x200B;

https://preview.redd.it/i0cxvgydoug81.png?width=1276&format=png&auto=webp&s=45638c92467c9af6360ca2213bfb4f48f1e4b594

&#x200B;

https://preview.redd.it/38dv2eocoug81.png?width=1480&format=png&auto=webp&s=64caa581baf2d890298350507ca909cde9c2673a",2022-02-09 20:24:05
Day-to-day motivation as a data scientist,19,sojmje,https://www.reddit.com/r/datascience/comments/sojmje/daytoday_motivation_as_a_data_scientist/,12,1644429407.0,"I’ve been reflecting on this a lot recently. I’d define motivation is what keeps you focused, on task, and willing to get up in the morning. I think this is different than inspiration, which keeps you sustained and engaged over a longer period of time (although inspiration can definitely feed motivation).

I bring this up because I haven’t been feeling motivated to do my job lately, and based on recent posts I’ve seen on here I think many can relate. Making a list of what motivates me in general as a data scientist definitely allowed me to think more clearly about how I think about my job, and ultimately, my life. 

Here are my main motivators currently:
1. Being able to learn the things I want to on the job (e.g. advanced analytical techniques like ML, NLP, DL, etc.)
2. Not letting others down/maintaining a good reputation
3. Money (not in the sense that I need the highest salary, more in the base sense that I need to provide for myself and want to pursue a CS masters)
4. Guilt, the worst motivator of them all. Maybe it’s a bit of imposter syndrome. Maybe you got a promotion over someone you think outperformed you. etc. This has ruined me in the past as the primary motivator. I think it’s unavoidable to some extent because it comes coupled with responsibility, but can be really dangerous if it’s the only thing spinning your wheels.

In short, I think we all get into DS and are ideally motivated by #1, because at a base level all of us here love to learn and learning how to learn. DS is a very large umbrella with lots of opportunities to try out new skills, as well as new techniques being iterated, improved, and invented all the time. But a lot of the time we do not achieve #1 as the primary motivator, either because the job ends up being not what we expected or we hit a learning ceiling within our role. I think this can lead us to drop down to one or more of the other motivators to keep us going.

Sorry to say I’m not really offering a solution to this dilemma, but just wanted to suggest this exercise as a way to stop and think about everything in a larger, psychological context. 

Be well! This profession is notoriously demanding. Nothing should take a backseat to your mental health.",2022-02-09 19:56:47
"I find myself wondering why olympic snow sports are so Eurocentric. How would I go about making a map that weights ""reliable presence of snow"", ""population density"", and other factors necessary for a sport to flourish? Not a homework, I just felt curious.",2,soe06t,https://www.reddit.com/r/datascience/comments/soe06t/i_find_myself_wondering_why_olympic_snow_sports/,4,1644414443.0,"Is it as ""simple"" as looking up the databases for maps like [this one for snow](https://snow-cci.enveo.at/images/global_snow_map_modis_v20170318_22.png), [https://mapstor.com/news/digital-cartography-and-gps-navigation/02-11-2016-number-density-and-population-growth-in-the-world.html] and then scaling the ""tiles"" to be the same size for multiplication? How to account for factors like *local* concentrations of wealth and industry, state sponsorship of sports...?",2022-02-09 15:47:23
Monitoring Conv Net in Production,2,sodwpl,https://www.reddit.com/r/datascience/comments/sodwpl/monitoring_conv_net_in_production/,2,1644414150.0,How do you monitor your image classification models in production without labels? I’m thinking of trying to quantify how similar the input is to other images in the training set and then maybe raise a flag if it drops below a threshold but I’m not sure how computationally feasible this will be. Any other recommendations?,2022-02-09 15:42:30
Using Python/ R with IBM Netezza,1,sodeyr,https://www.reddit.com/r/datascience/comments/sodeyr/using_python_r_with_ibm_netezza/,8,1644412746.0,"Hi, I joined a new company about two weeks ago and so far have been attending trainings and not completely aware about the workflow of the teams. But, from what i understand they use IBM Netezza as the data warehouse and use SAS on top of it for any kind of processing and finding insights & eventually put everything into an Excel to share with stakeholders. I want to understand what other workflows are possible to incorporate Python/ R while having Netezza as the warehousing tool",2022-02-09 15:19:06
Must reads?,217,so7l3n,https://www.reddit.com/r/datascience/comments/so7l3n/must_reads/,73,1644391261.0,I want to know which books on data science/computer science/coding/programming interested you the most. Drop any recommendations please!,2022-02-09 09:21:01
How to match similarly shaped curves in python using dynamic time warping?,3,so4ab9,https://www.reddit.com/r/datascience/comments/so4ab9/how_to_match_similarly_shaped_curves_in_python/,1,1644380063.0,"Hello, so I have been experimenting with dynamic time warping of time series data using the ""dtw"" package, and while I have been able to successfully implement the code to find DTW distances for pairs of curves, I am confused about how to actually group the curves together. I will explain further in more detail. Here is the link to the dtw package documentation: [https://dynamictimewarping.github.io/python/](https://dynamictimewarping.github.io/python/)

I have time series data which consists of many lines making up a wide range of curve shapes. These lines start at different time stamps on the x-axis, and so I send all of the lines to individual arrays, recording just their y-axis values, and assuming each observation value occurs at equally spaced time intervals, so essentially having each line as if it started at the same time-stamp. So each of these arrays represents a different line. What I want to do is use dynamic time warping to pair each line together and assign a DTW distance score for the purpose of matching like/similar curve shapes. For instance, if I have two plateau-looking curves from array X and Y, then this pair should be assigned a much lower score than between array X and array Z, where Z would be a wavy-shaped curve. So that is the basic idea. I am using the dtw-python package to carry this out. This is what I have so far, where ""ts1"" and ts2"" are the time series arrays to be compared and ""111"" and ""222"" are just different IDs for the arrays:

    #Indicate two time series IDs to be compared
    ts1 = '111' 
    ts2 = '222'
    
    #Convert time series curves to arrays
    df_y['ID'] = df_y['ID'].astype(str)
    v = df_y[df_y[""ID""].str.contains(ts1)]
    v = v['Value'].to_numpy()
    
    df_y['ID'] = df_y['ID'].astype(str)
    z = df_y[df_y[""ID""].str.contains(ts2)]
    z = z['Value'].to_numpy()
    
    #Run DTW
    ds = dtw(v,z, keep_internals=True)
    ds.plot(type=""twoway"")
    ds.plot(type=""threeway"")
    print(""DTW Distance Metric:"")
    print(ds.distance)

This outputs a dtw distance score for comparing these two arrays. What I am trying to address is what if I have many, many arrays, each with their own ID and want to group the similar shapes together? Let's say I have a list of 50 arrays (representing time series data but without the timestamps), and I want to run each possible pair through my DTW script above to calculate the DTW score. What I want to do is group array IDs with the lowest scores between the two. Though I cannot seem to figure out how to do this. I know this gets into the field of k-means clustering and time series clustering, but I am wondering if their is a more straightforward and pythonic way to group these array (time series) IDs together based on which pairs have the lowest scores between the two. It seems logical since I am able to find out which pairs match relative to others, but I don't know how to actually group them together. The output I am looking for would look like this: 

           ID     Shape
    --------------------
    0     111        1 
    1     222        1 
    2     255        1
    3     270        2
    4     323        2
    5     370        3
    6     444        3
    7     470        2
    ...

And so I would want to output a simple dataframe like this with the ID and a corresponding curve shape ID. Is there a simple way to do this in python? I would really appreciate any suggestions on this because I am so confused! I am thinking this would be straightforward, but I am also wondering if this would involve a whole other major data science problem that I will need to consider. Thanks!",2022-02-09 06:14:23
How can I analyze extremely large files and what software works best for it?,10,snx3iu,https://www.reddit.com/r/datascience/comments/snx3iu/how_can_i_analyze_extremely_large_files_and_what/,34,1644360062.0,"I'm a student researcher and just got access to some *extremely* large datasets from a state govt. (I have five years worth of data and for perspective, each year is about 11GB large). I've never worked with datasets this large before and was hoping someone could guide me to resources I could use? 

How do I split the files up and ‘load’, import or select fewer variables to process? 

Should I work with Python/ R? Any guidance is appreciated and sorry if this is a silly question! I'm still learning and am very much an amateur.

Edit: Thank you to everyone who’s replied!! I think I have an idea of how to proceed now.",2022-02-09 00:41:02
Advice from Bioinformaticians! TIA,2,snx2ex,https://www.reddit.com/r/datascience/comments/snx2ex/advice_from_bioinformaticians_tia/,7,1644359983.0,"I have got a couple questions kinda all over the place so here they are

1. What made you choose bioinformatics over your other degree pathway?
2. Is it plausible to get a stable job in the field with a MS?
3. I'm in the US, how is pay/job stability in the field?
4. What does your typical work day look like? Are you in the field or are you mostly in an analytics lab, etc. What other day-to-day have you seen in the field.

I would be switching from Environmental Science and have loved working in the data side of our lab that deals with running and debugging a lot of R (spatial stuff) and Python. Thank you so much for responding in advance!!",2022-02-09 00:39:43
How satisfied are you in your position?,140,snu5g8,https://www.reddit.com/r/datascience/comments/snu5g8/how_satisfied_are_you_in_your_position/,137,1644352555.0,"I'm currently working on my master's in data science, coming from a non-technical background. I was reading through this subreddit, and someone made a post about software engineering vs data science, and it had me wondering how many people are satisfied with their position in data science. I remember reading before that data scientist had a very high job satisfaction rate.",2022-02-08 22:35:55
Compensation for Tech Workers in 2022 - How big are Wage Gains in Datascience?,1,snth37,https://www.reddit.com/r/datascience/comments/snth37/compensation_for_tech_workers_in_2022_how_big_are/,2,1644350809.0,"With the Great resignation and more demand for datascience, software engineers and cybersecurity professionals I wonder what you think wage gains will be like in 2022? Given the higher inflation, I think it could accelerate but I am not sure. 

How much will compensation rise during this period of inflation with no end in sight?

Given talent shortages will this be more than usual?

Some context and figures: [https://datasciencelearningcenter.substack.com/p/2022-is-the-year-of-compensation](https://datasciencelearningcenter.substack.com/p/2022-is-the-year-of-compensation)",2022-02-08 22:06:49
Curiosity: Does running multiple models on one dataset,2,sntcwr,https://www.reddit.com/r/datascience/comments/sntcwr/curiosity_does_running_multiple_models_on_one/,12,1644350509.0,"I'm currently working in R and applying different models such as random forest, KNN, and SVM to predict a binary outcome of a member's enrollment status.  The models range in accuracy from 60%-70% in cross validation.

My curiosity question is if each model is run, and the three results compiled, is there any benefit to overall accuracy by comparing the decisions from each algorithm?

For instance, for a given member, if RF states the member will remain enrolled, but KNN and SVM state member will disenroll, since the majority say disenroll the overall decision is the member will disenroll.

Does anyone have any input on if this idea will yield more accurate results compared to only utilizing one model? I'd be happy to give more information if needed",2022-02-08 22:01:49
Troubles with merge,0,snrwbi,https://www.reddit.com/r/datascience/comments/snrwbi/troubles_with_merge/,20,1644346822.0,"Hello, my friends

&#x200B;

i'm getting some troubles when i try to merge two differentes dataframes with the same shape(48,6)

when i merge the, the merged df get a big number of rowls (bigger then the originals df) and the rowls keep repeting the same values

&#x200B;

I tried some solutions wich i find in the google, but anyone of them resolve it 

https://preview.redd.it/pfzr38qopng81.png?width=426&format=png&auto=webp&s=b37296837cf3497206b859bd719733d98f223520

https://preview.redd.it/39hoc0qopng81.png?width=740&format=png&auto=webp&s=c76aa6b033a0f09018128c2ae9e3abd35f7d9c6f",2022-02-08 21:00:22
How do u rate MATLAB for data science applications,1,snrsxf,https://www.reddit.com/r/datascience/comments/snrsxf/how_do_u_rate_matlab_for_data_science_applications/,70,1644346598.0,"So, I'm an electrical graduate and there the only thing we have learned was MATLAB. Now have completed some basic data science courses (stats, prob, and R) and enrolled myself in MS DS. 

I had some hands on practice on MATLAB, and till now (it's my start) I can manage any analysis on it. Although python is a lot similar to MATLAB, but u know remembering functions is the most tedious task of learning a programming language (and then there's a practice). I know a lot of analysis and statistical tools of MATLAB and searching for same for python is boring. Although I haven't cover my ML yet, but I have heard model training on MATLAB is simple... I know python for DS is mandatory and if MATLAB is good enough then learning a 2nd tool would give additional benefits. 

So, I was wondering why the demand of MATLAB for data science isn't that high. For real engineering applications like audio analysis, drone design, image processing and autonomous cars nothing competes with MATLAB yet, and if we want to apply data science on these applications MATLAB also provide tools for that. So, why people prefer python over it? 

Is it because it's paid?

R is a separate case, and best for statistical analysis - and is like a good shortcut.",2022-02-08 20:56:38
Quantify Disagreement between binary features?,2,snrs50,https://www.reddit.com/r/datascience/comments/snrs50/quantify_disagreement_between_binary_features/,4,1644346543.0,"I have data where the features are a doctor's diagnosis of a disease (one-hot encoded) broken down by patient, so:

|Patients|Cold|Anemia|No Diagnosis|
|:-|:-|:-|:-|
|Patient #1|1|0|0|
|Patient #2|0|1|0|

Means that the doctor thought Patient #1 had a cold and Patient #2 had Anemia. But then also have similar data from another doctor who made diagnoses on the same set of patients:

|Patients|Cold|Anemia|No Diagnosis|
|:-|:-|:-|:-|
|Patient #1|0|0|1|
|Patient #2|1|0|0|

And I concatenated them so for each patient they have a Doctor #1 diagnosis and a Doctor #2 diagnosis that may or may not agree. How could I statistically quantify the doctors' disagreements by disease / find which diseases they disagree on the most?",2022-02-08 20:55:43
Job Titles Alternatives to Data Scientist,2,snrpq9,https://www.reddit.com/r/datascience/comments/snrpq9/job_titles_alternatives_to_data_scientist/,7,1644346371.0,"I have two roles on my team that are “Data Scientist” roles, but we don’t really do what I would consider “data science”.

We are more like an analytics/consulting.  Combination of research, data analytics, and problem-solving/solution-ing. 

Two questions:

-What are some titles that better-correspond to our function

-How would you react if your title changed to something else",2022-02-08 20:52:51
How would you use DS to figure out why something has changed?,14,snku4l,https://www.reddit.com/r/datascience/comments/snku4l/how_would_you_use_ds_to_figure_out_why_something/,23,1644328579.0,"So i'm sure any analysts (or data scientists who are asked to do analysis) have had some variation of this question from someone at work before, ""prick, engagement is down compared to last week can you tell me why?""

What is want to know is, outside of the usual methods such as breaking the metric down by different dimensions, checking for seasonality, monitoring any changes (so for a website releases perhaps) that correlate with the fall in said metric. 

What are some other, maybe smarter, methods of tackling this problem?",2022-02-08 15:56:19
Comparing distributions Python,12,sng9i7,https://www.reddit.com/r/datascience/comments/sng9i7/comparing_distributions_python/,15,1644312831.0,"I have a larger dataset (random variable) 'x' containing values approximating a Gaussian distribution. From 'x', a much smaller random variable 'y' is sampled without replacement. I want to compare their distributions using histograms. The code in Python 3.9 is as follows:

&#x200B;

    # Create a gaussian distribution- 
    x = np.random.normal(loc = 0, scale = 2.0, size = 20000000)
        
    # Sample from 'x' without replacement-
    y = np.random.choice(a = x, size = 400000, replace = False)
        
    x.size, y.size
    # (20000000, 400000)
        
    # Compare the distributions using 'histplot()' in seaborn with different bin sizes for x & y-
    sns.histplot(data = x, bins = int(np.ceil(np.sqrt(x.size))), label = 'x')
    sns.histplot(data = y, bins = int(np.ceil(np.sqrt(y.size))), label = 'y')
    plt.xlabel(""values"")
    plt.legend(loc = 'best')
    plt.title(""Comparing Distributions"")
    plt.show()

This produces the output:

&#x200B;

[histograms with different bin sizes](https://preview.redd.it/ffgyatxcwkg81.png?width=1920&format=png&auto=webp&s=dfa3571f0bd3ba54afc8f3e767cd14842acd5042)

&#x200B;

    # Compare the distributions using 'histplot()' in seaborn with same bin sizes for x & y-
    sns.histplot(data = x, bins = int(np.ceil(np.sqrt(x.size))), label = 'x')
    sns.histplot(data = y, bins = int(np.ceil(np.sqrt(x.size))), label = 'y')
    plt.xlabel(""values"")
    plt.legend(loc = 'best')
    plt.title(""Comparing Distributions"")
    plt.show()
    

This produces the output:

&#x200B;

[histograms with same bin sizes](https://preview.redd.it/gm7nibtkwkg81.png?width=640&format=png&auto=webp&s=176b4b57bd464c3ecbe505318c82bac2eb21e994)

In my opinion, the second plot is wrong because each histogram should be computed and visualized with it's own bin size for the given data.

&#x200B;

To further analyze the two distributions using a histogram:

        n_x, bins_x, _ = plt.hist(x, bins = int(np.ceil(np.sqrt(x.size))))
        n_y, bins_y, _ = plt.hist(y, bins = int(np.ceil(np.sqrt(y.size))))
        
        # number of values in all bins-
        n_x.size, n_y.size
        # (4473, 633)
        
        # bin size-
        bins_x.size, bins_y.size
        # (4474, 634)
        
        # bin-width-
        bw_x = bins_x[1] - bins_x[0]
        bw_y = bins_y[1] - bins_y[0]
        
        bw_x, bw_y
        # (0.004882625722377298, 0.02781399915135907)

Since 'y' has a much smaller size than 'x', consequently, it's bin-width (0.0278) is much larger than 'x' bin-width (0.0049). Hence, this produces a different histogram and visualization. Since 'y' is sampled from 'x', using Kolmogorov Smirnov two sample test doesn't make sense.

What's the appropriate way to compare these two distributions?",2022-02-08 11:33:51
Why are there so many more statistics courses in R and so few in Python?,324,snexoa,https://www.reddit.com/r/datascience/comments/snexoa/why_are_there_so_many_more_statistics_courses_in/,154,1644307498.0,"Honest question, I’ve completed a couple machine learning and data science courses in Python and I wanted to see how the stats I’ve learnt so far in uni apply in the field. However I noticed that stuff like Bayesian stats is only taught and applied in R courses. Is there a reason for that?",2022-02-08 10:04:58
Trying to improve performance of dynamic time warping in matching curve shapes,1,snbw2b,https://www.reddit.com/r/datascience/comments/snbw2b/trying_to_improve_performance_of_dynamic_time/,1,1644297142.0,"Hello, so I am new to the practice of dynamic time warping for matching curve shapes from time series data, and wanted to reach out to this community for some potential feedback on whether I am on the right track with my project and how I can improve it. I have time series data which consists of many lines making up a wide range of curve shapes. These lines start at different time stamps on the x-axis, and so I send all of the lines to individual arrays, recording just their y-axis values, and assuming each observation value occurs at equally spaced time intervals, so essentially having each line as if it started at the same time-stamp. So each of these arrays represents a different line. What I want to do is use dynamic time warping (DTW) to pair each line together and assign a DTW distance score for the purpose of matching like/similar curve shapes. For instance, if I have two plateau-looking curves from array X and Y, then this pair should be assigned a much lower score than between array X and array Z, where Z would be a wavy-shaped curve. So that is the basic idea. I am using the dtw-python package to carry this out. This is what I have so far, where ""ts1"" and ts2"" are the time series arrays to be compared and ""111"" and ""222"" are just different IDs for the arrays: 

    #Indicate two time series IDs to be compared
    ts1 = '111' 
    ts2 = '222'
    
    #Convert time series curves to arrays
    df_y['ID'] = df_y['ID'].astype(str)
    v = df_y[df_y[""ID""].str.contains(ts1)]
    v = v['Value'].to_numpy()
    
    df_y['ID'] = df_y['ID'].astype(str)
    z = df_y[df_y[""ID""].str.contains(ts2)]
    z = z['Value'].to_numpy()
    
    #Run DTW
    ds = dtw(v,z, keep_internals=True)
    ds.plot(type=""twoway"")
    ds.plot(type=""threeway"")
    print(""DTW Distance Metric:"")
    print(ds.distance)

 and then I see this: 

https://preview.redd.it/8dwd00lhljg81.png?width=385&format=png&auto=webp&s=7c9acf294c2027992e10bb574ec74abd9a629188

with a DTW score of: 1074.0

And then I try comparing to wavy-shaped curves and receive this:

https://preview.redd.it/spkmxgbjljg81.png?width=385&format=png&auto=webp&s=0696ebb2d49112d2d3f5f5e9b598f3508d2c6d54

This receives a DTW score of 16103.0

Ok, this seems reasonable, the plateau shape matches the plateau shape, and the wavy shapes matches the wavy shape. Ok, but what if I am trying to match two wavy-shaped curves with different numbers of oscillations?

And I try this and see:

https://preview.redd.it/s771nf2lljg81.png?width=385&format=png&auto=webp&s=e9554e636d99b3adb738b04f2dbff909a48c5d38

with a score of 73745.0 (This does not look so good!)

Then I try adding some parameter arguments in the code:

    ds = dtw(v,z, keep_internals=True, 
             window_type=None, 
             open_end=True)

 And then I see this: 

https://preview.redd.it/z1tqem6pljg81.png?width=385&format=png&auto=webp&s=eb27aac59af8d61b5018f60f0eb324308dfbb64f

with a score of 21365.0 (This is much lower now!)

And then I try:

    ds = dtw(v,z, keep_internals=True, 
             step_pattern=asymmetric, 
             window_type=None, 
             open_end=True)

 And I see: 

https://preview.redd.it/81b4vbitljg81.png?width=385&format=png&auto=webp&s=091860dd2321a59166aa4e63b949f9073d202654

with a score of 12572.0, which is even lower now! I see the last oscillations are ignored, which is interesting, since that might be the approach I am looking for.

And lastly I try:

    ds = dtw(v,z, keep_internals=True, 
             step_pattern=asymmetric, 
             window_type=None, 
             open_end=False, 
             open_begin=True)

 And I see: 

https://preview.redd.it/ex10zmoxljg81.png?width=385&format=png&auto=webp&s=1bc4a04ee2974e45237e17217213ba05c7c9edf2

with a score of 19227.0, which is now worse than before, and I am a bit confused about what is happening here.

So I wanted to ask whether this looks like I am on the right track with curve shape matching here, but also I wanted to ask what these parameter arguments are actually doing and whether I am using them correctly, since I was really just experimenting with them here. I have had difficulty finding sufficient background and documentation on what these arguments mean from the available documentation for dtw-python: [https://dynamictimewarping.github.io/python/#online-documentation](https://dynamictimewarping.github.io/python/#online-documentation)

What are these arguments actually doing? I am specifically trying to use them to address the issue of two similar looking wavy-shaped curves that I do want to have grouped as similarly shaped, having different numbers of oscillations. Should these extra oscillations be ignored? Maybe just look at the parts of the two curves that actually do largely match? I would really appreciate any insight and feedback on this, thank you!",2022-02-08 07:12:22
Birth of a “metric”,18,sn9myj,https://www.reddit.com/r/datascience/comments/sn9myj/birth_of_a_metric/,30,1644290516.0,"I was recently asked my someone at my company to come up with a single metric that represents our overall success as a business. I started off with a ratio of our two most important metrics, then played with the SQL query until I got something that looked right to me. I ended up with something like:

Success = Log(output/(time spent working)^3 )

I think the line plot looks great. It’s mid point is at the beginning of our relationship with our biggest client, it’s low point is a couple months later when we broke all our promises to this client with our poor performance, and the high point comes after that, when we hired more staff, increased production, and recovered from this failure.

Am I “allowed” to just make up metrics like this? Or have I violated some principle that will come back to haunt me later?",2022-02-08 05:21:56
How do you deal with ambiguity in your job?,27,sn7fxu,https://www.reddit.com/r/datascience/comments/sn7fxu/how_do_you_deal_with_ambiguity_in_your_job/,21,1644284503.0,"For some context, I'm a data analyst working at a startup that came over from a more archaic and traditional company. At my previous company, I was always given very clear instructions and answers on how to go about completing tickets assigned to me. I hit a ceiling quickly with this and thought I'd tryout going to a startup in order to try learning more things and quicker. 

Since joining this new company, I've felt pretty dumb every step of the way. I have learned a ton but compared to everyone else, the gap in skills, domain knowledge etc. is just massive. I do my best to always ask questions if I get blocked and try to find solutions on my own before reaching out but I'm starting to think the issue is that I just grasp things slower than others. 

I have new stakeholders now in a different department and the assignments are incredibly ambiguous and seems out of my scope of knowledge. I've been actively doing research and reaching out for clarification but it still doesn't seem like it's enough.

So I guess my main question is how do you deal with being dropped into a team with ambiguous assignments and in a domain out of your scope?",2022-02-08 03:41:43
Requirements and Scope Gathering,2,sn5obi,https://www.reddit.com/r/datascience/comments/sn5obi/requirements_and_scope_gathering/,0,1644279685.0,"Hi all I am a data scientist working for a telecom client. My work mostly involves competitive analytics and solution building. I have been recently given multiple responsibilities like stakeholder interactions and c level communication. The current state of the project is ad hoc and I would like to know how can I capture the most information from the stakeholders in terms of scope and business goals as they don't have a clear vision for this work until now. Is there any framework I can refer or any practice I can start following which will help me define these goals better for me and for directing my team. Right now we come up with kpis and consult them whether they think it's the right approach and anything else needs to be added.
Would love some input here.",2022-02-08 02:21:25
Desktop PC,0,sn3m5s,https://www.reddit.com/r/datascience/comments/sn3m5s/desktop_pc/,7,1644274419.0,"I know this question is probably asked a lot (my apologies) and I realize that I can run heavy GPU tasks on the cloud. I am currently using a 9 year old Mac Book Pro laptop. I work on data science projects for fun on the side. I am going to buy a new desktop PC this year anyway. I am thinking of going with the Lenovo ThinkCentre. I don't know much about computer hardware and I don't want to build my own PC. What would you recommend for me? I have a fairly high budget, but don't want to overspend if it's not needed. I will probably go with a top of the line CPU, 32gb of ram, 1tb hard drive, descent GPU.  Any models or other brands you recommend? Thank you.

&#x200B;

[https://www.lenovo.com/ca/en/think-workstations/thinkstation-p-series-towers/ThinkStation-P350-Tower/p/30E3006YUS](https://www.lenovo.com/ca/en/think-workstations/thinkstation-p-series-towers/ThinkStation-P350-Tower/p/30E3006YUS)",2022-02-08 00:53:39
Thoughts on European Artificial Intelligence Board?,0,sn1znh,https://www.reddit.com/r/datascience/comments/sn1znh/thoughts_on_european_artificial_intelligence_board/,5,1644270497.0,I’m writing an article.,2022-02-07 23:48:17
Looking for a sparring partner for a DS portfolio project,14,smy2tp,https://www.reddit.com/r/datascience/comments/smy2tp/looking_for_a_sparring_partner_for_a_ds_portfolio/,11,1644260899.0,"Hey there,

I am currently a Sr Data Scientist, and I always had the goal of working on some hands-on project to put on my CV.
However, I always got a little lazy and never really found the motivation (or discipline, if you wish) to actually work on one.

I feel that it would be much more interesting and motivating to work on a ML/DL project with someone else that has the same ambition, so that we can both benefit from it and learn from each other.

Ideally, within the scope of the project that I have mind, we would be covering the following areas:

1. Relatively complex project, where we would need to do some data preparation (no “ready” datasets)
2. It would need to be end to end (from loading the data to deploying the model)
3. All (Python) code should be on Git and we would make heavy use of PRs
4. OOP whenever possible
5. Adding some automation (eg. Airflow) would be nice
6. Containerization is something I would also like to include to the project

So it would really be an end-to-end project, and the goal is to showcase to potential new employers that we can really code and deploy to production, and not only fit some sklearn object on a toy dataset.

In terms of modelling, once we decide what we want to do, we could try different approaches/models and compare them. I am familiar with the usual sci-kit repo and Keras (both functional and sequential APIs, specifically within LSTMs and VAE/Enc-Dec architectures). I am also experienced with Airflow and Docker (not an expert though).

Ping me if interested!

EDIT: Found someone, many thanks to everyone!",2022-02-07 21:08:19
R connection with SQL Server to fetch raw data - Reason to learn dplyr - tidyverse tools?,13,smvrf8,https://www.reddit.com/r/datascience/comments/smvrf8/r_connection_with_sql_server_to_fetch_raw_data/,12,1644255125.0," Hi,

the title might be a bit confusing so let me explain myself better. R can be very easily connected with SQL Server to fetch raw data. I am not an expert in R but I am quite good with T-SQL, thus I am wondering if it would make sense to me to learn the tools offered by the tidyverse to manipulate, clean the data, since I already clean and prepare my raw data already from SQL?

However, since I am no expert in R and I still read lots of documentation on internet etc... very often I see people who swear to god that dplyr / tidyverse changed their life and wondered how they could work before without these tools.

Now, I am sure I miss something but... If I already prepare, clean, merge, etc.. the raw data with SQL and just run a query to fetch the resutls in R.. Are there still reasons that I am missing for which it would make sense to ""explore"" the tidyverse?

What advantages of these tools that SQL scripts can't handle? Opinions?

Edit:
I am referring only about raw data fetching / manipulation / cleaning. Of course the analysis would be done in R. I am just wondering about the usefulness of learning the tools and syntax from the tidyverse for the purpose of data cleaning/ manipulation if somebody is already good in SQL.",2022-02-07 19:32:05
I cant find any good examples explaining 3rd normal form.,3,smvcqt,https://www.reddit.com/r/datascience/comments/smvcqt/i_cant_find_any_good_examples_explaining_3rd/,7,1644254083.0,"TLDR:Can someone point me at an example when someone takes non normilised data and takes it through 1st, 2nd, and 3rd normal form.

EDIT, the title should really be looking for a good example of data in 2ND normal form that needs taking to 3NF.

Been looking at a number of tutorials and non of the bits explaining 3NF seem to make sense.  Here are a couple of examples of data that is supposed to be in 2NF that needs to be taken to 3NF.

[Example 1](https://preview.redd.it/56ckky0x0gg81.png?width=874&format=png&auto=webp&s=f9211bab862dc81d3a33592a3d25b15d3f9885e1)

[Example 2](https://preview.redd.it/ful32otu0gg81.png?width=704&format=png&auto=webp&s=e861164ae48d90bbf5be41dbbdb4f841b269d754)

But I can't see how these two examples are actually in 2NF.  The first Winner/WinnerDOB and the second SubjectID/Subject are both partial dependencies.

What I find really confusing is none of the examples start with non-normalized data and take it through 1,2 and 3rd NF.  All the examples start with different starting data for each NF.  I get the feeling they do this as they do not really understand what they are talking about.

I know this is kind of academic but think fully understanding the forms is a good idea.",2022-02-07 19:14:43
Nowcasting / Time-series urban activity project,2,smuo02,https://www.reddit.com/r/datascience/comments/smuo02/nowcasting_timeseries_urban_activity_project/,0,1644252373.0,"Hi everyone I am currently working on a personal project, trying to build an index for urban activity.  
I'm facing two major obstacles that I would love this community to help.

1) Being the first time I'm dealing with Geospatial data, I'm having trouble aggregating the different variables into the same pivot table let's say. These variables are from the same city/state but are categorized by different areatype (municipality, street address, council, lat/lon, etc...)  
**What would be the best approach for this aggregation?** (I've tried geopandas but w/no success)

**2) What alternative technique would you recommend for dimensionality reduction besides PCA?** 

&#x200B;

Any decent bibliography on Nowcasting and Index Time-series is appreciated :)

P.S. Apologies if my explanation was not the best, English is not my first language",2022-02-07 18:46:13
Software Engineer or Data Science,175,smr1z0,https://www.reddit.com/r/datascience/comments/smr1z0/software_engineer_or_data_science/,114,1644242795.0,"People who have experienced both of these fields, which one would you recommend, and why ?",2022-02-07 16:06:35
How do ya'll code in real corp environments?,42,smq4bt,https://www.reddit.com/r/datascience/comments/smq4bt/how_do_yall_code_in_real_corp_environments/,21,1644240103.0,"Maybe a rant but I've been doing data with Python for several years.  Started at new company and then bam!  Corporate proxy and VPN just hits me in the face.  My requests code get SSL cant verify certificates errors, etc.  The usual verify=False is suggested, but you cant do that!  Yadda yadda... Then the usual, issue support ticket to IT or find workarounds like manually export root and intermediate certs with browser, etc.  I swear there should be a lessons learned or help line for this sort of stuff and basic computer security knowledge, maybe there is?  Do they actually teach this stuff in boot camps and universities?",2022-02-07 15:21:43
Fear of sharing what I write,0,smpjx3,https://www.reddit.com/r/datascience/comments/smpjx3/fear_of_sharing_what_i_write/,11,1644238393.0,"Hi \*,

Some time ago I started my first blog. My idea is to share projects that I've done, ideas about data science, and other miscellaneous stuff. Also, my 2022 resolution is to write more, mainly to improve my writing skills and also to start building my personal brand.

I've 5 years of experience in DS and ML, so I should be confident enough to share my writings with other people, however, I don't feel comfortable sharing them with anyone - I guess it's because of the impostor syndrome... Also, English is not my first language and I don't want to make a fool of myself in public...

Do you have any tips on how to overcome this fear? 

Thank you for your help!",2022-02-07 14:53:13
What’s an effective way to do code reviews in Data science?,13,smmfks,https://www.reddit.com/r/datascience/comments/smmfks/whats_an_effective_way_to_do_code_reviews_in_data/,8,1644227312.0,"Coming from a software engineering background, I feel this process should somehow be different. The problem area and the dimensions you want input on is more around whether you modeled the world correctly, used the right methods & data as opposed to software engineering focusing where the focus is more on best practices, code quality, robustness, etc.

What do successful/efficient code reviews look like in a strong data science team?",2022-02-07 11:48:32
Books/online material which incorporates both programming and math/stats?,1,smjx7u,https://www.reddit.com/r/datascience/comments/smjx7u/booksonline_material_which_incorporates_both/,5,1644217400.0,"Analyst here, with primarily experience working with SQL looking to update my skills with an object based language such as python. Problem is it's been a while since I've done any stats/math which was back in university.

Is there any material which covers both topics simultaneously? I'd like to learn/review both the programming and the stats/math which complement it.",2022-02-07 09:03:20
"Thinking of switching to more technical ML domains, not sure if I should",6,smir52,https://www.reddit.com/r/datascience/comments/smir52/thinking_of_switching_to_more_technical_ml/,3,1644213332.0,"I work in Data Science in Credit Card industry and I work on simple tree based models. I was looking to make a switch to more technical domains like NLP, Image Recognition, Machine Translation, Recommender systems etc. The idea is to be more technically apt with Data Science in general, to be able to (in future) make a switch to any role in the industry and be in touch with state of the art developments in ML. Also, I want to work for tech companies which definitely are going to pay me higher than what I'm getting in the current role
 
The problem is that right now I have been given an option to move to a Managerial role in the same Data Science team, and I'm not sure if I should opt for it OR wait & choose a role for which I just have a mental image (right now), not the full idea. I haven't actually worked in those (aforementioned) fields in a professional setting. Also I'm not sure how my daily work would look like there. I was hoping this community can help me make that decision.",2022-02-07 07:55:32
Pipeline for reproducible research in industry,2,sm9phl,https://www.reddit.com/r/datascience/comments/sm9phl/pipeline_for_reproducible_research_in_industry/,1,1644186902.0,"I'm  working in a small company where ML is the core product. We do lots of  experiments/research to try improve our current product however one  thing I noticed it's hard to reproduce experiments/research done by  other colleagues.

Let's say I try  out a new approach on a particular task and get some improvements on the  currently deployed models. Then 6 months from now those results seems  outdated (new papers/shift in business paradigms/...).

What  are the best practices on setting up a framework/pipeline to make  experiments easy to track/reproduce?  I was thinking about using MLFlow  + DVC  + Git. Has anyone experienced this sort of issues? if so, how  did you solve them?

Thanks!",2022-02-07 00:35:02
Research Analyst in a Postsecondary Education Setting,2,sm980z,https://www.reddit.com/r/datascience/comments/sm980z/research_analyst_in_a_postsecondary_education/,0,1644185666.0,"I've got an interview at a Canadian college tomorrow for a research analyst position.


Does anyone out there have experience in this type of setting?


It seems like I'd be doing some enrolment data analysis, administer the student survey, and manage the course evaluation data, among other things.


My background is in applied economics, and I've designed, tested, administered, and analyzed surveys in a previous role.

Any advice welcome in terms of what questions they may ask, anything I should brush up on, etc. 


Thanks in advance.",2022-02-07 00:14:26
Machine Learning Simplified Book,627,sm96f5,https://www.reddit.com/r/datascience/comments/sm96f5/machine_learning_simplified_book/,44,1644185549.0,"Hello everyone. My name is Andrew and for several years I've been working on to make the learning path for ML easier. I wrote a manual on machine learning that everyone understands - Machine Learning Simplified Book.

The main purpose of my book is to build **an intuitive understanding** of how algorithms work through basic examples. In order to understand the presented material, it is enough to know basic mathematics and linear algebra.

After reading this book, you will know the basics of supervised learning, understand complex mathematical models, understand the entire pipeline of a typical ML project, and also be able to share your knowledge with colleagues from related industries and with technical professionals.

And for those who find the theoretical part not enough - I supplemented the book with a repository on **GitHub**, which has Python implementation of every method and algorithm that I describe in each chapter.

You can read the book absolutely free at the link below: -> https://themlsbook.com

I would appreciate it if you recommend my book to those who might be interested in this topic, as well as for any feedback provided. Thanks! (attaching one of the pipelines described in the book).;

https://preview.redd.it/5qqsym19eag81.png?width=1572&format=png&auto=webp&s=518d233c52c3f8266e7812f0c7132239247769b5",2022-02-07 00:12:29
Data Science career advice & mentoring,128,sm834r,https://www.reddit.com/r/datascience/comments/sm834r/data_science_career_advice_mentoring/,172,1644182852.0,"A little bit about myself: I got started in data science before it was called that, so I have seen the crazy progression of the profession. Now, I work as a  Director of Data Science at a retail company.  Side note: I also worked for a successful blockchain company back when bitcoin was a $1000

What inspired this post, I have gotten a lot of my friends that are interested in Data Science hired at their top companies by giving them advice and steering down the correct path. However, I have been kind of conflicted about just giving the advice to only my friends.

so here's what this post is about: who needs mentoring/career advice help trying to get into the industry?  I would be more than happy to help

&#x200B;

Update:  I am answering questions as they come up, but for people looking for longer-term help, I am only able to take on a few people( as time permits).  I will wait a couple of days to give more people a chance

Update #2: The demand has been bigger than I expected, so I'm going to initially help the most peoplet(first) and then more targeted help after that lol.

This is my new game plan: I will help everyone by okaying the personal project you have chosen. if you need more personalized help with picking projects and need a 1:1 to choose one then we can chat about it.  In order not to spam this community,  I would like people that need help with projects to post on r/dataprofessionals with what your project is. I will create a template for how to post the projects.  Ideally, the post should be written like you are explaining the project to your potential manager. so I want to know the

* what's the purpose & impact of the project?
* where is the data coming from (API, csv, etc)?
* where is the project being stored and what is the structure?
* what type of cleaning/transformations does it need?
* how do you plan to productionize the project?

This isnt only open to DS, but any data professional btw.",2022-02-06 23:27:32
Do you prefer data APIs with offset or pagination,2,sm6cs4,https://www.reddit.com/r/datascience/comments/sm6cs4/do_you_prefer_data_apis_with_offset_or_pagination/,6,1644178628.0,"My friends and I are currently working on [databar.ai](https://databar.ai) (a no-code API platform) and we noticed there's a pretty even split between APIs using offset/limits and pagination for limiting the number of results retrieved. Curious if anyone here has a preference for one or the other & benefits of either. I personally think working with pagination is much cleaner and easier, but maybe I'm missing something..",2022-02-06 22:17:08
"Employed Data scientists who work in the Bay Area, what’s your educational background?",0,sm1v5b,https://www.reddit.com/r/datascience/comments/sm1v5b/employed_data_scientists_who_work_in_the_bay_area/,8,1644167623.0,"

[View Poll](https://www.reddit.com/poll/sm1v5b)",2022-02-06 19:13:43
How do you organize your notes / code snippets?,26,sm1usb,https://www.reddit.com/r/datascience/comments/sm1usb/how_do_you_organize_your_notes_code_snippets/,38,1644167597.0,"I have been using R for almost 2 years and since the beginning of my learning journey I have written R files for my own reference when I don’t remember a function or how to do something I rarely use. For example I have one R file for “basic statistics and visuals”, one for R basic syntax and basic code, etc…
Sometimes I created R files with full examples if the topic was too big to be summarized in one of my “reference / documentation files”

However the files have gotten bigger and more numerous and now I am thinking about reorganizing all the knowledge and notes, code snippets I have so that I know where to find it faster and maybe in a centralized way.

The problem is, I don’t know which approach is more appropriate. Do you make word documents? Do you create a huge R file with all the essentials? Do you use OneNote..? something else..?
What are some good tips? 

How do you organize “your knowledge” / notes / code snippets?",2022-02-06 19:13:17
Is it better to specialize for one’s career progression in data science?,6,sm1bwn,https://www.reddit.com/r/datascience/comments/sm1bwn/is_it_better_to_specialize_for_ones_career/,8,1644166391.0,"Recently, I joined the tech industry as a data scientist. My primary motivation in doing so is to learn more data science from my work (previously data engineering, visualization, and now machine learning) and my peers. Previously, I have ~4 years of data science experience (1.5 in finance and 2.5 in consulting) and I hold graduate degrees in mathematics and analytics.

I heard that there is risk in trying to over-generalize and becoming a jack of all trades but a master of none. This question can be interpreted in two ways (both which I’d like answers for)

- Is it better to specialize in industry domain? Would it be better if I focus much more on consulting, real estate, tech, finance, etc.?

- Within the data science pipeline, is it better if I specialize in one part of data science (focus on ML, data engineering, visualization, communication, etc)? 

As someone new in data science, I’m not exactly sure what is better for my career growth. I don’t even know my options after my current plans to up-skill.

The “pure math” side of me thinks that it’s better to generalize so that when the problems are faced, I would know what tools to recommend and how to create business value through requirements gathering and conversations in understanding the business goals. Being “full stack” gives you so much opportunity to solve many problems.

The other side of me thinks that narrowing focus will allow me to focus on a specific set of problems faced in my career, making it easier to build a career through that. It can also convey more business value through past experience from industry competitors, making one more competitive within that industry.

I’m sure this also depends on my future goals. I fear that specializing too much will pigeonhole myself with outdated technologies and industry opportunities, but maybe I’m naive in thinking that. At least with being able to generalize across multiple industries and functions, one can bring transferable skills across many industries and types of data science work.

Any advice would greatly help me. Thanks!",2022-02-06 18:53:11
Process text message text into report,1,sm0ew5,https://www.reddit.com/r/datascience/comments/sm0ew5/process_text_message_text_into_report/,4,1644164114.0,"I am not a data scientist by any means, just someone who uses data analysis and has an interest in learning more so forgive me if my question doesn’t use all the correct terminology. 

In the industry which I work we use a lot of 3rd party rental equipment which we aren’t allowed to install our own comm devices on or bring into our SCADA network. These different pieces of equipment send text messages out to different operators at my company when the equipment faults or has a malfunction. Then it will send text messages again once the alarm clears and the unit is back to running. The problem is we have hundreds of these units that have many different people they send text messages to depending on the specific geographic area. 

I am curious if anyone has any knowledge about if I could leave those text messages to the individuals in place but also take those text messages into an automated report or dashboard to give a snapshot of all of the alarms. 


Needing to: 
•figure out how to get text messages into spotfire or other program 
• teach program to decipher text message 
• auto populate report with on/off status and error codes.",2022-02-06 18:15:14
Best guides on knowing when to use which statistical test ?,115,slzrzk,https://www.reddit.com/r/datascience/comments/slzrzk/best_guides_on_knowing_when_to_use_which/,26,1644162527.0,"Would like to get some reading sources/ guides on this as Im still fairly new on knowing when to apply certain statistical test on different scenario.

&#x200B;

Thanks :)",2022-02-06 17:48:47
Ways to prepare for a product-oriented case study that has to be answered on the spot ? (Fintech industry),0,slz7yb,https://www.reddit.com/r/datascience/comments/slz7yb/ways_to_prepare_for_a_productoriented_case_study/,1,1644161072.0,"or as others may refer it as 'product interview' ? 

&#x200B;

e.g.

\- Given a business case study, how would you create an experiment for this? 

\- What are the success criteria/metrics ?

&#x200B;

Any guides / reading materials on this as a preparation will be much appreciated :)

&#x200B;

Thanks",2022-02-06 17:24:32
PRAW Project - Preferable to dump output to CSV/JSON/TXT and work from that or process from PRAW output directly then dump that?,2,slxaan,https://www.reddit.com/r/datascience/comments/slxaan/praw_project_preferable_to_dump_output_to/,1,1644155998.0,"Hi,

New to coding and taken up Python. It's fun. Slowly getting into data science, which is even more fun.

A question if I may?

I'm building an scraper, one of many that will provide data that underpins a longer term project.

From a data science point of view, do you feel it would it be preferable to either:

* Dump the raw output from PRAW query(s) to a file then manipulate/analyze that data from file?
* Manipulate/analyze the data directly from PRAW and output the processed data into a data file?

What would you do, and why?

Many thanks",2022-02-06 15:59:58
Successful Data Science Organization Structures,5,slwroo,https://www.reddit.com/r/datascience/comments/slwroo/successful_data_science_organization_structures/,6,1644154426.0,"TL;DR: work in siloed old school org trying to modernize structure and process, help



I work at a large company in an applied data science role. My team supports multiple sub organizations as part of a larger, global function. Our company as a whole is extremely siloed - business functions have different process, software and practices pretty much everywhere. Work is particularly siloed in non engineering focused orgs (eg sales hr finance etc). The company will never move to a single org owns all model.

Our team has been trying to establish a common framework for scaling and doing data science (and generally analytics) for our organization with a goal of establishing common practices, feature stores, environments, and even a common platform. The goal is to give data scientists and analysts a “home” as they onboard and support this via a mostly federated structure. Another major goal is to share knowledge and code to upskill and build community inside of the organization.

We’ve run into headwinds from old school practices of IT teams full of offshore temp resource and a few PMs trying to “break into ML” and charge our partners in the organization capex while doing it. They don’t like to partner and would rather prefer to work in the early 2000s IT type silo (see siloes in this case). Other IT teams host common enterprise platforms. We also have managers in place who have trouble understanding that technical and highly quantitative employees can actually be part of business teams solving problems and gaining domain knowledge.

There is a definite culture shift / change management exercise needed and maybe I’m wrong in thinking establishing scalable working practices, data sharing and building a common knowledge graph are ideals to aspire to.

I’d love to know if someone has built or worked in what they think is a good organizational model for data science in support type functions… it would also be great to hear the horror stories too.",2022-02-06 15:33:46
Weekly Entering & Transitioning Thread | 06 Feb 2022 - 13 Feb 2022,8,slv2sn,https://www.reddit.com/r/datascience/comments/slv2sn/weekly_entering_transitioning_thread_06_feb_2022/,204,1644148830.0,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",2022-02-06 14:00:30
What's your dream company?,184,slst7r,https://www.reddit.com/r/datascience/comments/slst7r/whats_your_dream_company/,278,1644139800.0,"What's your endgame company that you feel like you will be the most fulfilled to work for? For a lot of animators it's pixar, for sports players it's the NBA, MLB etc. what's the data scientist equivalent?",2022-02-06 11:30:00
Using regression analysis to forecast sales in a SAaS firm?,4,slq3c2,https://www.reddit.com/r/datascience/comments/slq3c2/using_regression_analysis_to_forecast_sales_in_a/,10,1644129402.0,"I recently got hired at a small SAaS company as an FP&A analyst. The girl I’m backfilling was a genius who went to an IVY league school with a heavy comp sci/data analytics background. However, she made her way into Finance at my company and created this crazy model in R to essentially do regression analysis on our historical bookings and use it to project future order intake. She’s pretty much using actuals and I think she has some slices on both products and segments/verticals. But I also think there is a component where she layers on pipeline data.

I’m in the process of learning how her model works but I started trying to do some of my own analysis. Basically, I wanted to see if some of the bookings in our verticals which house our customers from different industries (healthcare, telecom, energy) could match up against different stock price indices (SPDR S&P 500, Russell 3000, healthcare, telco, tickers etc.) as an example, I compared our ACV closes the past 2 years in our healthcare segment to the XLV healthcare ETF performance for the same period of time and did the regression in Excel. My R^2 was basically 0, which essentially means that there is no correlation between the 2. I would’ve figured if our healthcare customers are doing well and growing revenues, that would be reflected in increases in the XLV healthcare etf price.

I did a separate regression on UPS and looked at their stock price and revenue for the last 15 years and the R^2 came out to 0.9 which means there is a decent amount of correlation. So if growing revenue typically leads to higher company stock price, why were my results basically inconclusive?",2022-02-06 08:36:42
I'm not creative about EDA...any tips?,10,slmgxh,https://www.reddit.com/r/datascience/comments/slmgxh/im_not_creative_about_edaany_tips/,10,1644110967.0,"I'm just never really that sure what I should be doing.

Like right now I'm working with some text data scraped Reddit. It has class labels, upvotes/sometimes update ratios, etc.

The only ""exploration"" I've done is to look at the label distribution to see how balanced/imbalanced they are and plot word clouds of each class and been like ""yeah most of these words make sense for that class"" or ""this word is probably over-represented due to biases in my data source (Reddit vs world at large differences)""

What kind of stuff would you look at/what are your general go-to EDA activities?",2022-02-06 03:29:27
"For those interested in data privacy, what recent privacy issue has caught your attention and why?",1,slg0l5,https://www.reddit.com/r/datascience/comments/slg0l5/for_those_interested_in_data_privacy_what_recent/,3,1644093365.0,"In addition, I'd love to hear about your interest in the privacy space. I'm just beginning to learn about data privacy and I'd appreciate hearing everyone's insights about its importance, impacts, and why it appeals to you. Thanks!",2022-02-05 22:36:05
Applications of environmental Data Science to economics? Are there topics in environmental sciences or environmental data sets that are of interest to research in certain fields in economics ?,3,slefvh,https://www.reddit.com/r/datascience/comments/slefvh/applications_of_environmental_data_science_to/,3,1644088611.0,"I am currently taking an environmental Data Science course at my university . While the course in the geography department , due to it's emphasis on using programming and a variety of data analytical techniques such as machine learning to process environmental and geospatial data , a lot of different majors end up taking it to build their skills in data science.  Since a semester long research project in processing environmental Data is a part of the grade , students try to pick research projects that align with their academic interests.

As a potential economics major I am interested in conducting research in a topic or analysis of some data set that might have applications to economics. So I was hoping this subreddit could point me towards fields or  economics where environmental Data analysis may be of value.",2022-02-05 21:16:51
I am looking to do data visualization work for free for small businesses and nonprofits in return for client testimonials and publishing the work in my portfolio. Where can I get such clients?,11,slb5l2,https://www.reddit.com/r/datascience/comments/slb5l2/i_am_looking_to_do_data_visualization_work_for/,12,1644079249.0,"Non-native English speaker here. I live in Bangladesh.

I just finished a course learning Tableau. I am looking to do freelance work on Tableau eventually and right now I want to test out the skills that I learned in a practical environment. As part of creating a portfolio, I am looking for small businesses or nonprofits for whom I can build a data visualization or a dashboard. The work will be pro bono, in return for a client testimonial and the permission to publish the work on my portfolio website. 

Now I was wondering, where can I get such clients?",2022-02-05 18:40:49
Is the average salary for Data Analyst based on just the job title?,125,sl8u05,https://www.reddit.com/r/datascience/comments/sl8u05/is_the_average_salary_for_data_analyst_based_on/,90,1644073120.0,"I'm looking at the average salary for a Data Analyst position at my current company and it is low at around $60k. However, the job descriptions for the majority of full-time Data Analyst positions at my company requires no coding skills, or even SQL and Tableau skills. A small amount requires SQL and Tableau, but zero coding skills. 

My upcoming internship is for a Data Analyst position, but talking to my Hiring Manager, he said that I'll be building data pipelines, extracting, processing and analyzing data with SQL and Python. I'll also be building Tableau dashboards. Additionally, I'll work with Machine Learning Engineers to deploy ML models by developing full stack web applications (also using a lot of Python, Flask and JavaScript). So I was thinking if I continue full-time with the company for this role, would I be paid the average $60k salary or is Data Analyst just a title and the pay is more aligned with the work you're doing?",2022-02-05 16:58:40
Anyone familiar with EMD ( empirical mode decomposition)?,21,sl72cw,https://www.reddit.com/r/datascience/comments/sl72cw/anyone_familiar_with_emd_empirical_mode/,2,1644068070.0,"So I am writing a thesis and was told to use ANN with EMD, predicting a crop production using weather variables. It’s the EMD part that I don’t quite understand. After getting several IMFs, how am I supposed to continue with my ANN? Do I just EMD all my predictors and just fit it into ANN without touching my response variable?

Most of the paper & resources are based on time series forecasting. Would be great if someone can point me some directions. Thanks !",2022-02-05 15:34:30
[ Q ] : When did you realize that you wanted to switch jobs (move from your firm to a different firm)?,5,skzkgy,https://www.reddit.com/r/datascience/comments/skzkgy/q_when_did_you_realize_that_you_wanted_to_switch/,15,1644040237.0,"Hi all,

I have recently noticed a decent number of Data Scientists and SWE from my firm (Management Consulting) have been leaving for non-consulting roles. This is not that uncommon in the consulting space. But, it made me curious as to what motivates DS people to want to switch jobs?

So, I’m asking you lot about what drivers pushed you to pursue a different role?

I am pretty satisfied with my role, currently. Learning a lot and expecting a promotion in the near future. So, I’m not looking for a change per say. Just asking for other perspectives.

Cheers",2022-02-05 07:50:37
What GIT workflow do you use?,4,skti1a,https://www.reddit.com/r/datascience/comments/skti1a/what_git_workflow_do_you_use/,8,1644021888.0,"My work is switching over from Bitbucket to GitHub and I am in the process of migrating.  In BitBucket, I was using 1 repo for my team, and each project and report was a folder.  In GitHub, I was thinking about switching to have each project and report be it own repo.

Wanted to understand what other people were doing, and what the pros and cons of each approach would be.",2022-02-05 02:44:48
Confused about Randomforest model result,16,sksr99,https://www.reddit.com/r/datascience/comments/sksr99/confused_about_randomforest_model_result/,23,1644019910.0,"Hello fellow data scientists good afternoon. I have a question about my random forest model results which are misleading and I have a feeling about what’s going on but want to run it by more data scientists. I have a data set that has codes and an outcome, so all predictors and the outcome are categorial variables. Some predictors have more than 20 categories and they they are distributed non-uniformly. The dataset contains 6.7k observations with 20 predictors not counting the outcome variable. Here is example data. (I can’t post actual data due to it being sensitive). Please note that the Outcome variable is distributed evenly \~ 3.3k No-Disease/ 3.3k Yes-Disease, and evenly split in the test/training set, and I have no continuous predictors in my dataset.

&#x200B;

|Code1|Code2|Code10|Code20|Outcome|
|:-|:-|:-|:-|:-|
|BP High|Active|Vegan|Hypertension|No-Disease|
|BP High|Moderate Active|Vegan|Hypertension|Yes-Disease|
|BP Low|Low Active|Non-Vegan|No-hypertension|No-Disease|

&#x200B;

Now after my 80/20 train test split and running a random forest model with 500 trees, and 10 splits per tree I am getting 98% accuracy on test set and training set. The confusion matrix is also classifying all instances of yes / no Disease almost perfectly for training set, and test set..for example here is what the confusion matrix looks like for the test set

&#x200B;

|Test\_set\_confusion\_matrix|Yes-Disease|No-Disease|
|:-|:-|:-|
|Yes-Disease|500|5|
|No-Disease|3|500|

&#x200B;

Obviously this is an extreme case of over-fitting and I have a feeling that in my data I have some codes that are extremely strong predictors of the outcome or I have a data leakage which I an unable to find. What do you guys think?",2022-02-05 02:11:50
Time-varying Windrose,1,skorbk,https://www.reddit.com/r/datascience/comments/skorbk/timevarying_windrose/,0,1644009825.0," Does anyone have any suggestions on how to have a time-varying windrose? I was thinking of doing a regular joint-histogram for directionXtime, but would like to check if there is a better option.",2022-02-04 23:23:45
All Negaive weights in Logistic Regression (Please help),3,skmg6z,https://www.reddit.com/r/datascience/comments/skmg6z/all_negaive_weights_in_logistic_regression_please/,38,1644004077.0,"EDIT:  Thank you, everybody. I can't appreciate enough how much you helped me.  The problem was merely in the fact that standardization(z-score)  should have been applied alone rather than normalization. Normalization apparently failed since we deal with almost 20 (out of 60) columns of categorical data. Or maybe it is deeper than that - as I said I am new to ML and DS.  Thanks again!)

&#x200B;

&#x200B;

I have a project where I have to build a Logistic Regression from scratch. For two weeks now, I have been encountering the same problem regardless of what I do: all 60+ of my weights are negative. First I scan the given data: normalization, standardization, replacing missing values with inter-row interpolation, then I just removed the rows containing missing values (like 0,5% of all data). I wrote the first code myself with whatever linear algebra I remembered from college, but it yielded negative weights. I then looked up other build from scratch codes for LR - run them with my data(as processed above), again negative.

I know maybe this is not the correct place to write, but I am desperate to find out what is the problem. I'm losing sleep over it. And if any of you encountered such a problem of all-negative weights any help would do. I am not asking you to spoonfeed me, just a piece of advice.  Thank you.",2022-02-04 21:47:57
How often is optimization used vs statistical modeling?,5,skhf9w,https://www.reddit.com/r/datascience/comments/skhf9w/how_often_is_optimization_used_vs_statistical/,20,1643991768.0,"I was wondering if optimization is ever used to solve problems in data science vs using statistical models. I’m sure it depends on the problem entirely, but I’m wondering how often any of you have relied on creating an objective function, creating some constraints and used some sort of linear programming or optimization algorithm to understand parameters vs using statistical modeling methods like regression or any other techniques. Asking because for a math minor course i am wondering if I should take that class vs a second linear algebra or real analysis course.",2022-02-04 18:22:48
Job asks for DA but they need a highly skilled DS.,24,skf86p,https://www.reddit.com/r/datascience/comments/skf86p/job_asks_for_da_but_they_need_a_highly_skilled_ds/,18,1643986645.0,"Self taught Python and R. Made some decent projects in each to help land my first job as a data analyst. 3-4 years of SQL in the workplace (designing schema for new DB, creating tables, windows functions, reg ex, joins, creating queries, and management of the database) and 6+ years in finance with some BI sprinkled in and creating dashboards. 

Applied for a job that asks for 2-4 years of SQL, ML nice to have, and R. Great. I apply. Four rounds of interviews. 3/4 (including technical) not a problem. Did well in the others (senior management interview and HR) and technical I passed and got positive feedback during it. 

I do my final round with the group I’d be working with. That’s when the red flags came. Have a group of managers who need not a data analyst with 2-4 years of experience but a data scientist. 

Predictive modeling, needs AI, needs to be this model that predicts who to target, trends of who may want to leave, results of attempting to to retain. Previous attempts of this giant model failed after a handful of times of attempting and they needed it yesterday and if hired this thing needs to be up and running as soon as possible. With all the problems I’d solve IF I could make this, I could easily go to a competitor and ask $40K more. Entire three departments rely on this one model, if made correctly. 

I’m sitting there like, wtf?! This was sold to me in the previous rounds as a late entry level to early mid to grow into. What they need is a data scientist with years of experience and at least exposure to the industry to understand all the terms they use. 

I carefully read and re-read the job requirements. Nothing in it set off any red flags. 

How often does this happen? I went two weeks thinking this is amazing and then when I see the actual work I’m like don’t be cheap and get someone who knows this because you need someone not a data analyst.

How to avoid this in the future? I asked the entire way what’s the work like and and all were like don’t worry all good.",2022-02-04 16:57:25
Welcome to r/datarace! Have you created an animated visualization? Or have you seen one in the wild? Here is the community to share it.,0,skdob5,/r/datarace/comments/sk40yx/welcome_to_rdatarace_have_you_created_an_animated/,0,1643982405.0,,2022-02-04 15:46:45
What's a sign somebody's unusually good at SQL?,533,skc72q,https://www.reddit.com/r/datascience/comments/skc72q/whats_a_sign_somebodys_unusually_good_at_sql/,137,1643977906.0,"I have a few job interviews coming up, and all of the employers are hyper-focused on SQL. I have to do SQL tests and I get grilled on SQL questions.

Passing the tests hasn't been a problem, but SQL feels simple to me, and I'm worried that's because I'm just completely unaware of the intricacies.

Are there performant ways of coding or best practices that would make it clear a candidate had a deep understanding of SQL?

Or do recruiters truly just want to know that I can SELECT * FROM Table?",2022-02-04 14:31:46
"Data scientist in name only, feel stuck",198,sjyg4s,https://www.reddit.com/r/datascience/comments/sjyg4s/data_scientist_in_name_only_feel_stuck/,89,1643932631.0,"I'm looking for advice on how to move on from my current job.

My title is data scientist, but I don't do any data science. My job mostly consists of: stakeholders giving vague requests for data, I go figure out which database(s) the data lives in, write some SQL/mongo queries/parse some json, and send off the output. 
Usually a CSV file or a simple Power BI dashboard. The stakeholders say thank you, take the output and maybe they do something with it. I get told there is a lot of value to my work, but it's not clear to me what that value is and it's not directly tied to saving or making money for the company.

I don't analyze the data for trends. I don't come up with KPIs. I don't build models. I don't forecast. Nothing I do is directly tied to making the company money. I certainly can't put anything on my resume like ""saved/generated $x"", because I don't do anything but churn out flat files and dashboards.

I don't get to use any interesting technology. Everything is on prem, data sets are small, and I have to use Windows Task Scheduler to schedule things that are repeated (no access to Linux servers).

My job is easy the WLB is good, I make enough to live comfortably in a medium CoL city, but I'm so bored and afraid I'll be stuck in this forever. Looking at job postings, I don't feel remotely qualified for anything.

What do I do? How do I move on?

Do I apply for data analyst positions? This is my first job out of school (MS in operations research). I've been with the company for five years, three as an analyst and two as a ""data scientist"". Mostly it was a title change, with the only major difference being that I spend more time helping less experienced teammates.",2022-02-04 01:57:11
Random Forest Output (Date / Quarters),2,sjw77y,https://www.reddit.com/r/datascience/comments/sjw77y/random_forest_output_date_quarters/,4,1643926911.0,"Random Forest Model

I have variables that are quarters within the data set, Q1 thru Q4, that look like just 1,2,3,4. This is a result of me stripping out the months and using the date function to give me quarters. I was trying to simplify my model and not use all 12 months.

When I go to visualize my decision tree(s) in my random forest (sklearn), it seems as though I am getting splits as Quarter 2.5 or 3.5. In reality one could ascertain hey that makes sense, its half-way through the quarter but what I gather is between the encoder and random forest its just being treated as an integer and splitting it rather than looking at it as halfway through the quarter. I know this as I have another categorical variable called subset which signifies types of projects and its also splitting those up, such that I have a 2.5 type project rather then it is splitting at type 1 project or type 3, not a 2.5.

I thought I could fix this by making them into dummy variables so at least I was stripping away the int part of the equation but alas, this still does not work. There might be something in my code which I will go take a look but does this approach make sense or should I be trying something else?

Thanks",2022-02-04 00:21:51
How to distribute ML tasks across CPU and GPU?,3,sjrzhl,https://www.reddit.com/r/datascience/comments/sjrzhl/how_to_distribute_ml_tasks_across_cpu_and_gpu/,8,1643916678.0,"So I am new to all the multiprocessing stuff and having a hard time figuring it all out. 

For work we have a Linux box to run our ML code on, the box has 3 GPUs and 160 CPUs. 

We run the same data set through 2 different models (LSTM and XGboost) to compare performance and results. 

Both the LSTM and XGboost run on a single successfully (according the nvidia-smi). 

Right now the code is set up to run in order so the XGboost won’t start training till the LSTM is done. I’m looking to train these simultaneously on two different GPUs to speed up training. Is the only solution to use something like Rapids?",2022-02-03 21:31:18
Hypothesis Generation + Leading Data Science Projects,2,sjog5r,https://www.reddit.com/r/datascience/comments/sjog5r/hypothesis_generation_leading_data_science/,3,1643908162.0,"Hi everyone, I'm still fairly new in my data science career and I find that where I am lacking is in hypothesis generation and leading data science projects. 

&#x200B;

For instance, if I am given a clear defined task of doing data exploration and then building a predictive model, I can usually do well at that. What I find difficult is driving my own projects, figuring out which hypotheses to test in terms of where we can take the project and what to do with the data, what is possible to do with the data, what additional data can be brought in to further develop the hypothesis or create new ones.

&#x200B;

Is there any advice on how to develop this skill or type of thinking?",2022-02-03 19:09:22
DeepMind says its new AI coding engine is as good as an average human programmer,367,sjn4fl,https://www.theverge.com/2022/2/2/22914085/alphacode-ai-coding-program-automatic-deepmind-codeforce,121,1643904916.0,,2022-02-03 18:15:16
Using Time series Feature for Customer churn of Products,11,sjmdnj,https://www.reddit.com/r/datascience/comments/sjmdnj/using_time_series_feature_for_customer_churn_of/,3,1643903094.0,"HI All,

At work we are trying to predict customer churn in the next N days ( N is yet to be defined) and apart from the customer level features like Age, Gender , Address etc we also have their product usage details at day level as well.

I was thinking to approach it using a typical classification algorithm with aggregating time series data points as features for ex if we have 3 months of user data then we will have a single record for a user and will have activities captures in M1\_past, M2\_past, M3\_past, M3-M1 , M3-M2 etc.

This sounds okay to me but wanted to see if this is the standard way to approach this problem. Also if I use the above framework then every prediction is telling me the probability that the customer will churn in next N days , depending on my training data.

Is there a better way than this ?",2022-02-03 17:44:54
A/B Testing: When would you conclude the result after a trial has ended?,26,sjigth,https://www.reddit.com/r/datascience/comments/sjigth/ab_testing_when_would_you_conclude_the_result/,19,1643892886.0,"At my company, we want to conduct ab testing where a treatment group receives a one-off discount voucher, which would be valid for a month and the top metric our stakeholders want to see is avg. order value per customer. 

However, the issue is that they want to see the effect of this intervention on the value after 3 months as they thought it’s likely to be lagged effect, which I disagree as the longer we wait, the more uncertainty we might have.

My questions are
1. Should this order value be a successful metric?
2. What time period in the data do you normally consider in order to conduct the test? For example, if we use CTR, it’s the data during the trial that we’re looking at, right? But for my case, I have no idea.
3. How do you communicate that a/b testing is not designed for finding a long term impact to stakeholders? I would rather do multiple trials in a different period rather than checking that there’s a long term effect of this on the value. (I’m not even sure if it’s possible to draw a conclusion/inference for that)

I'm still new to such testing but hope you could enlighten me, thanks :)",2022-02-03 14:54:46
How do you solve problems with your team and domain experts?,2,sjid6v,https://www.reddit.com/r/datascience/comments/sjid6v/how_do_you_solve_problems_with_your_team_and/,4,1643892594.0,"Hi all!

I'm working on a product where our goal is to help data experts (data scientists, ml engineers, data engineers, etc) solicit input, get feedback, and problem solve together with non-experts and each other. We have quite a bit of experience with this ourselves, but we need more data points to build a product off of. Would appreciate enormously if you could help us out!

**My question to you is:** What do you do when you need input on what you are building, particularly from non-technical people/business experts? 

For instance,

* How do you provide the right context for them to understand what you are doing and what you really need input on?
* How are they able to express themselves and their ideas to give you feedback?
* If you discover something unexpected in the data, how do you go about asking questions about that to sort it out?

I'm particularly trying to understand what tools you find most useful in this process and where your biggest challenges are today (especially in a remote work environment).

Thanks so much for taking the time to answer!",2022-02-03 14:49:54
"ELI5: what’s the difference between correlation between each feature and the target variable, and feature importance?",9,sjhcdm,https://www.reddit.com/r/datascience/comments/sjhcdm/eli5_whats_the_difference_between_correlation/,5,1643889244.0,"If I wanted to see which feature had the most impact on my target variable, would I use correlation between each feature and the target, or run it through a random forest regressor and look at feature importance? I feel it’s likely they will output similar results right?

Just to note, this isn’t a feature selection stage, nor is the aim to build a model, I simply want to see which feature has the larger impact on the target variable. Am I getting confused with correlation vs causation? Does it matter? What measure would I use in this scenario?",2022-02-03 13:54:04
How to solve this problem? Training data is and will always be generate from a different source to the real world/test data.,12,sjh11v,https://www.reddit.com/r/datascience/comments/sjh11v/how_to_solve_this_problem_training_data_is_and/,17,1643888130.0,"The client has a machine that produces a reading (a 1024 1-D vector) that serves as an identifier for that material.

The client does **not** have access to other machines **outside of his.** He wants to create a model that others can use (all will have different machines) to identify the material using their own machine.

He has given me some training data (from **his machine**) and test data from an **external machine.**

If I do a 30:70 split on the training data I get 100% accuracy easy peasy. 

However, if I use only **machine 1 for training** and **test on machine 2's data**, I get 70% accuracy.

**He said going forward in the real world they'll only be able to create a training dataset from his machine.**

&#x200B;

How would you solve this?

1. Would I need some sort of auto-encoder that learns to map machine 2 to machine 1? and then classifiy using a model built on machine 1's data.
2. I'm thinking Siamese Networks might also be appropriate (as they update and delete their database of materials regularly), I can covert the measurement to an image using pyts. But again I will have the same problem as above though.
3. However, the database is huge, with tens of thousands of rows. How do Siamese Networks in the real world perform such a fast similarity search? Don't they have to get a similarity score to each entry in a database and then use the highest as the prediction?",2022-02-03 13:35:30
Day in Life of a Healthcare Data Scientist?,35,sj8vu1,https://www.reddit.com/r/datascience/comments/sj8vu1/day_in_life_of_a_healthcare_data_scientist/,25,1643859651.0,"I want to explore other possible fields in Data Science such as healthcare. Currently an undergrad math major looking at a Masters Data Science (I have reasons for this instead of bootcamp) at a school with deep connections with healthcare companies. 

I am wondering what sort of projects and topics come up in the healthcare realm of data science. I understand “healthcare data science” is very ambiguous and vague, but any feedback is much appreciated. :) Cheers",2022-02-03 05:40:51
"Data science part of Max Deutsch: 1 - In 2017, chess n00b challenges world champion magnus carlsen and fails miserably. 2 - Few months later chess engine alphazero comes out. 3 - In 2022, data scientist points this out XD 4 - My lame joke: This n00b is the creator of alphazero.",0,sj8rql,https://www.reddit.com/r/datascience/comments/sj8rql/data_science_part_of_max_deutsch_1_in_2017_chess/,1,1643859313.0,"[https://www.youtube.com/watch?v=RKsFu6V55jc](https://www.youtube.com/watch?v=RKsFu6V55jc)

Cross-posted: [https://www.reddit.com/r/chess/duplicates/sdtvll/data\_science\_part\_of\_max\_deutsch\_data\_scientist/](https://www.reddit.com/r/chess/duplicates/sdtvll/data_science_part_of_max_deutsch_data_scientist/)

# Intro:

In 2017, an 'obsessive learner' named Max Deutsch challenged the world chess champion magnus carlsen ( r/magnuscarlsen  not r/wesleyso ) to chess after a month of learning. Well, e didn't actually train. E was supposed to create an algorithm and then...I guess let a [bot](https://lichess.org/@/thibault/blog/how-to-create-a-lichess-bot/FuKyvDuB) based on the algorithm play against magnus. The algorithm didn't finish or whatever, so they just played a regular game for kicks. **The whole thing was a stunt basically.**

# About:

There have been many reviews(/revisions) in the chess community about this (see appendix), but this is the 1st video that gives an actual data science perspective. It includes an inside look and some discussion of engines, in particular [alphazero](https://en.wikipedia.org/wiki/AlphaZero), in general.

There's something the data science guy points out something that I found **a funny coincidence**: [Alphazero](https://en.wikipedia.org/wiki/AlphaZero) apparently came out in 2017 a bit after this stunt. And alphazero does something similar to what max deutsch thought of for the algorithm. Lol.

I said

> \> On December 5, 2017, the DeepMind team released a preprint introducing AlphaZero, which within 24 hours of training achieved a superhuman level of play in these three games by defeating world-champion programs Stockfish, elmo, and the three-day version of AlphaGo Zero.  (re [15:45](https://www.youtube.com/watch?v=RKsFu6V55jc&t=945s))  1 - ah so alphazero really came out in late 2017 just after the max deutsch thing?  2 - if no, then what do i misunderstand? if yes, then COINCIDENCE? I THINK NOT!!!!!!! XD 

Response  


>Yeah, that's exactly right, AlphaZero did come out just after this piece was published in 2017, so it very well could be that Max Deutsch developed AlphaZero in one month and sold it to the Google DeepMind team who then took all the credit haha 

&#x200B;

# Appendix: Chess community videos on Max Deutsch's Challenge:

Agadmator (2017) - [https://www.youtube.com/watch?v=kNF0L...](https://www.youtube.com/watch?v=kNF0LkIodXw&t=0s)

Agadmator (2021) - [https://www.youtube.com/watch?v=\_jx\_jySDkN0](https://www.youtube.com/watch?v=_jx_jySDkN0)

Gotham Chess (2021) - [https://www.youtube.com/watch?v=a\_6rT...](https://www.youtube.com/watch?v=a_6rTnbUQOo&t=0s)

Daniel Naroditsky (2021) - [https://www.youtube.com/watch?v=aux7N...](https://www.youtube.com/watch?v=aux7NOLq3sY&t=0s) 

1st and so far only philippine wgm janelle frayna (2021) [https://www.youtube.com/watch?v=GSJ0Ah\_iTkY](https://www.youtube.com/watch?v=GSJ0Ah_iTkY)",2022-02-03 05:35:13
How often is deep learning used in the general workplace?,141,sj7umz,https://www.reddit.com/r/datascience/comments/sj7umz/how_often_is_deep_learning_used_in_the_general/,70,1643856622.0,"So my machine learning professor went on a rant today saying that in the general workplace, 80% of the problems you'll most likely face will requires no deep-learning, and while fancy stuff like GANs, reinforcement learning are still useful for fields dealing with image/video/NLP data etc., he said that using a neural network for everything, is like ""using a chainsaw to slice tomatos"". Just as an informal survey, how often do you use neural networks, in the workplace?",2022-02-03 04:50:22
How to you analyse Data that occurs in a Controlled System?,2,sj6pep,https://www.reddit.com/r/datascience/comments/sj6pep/how_to_you_analyse_data_that_occurs_in_a/,2,1643853402.0,"I read a blog post about Milton Friedman’s Thermostat Analogy - discussing how a controlled system can lead to the data indicating no correlation when it is something that is in fact correlated, but the system controls it the the point that the correlation cannot be found by observing the data. 

I work in the Resources industry and deal with Industrial Processing Plant data. The plant has lots of PIDs and a DSS Control System. 

Has anyone got any experience working in this type of field, and finding relationships despite the control system seeming nullifying any natural relationships in the data? Is understanding the control theory of the part of the system I’m looking at always going to be a relevant part of my analysis? 

I’m a graduate Data Scientist and our company is only just beginning to develop a Data Science team in-house, so any advice would be greatly appreciated.",2022-02-03 03:56:42
What's your learning method?,9,sj2k8h,https://www.reddit.com/r/datascience/comments/sj2k8h/whats_your_learning_method/,12,1643842403.0,"Hello everyone, I have some experience in web development, but it seems that learning DS isn't the same as learning how to make a web application.

What's your learning method? How would you learn data science if you could go back in time?

And how do you practice what you learn?

EDIT: for context I'm studying data science at school so I have the important basics of mathematics and software engineering, but school aren't doing a good job since they didn't use to teach DS subjects (used to teach SWE and maths).",2022-02-03 00:53:23
Suggestions needed... having really bad time with Databricks and PySpark,17,sj29i8,https://www.reddit.com/r/datascience/comments/sj29i8/suggestions_needed_having_really_bad_time_with/,26,1643841680.0,"I started to work in a company that use Databricks and PySpark a couple of months ago and I'm having some really bad time with them. I have extensive experience with python, R, SQL and C++ but I have never been in such a pain with any language franework or library. A laggish interface and a constant stream of gibberish java errors, variables that disappear without any notification and uselss documentation.

How do you manage to maintain your sanity while working with them?",2022-02-03 00:41:20
Your Favorite Pair Programming Interview,128,sj0sjx,https://www.reddit.com/r/datascience/comments/sj0sjx/your_favorite_pair_programming_interview/,60,1643838118.0,"Hey all.  My new team is currently hiring MLEs and I am on the interview panel.  We're revamping our interview process to not involve any Leetcode or take homes.  Specifically, we'd like to do a 45 minute pair programming session which will focus on data manipulation and EDA tasks similar to what you might actually do on the job.  I was thinking of taking a toy dataset from a public repository and asking them to load it, then perform operations on the data in a language of their choice such that we arrive at a solution to a given objective.

Has anyone conducted or experienced any data-centric pair programming interviews that you thought were relatively well-designed?  We're really just looking to understand how they reason with and work with real-life data.",2022-02-02 23:41:58
How to know if linear regression model is over or under fitting without having access to the test data?,5,sitne3,https://www.reddit.com/r/datascience/comments/sitne3/how_to_know_if_linear_regression_model_is_over_or/,16,1643821180.0,"Hey, so I’m building several models for school where I’m only given a training dataset, and have to test my model on the school’s page which only returns an RMSE score. 

So far, the lowest RMSE Score my model got is 8.33, and I’d like to know if there’s any way to know whether my model is over or under fitting when I don’t have access to the test data to plot it?",2022-02-02 18:59:40
Visualising Code,2,sis3ae,https://www.reddit.com/r/datascience/comments/sis3ae/visualising_code/,3,1643817460.0,"I use two models, one written in python, one written in fortran. They are fairly complicated, and I would like to be able to visualise what functions call what, for example, what relies on what, what data gets fed into which functions and so on to help me learn them/understand them as I add bits/want to modify bits and know what's doing what.

I can imagine this being pretty horrendous to look at, and maybe impossible. Is there any way that code can be visualised? (either python or fortran ... or converted to something that could be visualisable?) If you have any hints/tips or anything that could be similar to this sort of thing, slightly or more, thank you so much!!",2022-02-02 17:57:40
"How often is PCA used in ""the real world""?",234,siruz8,https://www.reddit.com/r/datascience/comments/siruz8/how_often_is_pca_used_in_the_real_world/,190,1643816889.0,"In school right now and a ML class is having us use PCA prior to the modeling. I'm wondering if it's one of those ""yea they teach that but you'll never really need it"". If that's the case I'm wondering what is maybe more ""industry standard"". I know there isn't 1 specific approach but I was wondering maybe what's a good approach or how you decide the approach.",2022-02-02 17:48:09
Reasons not to pursue FAANG Data Science?,0,sirorn,https://www.reddit.com/r/datascience/comments/sirorn/reasons_not_to_pursue_faang_data_science/,95,1643816459.0,"Hello,

I will be graduating this semester with an engineering degree (data science concentration) from a top 10 engineering school. I came upon this path late so don’t have any internship experience, but it seems like many people in my network get their Masters in Analytics afterwards and then work a nice cushy data science job at a FAANG or similar company paying $150-200k+.

I’m not trying to disrespect anyone’s skills or intelligence, but I just want to get a better understanding. Why does everyone just not work at FAANG (and adjacent companies) given their high compensation? What are the downsides to working in these companies? Is a PhD typically required for career progression? 

I see many posts on here talking about making ~100K after X years of experience, so just wanted to hopefully gain a better understanding of the difference between these lower paying jobs as compared to big tech. 

I appreciate you all sharing all your insight and experience. Thanks for the help!",2022-02-02 17:40:59
Data Science in smaller company VS Bigger one,49,sipdwk,https://www.reddit.com/r/datascience/comments/sipdwk/data_science_in_smaller_company_vs_bigger_one/,28,1643810371.0,"Hello everyone!

I have a big doubt and I would like the opinion of someone who has been working in this field for a while.

I've has been working for 7 months as Data Scientist in a small startup that is growing very fast, but there Is not much data science to do. What I do is basically Counting corrupted data. I built a model my first month for user identification, then for the other 6, I just made counts. No one is coaching me, so I self-learn most of the time. In addition, data science is a mess and they don't seem to care too much.

On the other hand, there is a smaller videogame company that is looking for a data scientist for 'classic problems' (such as predicting churn, videogame analytics, business models, regressions, etc.).

The founder is a computer scientist with a Ph.D. who has worked in the industry for over 10 years, and he offered to teach me everything about videogame economy design and business intelligence about the gaming industry.

The pay is the same, but I would join a smaller company that relies mostly on data science.

On the other hand, my actual company is growing faster but they don't care too much about data science.

Any tips ?

PS I got 28 years, I just started my career in data science 7 months ago and I'm scared to do the wrong thing for my career",2022-02-02 15:59:31
What's your tip on going through research papers? Need advice!,9,siotyw,https://www.reddit.com/r/datascience/comments/siotyw/whats_your_tip_on_going_through_research_papers/,13,1643808901.0,"I am a student(masters), having a hard time going through so many papers. Can't seem to focus and sit through the papers at once. I find some interesting and sometimes too many math equations kill me. any tips/advice from your experiences?!",2022-02-02 15:35:01
How can I determine the difficulty of a ticket on unlabeled data?,0,siogpp,https://www.reddit.com/r/datascience/comments/siogpp/how_can_i_determine_the_difficulty_of_a_ticket_on/,10,1643807832.0,"I was tasked with a project, where the goal is to figure out in a somewhat objective way the level of difficulty of a ticket that an employee has processed. I have about 50 attributes and almost all of them are categorical. Among those there is one attribute, which is sort of the type of task that was performed and I think it will be important, although I'm not sure how to incorporate this into the model.

Since the data is unlabeled and there is no way I can go through with this without making any assumptions at all I have defined my goal as this - Create such groupings of the data, so that I will be able to tell with a high level of confidence that if the tickets in a specific region are on average characterized by those values of attributes and those relationships between them, than they are easy/medium/hard.

Do you have any suggestions on how can I approach this? How do I find the important relationships and then incorporate them into the model? How can I evaluate quality of the groupings, while making as few assumptions as possible?",2022-02-02 15:17:12
Looking for pointers on where to begin learning about databases specifically for sensoric data.,0,sioeg1,https://www.reddit.com/r/datascience/comments/sioeg1/looking_for_pointers_on_where_to_begin_learning/,0,1643807657.0,"Dear data science,

I would like to to learn how to create and manage databases for sensoric data from a lot of different people, which should be easily available to upload and also be able to be used as input for machine learning models. For each person, millions og data pouts would exist since they are sampled at quite a high frequency. 

I have little to no experience with databases and would really much like to learn more about it. I have great experience with python, and using this to interact with my database would be awesome. I am also keen on learning a new language to expand my competence with databases for this type of data.

Where do I begin? What would be the best to use in this case? Anything will be helpful! Cheers",2022-02-02 15:14:17
"""Ordinal data, metadata, and models""",1,sio5z0,https://www.reddit.com/r/datascience/comments/sio5z0/ordinal_data_metadata_and_models/,0,1643806968.0,"From Thomas Lumley (who created the survey/surveyglm packages in R): https://notstatschat.rbind.io/2021/09/03/ordinal-data-and-models/. It's an interesting discussion of what ""ordinal"" and ""rank"" data mean, and the statistical implications thereof. Comparing and contrasting: 

""[O]rdinal data, as a scale of measurement: data that has a finite (or, I suppose, infinite) set of possible values and where the metadata specifies a linear ordering on the values but nothing more.

[R]ank tests: tests that are functions only of the ranks of the observations in a dataset

[O]rdinal models: genuine parametric or semiparametric models that imply an ordering (usually, but not necessarily a linear order) of values but not on any other constraints on the values.""",2022-02-02 15:02:48
Having trouble with sales data modeling?,0,silxgt,https://www.reddit.com/r/datascience/comments/silxgt/having_trouble_with_sales_data_modeling/,6,1643799636.0,"Hello, all. I would need advice on the following problem. 

&#x200B;

I have transaction data from online sales. I can work out the volume of sales, size of sales, number of products purchased per customer by product type. Against this, I have a set of marketing campaign data - what sort of marketing campaign was active at any given time, how many, what type, and what channel. 

&#x200B;

Here's what I am hoping to do:

\- Understand the impact of a campaign - how many more units of products were sold as a result of a promotion.

\- Whether there is a difference in customer behavior due to the marketing campaign - what's the uplift from running a promotion in terms of average transaction value and products purchase per customer.

\- Check whether running multiple marketing campaigns results in a lesser return on investment. If so, determine what's the ideal mix of campaigns.

&#x200B;

I initially thought of this as a time-series analysis problem. Since the data are available at a very granular level (seconds), I was looking to aggregate sales into a bigger timescale (hourly). The idea is that if the sales curve has a peak at the time when marketing campaigns are active then an uplift can be calculated. The trouble is campaign has been active at pretty much 95% of the time, and I feel this would make it difficult to discern between the uplift and noise.

I feel like I am missing something quite trivial - or perhaps bitten off more than I can chew, as I can't seem to work out a reliable baseline. Any advice would be much appreciated.",2022-02-02 13:00:36
Has anybody successfully built a business case for new DS/ML tools?,0,siled1,https://www.reddit.com/r/datascience/comments/siled1/has_anybody_successfully_built_a_business_case/,1,1643797708.0,"Our group currently uses Linux terminals, Python 2, and is restricted in packages we can install due to our cluster configuration. I'm trying to make a case for how a dedicated ML platform (e.g. SageMaker but on-prem) will enable is to do more things faster (containerized environments, ML pipelines, data+model governance, monitoring). I can list out the technical benefits, but translating this to time/money is difficult. There is also pushback from the data admin team who will be responsible for maintaining this.

Has anybody here done something similar? If so, how did you approach it? What evidence best convinced managers?",2022-02-02 12:28:28
Curious If this is worth pursuing,0,siklfu,https://www.reddit.com/r/datascience/comments/siklfu/curious_if_this_is_worth_pursuing/,7,1643794648.0,"I'm a 25 year old guy, with 2 very young children. I've been in manufacturing since I graduated high school, mainly printing companies. I've got no college experience at all. Is this a viable career path for me as someone who loves numbers and did really good all the way through pre Calc in highschool?",2022-02-02 11:37:28
"How the Netflix film ""Don't look up"" is a lesson in data storytelling...",0,sikimn,https://www.customerinsightleader.com/others/dont-look-up-how-its-a-lesson-in-data-storytelling/,0,1643794337.0,,2022-02-02 11:32:17
Which path?,0,sik3k1,https://www.reddit.com/r/datascience/comments/sik3k1/which_path/,0,1643792654.0,"Hi All,

I’ve several years experience in supply chain, working as a supply and production planner. I’ve previous experience as a buyer and materials planner. I also have an IT degree but very outdated at this stage!

I’d love to marry it all and get into a more data based role where I analyzed data and just crunched numbers etc

I was thinking python might be a good way to skill up?
 Would anyone have any career advice or tips? 

Thanks",2022-02-02 11:04:14
"Scripts vs sklearn.pipeline.Pipeline for pre-processing, when training/deploying with Vertex AI",2,sijs5j,https://www.reddit.com/r/datascience/comments/sijs5j/scripts_vs_sklearnpipelinepipeline_for/,3,1643791452.0,"I’m currently working on a simple classification problem, where data fits in memory and the deployed model is supposed to serve batch predictions only once per day. Before going the tf route, I would like to try out basic sklearn models. Training and deployment should be on GCP, because that’s what my company is moving towards. Now, when using Vertex AI, can I use sklearn pipelines to drop features, perform column transformations etc.? Or is it better to write a separate Python script for data pre-processing? Google’s documentation appears to favour the latter. Why is that?",2022-02-02 10:44:12
Blockchain for Industry,0,sijrqf,https://www.reddit.com/r/datascience/comments/sijrqf/blockchain_for_industry/,7,1643791401.0,"I am currently trying to help scale a small risk analytics company. We are trying to build out our current product while also exploring the latest trending technologies to ensure we are current and stay ahead of the competition.

We have often discussed Blockchain technology as a topical subject but have never been able to design a viable implementation for its technology

So my question for you is: Has anyone here implement Blockchain technology, in any fashion, within their company ? If so, what did you implement it for ? What problem was Blockchain the viable solution for ?",2022-02-02 10:43:21
Dataset for White Flies and Aphids,0,sij6hh,https://www.reddit.com/r/datascience/comments/sij6hh/dataset_for_white_flies_and_aphids/,1,1643789105.0,"I am working on an object detection project to identify White Flies and Aphids. I have found some dataset but no annotation is available \[`(xmin, ymin, xmax, ymax)` or a mask\]. Anyone worked with these pests that can provide some insight about a dataset?",2022-02-02 10:05:05
Webinar on Multimodal Architectures,0,sij240,https://mentorcolor.org/group-session/multimodal-architectures-307,0,1643788699.0,,2022-02-02 09:58:19
Time Series lstm problem,1,sihkp4,https://www.reddit.com/r/datascience/comments/sihkp4/time_series_lstm_problem/,4,1643783100.0,"Hi all, I have a question regarding training for time series problem. In the dataset I only have days and value of task request (I'm using Google cluster trace data). I trained my model using LSTM and I suspect the model is overfitting as loss and val\_loss is pretty bad. I am thinking about investigating how my train data maybe not really representing the whole dataset and there is imbalance of some sort. I have been reading a lot of articles, however the more I read, the more tangled I feel. Therefore, here I am, asking on what I should do to analyze my train vs test data to see firsthand if there is anything wrong with those. Please note, I have adjusted the layers, batch size, epoch size, learning rate, different optimizers and scalers as well but it does not seem to improve. Thanks!",2022-02-02 08:25:00
mathematical background of algorithms,1,sihhjw,https://www.reddit.com/r/datascience/comments/sihhjw/mathematical_background_of_algorithms/,1,1643782785.0,"Hello dear Reddit members,

I just started my data science learning process. While attending my university, I am taking my elective courses on this subject.

But there is one thing I am wondering about. Is it really important to know the mathematical background of algorithms? For example, when I was studying Multi-Armed Bandit problems, which is the subject of reinforcement learning, I saw that mathematics was intense.

I have 2 options in front of me.

1. To learn the logic and Python codes in general all machine learning and deep learning topics without examining mathematically.

2. To examine the mathematical background of all subjects.

Which one would you recommend?",2022-02-02 08:19:45
Those with a “data scientist/ML Engineer/Deep Learning/etc” title. How do you think you rank up to coworkers?,0,sienu6,https://www.reddit.com/r/datascience/comments/sienu6/those_with_a_data_scientistml_engineerdeep/,7,1643773767.0,"I’m in a graduate program and I’m definitely measuring myself up against others. I’m curious how many people who’ve landed that job(s) do the same? 


Titles apart (jr, sr, associate, mid, etc). I know from experience that software engineers with years of experience may be less technically competent than some juniors. Wondering if DS is the same.",2022-02-02 05:49:27
"Matching curve shapes with DTW, am I doing this right?",3,sie0r0,https://www.reddit.com/r/datascience/comments/sie0r0/matching_curve_shapes_with_dtw_am_i_doing_this/,4,1643771955.0,"Hello, so I am trying to address a curve shape matching challenge with dynamic time warping, and I have a basic simple script/method down, but it is having issues. I converted my time series curves to arrays so they all essentially start at the same point, assuming equal time intervals. Each array is a separate curve. I am trying to compare different curves to see how close they match in shape. I have essentially two different types of curves, plateau shaped curves and wavy sine-wave curves (sorry for the poor terminology!). From my understanding, the closer the shapes are, the lower the DTW score will be.

I am using the following code in python using the dtw() function:

    #Indicate two time series IDs to be compared
    ts1 = '111' 
    ts2 = '222'
    
    #Convert time series curves to arrays
    df_y['ID'] = df_y['ID'].astype(str)
    v = df_y[df_y[""ID""].str.contains(ts1)]
    v = v['Value'].to_numpy()
    
    df_y['ID'] = df_y['ID'].astype(str)
    z = df_y[df_y[""ID""].str.contains(ts2)]
    z = z['Value'].to_numpy()
    
    #Run DTW
    ds = dtw(v,z, keep_internals=True)
    ds.plot(type=""twoway"")
    ds.plot(type=""threeway"")
    print(""DTW Distance Metric:"")
    print(ds.distance)

This is running DTW on curves with IDs ""111"" and ""222"", which are both plateau-shaped curves. This is what is produced:

https://preview.redd.it/45u05pjt5cf81.png?width=637&format=png&auto=webp&s=7c646e81e65d8c645d303c994184bd37506b9f21

with a DTW score of: 2960.0

I would think this should be a low score since these shapes are similar. I then want to compare two wavy sine-wave curves, and so now I compare curves with IDs ""333"" and ""444"" and receive this:

&#x200B;

https://preview.redd.it/7t1amlni6cf81.png?width=639&format=png&auto=webp&s=e3bd02a62769a7e9de7f96c743feac3b64655806

This receives a DTW score of  16102.0 (which seems strange since this value is so much higher than with the other curves, even though these wavy curves are quite similar.

Next I compare curve ID ""444"" with curve ID ""555"", which are both wavy sine-wave curves. The problem however is that these two curves have a different number of oscillations, where while they both have the same intensity of the curves, the first curve has 6 peaks, while the second curve has 10 peaks. Running DTW I receive this absolute mess:

https://preview.redd.it/2vvy7nya7cf81.png?width=655&format=png&auto=webp&s=dea73977d21c816040043a5547e560ede0687873

With a DTW score of 73745.0, which is way higher than the other scores. The problem is that I want these curves to be seen as similar! They are both wavy curves and so I want them to be seen as relatively similar, so as to be seen as completely distinct from the plateau curve shape. What I received above makes no sense, where the lines do not even know how to match up.

My overall question here is whether I am approaching DTW correctly or if I am way off in how I am interpreting all of this. Also, my big question is how can I get similarly shaped curves to be seen as similarly shaped if the two curves being compared have different numbers of oscillations (different numbers of peaks and valleys)? I had tried to take the advice from this community to try DTW for my project and to just give it a try and see what happens, and so my apologies for sounding so new to this, but I am really trying to learn here and would appreciate any feedback on how I could improve my approach in python! Thank you!",2022-02-02 05:19:15
Recommender Systems - imputing unary ratings with explicit ones and how not to induce biases,1,sic00s,https://www.reddit.com/r/datascience/comments/sic00s/recommender_systems_imputing_unary_ratings_with/,2,1643766287.0,"I have a dataset that contains both explicit ratings and unary ratings and I want to convert the unary ratings to explicit ratings.

I was thinking that for each unary rating (user u, item i), I could impute the values by taking averages of the explicit ratings. For example, I would do something like this:

`r(u,i) = global_avg + user_u_bias + item_i_bias`

But can I use the entire dataset to do this or would I be inducing bias in my models? Should I only use the train dataset?

Can I impute the values in the test set also without restricting myself to the relatively small testset?",2022-02-02 03:44:47
When to search for next role?,12,sib5ky,https://www.reddit.com/r/datascience/comments/sib5ky/when_to_search_for_next_role/,11,1643763962.0,"**Main Context:** Transitioned from life sciences to DS about a year ago. Have MS DS and have found a niche where I feel like my skills have grown substantially (computer vision).

&#x200B;

**Question:** When is the right time to start leet coding / personal projecting in order to bump up to a higher pay?

&#x200B;

**Detail:** If I'm not going to be considered for roles until 2 YOE or some arbitrary number then I would rather spend my free time biking/climbing/anything else compared to the job application circuit until I need to. However, current base pay is <80k in MCOL which was likely appropriate for a novice but feels potentially low compared to how my skills have progressed. I know the answer to determining your worth is to start applying, but I'm just wondering when to optimally time that effort. Additionally, I do quite like my current work and team, so I'm not in a huge rush to leave other than my desire to be financially independent sooner. Ideally I'd like to just get bumped up here, but that does not seem to be common.

&#x200B;

**Disclaimer:** Yes, this post was in fact inspired by FOMO from the unicorns in r/cscareerquestions making bank. No, I am probably not as skilled as I think I have become. Oh well.

&#x200B;

Appreciate any insight!",2022-02-02 03:06:02
How Lyft predicts a rider’s destination with attention model,4,si9eia,https://eng.lyft.com/how-lyft-predicts-your-destination-with-attention-791146b0a439,0,1643759244.0,,2022-02-02 01:47:24
Transitioning to Remote DS,1,si5w74,https://www.reddit.com/r/datascience/comments/si5w74/transitioning_to_remote_ds/,9,1643750258.0,"For several months now I’ve seen more remote DS and ML roles posted at large companies such as Amazon, Meta, etc. Has anyone recently transitioned to working remotely as a Data Scientist? It would be great if others would share their experience working remote.",2022-02-01 23:17:38
How can I know which robot will win based on match data?,1,si5cfi,https://www.reddit.com/r/datascience/comments/si5cfi/how_can_i_know_which_robot_will_win_based_on/,2,1643748915.0,"Hello, total noob here and also new to this sub

I used to be in a robotics team (frc) a few years back and I had a thought the other day: the data of every game that every team ever played is stored on a bunch of json files on an easy to access website. can I take this data and predict in a game which alliance will win?

&#x200B;

the game goes like so: there are 2 alliances: red and blue. in each alliance there are three robots, for  the first part of the competition the alliances are random so each robot playes most games with random two robots and against random three robots. At the second part the eight teams that did best at the first part become the alliance captines and they get to choose who will be in thier final alliance (the pick order is always the same and the sooner you get picked the better). 

The rules of the game change from year to year but the data that I know about all the years is which robot played at which competition, how many points the whole alliance made, which alliance won, who were the alliance members, in what stage did the match took place (in the random alliance stage or in the stage where alliances are set), who got picked when, if a robot was an alliance captin and the rank in which the robot ended up in at the end of the random stage (based on who many ranking points the robot made on an avarge game, which is related to if his alliance won or lost and did his alliance succeded in the special missions during the match)

&#x200B;

The idea is to know which robot is better, which robot will give you the highest chances of winning if it was on your alliance. If I can know that I can pick the best robot out of my options and have the highest winning chances

I never done anything like that before but I do have coding experience and I know python to some degree so this should be a fun project to get me started on understanding and learning data science

I really need the help, any tips on where to start and how to approch this will be greatly appreciated",2022-02-01 22:55:15
Database with Jupyter,3,si4nou,https://www.reddit.com/r/datascience/comments/si4nou/database_with_jupyter/,15,1643747192.0,"Hi!

Hoping you all can point me in a direction. I’m looking for a database I can use, with jupyter, for some small scale data storage/visualization. Can anyone make a recommendation?",2022-02-01 22:26:32
Infographics of Machine Learning Algorithms?,3,si3cpb,https://www.reddit.com/r/datascience/comments/si3cpb/infographics_of_machine_learning_algorithms/,8,1643743892.0,"Hi, (beginner here)

I'm learning about the different types of Machine Learning algorithms mainly regression and classification, and started to wonder if there's some infographic, webpage, cheatsheet or some resource where I can see how these algorithms work, (an overview of) the steps they follow to find the patterns/ make the predictions, and important parameters /hyper parameters.",2022-02-01 21:31:32
Ex Python users who switched to 100% R (or almost),165,si14ds,https://www.reddit.com/r/datascience/comments/si14ds/ex_python_users_who_switched_to_100_r_or_almost/,135,1643738267.0,"There are so many posts here about people who were R users who then switched to Python. There are also posts about people who claim ""right tool for the right work. I use both"". But how about Ex Python users who switched to R and rarely use Python since the switch? What are some of the reasons of your switch? What did it make you change?",2022-02-01 19:57:47
DS @Meta = Strategy Analyst,67,si00zx,https://www.reddit.com/r/datascience/comments/si00zx/ds_meta_strategy_analyst/,56,1643735496.0,"My LinkedIn has been getting blown up since I announced that I accepted a DS product analytics role at Meta- largely with questions about what it is that I do, TC, or interview process. Since this is apparently a hot topic, I wanted to loop in the greater community. 

At Meta, DS Product Analytics should be called 'Strategy Analyst.' In my time at the company, I've spent about 40% of my time reviewing experiments and developing storytelling what happened and why, which calibrates future product strategy/development/experiment efforts. The other 60% of my time is sizing market opportunities. This is the sort of work I'd expect that McKinsey consultants and product managers would do well- for whatever reason, it's a DS responsibility. 

My end goal is to launch my own startup, so I'm not mad about getting strategy exposure, accruing a nice salary/stock, or having a catchy company/title on my resume. That said, if you want to be in the weeds on upper level stats, ML, etc. This role really won't be emotionally fulfilling for you. Like I said, it should be called Strategy Analyst, not data scientist (product analytics or otherwise.) 

From scrolling the LinkedIn jobs, I'm starting to see a new wave of DS roles resembling my experience at Meta at companies like Uber, TikTok, etc. I don't think that this strategy analyst flavor of DS is going away anytime soon; but be warned- it does exist and if that's not for you, you'll need to be mindful of where you steer your career.",2022-02-01 19:11:36
SQL Data Warehouse to talk to Python,7,shy6j8,https://www.reddit.com/r/datascience/comments/shy6j8/sql_data_warehouse_to_talk_to_python/,4,1643730840.0,"In my previous role I had a lot of success using Snowflake as a data warehouse as Snowflake built a python connector library that supported converting pandas tables into SQL tables with one line of code.

I'm in a new role and am trying to bring a data warehouse online, but since there isn't one I'm trying to do my due diligence. 

Does anyone have recommendations for alternatives of databases and Python connectors? Being able to directly convert from pandas to a table is the key feature.",2022-02-01 17:54:00
"This shouldn't be issue, but they are taking unusually extra time to reply. Did I make some mistake? This will be my first job and interaction with tech company.",0,shxo3q,https://i.redd.it/wlxjper1q8f81.jpg,31,1643729451.0,,2022-02-01 17:30:51
Applied Scientist levels at Amazon,27,shxhyl,https://www.reddit.com/r/datascience/comments/shxhyl/applied_scientist_levels_at_amazon/,36,1643728981.0,"I got a verbal offer from Amazon for Applied Scientist L5. I have 8 years of experience after my PhD, and I was clear with the recruiter that I only interview for L6, and I think I did pretty well in my interviews. I understand that the level is based on the performance in the interviews, and I know that tech companies love to down-level, but I'm bummed about L6 -> L5 thing.  


Has anybody here been successful to negotiate with Amazon to up-level after receiving the initial offer?",2022-02-01 17:23:01
What types of opportunities do you think exist for a management consultant with SQL experience?,0,shxhh1,https://www.reddit.com/r/datascience/comments/shxhh1/what_types_of_opportunities_do_you_think_exist/,3,1643728944.0,SQL seems to be a niche skillset within the management consultant space! Thank you for your input.,2022-02-01 17:22:24
Top 15 DevOps Programming Languages to Learn in 2022,0,shwqbc,https://bigdataanalyticsnews.com/devops-programming-languages/,1,1643727010.0,,2022-02-01 16:50:10
"Stressed out with my electrical coursework, how to switch to data?",0,shwgxs,https://www.reddit.com/r/datascience/comments/shwgxs/stressed_out_with_my_electrical_coursework_how_to/,2,1643726298.0,"I am a current masters student in electrical and computer engineering, and I dislike my coursework. I like data science and I know that data analysis jobs are way easier to land than whatever I'm doing. I have done some courses in data science so I have some knowledge, but in my course work I am learning about filters and image analysis. I have also taken AI because I thought it'd be related to data science but it is just programming (which I like but is it really related to Data Science?). As an international student, it's already tough for me to get an entry level job in data and this has made it even tougher. I should have picked CS or data science but I messed up in that regard. How do i cope? also what jobs can i land? The coursework for my uni is [https://catalog.uic.edu/all-course-descriptions/ece/](https://catalog.uic.edu/all-course-descriptions/ece/) if its of any help. Its my second semester so its too late to change my degree without incurring a huge loss on my fees.",2022-02-01 16:38:18
Please explain to me the benefits of real time data,0,shuda9,https://www.reddit.com/r/datascience/comments/shuda9/please_explain_to_me_the_benefits_of_real_time/,6,1643720345.0,"I am trying to make the argument to collect data on a month by month basis, as opposed to in a single 'block' of several months. This information is the number of people accessing a service. 

I would like to receive it month by month as I believe it would be more likely to be accurate and inform us better of what is happening, but I cannot articulate why. 

All I can find online is about the advantages of having this for sales data, but can you help me articulate why it is better for information about people?

Thanks",2022-02-01 14:59:05
Got my first offer,404,shtsnt,https://www.reddit.com/r/datascience/comments/shtsnt/got_my_first_offer/,77,1643718396.0,After 30 + rejections i got my first job as a data scientist. I got rejected from worse roles and yet it somehow worked out. Its honestly just luck.,2022-02-01 14:26:36
Recruiters: How much does a candidate's Kaggle profile matter while hiring?,172,shsq5a,https://www.reddit.com/r/datascience/comments/shsq5a/recruiters_how_much_does_a_candidates_kaggle/,123,1643714636.0,"For example if a guy is Kaggle Master, would that boost his chances of getting selected. I just wanna know if a Kaggle profile of a candidate matters or not. If yes then how much?

Edit 1: one more question, what if a experienced data scientist mentions about his kaggle achivement in the resume, for eg. ""Kaggle Dataset Master Global Rank 15"". Will this be a red flag ?",2022-02-01 13:23:56
What is the best resource to learn Data science? I would like an advice even for phyton.,0,shq41m,https://www.reddit.com/r/datascience/comments/shq41m/what_is_the_best_resource_to_learn_data_science_i/,4,1643704254.0,"I tryed many free courses, but none of them makes me to want to pursue further. I think CodeAcademy is one of the best made and I liked that study enviroment. But some online reviews says that CodeAcademy is not good at all, and before seeing that I wanted to buy the pro subscription. What you guys think? Is CodeAcademy worth to buy? Do you have another source to learn where is similar to CodeAcademy?
Thanks!",2022-02-01 10:30:54
"What are some remote and freelance data science roles in the non-profit sector for non-CS graduates, that are in high demand?",0,shogk0,https://www.reddit.com/r/datascience/comments/shogk0/what_are_some_remote_and_freelance_data_science/,2,1643697900.0,"Non-native English speaker here. 

I was thinking about getting into the non-profit sector. Maybe first doing a few freelance projects for non-profits and then joining one as a fulltime remote, or fulltime onsite employee. 

I have a BS in Economics, and an MBA. So I am trying to get into ""Data Science Lite"". Something like Business Intelligence, Data Visualization. You know things that I can transition into. But not things that would be nearly impossible to get into without a CS degree like Machine Learning Engineer, Data Engineer and such. 

I am looking for roles that have a good work-life balance, work flexibility, availability of 100% remote work and freelance gigs. 

Can someone tell me, what roles are open to me and I should aim for if I want to join the non-profit sector?",2022-02-01 08:45:00
Heard of Palantir?,0,shn8qc,https://www.reddit.com/r/datascience/comments/shn8qc/heard_of_palantir/,2,1643693640.0,"Is anyone working with any organization that uses platform/software provided by Palantir?

How demanded is this? What would be it's growth in the next 5 years in the field of IT?

I'm in a company which has this and we have no other option other than getting trained for this. I would like to know, how much of this would be useful. Hopefully it's not a niche software. It consists of every tool one can use in the field of data i.e engineering, visualization, AI etc.",2022-02-01 07:34:00
How do you react when you catch a long-standing error in your code?,21,shhhwi,https://www.reddit.com/r/datascience/comments/shhhwi/how_do_you_react_when_you_catch_a_longstanding/,10,1643676750.0,"I just caught an error where my absolute value function was nested in the wrong set of parentheses. After fixing it, I checked one analysis and the outcome had changed. Now I need to rerun a long list of analyses and inform any impacted stakeholders…",2022-02-01 02:52:30
Info Session for LinkedIn's REACH engineering apprenticeship program,1,shh0g7,https://www.reddit.com/r/datascience/comments/shh0g7/info_session_for_linkedins_reach_engineering/,6,1643675347.0,"Hope it's ok to post job opportunities. Learn about LinkedIn's REACH Apprenticeship program; REACH is a technical apprenticeship program at LinkedIn that creates opportunity for every individual with the passion, potential, and drive to either develop or restart their career in engineering or technical program management. To learn more about REACH, check out our website [here](https://nam06.safelinks.protection.outlook.com/?url=https%3A%2F%2Fcareers.linkedin.com%2Freach&data=04%7C01%7Caip%40linkedin.com%7C2c87f6fc8c97416da47008d9e4e4ae96%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C637792493097700145%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&sdata=GLhr4nj0uyn7MS2vwk0uueJAmTo1hG2KB8iJ6moRVFg%3D&reserved=0) and watch this [video.](https://nam06.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DwPJKJnDGhKY&data=04%7C01%7Caip%40linkedin.com%7C2c87f6fc8c97416da47008d9e4e4ae96%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C637792493097700145%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&sdata=NQyu0qtKEfH%2B%2FtIX5zEe9B4aTvflFZRotfYe60YlrxU%3D&reserved=0)

On February 11, 2022 our applications for our June 2022 cohort will go live [here](https://nam06.safelinks.protection.outlook.com/?url=https%3A%2F%2Fcareers.linkedin.com%2Freach&data=04%7C01%7Caip%40linkedin.com%7C2c87f6fc8c97416da47008d9e4e4ae96%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C637792493097700145%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&sdata=GLhr4nj0uyn7MS2vwk0uueJAmTo1hG2KB8iJ6moRVFg%3D&reserved=0). Please note that we release applications details early in order to give applicants sufficient time to prepare their application materials, and pull the application down within a week or two of posting.

**Additionally, there will be two information sessions.** [**fill out this form**](https://nam06.safelinks.protection.outlook.com/?url=https%3A%2F%2Fforms.office.com%2FPages%2FResponsePage.aspx%3Fid%3Dv4j5cvGGr0GRqy180BHbR7QdLA-wm_tJvsDzokEA8Q1UQkIwUjVKSkRKMzdOOFpTWFlMMzVQSFcxTiQlQCN0PWcu&data=04%7C01%7Caip%40linkedin.com%7C2c87f6fc8c97416da47008d9e4e4ae96%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C637792493097700145%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&sdata=j8nqa0QXvHSEndCbfdpH6uJS8ko5RMosv%2FVdFaXqGx0%3D&reserved=0) **so we can send additional invitation details. The dates and times of our information sessions are as follows:**

* **REACH Info Session 1: Monday, 2/7 5:30pm PT**
* **REACH Info Session 2: Thursday, 2/10 12:00pm PT**",2022-02-01 02:29:07
Data Cleaning,1,shgydi,https://www.reddit.com/r/datascience/comments/shgydi/data_cleaning/,9,1643675179.0,"Newer to programming and am curious if people think cleaning data is easier in R or Python, rather than Excel? I am pretty savvy in excel and am thinking there is no way it’s easier to clean data outside excel unless you have an enormous data set that just doesn’t fit in excel. Thoughts?",2022-02-01 02:26:19
Do data scientists use a lot of probability (theory and application) on the job? Probability and stats classes need to be taught differently (using real life examples instead of dices and playing cards).,0,shfli3,https://www.reddit.com/r/datascience/comments/shfli3/do_data_scientists_use_a_lot_of_probability/,18,1643671415.0,"I'm learning data science after working as an engineer for 10+ years. I used to take probability in college and struggled through it. So happy I didn't have to use probability or stats for my previous jobs... until I learn you need quite a bite of stats and probability to be a data scientist.

I'm re-learning probability now and found that most of the examples were of dice or cards drawing; same thing that caused me to struggle in college then. I never played any dice game and seldom played card games. I know of them but it does take me a minute to map the scenarios in my brain. I would have to imagine 'what does this mean?', 'is it possible?', 'what if it's not?', and had to try to see other cases if it's not true (iterations & calculate success rate of each). By the time the first scenario made sense to me, the lecture had gone through 5 more examples of just (or majority of) dice or card games. Ugh!! 

The irony of this is: data science look at real life events and make prediction/correlations of every day situation... aka NON dice or card games (unless you work for a casino 'house' or to create slot machine, IDK...) My point is everyone struggled through stats class having to make sense of something they don't do or use daily. THEN, flip around trying to make sense of the world using concepts they have a hard time understanding because the examples are not correlate well with real life (dice game vs chances of finding someone you really click with on a dating app). 

We grow up and see lots of events happening and the chances of something succeed or fail given something else (like the chance of you getting into a car accident if you had a bad argument with your spouse right before you left the house). Not many of us grow up playing card games days after days so our brain don't get used to see these examples being given in prob/stats classes. Yet for professors, they had to probably struggle through the same thing through 4 yrs undergrad, researched and explain in these dice or card games through  4 more years in PhD; so they teach what they are familiar with. That's not the same for the rest of us, especially non card/dice players. 

One upside of using cards and dices is that you have concrete numbers to calculate with. From my limited data science exposure, all models have a certain degree of uncertainty / error. Then why teach something 'absolute' (like chance of getting 2 heads in 6 coin flips where inputs are known and you can calculate them) in class, when real life scenarios involves many unknown factors that contribute to the error rate of the model (chances of you getting cancers could depend on gene, environment, stress, food, etc.). 

My request is if you teach others how to learn concepts in prob/stats or data science, please use daily examples that, say, someone who has gone through at least 10+ years of life could relate too. The brain learns best if it can connect new concepts with what it already  knows (chances of you tripping is increased if you don't tie your shoe laces AND start running). Yes you might have to really think through what examples make sense for the theory you want to teach. Please don't regurgitate what was taught to you before if you yourself had a hard time initially. 

Teaching is an art and a special skill. Many thanks to those who can turn on the light bulbs in others instead of completely break that fragile light bulbs from young minds.",2022-02-01 01:23:35
Any good book that talks specifically about working with very large datasets,0,shf2yc,https://www.reddit.com/r/datascience/comments/shf2yc/any_good_book_that_talks_specifically_about/,4,1643670138.0,"I am looking for a book that talks specifically about the problems encountered when dealing with massive datasets and the strategies/algorithms/tools developed to 1. feasibly process the dataset and 2. manage or organize your time effectively as a data scientist

 I am looking for things like a discussion of data processing engines (MapReduce, Hadoop, and Spark), the purpose of creating data pipelines (Airflow, Luigi), etc.

I looked on the [DS Book Megathread](https://www.reddit.com/r/datascience/comments/8jneyb/ds_book_suggestionsrecommendations_megathread/) but from the titles, I did not seem to find quite what I am looking for.",2022-02-01 01:02:18
Trying to import uint16 file but it's giving funny values,0,shexex,https://www.reddit.com/r/datascience/comments/shexex/trying_to_import_uint16_file_but_its_giving_funny/,5,1643669797.0,"I'm trying to import a file named in.dat into python which is an int16 file, however the file is giving some values of greater than 60,000 which seems odd since int16 can only house numbers -32767 to +32767. Some of the values are correct!

import numpy as np  
f = open(""in.dat"", ""rb"")  
a = np.fromfile(f, dtype = np.uint16)  
print(a)

The output returns:

\[64594 64232 64418 ... 58 51 10\]

I have tried testing this in other programming languages e.g. c and MATLAB but obtain the same results.",2022-02-01 00:56:37
What is Administatative Data,3,shesec,https://www.reddit.com/r/datascience/comments/shesec/what_is_administatative_data/,4,1643669454.0,"Globe down of a bit of rabbit hole.  In most places, this is defined as government data but in a few, it seems is not. Wold like people's thoughts on this.",2022-02-01 00:50:54
Jupyter Notebook or .py Portfolio,0,shedzp,https://www.reddit.com/r/datascience/comments/shedzp/jupyter_notebook_or_py_portfolio/,9,1643668426.0,"For my portfolio of projects that I will be showcasing to employers, should they be in a Jupyter Notebooks format or should they be .py files?

&#x200B;

I originally did them in jupyter notebook, but I don't want to come off as unprofessional. Is there a preference/industry standard?",2022-02-01 00:33:46
you only need to see a small fraction of a LinkedIn learning course to say you completed it?,1,shdqmx,https://www.reddit.com/r/datascience/comments/shdqmx/you_only_need_to_see_a_small_fraction_of_a/,1,1643666871.0,"Has anyone noticed this? I've noticed this before, and now taking a course for a company compliance requirement. It happens to be on NLTK in Python but that doesn't matter. 

What I'm seeing is the green check mark after one minute, even for five or ten minute videos. This says to me that you could watch a minor fraction of each video (and the whole course) to say you completed it. 

By comparison, when I've taken Udemy courses I recall that it got marked as complete when you were like 10-20 seconds from the end. 

Is it just me or is that problematic? So people just want to say they learned something without actually learning it?",2022-02-01 00:07:51
Implementation of Count Sort via a Sparse Matrix,0,shassl,https://www.reddit.com/r/datascience/comments/shassl/implementation_of_count_sort_via_a_sparse_matrix/,0,1643659811.0,"Hi, The count sort is only feasible for some inputs of 'k' that are not abnormally large since the space complexity increases arbitrarily. Can it be implemented using a sparse Matrix to counter that drawback.

I've tried but can't seem to get it work, can someone provide some insight on this. Thanks",2022-01-31 22:10:11
Connecting R to Oracle Database,1,sh95c9,https://www.reddit.com/r/datascience/comments/sh95c9/connecting_r_to_oracle_database/,0,1643655837.0,"I am on R 4.1.2 and have been looking everywhere to try and solve why I am getting a “Java.sql.SQLRecoverableException: The network Adaptor could not establish the connection ()” error when I run dbConnect. The following code i am using is below:

jdbcDriver <- JDBC(driverClass = “oracle.jdbc.OracleDriver”, classPath = (/users/desktop/folder/ojdbc11.jar”) ##okay

jdbcConnect <- dbConnect(jdbcDriver, “jdbc:oracle:thin:@//host:port/databasename”, “scheme”, “password”)

My user name and scheme are the same. Other blogs or post on stackoverflow are connecting usually to my SQL and the one post I found on LinkedIn is from 2015. I’ve reached out to our IT team that typically manages issues connecting to Oracle Database using TOAD and they said they do not support Orcale R which leads me to think they are thinking of the wrong software or I am not fully grasping the limitations we have. Any help would be awesome.",2022-01-31 21:03:57
"In over my head in new role, best resources?",20,sh6iqa,https://www.reddit.com/r/datascience/comments/sh6iqa/in_over_my_head_in_new_role_best_resources/,38,1643649537.0,"I am hopelessly lost in my new role at work. I'm an experienced analyst but find myself now working in a data lab doing financial forecasts, all of our work is in SQL. I'm not very good at SQL and have read some books but ultimately have no real understanding of it.


Some background is that I'm not formally trained in data science or statistics or anything, I'm feeling pretty intimidated by everything I'm being faced with now, Olap Cubes, snowflake, cognos, et cetera.....I can't make heads or tails of it. Is there any way I should systematically go about understanding all of this so I can presumably do.....anything.


What I'm experienced in is Excel, with some R and some SQL, but basically beginner level, I know typically people here will say this is just imposter syndrome but in this case I legit just don't know much. I am not in the same bucket as people who have MS and PhDs in this stuff. 


Has anyone else been in this position? I took this as a consulting role but it very much feels like what they actually meant was data science. Most of the work I've been exposed to thus far is running SQL scripts that give us some forecasts based on strict models(no prediction, it's looking at specific data points and spitting out a number) but there isn't anything about how close this number is or how confident we are in it.....it just plops out. I've ran one script thus far and still have no idea how I'd even explain what it did. It seems like my team inherited scripts from 3+ years ago and we just modify them as new customers are added.


So yeah, any advice would be appreciated, all my previous roles moving up the seniority chain sounded big and ended up always being generic spreadsheets, so I'm woefully, woefully ignorant of **real data science**. I believe I *can* learn this stuff but I've been given minimal to ineffective training and I simply don't know where to start. I have various DS books or SQL books I have in physical and online form but with no clear direction I'm feeling confounded on where to begin or what sequence I should take to become competent.",2022-01-31 19:18:57
Sites to view what's trending weekly/monthly/daily on social media,0,sh5nl7,/r/GrowthHacking/comments/sh34xt/sites_to_view_whats_trending_weeklymonthlydaily/,0,1643647488.0,,2022-01-31 18:44:48
Cleaning the data to get it ready for analysis. Hehe!,918,sh4otq,https://i.redd.it/vy7o0jp1r1f81.png,35,1643645114.0,,2022-01-31 18:05:14
How can I store a numpy matrix in a pandas dataframe?,0,sh3clz,https://www.reddit.com/r/datascience/comments/sh3clz/how_can_i_store_a_numpy_matrix_in_a_pandas/,6,1643641656.0,,2022-01-31 17:07:36
Do you push for a more complex model at work when it's justified?,15,sh39ni,https://www.reddit.com/r/datascience/comments/sh39ni/do_you_push_for_a_more_complex_model_at_work_when/,16,1643641426.0,"A reasonable amount of my degree was 'advanced' Bayesian methods like [LS-SVMs](https://en.wikipedia.org/wiki/Least-squares_support-vector_machine), gaussian processes and various kinds of graphical models: DAGs, Markov networks and their combinations. I've honestly never ever bothered using any of these in my career for two reasons:

&#x200B;

1. Most of the material was just math and the little code was in MATLAB and just haven't committed to learning STAN or pymc3. \*
2. Main reason: Up til now I've always been in consulting and I will be again after the summer. Somehow I don't feel comfy leaving the customer (or my colleagues) with something they just wouldn't understand. For this reason I mainly stick to stuff that exists either in sklearn, statsmodels, SparkML or Tensorflow.

&#x200B;

Since I have a lot of time on my hands recently I'll go through my syllabus again and and properly learn how to properly use STAN. My main use case would be the research project I've been working on for a few months. Something like hierarchical modelling with shrinkage would work wonders here. The problem is I'm partnering with a company, I get to use their hardware to train the models using databricks but I have to deploy the best results. 

Assuming my research tells me some non sklearn / SM / Tensorflow model is really the best and most elegant solution. Should I bother with trying to explain how they work to both the data scientists that don't have a background in this.... and even worse, business?  How do you experienced folks tackle this?

^(\*I know R has better alternatives but I'm stuck with Python / PySpark on this.)",2022-01-31 17:03:46
Does Anyone Know What Software Was Used To Make These Graphs?,0,sgv7ip,https://www.reddit.com/r/datascience/comments/sgv7ip/does_anyone_know_what_software_was_used_to_make/,3,1643613345.0,"[https://en.wikipedia.org/wiki/Lagrange\_polynomial#/media/File:Lagrange\_polynomial.svg](https://en.wikipedia.org/wiki/Lagrange_polynomial#/media/File:Lagrange_polynomial.svg)

I saw these graphs I really liked - does anyone know what software might have been used to make these graphs? E.g. R, Python, Julia?

Thanks!",2022-01-31 09:15:45
Love-Hate Relationship w/ Tableau: What's Your Take?,40,sgrsdy,https://www.reddit.com/r/datascience/comments/sgrsdy/lovehate_relationship_w_tableau_whats_your_take/,63,1643601817.0,"Across my career as DS, I've come across differing opinions on Tableau. To be honest, I hate it but it seems enterprises and some people love it and swore by it; maybe due to its aggressive marketing and almost turnkey approach on dashboarding.

I also can't believe the license costs. It's like an invitation to having a sunk cost mentality when your management decided to purchase Tableau for a year.

As a user, I hate that it is not intuitive like other dashboarding tools. You have to jump through many settings and even code yourself just to implement a visual that only requires a single click in other tools.

There is also a lack of serious competitors that isn't cloud-locked (I'm looking at you, PowerBI). I also find no open-source alternatives that rivals the visual fidelity and ""enterprise""-readiness of Tableau. I've tried Superset, Metabase, and Grafana but they are not at the level of Tableau yet in my opinion.  


What's your take on Tableau? Interested to hear your thoughts on this.",2022-01-31 06:03:37
Data Science Contractors...where do your clients let you work on their data?,0,sgq1np,https://www.reddit.com/r/datascience/comments/sgq1np/data_science_contractorswhere_do_your_clients_let/,16,1643596677.0,"This is a question for those that freelance or do side jobs as Data Science contractors...Do most clients prefer that you work and deliver solutions inside their cloud environment or are you allowed to download their data and crunch it on your workstation?

I'm asking because I don't really understand why people are buying personal workstations unless they are just researching on the side. If you are actually doing production work for a client, wouldn't they have preferences on where you build your solution, data security risks, containers to use, etc?

As a side question, does anyone have experience with [OpenMined/PySyft-spirited](https://github.com/OpenMined/PySyft) workflows - where you could download encrypted versions of client data locally, crunch, and model without actually moving sensitive data out of your client's environment?

[View Poll](https://www.reddit.com/poll/sgq1np)",2022-01-31 04:37:57
"Welcome! Have you created something using Excel? Do you have mad VBA skills? If so, Excel Projects is for you!",0,sgodto,/r/ExcelProjects/comments/sgo6p8/welcome_have_you_created_something_using_excel_do/,3,1643591814.0,,2022-01-31 03:16:54
Difference between regularization and ensembling?,18,sgmwc5,https://www.reddit.com/r/datascience/comments/sgmwc5/difference_between_regularization_and_ensembling/,9,1643587587.0,"Disclosure I'm a beginner...

I'm a little confused with these two terms, in the case of decision trees we use the same methods of bagging and boosting for both regularizing and ensembling, so I want to know if when someone regularize the model is also ensembling it? Or what would be the difference between the two concepts and how the same methods are applied to those two different situations?",2022-01-31 02:06:27
Insignificant feature in different models,1,sgm8qs,https://www.reddit.com/r/datascience/comments/sgm8qs/insignificant_feature_in_different_models/,9,1643585772.0,"A general question about feature selection - For any model, is it correct to say an insignificant variable (by feature importance or eliminated during stepwise selection) in one model will very likely be insignificant in all others?",2022-01-31 01:36:12
How would you use linear contrasts or orthogonality tests in Data Science models?,0,sgjxj7,https://www.reddit.com/r/datascience/comments/sgjxj7/how_would_you_use_linear_contrasts_or/,3,1643579331.0,"This is a stats and data science cross-over question, so I hope I'm doing this crosspost correctly.

I've been studying linear contrasts and it feels like I have missed a meeting on what they actually do. I get that each row of treatment coefficients should equal 0, and I somewhat understand that they get the variables to 1 or 0 or -1, or that -2 can be balanced by 0 1 0 1 by isolating a variable but it's confusing how they do that. So with reciprocals the 3/1 times 1/3 = 1, but how are they getting them to zero? Is this like a blind crossover in medical trials where the dog gets a piece of a hotdog with a pill inside with null effect vs a piece of a hotdog with a new pill that might rabies?

So hotdog with medicine = 1, hotdog with sugar pill with essentially no effect = 0? Then where do the -1 come from?

The second part of this is asking is a statistical test of goodness that the rows add up to zero, else it's a bad fit and they are not parallel thus not collinear? Then if they are not linear that means the two sets of data indicate the data is not parallel to each other and not exactly collinear so one might be gradually more important than the other. So Y=mx1+2mx2+mx3+b should be more like Y=mx1+3mx2+2.1mx3+b when mx3>2 ?

The third bigger question is that does this transformation of integer variables in a linear equation to a grid become computable like a matrix calculation?

1. How do they get the coefficient of a variable to be 0
2. What real-world use is a linear contrast good for
3. Is it just a 'stats professor' wanting me to know how to do something the old school way that computers do for us with code in a matrix calculation and he is prepping me with 'you need to know how this works by hand'?

This isn't a homework question, I'm not understanding the concept of its calculation or how it's used. So I've also posted a similar question in [this thread in](https://www.reddit.com/r/statistics/comments/sgjy76/how_would_you_use_linear_contrasts_or/) r/Stats for the application part without photos of the below slides I'm referencing since I can't seem to post photos there.

[Page 9](https://preview.redd.it/h4wbr0n1cwe81.png?width=1519&format=png&auto=webp&s=88bc987b02493bccb554d9add86882780e885dfb)

&#x200B;

[page 10](https://preview.redd.it/m5974bn1cwe81.png?width=1553&format=png&auto=webp&s=af6122cc742870028bd9d22924b5d75d75660c81)

[page 11](https://preview.redd.it/s8km68n1cwe81.png?width=1554&format=png&auto=webp&s=9297581f69dde35f95ce58364b8e71e1019f2408)

[page 12](https://preview.redd.it/7paxk4n1cwe81.png?width=1523&format=png&auto=webp&s=efff4b4b298fe28609d872170063959a2df7ec8c)

[page 13](https://preview.redd.it/z7hzq3n1cwe81.png?width=1473&format=png&auto=webp&s=231784e396fd8e78842f790757c57cfc7e8cc81d)",2022-01-30 23:48:51
What data project of yours are you most excited about?,8,sgj7y1,https://www.reddit.com/r/datascience/comments/sgj7y1/what_data_project_of_yours_are_you_most_excited/,4,1643577447.0,,2022-01-30 23:17:27
Best Datasets to Practice Feature Engineering,2,sgewbs,https://www.reddit.com/r/datascience/comments/sgewbs/best_datasets_to_practice_feature_engineering/,5,1643565959.0,"As the title states, I'd love to know if anyone can point to publicly available datasets especially conducive to practicing feature engineering, a subset I want to understand more deeply through practice.

By ""especially conducive"", I mean datasets that produce noteworthy improvements in model performance when moving from base to engineered features.

Thank you!",2022-01-30 20:05:59
Where can I learn about model deployment?,219,sgdnw8,https://www.reddit.com/r/datascience/comments/sgdnw8/where_can_i_learn_about_model_deployment/,29,1643562603.0,"Through my career and over the past few years I’ve spent significant time developing an understanding of different models and use cases in Python. I’ve been working towards a Data Science certificate from MIT and have a Masters Degree in Data Analytics. What I’m struggling with is learning how models are deployed to scale through Spark/PySpark and the likes.

EDIT: Holy guacamole I didn’t expect this to blow up the way it has. Thank you so much everyone for your help I greatly appreciate it!",2022-01-30 19:10:03
Weekly Entering & Transitioning Thread | 30 Jan 2022 - 06 Feb 2022,20,sg7rx3,https://www.reddit.com/r/datascience/comments/sg7rx3/weekly_entering_transitioning_thread_30_jan_2022/,199,1643544030.0,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",2022-01-30 14:00:30
Sampling Question for Decision Trees - Help Please!,1,sg6kg4,https://www.reddit.com/r/datascience/comments/sg6kg4/sampling_question_for_decision_trees_help_please/,0,1643539226.0,"I'm working on this project at work. We are building a dynamic microsimulation model to try to forecast how many different events our customers will have and therefore, off the back of that, we will be able to understand how many people we need to employ to action these events.

I have been tasked with understanding the probabilities of different customers having each of these events given their/given a combination of their characteristics.

I have opted for a decision tree approach to determine what combinations of characteristics are most important and therefore what the probabilities of having events are based on their characteristics. These probabilities will ultimately get built into the model.

However, the data that I am using to construct the trees is a bit confusing. We keep monthly data on customers. So if someone remains a customer for 12 months we have 12 frames of data and 1 frame of data if they are a customer for just 1 month.

Ideally I would just take 1 month's data and put it into the trees. The issue is that the month of the year could also be an important variable in determining whether an event happened. So instead I am using all data from 2019 (pre COVID).

The question I am struggling to understand is how - if at all - do I sample this data to put into my trees? (I run 1 tree for each event).

Do I just put in all the data? I think this is probably the best option but I am worried if I am biasing my trees because someone with 12 month's data will get a lot more representation than someone with 1 month's data...?

The other way I'm looking at it is, ultimately I want to be able to take someone's 1 month data and determine whether they are likely to have a range of events based on their characteristics. So surely I want one random month's data per person? The issue is then sampling. If I just select a random month's data per person, I will actually bias my sample because I will be biased towards selecting someone's early month's data - so would have to be a stratified sample based on time as a customer.

Sorry a bit waffely, but based on what I am trying to get out of the trees, and the monthly data I have, how would you adapt the 2019 data I have before putting into the tree algorithm? I.e. if I used all the data and ran a tree - say the top node basically said 1/10 customers had this event in 2019, could I also interpret that as if I select a random month's data from this year, there is a 1/10 chance of them also having an event? Or is that wrong because I am using multiple months of data per person if I put all data into the trees?

Thanks!",2022-01-30 12:40:26
Are there any Twitter accounts worth following related to our field?,0,sg2daz,https://www.reddit.com/r/datascience/comments/sg2daz/are_there_any_twitter_accounts_worth_following/,6,1643522405.0,I use a lot of Twitter and would love to follow people/accounts related to what we do.,2022-01-30 08:00:05
Data Engineering skills for data science,19,sg25er,https://www.reddit.com/r/datascience/comments/sg25er/data_engineering_skills_for_data_science/,3,1643521625.0,"I am entering data science with a data analyst skillset. I know that building data pipelines is a prerequisite to conducting analysis, but feel out of my depth with this because my degree has mainly focussed on analytics and statistics. 

When I have been exposed to using a virtual server with CLI to run Apache Airflow (which are all new concepts to me), I feel that I lack understanding of how systems like this are structured and that I don’t know what I don’t know about this topic.

I have coupe of questions about this:

1. What are the key concepts I should be familiar with to understand computer networks and systems related to data engineering?

2. To what extent should I have technical expertise with these systems in a data science environment, despite not aiming to be a data engineer?

For context, I am proficient in python(np, pd, plt), R, SQL + rdbms, powerbi, tableau, stats+ml.",2022-01-30 07:47:05
Is DS and MLE usually split?,5,sg1ewv,https://www.reddit.com/r/datascience/comments/sg1ewv/is_ds_and_mle_usually_split/,3,1643519081.0,"I'm trying to see if this is normal or just unique to my firm.

I've always worked at smaller firms as a somewhat ""Full Stack Data Scientist"" where I speak directly to stakeholders, do data analysis, feature engineering, model building, and deployment to the cloud (always batch inference, not live so they're pretty much just scheduled or triggered pipelines in AWS or GCP). These models are never really super custom, generally just heavily feature engineered combined with open source classical models (xgboost, etc...). I then setup and host internal dashboards for model metrics and inference exploration through open source tools like plotly Dash. I lead a team with this same model.

I enjoy getting to own the process from start to finish and the variety it brings. I love the feeling of going from problem generation to solving a problem on an ongoing basis. I get really bored doing just one thing for a while.

As we recently became public, there's been a huge push for engineering to get more involved in our processes, and they've created a team of ""machine learning engineers"" that only have front end website building experience. They've begun locking down our abilities to deploy anything, adding really strict processes, and making everything take ten times longer while having less accuracy (like telling us to train models on obfuscated and randomized dev data and deploy from there).

Probably too much backstory... But is this normal for bigger firms? I'm thinking it might be time to look elsewhere but if I'm always going to be stuck in one area (only working on the DS side or only working on the MLE side). I don't know what to do... I'm not super specialized in either area.",2022-01-30 07:04:41
Has anyone applied for/gotten a data science (PhD) internship with Google before? How long was the process?,17,sg0c7s,https://www.reddit.com/r/datascience/comments/sg0c7s/has_anyone_applied_forgotten_a_data_science_phd/,4,1643515568.0,"I'm not particularly hopeful about my odds of hearing back at all because I found out about it pretty late and didn't really put my best foot forward. I'm curious to know how long it was before you received a response after submitting the application. I'm assuming I'll only hear back if I get an interview.

Bonus for those who got the internship: how many stages were the interviews and what was the timeline like after you initially heard back from Google?",2022-01-30 06:06:08
Building new DS department,11,sfx8dn,https://www.reddit.com/r/datascience/comments/sfx8dn/building_new_ds_department/,22,1643505917.0,"tl;dr: New data science department, not a data scientist, how should I proceed?

I've been tasked with establishing a Data Science department at my mid-sized, fairly traditional company. We have an Analytics department that focuses on descriptive analysis and data viz. My background is in operations research, so while I have some technical/stats knowledge, there's a lot that I don't know about being a Data Scientist.

I'm planning for 2022 and I know I need to build my fundamentals in Python and re-educate myself on forecasting best-practices. If you were in a similar position, how would you go about building a department like this? What knowledge do you wish you had when first starting out?

Edit:

I should've been more clear on a couple points: I am the only Data Scientist for now, my success/failure will determine the future of the 'department'. I haven't been given a specific direction other than 'start with forecasting'.",2022-01-30 03:25:17
Graph/ relations analysis,2,sfv89p,https://www.reddit.com/r/datascience/comments/sfv89p/graph_relations_analysis/,1,1643500111.0,"I got a job task on relations analysis and community discovery and I don't have any experience about it. 

Basically we have a set of people related by different kind of relations to other people. Some of those relations are relevant, some aren't depending on another particular relation. We want to test and predict its existence. Better if we can discover communities sharing that particular relation.
I can model each people pair as an A/B test with a set of features, but I suppose graph theory can help. 

Do you know of any useful online resources on the subject?

TIA",2022-01-30 01:48:31
Is beta hat dead?,77,sfv7i8,https://www.reddit.com/r/datascience/comments/sfv7i8/is_beta_hat_dead/,34,1643500047.0,"Hello all, I was in my ugrad Bayesian stats class the other day when my professor started lecture off with an interesting discussion. He was talking about how nowadays there’s no frequentist vs Bayesian battle, and it’s more of a predictive vs explanatory modeling battle. Ie. Statisticians focus on interpretable modeling, Computer Scientists focus on predictive modeling. 

He went on to mention how he was at a talk and a computer scientist was saying how beta hat is dead, and no one cares about finding coefficients anymore, and the focus has shifted to y hat. Ie. Predictions > coefficients.

Funny enough, the professor said how he raised his hand and mentioned clinical trials, and the speaker had nothing to say.

It made me ponder, whether something like this is industry dependent, ie. Maybe in tech it’s more about predictions, not caring about interpretability, and maybe in biostatistics or other fields it’s the opposite.

Can anyone speak to the reality of what this computer scientist was saying?",2022-01-30 01:47:27
"Data scientists: What domain/sector do you work in? What do you like or dislike about it, and what makes your domain interesting from a data science perspective?",69,sfkfcy,https://www.reddit.com/r/datascience/comments/sfkfcy/data_scientists_what_domainsector_do_you_work_in/,92,1643470261.0,,2022-01-29 17:31:01
Users of Dash and Shiny…,1,sfj1gl,https://www.reddit.com/r/datascience/comments/sfj1gl/users_of_dash_and_shiny/,6,1643465979.0,"I’m considering starting a project in Dash and I’m just curious how it compares to Shiny, from a functionality, scripting and usability perspective. I learned Shiny last summer and the learning curve was mildly steep, but once I understood the fundamentals, became pretty intuitive. 

I really liked the functionality of the front end dashboard-like interface, and am wondering how Dash stacks up, or if there is another Python equivalent that would be better.

TIA.",2022-01-29 16:19:39
Data Science in South Asian countries?,6,sfh30w,https://www.reddit.com/r/datascience/comments/sfh30w/data_science_in_south_asian_countries/,1,1643458958.0,"I belong to a South Asian country, and one of my biggest problems here is that there just isn't good data infrastructure. How does one do data science when there isn't even any data?

Could anyone tell me what sort of data degree I should choose if I want to make more impact in a country where good quality data is sparse? Should I become a Business Analytics expert and help companies set up ETL? Or should I be a data engineer?",2022-01-29 14:22:38
Colab or Juypter? Which do you use and why?,16,sfgugr,https://www.reddit.com/r/datascience/comments/sfgugr/colab_or_juypter_which_do_you_use_and_why/,28,1643458004.0,"I am in the middle of moving from Juypter to Colab cause I find it alot more easy to use and portable and enables cooperation.

I was wondering what you guys use for your data science projects?

Im more so talking about the smaller projects not the ones that would need a full IDE like VS/Spyder or Pycharm 

PS. As for my R DS friends we all know RStudio is pretty much key :)",2022-01-29 14:06:44
"For already employed data scientists, what maths would you like to learn if time permitted?",258,sfgdvs,https://www.reddit.com/r/datascience/comments/sfgdvs/for_already_employed_data_scientists_what_maths/,210,1643456199.0,"So you are a data scientist, with a nice job with enough work that isn't data cleaning/ Excel manipulation to keep it both real and interesting. Obviously you took classes in linear algebra, calculus what have you to get where you are now.

Is there any maths you didn't get to learn at school that you wish you could have got to? Is there any maths you're trying to learn right now because you think you need it, or just because you're interested?",2022-01-29 13:36:39
Time-series econometric models in real-life cases,14,sffyqy,https://www.reddit.com/r/datascience/comments/sffyqy/timeseries_econometric_models_in_reallife_cases/,11,1643454480.0,"Hi everyone,

I am just curious how do you use time-series econometric models, let's say ARIMA, exponential smoothing, or TBATS, in real life? Have you ever achieved a successful model? What is the case?

I am asking mainly because of three reasons: 

1- The feature engineering aspect is somehow missing relative to machine learning.

2- The model structure might be very simple, especially in the case of the univariate time-series model.

3- Except for several cases, I always ended up with a very high confidence interval.

Also, I would love to learn if you have any experience regarding how performance of time-series econometric models are compared to xgbTree (or different ML algorithm) with time-series features?

Thank you very much.",2022-01-29 13:08:00
Sr. Data Scientist about to be promoted —> Which title shall I propose?,9,sffts4,https://www.reddit.com/r/datascience/comments/sffts4/sr_data_scientist_about_to_be_promoted_which/,42,1643453970.0,"Hello,

I am currently a Sr. Data Scientist at a medium sized company (manufacturing industry) and my boss will promote to “Line Manager”. 

Now the good news is that I have some freedom in proposing a new title, and I would like your advise here.

Some background info:

1. We do very little DS overall. I tried to bring to life some models (mostly DL related), and have succeeded in that, but there is virtually no DS culture in the organization.

2. Since we do very little DS, in the last 3 years I found myself very busy with Data Engineering and Business Intelligence related topics, rather than pure DS. Myself and two colleagues of mine had to build everything ground up. Literally everything: from frontend development to data warehousing, to data science and Airflow automation (all Python based).

3. If things don’t progress in the next two years (in terms of how the DS business peaks up), I’lll be moving on, as I have little faith in the overall organization (I was one of those DS hires that was hired because “you need to have a data scientist”, but both my boss and the boss of my boss, have very little to no understanding of any of this). On a good note, I am paid about 20% more than industry average.

Now, I have just hired a Data Engineer to join my new team and hopefully I’ll be given the budget to hire more people within the year (if not, see point 3). It will be a team with mixed skill set, not only purely DS. The next topic is which title to pick after my promotion.

Options are:
- Data science manager (proposed by my boss)
- Data science team lead
- Data science architect (proposed by my boss)
- Head of data science (not sure my boss will like it for political reasons)
- Something else that you can recommend?

I fear that “Data science manager” is one of those title that sounds senior but it isn’t. What do you reckon? And what would you pick, considering that I might be leaving the company if things don’t take a better turn?

Thanks and sorry for the long post",2022-01-29 12:59:30
"Advisory boards, board member and alike",3,sf6egy,https://www.reddit.com/r/datascience/comments/sf6egy/advisory_boards_board_member_and_alike/,7,1643419613.0,"I’m trying to get involved with some additional professional data science work outside of my 9-5 as a principal data scientist.

I’m looking for board positions, advisory boards or alike, but I’m having troubles finding something. I’m fine with unpaid work.

I’m in the Bay Area currently. If anyone have some suggestions on how to make this happen, I would very much welcome it!",2022-01-29 03:26:53
work for startup or more established company?,2,sf5a4x,https://www.reddit.com/r/datascience/comments/sf5a4x/work_for_startup_or_more_established_company/,5,1643416313.0,"Hey all

I just defended my PhD in biomed engineering, w/ a focus on medical imaging.  I'm starting to look for full-time Data Science roles, and am looking for some career advice.

Towards the tail end of my PhD, I was interning at a startup biotech company involved in tissue engineering, imaging systems, etc.  Originally, I was hired on as a ""Data Science Intern"", but the day-to-day work was / has been / is still primarily related to software engineering / testing / etc., and building up their software platform.   The general idea was that this company was planning to ""build up"" their Data Science team -- once I defended my PhD, and when / if I was hired on full-time, I would be their first ""official"" Data Scientist.

In the mean time, while they've been putting a job offer together, I've also been applying for other Data Scientist roles at more established biotech companies that have actual Data Science teams (at least a handful of employees).  I'm pretty far in the interview process with one, and am scheduled to start interviews with one more.  Ironically, given what people have been saying about it being an employee's job market right now due to Covid, interviews have been hard to come by.

**\*I don't have any offers yet\***, but I'm not sure how to weigh size of company, size of DS team, etc. against the prospect of being able to essentially ""start"" the team at another company.  I want to be able to learn certain skills, like team management, various software tools, and industry best-practices, and I'm concerned I won't get that at a startup of this size.  But I'm also drawn to the idea of building up something from scratch and think that would be a valuable resume builder, and could also boost my career.

**tldr**: when faced with the choice\* of working as a Data Scientist for a small or a bigger company, what concerns do you have?  What things do you value?  Why?",2022-01-29 02:31:53
Minor rant: I find troubleshooting in Excel awful,8,sf1qrd,https://www.reddit.com/r/datascience/comments/sf1qrd/minor_rant_i_find_troubleshooting_in_excel_awful/,5,1643406703.0,"Whenever I find some tough spot in Python, C++ or even Matlab I can google my problem. In Excel I always fall in some SEOed page that gives a basic tutorial in something that barely matches my search. I wish excel stack overflow had more people",2022-01-28 23:51:43
Career Progression Question (moving to a BI Director role),1,sezt2d,https://www.reddit.com/r/datascience/comments/sezt2d/career_progression_question_moving_to_a_bi/,12,1643401417.0,"Hoping for the $0.02 of the more experienced.

I work as a data science manager now with a group that's focused on predictive modeling and analytics. I've been reached out to by a recruiter for a Director role in a Business Intelligence group. The BI group is self-described 'immature' and the current work seems to be largely around turning reports into real time dashboarding. They also want to move into ""ML and AI"" which is clearly not a short term thing and I'm confident they don't even understand what that means.

Is it a terrible idea to take a step from a data science manager and move into a group that is doing mostly BI work and trying to build out their predictive function? Or is it the career kiss of death to go into a BI group? Will I be stuck there and never be able to get out of it?

There is a money bump, of course, and also additional headcount. That part I'm interested in but I worry about being yet another BI manager.",2022-01-28 22:23:37
How promising is remote sensing as a data science field?,0,sezcx5,https://www.reddit.com/r/datascience/comments/sezcx5/how_promising_is_remote_sensing_as_a_data_science/,0,1643400183.0,"Hi everyone,

My question is stated on the title. Thank you very much for your answers.

Have a nice weekend.",2022-01-28 22:03:03
Selling data analytics to higher-ups?,6,seyxnl,https://www.reddit.com/r/datascience/comments/seyxnl/selling_data_analytics_to_higherups/,14,1643399035.0,"I recently finished an MBA with an emphasis in data analytics, and while I'm not a math genius by any stretch, I'd like to apply what I learned to my job in comms/marketing. Unfortunately, every supervisor I discuss this with has very little interest, which I find strange considering how much analytics is used in marketing and comms. 

Is there a way to sell this that I'm missing? I'd like to use, for example, historical social media data to determine what works, what doesn't, best time to post, and other basic measurements to connect this information to sales.",2022-01-28 21:43:55
Who here does not utilize anything more complex than logistic/linear regression models?,61,sexpx3,https://www.reddit.com/r/datascience/comments/sexpx3/who_here_does_not_utilize_anything_more_complex/,32,1643395759.0,"I read a comment on this subreddit that said something like ""I'd bank that 98% of people that are in this sub do not utilize anything more complex than linear/logistic regression models."" I'm kinda wondering if there's truth to that.

I know DS is so broad, but I'm asking for specific people here to chime in :)",2022-01-28 20:49:19
We don’t construct black boxes,0,sewc1z,https://www.reddit.com/r/datascience/comments/sewc1z/we_dont_construct_black_boxes/,1,1643392052.0,"We are communicators of uncovered knowledge derived from data. And the only way we succeed in our job is when we communicate well.

If your goal is to research and develop AI and machine learning models, then go get a PhD in math or compsci. I can’t really think of any other way to do it. 

But if your goal is to research and develop solutions to problems that we all face every day, then you will have a better chance of landing a job in practically any industry around the world. I’m not saying that this is easy, but we as data scientists should think in terms of how well can we use our skills in math, stats, and coding/software to help people and businesses. Once I figured this out, it helped me get over my imposter syndrome and actually feel confident in my ability to work as a data scientist.",2022-01-28 19:47:32
Anyone else feel like the interview process for data science jobs is getting out of control?,597,seufwd,https://www.reddit.com/r/datascience/comments/seufwd/anyone_else_feel_like_the_interview_process_for/,199,1643386867.0,"It’s becoming more and more common to have 5-6 rounds of screening, coding test, case studies, and multiple rounds of panel interviews. Lots of ‘got you’ type of questions like ‘estimate the number of cows in the country’ because my ability to estimate farm life is relevant how?  


l had a company that even asked me to put together a PowerPoint presentation using actual company data and which point I said no after the recruiter told me the typical candidate spends at least a couple hours on it. I’ve found that it’s worse with midsize companies. Typically FAANGs have difficult interviews but at least they ask you relevant questions and don’t waste your time with endless rounds of take home   
assignments.   


When I got my first job at Amazon I actually only did a screening and some interviews with the team and that was it! Granted that was more than 5 years ago but it still surprises me the amount of hoops these companies want us to jump through. I guess there are enough people willing to so these companies don’t really care.   


For me Ive just started saying no because I really don’t feel it’s worth the effort to pursue some of these jobs personally.",2022-01-28 18:21:07
Looking for advice for software engineering interview,2,seu8xi,https://www.reddit.com/r/datascience/comments/seu8xi/looking_for_advice_for_software_engineering/,4,1643386332.0,"I have a maybe stupid question. I'm  training to become a data scientist, coming from chemistry and I have what is probably a combined one year of python coding (scientific industry) under my belt. I have now been invited to an interview as a software engineer.

The company looks quite interesting, also in that they hire mostly academics and they're willing to give beginners a go (I told them my background which includes a lot of scientific stuff and bash experience). They are known to offer jobs if beginners qualify in other parts of the interview, i.e. logic puzzles.

So far, so good. I was originally approached by a headhunter who then passed me on their colleague. The first time I talked to her before christmas about my qualifications, she was a bit hesitant when I explained my coding level. Fair enough.
The second time we talked in the new year I showed her the stuff I had been preparing and she reacted surprised - like not pleasantly surprised. I had a bad experience with a headhunter that tried to oversell my competence level before.

A few minutes into the preparation she got overly hyped about how many chapters I'd read in a book that she had recommended (like not that she was happy more that she was exaggerating).

She doesn't have a coding background, so I should probably just ignore her reaction but ever since that, I have been doubting myself:
- one if my level is okay (otherwise the company wouldn't interview me for four hours, right?), and
- two if I really want to do software engineering.

The second one is not something anyone can help me with but I'd appreciate some pointers/orientation that would help me get my head out of the self-doubt loop it's currently stuck in.

Thanks a lot in advance and I hope you're all happy and healthy! 💛",2022-01-28 18:12:12
"Easy speed optimizations for pandas, sklearn and tensorflow I just found!",4,seu47g,https://www.intel.com/content/www/us/en/developer/articles/technical/code-changes-boost-pandas-scikit-learn-tensorflow.html?cid=psm&source=facebook_synd_ih&campid=ww_q4_oneapi&content=art-idz_cross-seg&fbclid=PAAaYtFFbPWhLudOpEzTwLWPhNlkn-Aq-vzBvT_dYjhbfyWk7kvnXgOTtTNVw&external_browser_redirect=true#gs.nccx9y,0,1643385957.0,,2022-01-28 18:05:57
Visual clarity,0,seu1no,https://www.reddit.com/r/datascience/comments/seu1no/visual_clarity/,0,1643385762.0,"Hey  want to show these datapoints

* Health/nutrition
* Communication
* Friends/Family/relationships
* Well-being/Happiness/positivity
* Openness
* Goals/motiviation
* Compassion/Empathy
* Career/money
* Health/fitness
* And maybe others

Each datapoint would maybe be from 0-3, or  0-5 or 0-10 scale

&#x200B;

Which of these graphs charts (or others) do you think would be better to show/viz this? For visual clarity?

[https://datavizcatalogue.com/index.html](https://datavizcatalogue.com/index.html)

(If you have / know of better sites than this for graphs charts and what they're good for, that would be great) - a site that lists/ranks graphs charts would've been so much better and more helpful

This site also has a bunch of graphs charts that arent really good to show data

Currently thinking of horizonal bar chart  but wanna know what are other good options? For clarity

&#x200B;

For 'infographic' if it helps you decide on which graphs/charts are better   [https://miro.com/app/board/uXjVORoZ1bE=/](https://miro.com/app/board/uXjVORoZ1bE=/)",2022-01-28 18:02:42
Data Hygiene Tips,9,sesnu9,https://www.reddit.com/r/datascience/comments/sesnu9/data_hygiene_tips/,3,1643381865.0,"Hey everyone, I'm looking for small things that most business owners can do today to improve the quality of their data.

One example would be to replace ""free form"" fields from their CRM with ""closed-ended"" fields as much as possible.

Any other examples like this one?",2022-01-28 16:57:45
dbplyr vs SQL,22,sesbe8,https://www.reddit.com/r/datascience/comments/sesbe8/dbplyr_vs_sql/,42,1643380865.0,Is there a reason to learn SQL instead of just learning dbplyr in R package?,2022-01-28 16:41:05
Agent based model ideas for beginner?,1,serc2u,https://www.reddit.com/r/datascience/comments/serc2u/agent_based_model_ideas_for_beginner/,2,1643378074.0,"
Hi Reddit,

Sorry if this is not the right place to ask. 

Im doing a MSc data analytics with zero programming background, and am required to create an agent based model using Netlogo. 

I’ve been looking at several examples, but they seem quite contrived in the coding, and not suitable for my level of skill. 

By any chance, do you have any ideas for an agent based model I could create that it’s not too complicated?",2022-01-28 15:54:34
How to detect similarity between email IDs,1,semq3h,https://www.reddit.com/r/datascience/comments/semq3h/how_to_detect_similarity_between_email_ids/,8,1643361440.0,"Hi All,
Is there any technique to find similarity between email ids. I have list of email Ids, and wanted to create cluster based on the organisation, and wanted to remove any duplicate emails if there are any.

Eg: a.b@domain.com & b.a1@domain.com (find and remove those)",2022-01-28 11:17:20
Tell me one thing you love and one thing you hate about this field or your job.,60,sej1no,https://www.reddit.com/r/datascience/comments/sej1no/tell_me_one_thing_you_love_and_one_thing_you_hate/,56,1643347211.0,"Hello.

I’m interested in switching careers between these 3: data analytics, data engineering, and data science. 

They seem to be quite close to one another. I took it as DA takes current/historical  info, and shares it, DE builds the systems for data collection and DS seem to look for trends going forward? 

I was hoping you could share one thing you love and one thing you hate so that I can get a different perspective of what to expect if I pursue this. :)

My goal is to get a bachelors in Data Analytics and Data Management. I would be building up a portfolio during this time, and then hopefully going for a MS in Data Science. 

Thank you!",2022-01-28 07:20:11
Intro to economics,2,sehsr2,https://www.reddit.com/r/datascience/comments/sehsr2/intro_to_economics/,7,1643343115.0,"I came to DS from Academia, and now I am in my second role as a data scientist. This role is different from anything I had done before because it is more business focus

The question is, does anyone has a good recommendation on resources about introductory topics in Economics? I want to get a better hold of the basic concepts and language.",2022-01-28 06:11:55
(Intermittent) Time series forecasting,6,sef8ny,https://www.reddit.com/r/datascience/comments/sef8ny/intermittent_time_series_forecasting/,9,1643335295.0,"Hi all! I'm trying to forecast a daily time series that has many 0 days. For example, forecasting a person's daily expenditure for every day for the next N days. Customer's expenditure as one would expect has many days with 0 spend. 

Has anyone here dealt with a similar time series problem?

If yes, what methods would you recommend and also what metrics would be useful in this case to measure the success of a model. 

I'm relatively new to time series forecasting and any help is really appreciated. 

Thanks!",2022-01-28 04:01:35
Data Scientist vs. Platform Engineer,2,sedyxj,https://www.reddit.com/r/datascience/comments/sedyxj/data_scientist_vs_platform_engineer/,3,1643331639.0,"I'm considering a switch from a position as a data scientist to a platform engineering job. Currently at work I do data pull automation with PySpark and Airflow, but I do little actual analysis or science with it. I'm still pretty happy overall because I'm learning new things and I really love coding. 

This love of coding led me to find a job at the same company as a platform engineer. It sounds much closer to software engineering, and sounds like it is ""backend data science"", so to speak. It also has machine learning as a ""nice to have"" requirement. I would like to do more ML, so this would be great if the job actually needs it. 

These are my questions:

1. What exactly is platform engineering?
2. Would you consider the step from data scientist to platform engineer a lateral move?
3. Will experience as a platform engineer help me with my data science career in the future?
4. Will it be difficult to get a job as a data scientist again with ""Platform Engineer"" as my most recent title?",2022-01-28 03:00:39
"I made a simple chatbot from a dataset of the famous tv show ""The Office"" what do you think about it ? What can I try to improve ? [click the button at the end of the article to test it]",1,sed4hj,https://plural.run/articles/officeChatbot,2,1643329233.0,,2022-01-28 02:20:33
Career Trajectory - from IC to Executive?,21,sed0ne,https://www.reddit.com/r/datascience/comments/sed0ne/career_trajectory_from_ic_to_executive/,5,1643328943.0,"I'm wondering if anyone can share an experience of moving from an IC (Data Scientist / ML Practitioner - for reference I'm a Senior Computer Vision researcher working at a big FAANG company) - to an Executive level position (Director/VP/etc...)? 

As I progress in my career, I'm finding I'm much less interested in continuing to write papers and do research, and more interested in being involved in upper level decision making. I'm already on track to transition into a management position, but from there it seems like an impossible gap to make Director or VP.

I'm looking for some anecdotes of people who've moved from an IC to an Executive role, either passing through management or not. Did you find you needed to move between companies? Did you need to get an MBA? Is this actually impossible and I'm stuck in IC/technical management land?",2022-01-28 02:15:43
[D] How to deal with paragraphs in opinion mining (Sentiment Analysis)?,4,sebvzx,https://www.reddit.com/r/datascience/comments/sebvzx/d_how_to_deal_with_paragraphs_in_opinion_mining/,0,1643325915.0,"My goal is to find comments about stocks and create a model to classify the comment as good/bad/neutral (or maybe a 5 point scale so I can have good, really good, etc.) so that I can give an opinion for the stock. My issue is that I have some comments with multiple sentences. In some cases, all sentences are about one stock and in other cases, the sentences are about different stocks.

A simple solution to this could occur when I'm manually labeling the comments. I could group the sentences based on which stock they're about. The issue with this is that when I begin to apply the model to new comments, this won't work, as I won't be there to manually separate sentences by which stock they belong to.

Essentially I need a way to map the sentence(s) in a comment to the appropriate subject of the sentence(s). Any ideas?",2022-01-28 01:25:15
What does a Junior cloud practitioner do exactly?,0,seboii,https://www.reddit.com/r/datascience/comments/seboii/what_does_a_junior_cloud_practitioner_do_exactly/,4,1643325371.0,"I’m working on getting into tech and interested in data analysis/science. However, someone mentioned that I would be a good fit for a Junior Cloud Practitioner role. However, I can’t really find info on what this role is and what one does. Any info would be greatly appreciated!",2022-01-28 01:16:11
Anyone regret not doing a PhD?,94,seac59,https://www.reddit.com/r/datascience/comments/seac59/anyone_regret_not_doing_a_phd/,125,1643321881.0,"To me I am more interested in method/algorithm development. I am in DS but getting really tired of tabular data, tidyverse, ggplot, data wrangling/cleaning, p values, lm/glm/sklearn, constantly redoing analyses and visualizations and other ad hoc stuff. Its kind of all the same and I want something more innovative.  I also don’t really have any interest in building software/pipelines. 

Stuff in DL, graphical models, Bayesian/probabilistic programming, unstructured data like imaging, audio etc is really interesting and I want to do that but it seems impossible to break into that are without a PhD. Experience counts for nothing with such stuff.

I regret not realizing that the hardcore statistical/method dev DS needed a PhD. Feel like I wasted time with an MS stat as I don’t want to just be doing tabular data ad hoc stuff and visualization and p values and AUC etc. Nor am I interested in management or software dev.

Anyone else feel this way and what are you doing now? I applied to some PhD programs but don’t feel confident about getting in. I don’t have Real Analysis for stat/biostat PhD programs nor do I have hardcore DSA courses for CS programs. I also was a B+ student in my MS math stat courses. Haven’t heard back at all yet. 

Research scientist roles seem like the only place where the topics I mentioned are used, but all RS virtually needs a PhD and multiple publications in ICML, NeurIPS, etc. Im in my late 20s and it seems I’m far too late and lack the fundamental math+CS prereqs to ever get in even though I did stat MS. (My undergrad was in a different field entirely)",2022-01-28 00:18:01
Do I need a second phone?,0,sea3lj,https://www.reddit.com/r/datascience/comments/sea3lj/do_i_need_a_second_phone/,8,1643321256.0,"I was just hired as the main “data person” at a smaller company. Sometimes I get urgent requests that I need to respond to right away. I really don’t want to mix my personal phone with work, but my company does not offer phones or even to pay for a plan. What recommendations do you have for having access to information that I need right away given this context? Is it too ridiculous to buy myself another phone? Just trying to gauge how insane that would be. Thanks in advance.",2022-01-28 00:07:36
Does correlation vs causation have any meaning in Machine Learning?,9,se9g7w,https://www.reddit.com/r/datascience/comments/se9g7w/does_correlation_vs_causation_have_any_meaning_in/,16,1643319583.0,"In traditional statistics, it is hammered into us that correlation DOES NOT mean causation.

But I feel like that doesn't apply in something like a Neural Network seeing as we don't care if the input variable is causing the output variable or is merely correlated with it.",2022-01-27 23:39:43
Graph based data science and networked systems,8,se7sks,https://www.reddit.com/r/datascience/comments/se7sks/graph_based_data_science_and_networked_systems/,7,1643315235.0,Do you guys think graph theory and network systems are broadly crucial to a data science career?,2022-01-27 22:27:15
"Looking for textbook recommendations for information theory, any would be much appreciated!",2,se7h7y,https://www.reddit.com/r/datascience/comments/se7h7y/looking_for_textbook_recommendations_for/,2,1643314386.0,,2022-01-27 22:13:06
Can linear regression rank a vector of inputs?,0,se6zik,https://www.reddit.com/r/datascience/comments/se6zik/can_linear_regression_rank_a_vector_of_inputs/,1,1643313112.0,"I'm comparing performance of neural networks to linear regression for several problems - some linear, some not - to make a point to some non DS folks.

One thing I can do with NN is give an n-dimensional vector where each vector component is continuous and get back an n-dimensional vector that ranks the values (I know this is trivial, but in context it matters). For example, input = \[0.9, -0.6, 0.1\] -> output \[3, 1, 2\]

I want to say, there is no analogous way to do this with linear regression - meaning, I cant even do it badly / with low accuracy. Am I wrong?",2022-01-27 21:51:52
Researchers turned DS,1,se5z08,https://www.reddit.com/r/datascience/comments/se5z08/researchers_turned_ds/,7,1643310462.0,"did you go on to continue work in a field similar to the topic of your research? 

I am currently an undergrad ML researcher in remote sensing and satellite imagery and will be finishing (publishing) a little after graduation. I find this area really interesting, but I am unsure if I should try to branch out into a new field after finishing or try to continue w a firm doing related work. 

My only worry is that remote sensing and image processing is a bit of a niche area, and continuing may limit my exit opportunities down the road. But I also imagine it may be easier to sell myself to a related firm as opposed to for eg a consulting or insurance firm. 

I am curious to hear what your guys/gals experiences and thoughts.

**edit: why does this get downvoted lol",2022-01-27 21:07:42
Data professionals suggestions to improve this blog post about the differences between data analyst vs data scientist vs data engineer?,0,se40w0,https://www.reddit.com/r/datascience/comments/se40w0/data_professionals_suggestions_to_improve_this/,2,1643305420.0,[https://www.imaginarycloud.com/blog/data-analyst-vs-data-scientist-vs-data-engineer-what-is-the-difference-2/](https://www.imaginarycloud.com/blog/data-analyst-vs-data-scientist-vs-data-engineer-what-is-the-difference-2/),2022-01-27 19:43:40
My First Data Science Project: Anything I could improve on?,4,se0v7k,https://www.reddit.com/r/datascience/comments/se0v7k/my_first_data_science_project_anything_i_could/,7,1643297063.0,"Hey guys! I just finished my first data science project and would love to get some feedback on it! If you have some free time I would appreciate it!

This project was the first of a Udacity course I am currently taking and thankfully they let you have free range over what data you could use and how you use it.

I want to get a job as a data scientist (entry level) so I tried to make this as professional as possible. The rest of my Github is a mess so don't flame me on it. 

[https://github.com/SaintGemini/diamond-price-prediction](https://github.com/SaintGemini/diamond-price-prediction)

Thanks in advance!",2022-01-27 17:24:23
"After the 60 minutes interview, how can any data scientist rationalize working for Facebook?",535,sdzkex,https://www.reddit.com/r/datascience/comments/sdzkex/after_the_60_minutes_interview_how_can_any_data/,316,1643293488.0,"I'm in a graduate program for data science, and one of my instructors just started work as a data scientist for Facebook. The instructor is a super chill person, but I can't get past the fact that they *just started* working at Facebook.  


In context with all the other scandals, and now one of our own has come out so strongly against Facebook from the inside, how could anyone, especially data scientists, choose to work at Facebook?  


What's the rationale?",2022-01-27 16:24:48
"Gelman, Hill, and Vehtari's new book, ""Regression and Other Stories,"" is now free as a pdf from the authors!",71,sdxd7u,https://users.aalto.fi/~ave/ROS.pdf,2,1643286811.0,,2022-01-27 14:33:31
Suggestions for refreshing on data science,0,sdsxah,https://www.reddit.com/r/datascience/comments/sdsxah/suggestions_for_refreshing_on_data_science/,2,1643268944.0,"It's been a few years since I took my courses in Data Science (at my University), and I want to refresh. I haven't worked on Kaggle before, but that seems to be the place to go for doing this work in ways I can demonstrate my skills to future employers / teams / etc.

I was thinking of going through [The Elements](https://hastie.su.domains/ElemStatLearn/) and applying the tools they go over to some simple datasets; e.g. MNIST, Titanic, etc. Then I could keep those notebooks for reference, and I think it might be a good refresher; I've got a lot of time before I hear back about PhD's for the fall.

What's your opinion? Does this sound like a good idea? If you'd like to add anything, or suppose any alternatives, I would very much appreciate it.",2022-01-27 09:35:44
Data science or Business Intelligence.,9,sdsocz,https://www.reddit.com/r/datascience/comments/sdsocz/data_science_or_business_intelligence/,22,1643267950.0,"I am currently working as a data scientist for a logistics partner for a Tier 1 tech company.  I am expecting job offer from a tier 1 financial services company for the position  of business intelligence.

Would choosing business intelligence be a good idea or a bad idea? How is the future path looking for me if I accept this offer.
I understand that business intelligence is descriptive analytics while the data science role is predictive. 
I enjoy both but what would pay me more in future and what positions can i transition to from the new role.

Any guidance is appreciated, thanks!

A little background on me:
I’m a recent graduate with masters in computer science, 
4 years of data science experience, led teams in all positions(Internships, college research positions,part time,etc).
2 publications, 1 focused towards financial sector, other towards statistical analysis in geology.",2022-01-27 09:19:10
"AI facial editing models are getting so advanced it will be insanely hard to tell facts from fiction! 🤯🤯(video below: Kamala Harris, Vice President 🇺🇸 smiling when in the actual video she wasn't. In politics, smallest gestures have biggest implications)",8,sdk7yo,/r/LatestInML/comments/sdjz90/ai_facial_editing_models_are_getting_so_advanced/,3,1643241286.0,,2022-01-27 01:54:46
New to the field and am somewhat confused how publishing works?,6,sdhtbq,https://www.reddit.com/r/datascience/comments/sdhtbq/new_to_the_field_and_am_somewhat_confused_how/,11,1643234783.0,"Hey everyone, I wasn’t sure where to post this, but this just eating away at me and I’m not sure if it’s because I don’t understand, or if this really isn’t how it’s supposed to work. 

I started this job a few months back, at a National lab setting (in case that’s important). We’re in the process of writing up a paper for publication. 

A coworker decided to lead the paper and take first author. Well, said coworker actually has done nothing except create the initial outline, which consisted only of placing section headers. I filled in the majority of the content, wrangled other people into some, and in general engaged a lot with paper planning brainstorms. 

The coworker who should be leading has been been very hands off has enthusiastically declared they’re uninterested in writing at this time, that we should run with it, and he’ll serve as the overseer. And, as far as I know, still in the first author role. They’ve not mentioned stepping down from that. 

Is that normal? My experience has been first author goes to who did the majority of the work, both for the project and the paper, neither of which this coworker has done. 

I’m doing what my boss is asking of me, but I’m hesitant to do more for this paper that seemingly someone who has been very uninvolved with will stamp their name in front and submit as their own publication. 

Do I have a misunderstanding of how publications work? I want to know if I’d be out of line in not continuing to do a lot of heavy lifting on this paper.",2022-01-27 00:06:23
Did I Fall for a Recruiting Scam?,0,sdh7nh,https://www.reddit.com/r/datascience/comments/sdh7nh/did_i_fall_for_a_recruiting_scam/,32,1643233192.0,"I, a Lead DS at a large well-known company, received a recruitment email I now believe to be a scam. I have a good deal of work experience and am often contacted by recruiters, so I didn’t think twice about this email, except that normally I don’t respond - the email was for a senior role at Petco, which, as a dog lover, I thought, “this is the dream job”. I sent my résumé and availability for a call. No response since then, and I’m beginning to think this was phishing, except, what’s the scam? Everything on my résumé is on my LinkedIn and public knowledge. Should I be concerned I shared my résumé? 

The recruiter didn’t include any contact info or their last name, and the email had links to Petco’s website and workday app site (I even checked the URL before I clicked!). The recruiter’s email is paulc@paulrecruiter.com (yes, definitely several red flags that I ignored in my dream of dog data science problems). 

Email subject: Director of Inventory Analytics & Data Science Opportunity at Petco!

Email contents:
Hi pantherapardus,

I'm reaching out about an opportunity to join Petco, a category-defining health and wellness company focused on improving the lives of pets, pet parents and our own Petco partners. We are seeking a Director of Inventory Analytics&Data Science to join our team and thought you would be a great fit.

Since our founding in 1965, Petco has been trailblazing new standards in pet care, delivering comprehensive wellness solutions through our products and services, and creating communities that deepen the pet-pet parent bond.

If you’d like to learn more about this exciting opportunity, please let me know by sending over an updated copy of your resume and I'd be happy to set up a call to discuss further! Let me know if you have any questions, look forward to hearing from you!

Cheers, 
Paul

Guys, wtf is going on here? Or is this maybe legitimate and I’m just not qualified (honestly, this would be comforting at this point)?",2022-01-26 23:39:52
"After you graduate university and the university changes the name of your degree program, which degree program name do you use on your resume?",19,sdh6e4,https://www.reddit.com/r/datascience/comments/sdh6e4/after_you_graduate_university_and_the_university/,23,1643233101.0,"I graduated from a master program some years ago. Let's pretend the degree program was called ""MS, Data Studies."" Two years later, the school changed the name of the program to (let's also pretend) ""MS, Data Science.""

The program itself has not changed. I can see the same curricula and specialties on the website. But obviously the new program name is way the hell better than the old one.

If you're me, do you use the new name when talking to people and on your resume? Or do you stick with the old one so that the program name matches your grad year?

Thanks for any tips, DS friends.",2022-01-26 23:38:21
How to import tensors into a column from NLP task ? Want to replace the text in the csv with its tokens. I use pytorch,0,sdfsqa,https://www.reddit.com/r/datascience/comments/sdfsqa/how_to_import_tensors_into_a_column_from_nlp_task/,0,1643229540.0,,2022-01-26 22:39:00
Missing Values in Dataframes,1,sdf78c,https://www.reddit.com/r/datascience/comments/sdf78c/missing_values_in_dataframes/,4,1643227984.0,"What's the best way to replace missing values in a dataframe, that has missing 'text' values? I.e. say I have a pandas dataframe, 8 numeric columns, 2 non-numeric. If, say I had one column as ""Male/Female"" and had ""Male"", ""Female"", ""Female"", ""NaN"", ..., ""Female"", Would it be best to just insert ""MissingValue""? Is this anything really better than ""NaN"" for text values? For numeric values I may be able to insert a mean of all the other values. I cannot see if there is anything else of similar such value for text/non-numeric missing values?

Edit: the male/female was just an example. It was just the first that came to mind when I thought of non-numeric categories. It could be fruit or favourite band too etc.",2022-01-26 22:13:04
Data Mining and Sensemaking from a Collection of Notes and Documents,0,sdbt9k,https://www.reddit.com/r/datascience/comments/sdbt9k/data_mining_and_sensemaking_from_a_collection_of/,2,1643219364.0,"I figure someone here might have an idea:

I have a huge, and growing, collection of notes on my phone (voice, text, handwritten), and documents on my laptop - fragments of several books in process.

It sure would be nice to have some kind of tool that can bulk process all of these items - extract some keywords, and then help me visualize the mess - maybe auto-generate a mind-map style semantic network.

I expect that, between the marketing world, and the intelligence community, there must be some data mining and sense making software floating around.

Any pointers would be much appreciated!

Thanks!",2022-01-26 19:49:24
"Data, Infomation and Knowledge (with examples please)",2,sdad0m,https://www.reddit.com/r/datascience/comments/sdad0m/data_infomation_and_knowledge_with_examples_please/,6,1643215664.0,"I am doing a BSC Data qualification and did a session on Data, Information and Knowledge. Get the difference in principle but when I tried to totally get my head around it I was less unsure about whant their terms mean practically.

I did some background reading, which kind of helped but is lacking good examples.

[https://www.artegic.com/blog/difference-data-information-knowledge/](https://www.artegic.com/blog/difference-data-information-knowledge/)

[https://www.ontotext.com/knowledgehub/fundamentals/dikw-pyramid/](https://www.ontotext.com/knowledgehub/fundamentals/dikw-pyramid/)

Side note in the course we don't need to difientuate Knowledge and Wisdom.

Data to Infomation

So if I have a DOB field with a date of birth is this data or information. Is an atomic data item with a name/label data or information.  Some places seem to be indicating 'labelling' the data makes it information.  In other places, this example was also given and the labelled DOB field on its own was considered data.  To give it context (the DOB label not counting) you need a context like a person.  It becomes information when the DOB field/content is associated with a person (this is the context).

So another way of asking this is done do RDBMS tables contain Data or Infomation.  Should it really be called a Relational Info-base Management System (RIBMS).  Is a name field with the name Data or Infomation.

Infomation to Knolage

This gets tricky as to what data/Infomation needs nailing down first.

"" Knowledge thus describes the collected information that is available about a particular fact or a person. The knowledge of this situation makes it possible to make informed decisions and solve problems. "" https://www.artegic.com/blog/difference-data-information-knowledge/

This seems consistent with the idea of data labelled DOB being Information. It says a particular fact. DOB could be considered a fact and can be used to make a decision. I.e. to contact them about an offer applicable to people under 30. Or does the fact I need other information, like contact details, to actually implement the decision mean DOB alone is not Infomation.

Be good if someone could help me understand this. The literature seems very light on examples.",2022-01-26 18:47:44
Best way to find data science startups,29,sd8dfn,https://www.reddit.com/r/datascience/comments/sd8dfn/best_way_to_find_data_science_startups/,32,1643210468.0,"Looking for a way to find a bunch of data science startups. I'm trying to find a job to fill awkward gap between now and when I start grad school next fall. I've contacting startups is generally the easiest way to get the kinda interesting, remote, short term, relatively low barrier to entry mathematical modeling/AI jobs I'm looking for, but i've sort off tapped out the startups in my local area. What might be the best way to find some more?",2022-01-26 17:21:08
Meta,114,sd83sb,https://www.reddit.com/r/datascience/comments/sd83sb/meta/,96,1643209744.0,With all the propaganda going on with Facebook the past few months do you think FB still has its same reputation when it comes to working there? If you work for them now will other companies see that as a red flag? I know in the past if you worked at FB you could transfer easily to other FAANG companies. Wondering if that’s not the case anymore…,2022-01-26 17:09:04
"How to quickly predict a stationary, seasonal dataset?",9,sd7qqu,https://www.reddit.com/r/datascience/comments/sd7qqu/how_to_quickly_predict_a_stationary_seasonal/,3,1643208796.0,"Basically I have daily climate data with temperature (so very cyclical, stationary, seasonal - should be easy to predict) and I want a generalized way to predict this dataset into the future (but only a few years into the future). 

In essence, I want to be able to take any temperature series for any lat/long from this dataset and quickly make a prediction x days into the future. 

In the past, time wasn't of the essence, so I used SARIMA, which provided very accurate forecasting, but now, because of the new objective I have, the runtime of SARIMA is far too prohibitive. 

In reality, doing something like taking the last 10 7-day SMAs, each 1\*365, 2\*365, ..., 10\*365 into the past within the dataset and averaging them out would be a suitable way to do quick somewhat accurate prediction given that its simply temperature data, but I am perhaps looking for something a bit more ""datascience""y and generalized. 

Thank you for pointing me in the right direction or any help",2022-01-26 16:53:16
Is data science immoral?,0,sd6fu8,https://www.reddit.com/r/datascience/comments/sd6fu8/is_data_science_immoral/,88,1643205098.0,"Right now I'm a student in AI and I really want to work in a data science field. But as of late I began to doubt the morality of data science. It feels like the technology is mostly being used by the biggest companies just to get even bigger. Is data science just being used to help FANG (MANG?) companies get more money and gain more power in the world? Do we really want that? Sometimes I feel like quitting the field just so I won't have any part of it. 

How do you guys feel about this?",2022-01-26 15:51:38
Tabplot visualization in Python / tableplot,2,sd2pgn,https://www.reddit.com/r/datascience/comments/sd2pgn/tabplot_visualization_in_python_tableplot/,1,1643192031.0,Does anyone know how to create a tabplot vis in python? they look like the following : [https://mran.microsoft.com/snapshot/2016-08-08/web/packages/tabplot/vignettes/tabplot-vignette.html](https://mran.microsoft.com/snapshot/2016-08-08/web/packages/tabplot/vignettes/tabplot-vignette.html),2022-01-26 12:13:51
How Statistics is Taught at University,69,scvph7,https://www.reddit.com/r/datascience/comments/scvph7/how_statistics_is_taught_at_university/,49,1643166513.0,"Having read a couple of posts on here lately, there seems to be criticism in how statistics is taught at the undergraduate level.

I currently work full-time as a data analyst, while completing the undergrad statistics curriculum at a local university part-time. I pretty much have all the prerequisites to start the actual statistics and probability courses. From my conversations with fellow classmates and looking through previous course notes, there is a **huge** emphasis on computation in the 2nd and 3rd year courses.

Oddly enough, many of the 4th year courses in mathematical statistics and probability are cross-listed with their graduate level counterpart. Probably because they're more proof-based.

1. Is this/why is this ... rite of passage normal? 
2. Is there anything I should be doing? 
3. Part of me feels I will be wasting my time.

Edit: When I say ""computation"", I don't mean programming, but rather ""memorize formula, plug in numbers, get output"" akin to high school mathematics.",2022-01-26 05:08:33
¿Is there something like Data Scientists streamers?,1,sctn7z,https://www.reddit.com/r/datascience/comments/sctn7z/is_there_something_like_data_scientists_streamers/,10,1643160504.0,"I want to see more experienced data scientists approach machine learning projects/ problems, see how is their workflow. I'm studying to become a data scientist, so I thought that maybe seeing others how they work can be helpful for me.",2022-01-26 03:28:24
How to predict users' satisfaction on products such as clothes?,2,sct5b7,https://www.reddit.com/r/datascience/comments/sct5b7/how_to_predict_users_satisfaction_on_products/,5,1643159070.0,"I don't have a background in data science, but I came across a project recently to design a model to predict user satisfaction of clothes based on very noisy and subjective data.

Currently, our data involves 500 samples, with each sample has:

（1） 3D geometry scan of the person (height, weight,  width of shoulders, and any other info about the body shape) 

（2） questionaire about gender, age, sports and exercise routine，etc

We provide 10 different designs of clothes (color is not important, only size and shape matters) to them, and ask them to assign a satisfaction score (0\~100)  to these clothes.

The target is to train a model to predict which cloth can lead to highest satisfaction level to a particular customer based on (1) and (2), before he/she really tried on the cloth. Like a recommendation system.

I first formulated this as a classification problem， and tried a small deep learning network，but the prediction performance is really really bad. So I guess maybe neural networks are not suitable for such noisy data.  Could someone provide some guidance on how to solve such a problem?",2022-01-26 03:04:30
R Package for Multivariate Continuous Propensity Scores,23,scrpz4,https://www.reddit.com/r/datascience/comments/scrpz4/r_package_for_multivariate_continuous_propensity/,1,1643155137.0,"This could be useful if you're in a situation where you have multiple continuous (potentially correlated) treatments! Here's the vignette: https://cran.r-project.org/web/packages/mvGPS/vignettes/mvGPS-intro.html

Package description: ""Methods for estimating and utilizing the multivariate generalized propensity score (mvGPS) for multiple continuous exposures described in Williams, J.R, and Crespi, C.M. (2020) (https://arxiv.org/abs/2008.13767). The methods allow estimation of a dose-response surface relating the joint distribution of multiple continuous exposure variables to an outcome. Weights are constructed assuming a multivariate normal density for the marginal and conditional distribution of exposures given a set of confounders. Confounders can be different for different exposure variables. The weights are designed to achieve balance across all exposure dimensions and can be used to estimate dose-response surfaces.""",2022-01-26 01:58:57
[UPDATE] First job offer: great role but lots of red flags,146,scjx0i,https://www.reddit.com/r/datascience/comments/scjx0i/update_first_job_offer_great_role_but_lots_of_red/,18,1643134131.0,"I (22F) was offered a DS job with lots of red flags, some were considered real red flags and some were not...
[You can see the debate here ](https://www.reddit.com/r/datascience/comments/sbabat/first_job_offer_great_role_but_lots_of_red_flags/?utm_medium=android_app&utm_source=share)

First of all, is not that the previous post blew up that much but I appreciate your time and wanted to update you kind strangers ! 

I declined the DS offer and accepted the other one, there will be plenty of time for me to find a job in DS without having to sacrifice my mental health. 

Good news is... I got my first job !!!! So excited

Thank you all for sharing your experiences and giving me your adivice and support ! Definetely feeling more prepared for my future interviews.",2022-01-25 20:08:51
Hot Take: Scikit-learn,0,scjp82,https://www.reddit.com/r/datascience/comments/scjp82/hot_take_scikitlearn/,34,1643133599.0,"I got quite a few questions and comments regarding my hot take #3 in the hot takes thread yesterday, so I figured this might be good time to open up a discussion thread on the topic to clarify my position and invite others to chime in.

Hot take in question: ""Sklearn is a garbage library and shouldn't be used in a professional setting.""

I feel like I should start by saying that my take might have been a bit strong. Garbage might not have been the best word to describe the entirety of the package, and it does have a few uses in a professional setting - namely the pipeline and data transformation functions. That being said, I have some issues with sklearn.

Sklearn is, as the developers put it, ""[a machine learning package](https://twitter.com/hug_nicolas/status/1167508365083369478?s=20)"". When they say it is a machine learning package, they really mean they don't care one iota about anything besides predictive accuracy. This attitude is manifested in issues like logistic regression being regularized by default, because who cares about pesky things like your parameter estimates or colinear features so long as you're getting good predictive accuracy on your test set. Never mind that colinear features might cause your model performance to fall off a cliff the moment the underlying data distribution changes, or heaven forbid if you want to do any sort of hypothesis testing. Heck they don't even give you a way to see a model summary, because after all RSME is king and we don't care about peons like p-values. In the [immortal words](https://old.reddit.com/r/datascience/comments/fotjm9/statsmodels_vs_sklearn_for_the_linear_models/flhe2zo/) of /u/unsteady_panda, ""SKLearn is fine if you want to yolo some predictions and call it a day"".

From a technical standpoint, sklearn also has some scale issues with dealing with larger datasets that make it not incredibly well suited for #bigdata.

Then again, maybe this is all just a big ""get off my lawn"" opinion and I need to step down from my soapbox. I would love to hear everyone's thoughts on this!",2022-01-25 19:59:59
Should I push for a title that more accurately reflects what I do?,3,scifue,https://www.reddit.com/r/datascience/comments/scifue/should_i_push_for_a_title_that_more_accurately/,8,1643130294.0,"Going to keep this short and to the point. I have 6 years of experience and my current title is Data Management Analyst. The vast majority of my work is building ETLs to bring the data into our Data warehouse and data marts, and administering said DW and DMs. 

From what I can tell, this work would be classified as that of a Data Engineer.

From a career perspective, should I push my manager and HR to change my title so it more accurately reflects what I actually do?",2022-01-25 19:04:54
"Need a recommendation for a user-friendly, fast tool for displaying slick looking stats like in this image. The less complex the better. Thanks for your help!",82,schhvn,https://i.redd.it/h12wy06w0vd81.jpg,30,1643127772.0,,2022-01-25 18:22:52
Am I underpaid?,127,scfife,https://www.reddit.com/r/datascience/comments/scfife/am_i_underpaid/,107,1643122412.0,"Hello everybody!

In May I will receive my Master’s Degree in medical data science (sounds specific but has been very broad). With that, I’ve been looking at my compensation. I am a product data analyst for a medium-sized healthcare software company (2,000 employees) based remotely in UT (MCOL). I have been in this role for 1 year, and my former role was in the medical device realm. 

Total compensation: $77k salary with 5% bonus target. 

Day to day: designing lots of reporting frameworks for product offerings. 80% SQL and Python data manipulation and 20% visualization in Tableau. 

I have been wanting to pivot out of healthcare into more mainstream technology, and have a referral at (Meta) that is willing to refer me to their data analyst or scientist positions. After looking into these positions, it seems like many of their positions start at ~150k +equity +bonus. 

My questions are these:
1. Should I be able to get more than my current salary given my experience and education?
2. How realistic is it for me to be able to get a position at Meta? Or other mainstream tech?",2022-01-25 16:53:32
What does building scalable models mean to you?,2,sbzxj4,https://www.reddit.com/r/datascience/comments/sbzxj4/what_does_building_scalable_models_mean_to_you/,9,1643067332.0,"I'm fairly new to the field of data science and I've seen a few job postings where they ask for people that have experience building scalable data science models.

What does scalable data science models mean to you all?  Building models on large data sets?  Automating a model selection procedure?  Something totally different?",2022-01-25 01:35:32
Who creates the ML Models? Data Scientists or ML Engineers? [D],9,sbtdty,https://www.reddit.com/r/datascience/comments/sbtdty/who_creates_the_ml_models_data_scientists_or_ml/,23,1643050343.0,"Who creates or trains the preliminary models like xgboost, random forest, etc? I used to think ML engineers did that but was told by an ML engineer that the Data scientists at his company create the models & then he gets them ready for production. Is this typically the case or does it depend on the company?",2022-01-24 20:52:23
What tools do you use to report your findings for your non tech savvy peers?,3,sbpha6,https://www.reddit.com/r/datascience/comments/sbpha6/what_tools_do_you_use_to_report_your_findings_for/,26,1643040202.0,,2022-01-24 18:03:22
How to improve a model with high training accuracy but lower testing accuracy?,1,sbp8hn,https://www.reddit.com/r/datascience/comments/sbp8hn/how_to_improve_a_model_with_high_training/,12,1643039578.0,"I have a deep learning model which has high training accuracy(100 %) but very low testing accuracy (10%). How can I improve this model?

 I read somewhere that our model gets low testing accuracy because of under fitting.  I tried to remove excess neurons from layers but it causes both training and testing accuracy to decrease. I then add regularization such as dropouts and batch normalization but noting improved. I also trained it for more epochs.

Do you have any suggestion or ideas to improve such neural network models?",2022-01-24 17:52:58
Whats Your Data Science Hot Take?,556,sbnq4f,https://www.reddit.com/r/datascience/comments/sbnq4f/whats_your_data_science_hot_take/,514,1643035324.0,"Mastering excel is necessary for 99% of data scientists working in industry. 

Whats yours? 

*sorts by controversial*",2022-01-24 16:42:04
Is my job normal or am I just working in a startup?,86,sbm0sj,https://www.reddit.com/r/datascience/comments/sbm0sj/is_my_job_normal_or_am_i_just_working_in_a_startup/,47,1643030289.0,"I'm working in data role (mainly Analytics) at a small/mid-sized FinTech firm. It's pretty much a well established startup. This is my first job out of college and I've only been here for six months or so but I'm starting to really dislike it.

Every day, I have to get up at 8 for a 10 AM call to manually create this Excel tracker we use to track the Sales team's performance. I would love to automate it and create a dashboard of sorts but here comes the major problem I'm facing in my job. All the other work I have to complete is always urgent and the deadlines are always the end of the day or the first half of the next day. You can't take two days to complete anything and given this, I don't have the time to even take up other tasks like automating that ridiculous tracker. Now the tasks itself aren't very difficult but I don't get the time to actually understand what I'm doing or even problem solve when there's an issue. It's so fast paced and I'm not sure if this is my working style. 

I'm just pulling data and if I'm doing any analysis, it's always rushed and I don't feel like I'm learning. I think the timelines that are set by my manager and their managers seem reasonable only if we weren't working on anything else. But when you're getting tasks from multiple people, things tend to spiral. 

My biggest question is if all jobs in Analytics/Data Science are this fast-paced and expect results/insights so soon? I'd just like to understand if this is what I should be expecting in the future or if this is just the result of me being an entry-level professional and also working in a startup culture.",2022-01-24 15:18:09
Are vendor certifications useful for higher level jobs?,7,sbcmxq,https://www.reddit.com/r/datascience/comments/sbcmxq/are_vendor_certifications_useful_for_higher_level/,4,1642996482.0,"I run the data science department at a corporation. I was interviewing for a VP job at a big tech company and was asked about my specific experience with cloud providers. I said something like, ""We've made a number of acquisitions, so our services are split between on-prem, AWS, and Azure."" The question made me wonder if there's an advantage to getting certifications in AWS or other technologies at a higher career level. Being able to answer, ""I'm an AWS Certified Sergeant and an Azure Lieutenant"" would have been a clearer response. The blogs only answer the question for entry-level jobs.",2022-01-24 05:54:42
First job offer: great role but lots of red flags,127,sbabat,https://www.reddit.com/r/datascience/comments/sbabat/first_job_offer_great_role_but_lots_of_red_flags/,116,1642989521.0,"I'm (22F) going to work part-time on my last year (hopefully) of Computer Engineering. 

A start-up offered me an internship as a Data Scientist. Which is great cause I'm passionate about AI, my thesis uses AI, and I wanna do a PhD in Data Science

The thing is my gut is telling me not to accept the job... 
I need to know if the things I consider red flags are actually red flags or i'm being paranoid, I don't have any experience in this cause it's my first job. 

🚩1. the interview process took way too long. I applied on Dec 20th, had my first interview on Jan 4th, they ghosted me for two weeks so I asked if there were any news and a couple of days later they scheduled a second interview where they offered me the job. 
[EDIT] let's just blame the holidays and start-ups lack of organization. 

🚩2. The second interview was supposed to be a technical interview, but they just made me an offer instead of asking me questions. 

🚩3. They offered me a salary for less than I was expecting, I told them that and they offered me just a bit more (still less than other companies offered me but for a Full-Stack dev position) after telling me ""they don't have much money"". And they did not offer me anything else... 

🚩4. I asked them if they give their employees a notebook with the necessary specs (my notebook can't run neural networks and it's pretty common for companies to give their employees what they need to do the job, especially being a 100%remote job)... they said no but that it can be negotiated after a few months if I renew my contract. 

🚩5. They told me numerous times to prioritize learning over money. Like... dude, i'm still learning in college, I need money. 

I don't know what to do. I really LOVE the role. 

Thanks kind stranger

[EDIT] 

•numbered flags so you can reference ! 

•I've got another offer: more money, Full-Stack dev position, not a big company but it doesn't seem like a high risk, BUT not DS related

•CTO interviewed me always, giving me douchebag vibes, he'll be on my team.

•Need money to pay for my education this year.

•College already stresses me out way too much, don't want to add more stress and I really need to focus cause I need to graduate this year


[[FOLLOW-UP]](https://www.reddit.com/r/datascience/comments/scjx0i/update_first_job_offer_great_role_but_lots_of_red/?utm_medium=android_app&utm_source=share)",2022-01-24 03:58:41
[D] Subject bias in NLP?,4,sazk2f,https://www.reddit.com/r/datascience/comments/sazk2f/d_subject_bias_in_nlp/,5,1642960888.0,"Subject bias: When a trained model used in sentiment analysis gives bias results on un-learned data due to the subject in question having a learned-weight attached to it in your model.

For example, let's say we train a model to understand movies reviews. If Leonardo DiCaprio appears in many positive movie reviews, will his name contribute as a positive feature in general? This could be an issue for when we move on to use our model to evaluate other reviews. Would reviews that contain Leo's name in them have a positive bias since the model has learned from so many positive examples that he's been in (even if the comment itself says the movie is trash)?

I've just coined this term myself because I'm having a difficult time finding answers to it, but if someone else has already considered this, please point me in their direction.",2022-01-23 20:01:28
Advice for new data science team,146,saykfh,https://www.reddit.com/r/datascience/comments/saykfh/advice_for_new_data_science_team/,78,1642958401.0,"I was hired on as a data scientist at a mid-sized company. It's a small team and my boss was quickly promoted from a DS associate to manager to director within two years. His background is in data analytics (red flags... I know). He has immense business knowledge, but he admits his DS knowledge is limited and ""that's why he hired me"". He doesn't use Python or SQL.

For example, he has built almost all of our business logic transformative into tableau. Me and my other colleagues who use Python can't access that business logic from our redshift database. In fact, our database has very poor practices as well; it's essentially just a route data goes through to get to the end product: tableau, flask api and dash app. We're not using dbt and I'm the only one writing SQL queries.

Considering the ""data science hierarchy of needs"", we have a very strong team on the analytics side, but we have no data engineers (not one). Our team only uses jupyter notebooks and tableau (except for me). Our data pipelines and architecture is a mess. I identified this immediately, stepped in and started managing them (partially to gain experience for ML engineering). Previously, this was managed by the DevOps team.

Our CTO wants us to continue growing our team and we have multiple DS positions open. My boss recently asked me if it would make sense to hire more entry level employees or senior. I explained to him that regardless, we need data engineers. He explained that if we needed that, we could just have DevOps go back to managing our data infrastructure and pipelines. We have an innovative and mature software engineering team and DevOps is primarily focused on supporting them for CI/CD. We are the only team using redshift and the data science stack..

I'm hoping for some advice. Is it normal for a DevOps team to be involved in data engineering, architecture and database management for the data science team? It just seems to me that the data science team should own this because we are the only ones using it. I fear that the reason my boss doesn't want to manage it is because he literally doesn't understand it. Wouldn't it be wise to invest in data engineering as it's the foundation of DS? Any advise for convincing my boss to invest in data engineering over more data scientist?

TL;DR
My boss (director of data science) has an analyst background and doesn't know best practices for data engineering, architecture and database management. Is it normal for DevOps to own this? How can I convince him that we need to invest in data engineering on our team and own this process?",2022-01-23 19:20:01
Weekly Entering & Transitioning Thread | 23 Jan 2022 - 30 Jan 2022,33,sas6a4,https://www.reddit.com/r/datascience/comments/sas6a4/weekly_entering_transitioning_thread_23_jan_2022/,224,1642939231.0,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",2022-01-23 14:00:31
Py IDE that feels/acts similar to Jupyter?,7,saak7e,https://www.reddit.com/r/datascience/comments/saak7e/py_ide_that_feelsacts_similar_to_jupyter/,36,1642881184.0,"Problem: I create my stuff in Jupyter Notebooks/Lab. Then when I needs to be deployed by eng, I convert to .py. But when things ultimately need to be revised/fixed because of new requirements/columns, etc. (not errors), I find it’s much less straightforward to quickly diagnose/test/revise in a .py file. 

Two reasons: 

a) I LOVE cells. They’re just so easy to drag/drop/copy/paste and do whatever you need with them. Running a cell without having to highlight the specific lines (like most IDEs) saves hella time.

b) Or maybe I’m just using the wrong IDEs? Mainly it’s been Spyder via Anaconda. Pycharm looks interesting but not free.

Frequently I just convert the .py back to .ipynb and revise it that way. But with each conversion back and forth, stuff like annotations get lost along the way. 

tldr: Looking for suggestions on a .py IDE that feels/functions similarly to .ipynb.",2022-01-22 21:53:04
"Omg, switched from data science to data analysis and ended up in a team that does everything manually in Excel :o",734,s9zcyq,https://www.reddit.com/r/datascience/comments/s9zcyq/omg_switched_from_data_science_to_data_analysis/,252,1642846090.0,"Watching their tutorials is utterly excruciating.

I either regress to Excel monkey or have to push for Python.

Anybody can relate?",2022-01-22 12:08:10
Data science processes and the softwares used for them.,1,s9x530,https://www.reddit.com/r/datascience/comments/s9x530/data_science_processes_and_the_softwares_used_for/,3,1642836886.0,"I have been trying to understand data science processes and the tools used to execute those processes, can anyone tell me what are the tools that are used for the below processes? 

1. Data scrapping.
_?? 
2. Data cleaning.
_?? 
3. Data storage.
_ cloud storage, aws, __?? 
4. Data modelling.
_?? 
5. Data visualisation.
_ Tableu, wrapper, __??

Very thanks,
really appreciate it.",2022-01-22 09:34:46
Why data analysts/data scientists cannot analyze?,0,s9vhvn,https://www.reddit.com/r/datascience/comments/s9vhvn/why_data_analystsdata_scientists_cannot_analyze/,29,1642830671.0,"Within my company, all the data analysts cannot do good quality analyses that lead to actionable insights. They are all really good at building dashboards but have difficulty delivering analysis beyond surface level.

Is this just because of the saturation of the labor market when data science was such a hot field or my company just hires very poorly?",2022-01-22 07:51:11
modeling cyclical time series processes,4,s9p26x,https://www.reddit.com/r/datascience/comments/s9p26x/modeling_cyclical_time_series_processes/,3,1642810223.0,"Hello,

I am interested in creating graphs of stochastic processes with either python or R, but not really sure how. The resources I'm finding appear to be using pre-existing datasets to construct the time series graphs. I want to do it with functions. 

e.g., 

Yt=a\*cos(t)+b\*sin(t), t =1 ,..., T,

where a and b are two uncorrelated random variables with mean zero and common variance. 

Yes, this particular process is from a problem set, but the question is not to create a graph, I just think it would be useful to see what these processes look like.

I would imagine it would involve using a random number generator function, but not sure the proper way to do this.",2022-01-22 02:10:23
Data steward daily or routine activities?,1,s9owa5,https://www.reddit.com/r/datascience/comments/s9owa5/data_steward_daily_or_routine_activities/,0,1642809740.0,"I am curious what data stewards at other companies are doing on a regular basis compared to my company. Any body want to share what tools, programs, etc. they use as a steward? My company doesn’t know how many stewards per region they want and if they should be new hires or just appoint current employees to become stewards. 

We use Informatica at the moment and I believe we will add another tool to store any bug/issue tickets that our Stewards need to report or log.",2022-01-22 02:02:20
Danish government makes its new economic model open source,215,s9mqij,https://github.com/DREAM-DK/MAKRO,6,1642803881.0,,2022-01-22 00:24:41
How do Data Engineer salaries compare to general SWE salaries at top tech companies?,0,s9md2e,https://www.reddit.com/r/datascience/comments/s9md2e/how_do_data_engineer_salaries_compare_to_general/,1,1642802907.0,"I made a post asking why data science salaries were lower than general than SWE according to levels.FYI, but what about data engineers? Levels.FYI doesn’t have a specific data engineer salary, just a data science category",2022-01-22 00:08:27
Great tool! Now make it again but worse.,7,s9lx4z,https://www.reddit.com/r/datascience/comments/s9lx4z/great_tool_now_make_it_again_but_worse/,7,1642801748.0,"Just a quick vent. I work in healthcare, building tools to help doctors evaluate utilization, patient outcomes, etc. So I build this report that explores a new potential metric.. how much is spent on the procedure group by different cohorts, blah blah. The requester is happy with the results.. but my boss' peer is like ""oh this is awesome, I'd like to use it for %s, but these values are 'hard coded' i.e. there are no formulas."" % his_thing. 

I built the thingy in ipynb with some nice output/viz, but my boss wanted to show the output in excel.. no problem there, but now people think they are able to just hop in and alter stuff.. so I have to re-build the thing in excel but they hope that's not a big lift. 

To be clear.. it is very normal for me to deliver results in the aforementioned format.. we aren't even allowed to provide the underlying data because secrets. All in all not a big deal but just wanted to rant about it.. so thanks for indulging me.",2022-01-21 23:49:08
How do you explain time spent to non-data science supervisors?,7,s9h8il,https://www.reddit.com/r/datascience/comments/s9h8il/how_do_you_explain_time_spent_to_nondata_science/,2,1642789310.0,"It seems like a lot of time spent in data science is reviewing papers and methodology, finding usable data, exploratory analysis, cleaning data, etc. and very little time is actually running models and creating reports. 

How much time do you devote to each project step, and if you spend a lot of time reviewing papers and data, how do you explain to a non-data science supervisor that this is a valuable use of time?",2022-01-21 20:21:50
Having Trouble Understanding What MLE Really Is,5,s9gqin,https://www.reddit.com/r/datascience/comments/s9gqin/having_trouble_understanding_what_mle_really_is/,29,1642788035.0,"Hi everyone. I’m currently an almost-graduated Computer Engineering B.S. wanting to pick up a Masters so that I can learn more about machine learning, artificial intelligence, NLP, data, etc. I really like all this stuff and it seems like a Masters in Data Science is the move if I want to specialize in it—but I don’t want to be a data scientist. I want to still work in engineering software but want to focus more if not completely on data and ML. Is this what MLE is? The reason I’m confused is because Google is telling me so many different things, and it seems like it’s almost more of a DevOps kind of a role? If so, then how would you describe what I’m wanting? Data Engineer? Just wanted to see if anyone here has any insight based on personal experience—I know it’s a relatively simple question but it feels like some personal answers may give me what I’m looking for rather than whatever somewhat ambiguous information I’ve found on Google will give. Thanks!",2022-01-21 20:00:35
Did you get an invite for 40 under 40 Data Scientists??,190,s9boml,https://www.reddit.com/r/datascience/comments/s9boml/did_you_get_an_invite_for_40_under_40_data/,101,1642774523.0,"I had no idea people paid $1500 to be on these lists … I wonder if all the 40 under 40 lists are paid for ? 
What is your opinion of these ? Do you view people on these lists as leaders in the field ?

This is from analytics insight .",2022-01-21 16:15:23
How to incorporate time-series observations as features?,56,s9arrb,https://www.reddit.com/r/datascience/comments/s9arrb/how_to_incorporate_timeseries_observations_as/,34,1642771810.0,"Hi everyone,

I am working on a classification problem based on time-series observations. Theoretically, I expect that each class has a unique time-series distribution even though the distributions might be very similar.

I use the observations as features. I also include the maximum, minimum, variance, skewness values to capture the characteristics of the distribution.

Is there anything else that can be done? Do you have any further suggestions?

Thank you.",2022-01-21 15:30:10
"Do data scientists mostly have a ""supporting"" role in most companies?",21,s99yk5,https://www.reddit.com/r/datascience/comments/s99yk5/do_data_scientists_mostly_have_a_supporting_role/,23,1642769212.0,"I'm trying to understand the role of data scientists in a typical corporate organization. Of course this will depend from company to company, but is my impression correct that typically data scientists have  more of a supporting function than a key role in shaping the company's products?

Now I don't mean this in a negative sense, but when compared to engineers who directly design the products and services, are data scientists typically less involved in shaping a company's direction? Is the role of data scientists more comparable to HR, finance, sales, marketing, etc., or to engineering, R&D, etc.? 

To give a concrete example, suppose someone works as a data scientist at Apple. To what extent does such a person have a direct or indirect influence on the final products (iPhones, iPads, Macs) that come out in the end? For example, a designer/engineer who designed the shape of the corners would have had a much more direct influence on the product IMO than someone working in marketing or finance for instance.",2022-01-21 14:46:52
Team is based in India …red flag or normal?,28,s8ycew,https://www.reddit.com/r/datascience/comments/s8ycew/team_is_based_in_india_red_flag_or_normal/,35,1642728183.0,"Im interviewing for a couple jobs right now and for two of the jobs the managers are located in India and work on Indian time. I’m located in the US with a 13 hour time difference, so essentially I would never have any overlap with them because I would be expected to work normal hours in my time zone.   


Is this the new normal? One company is a FAANG and the other is also a major tech company in SF. It’s just strange to me because I’ve worked with remote teams but typically those teams were all India based instead of having members of the teams in the US, and they would also work adjusted hours so that they had some overlap with the US team unlike these jobs.   


Its just very odd to me and I’m honestly confused why theyre not just hiring someone in India. Is this a red flag? I kind of feel like the job might eventually get outsourced lol",2022-01-21 03:23:03
Data science writer,0,s8wm7c,https://www.reddit.com/r/datascience/comments/s8wm7c/data_science_writer/,1,1642723189.0,"I am not a data scientist, but I write about data science and enterprise-level hardware and software. I love writing about data science. I think it's a fascinating field and it will ultimately help save the world (I hope). I would love to get a job writing for a data science team or company. I am currently interviewing with a data science school, but I need to seek out other opportunities. Does anyone know of any such opportunities? I have about 15 years of writing and editing experience.",2022-01-21 01:59:49
Compelling cases for OR against Object-Oriented design in an ML code engine?,3,s8v96h,https://www.reddit.com/r/datascience/comments/s8v96h/compelling_cases_for_or_against_objectoriented/,6,1642719402.0,"I’m curious to hear opinions on why strict adherence to OOP design practices is either a help or a hindrance in data science development, as compared to more procedural or functional development design.  Please provide concrete examples or external resources where necessary.  Also, please keep examples specific to data science development whenever possible.  

For context, when I say ML engine, I mean a code base that does everything from ETL, to feature engineering, feature selection, model training, model evaluation, production deployment/integration, and data drift detection. We have built such an engine in R, and are in the beginning phases of transitioning it to Python as well.  Im currently putting together our development requirements for that transition, and wanted to gauge opinions on the actual  (as opposed to perceived) value of OOP for DS. 

Thanks",2022-01-21 00:56:42
"What are your thoughts on Gartner and it's ""research"" insights, magic quadrants etc related to DS?",3,s8tdkl,https://www.reddit.com/r/datascience/comments/s8tdkl/what_are_your_thoughts_on_gartner_and_its/,6,1642713935.0,"Hi all,

What are your thoughts on Gartner and it's ""research"" insights, magic quadrants etc related to DS?",2022-01-20 23:25:35
Question on differing statistics,2,s8quso,https://www.reddit.com/r/datascience/comments/s8quso/question_on_differing_statistics/,11,1642706835.0,"So I am currently having to fulfill a project on USA demographics and one of the pieces of information is the statistics of American religious identification. I was researching and found one study from pew research stating 63% Christian while another from Gallup polls and PRRI (public religion research institution) has the number around 70-72%. I am curious what do data scientists usually do when having studies show very different results? Both institutes are reputable and I have taken into account margins or error, pool of participants, and the like? I am not a data scientist and am only doing this research for a class so I was generally curious where to go from two studies having very large differences. Thank you.",2022-01-20 21:27:15
I feel that people are fudging their degrees on LinkedIn and I have mixed feelings about it,251,s8qjvv,https://www.reddit.com/r/datascience/comments/s8qjvv/i_feel_that_people_are_fudging_their_degrees_on/,213,1642706021.0,"I feel that people are fudging their degrees on LinkedIn and I have mixed feelings about it. 

For example, I just stumbled on a research scientist who has an ""MS Statistical Machine Learning @ U Chicago"". U Chicago doesn't offer this degree; they offer an MS Statistics. The degree, as advertised, doesn't exist and U Chicago is a name brand; I can't be the first person to dig into the claim. But I'm sure there was opportunity within the program to specialize in ML, which is fine.  

Another example, an alum from my uni, has a PhD in Business Administration, his concentration was ""information and decision science"", which obviously sounds way cooler. So his LinkedIn PhD is in IDS. 

Anyway, I have mixed feelings on this. In the tight market competition today, I think you owe it to yourself to articulate whatever it was that you focused on in your BS/MS/PhD. In the case of the alum I know, he really did focus on ML, Bayesian stats, etc. So I think it was sensible not to lead w/ Business Administration. 

On the flip side, I think it's really easy to slip into taking credit for coursework you've never taken. For example, a BS in Biology isn't exactly a BS in Biostatistics and if you don't have the stats coursework to back up the claim, you're setting yourself up for expectations that you won't be able to meet. 

What are the community's thoughts on the compromise between ethical self-reporting vs what you need to do to secure to growth opportunities?",2022-01-20 21:13:41
Databricks and Stan,3,s8pprh,https://www.reddit.com/r/datascience/comments/s8pprh/databricks_and_stan/,12,1642703725.0,Does anyone here have experience using Stan on Databricks?  I wonder if I can just install RStan or CmdStanR and be on my way…Thanks,2022-01-20 20:35:25
Good sources for data science papers,6,s8ppjx,https://www.reddit.com/r/datascience/comments/s8ppjx/good_sources_for_data_science_papers/,8,1642703711.0,"I am going to begin reading data science papers for about an hour a day as part of my training.

Journals tend to publish papers on the edges of data science, and aren't particularly useful for someone like me who is still learning.

What I am looking for are projects that walk through all the stages of cleaning, exploring, normalizing and analzying the data, and apply machine learning methods. 

Are there any good sources of such projects/papers?",2022-01-20 20:35:11
What are the basic insight that every data contain?,0,s8odsp,https://www.reddit.com/r/datascience/comments/s8odsp/what_are_the_basic_insight_that_every_data_contain/,6,1642700250.0,,2022-01-20 19:37:30
Applied Stats Resources,17,s8ne96,https://www.reddit.com/r/datascience/comments/s8ne96/applied_stats_resources/,16,1642697650.0,"Over the last couple of months I've been interviewing for Senior Data Scientist roles, everything has been going really well up until any applied statistics questions come up...

I've been a data scientist for about 5 years now, however in my current role I basically use no applied stats so I'm super rusty. I was wondering if anyone could recommend some websites or books for brushing up on this stuff.",2022-01-20 18:54:10
Cold email and LinkedIn texts for an Internship at startups,23,s8it31,https://www.reddit.com/r/datascience/comments/s8it31/cold_email_and_linkedin_texts_for_an_internship/,13,1642684742.0,"Hey all, I am a third-year student currently looking for an internship in Data Science/ML and through this post, I want your thoughts on my approach mentioned in the title. So far, I have made a list of about 80ish companies and I'll look for more once that's exhausted.

My battle plan was to find HR Managers (1) and ML people (2-3) in each company and reach out to them. Initially, I thought I would only cold email and I did, at the start of this week. This was my short mailer:

&#x200B;

Hi Mr. xyz,

My name is xyz and I’m a third-year CSE student at xyz. I am writing to inquire about potential internship opportunities available for Data Science at xyz, where a student such as myself might be able to join for a duration of 6 months with the view to winning a full-time Data position.

I would make a good fit for your company because I have experience in working with fast-changing teams and leading them, built multiple projects in NLP and Recommendations, and I have a knowledge of Python and Java.

I have attached my resume and would love to hear back from you.

Best, XYZ

&#x200B;

However, I had almost zero responses the first couple of days and it was getting difficult to get valid company emails for the people too. So I thought I'd give LinkedIn a try; I mean I have nothing to lose right. So I did send a couple of connection requests to both HRs and ML peeps. This was the short message I sent:

&#x200B;

Hi Sir, I'm interested in the work that xyz does and was wondering if you could spare a few minutes to chat about your experiences working there. If you’re swamped with work or feel someone else is better suited, I would greatly appreciate it if you could point me in the right direction.

&#x200B;

To my surprise, a couple of people did accept my requests and I tried to strike a short convo about how it is there and all, trying to make the ""ask"" in the end. One person said they were just done with the intern hiring but he did take in my resume and told me he'd let me know if anything comes up. I have a call set up with another person this weekend, though I don't have much of an idea what I should do there (any tips?).

What I want to know is your thoughts on this approach and whether something should be added or removed. I think for each company, I'll email the HR and a tech guy while also sending requests to a couple of tech peeps on LinkedIn too. Do you think this is enough and is there anything I should keep in mind while reaching out or talking to them? I should also mention, this is the first time that I'm doing this actively and I had no idea it'd be this exhausting, though the alternative is much worse, getting lost in a pile of resumes on LinkedIn. Any help would be great, thank you!",2022-01-20 15:19:02
Fastest iteration over large dataset in python,1,s8a7qh,https://www.reddit.com/r/datascience/comments/s8a7qh/fastest_iteration_over_large_dataset_in_python/,5,1642653254.0,"What is the fastest way to iterate over large datasets in python , other than numpy?

Any help is appreciated.",2022-01-20 06:34:14
"If you had access to all of Google’s, Facebook’s, or Uber’s data, how would you use it to invest?",5,s87vx0,https://www.reddit.com/r/datascience/comments/s87vx0/if_you_had_access_to_all_of_googles_facebooks_or/,15,1642646277.0,,2022-01-20 04:37:57
Do algorithmic trading projects make you roll your eyes?,195,s87t2d,https://www.reddit.com/r/datascience/comments/s87t2d/do_algorithmic_trading_projects_make_you_roll/,208,1642646026.0,"I have always heard in this sub that personal projects like “sentiment analysis stock price prediction” is considered a very cheesy idea for a personal project and hiring managers find it kinda weak. 

But what if algorithmic trading and quant finance is something your actually interested in, and you like applying statistics to finance. I’m a statistics major and math minor, and I genuinely enjoy time series analysis and econometric financial time series. I do a lot of research on equities and coming up with trading strategies involving creating my own trading signals and going through the whole workflow of data extraction, looking for trading signals, and backtesting.

Often times it involves me reading a research paper online and trying to implement ideas as a inspiration for my own strategy. It involves some ETL, like solving the problem of how to stream real time market data or high quality data, while also allowing me to make trades, and come up with metrics and a dashboard to view my trading strategies. 

I get that these stock projects can be a bit dull for most people since they are so common, but do people really care if it’s something a student is truly passionate about? Ultimately I want to become a data scientist and not a quant, but I find statistical applications to finance really interesting, and the projects are interesting too.


Edit: it seems like there’s some confusion here, I’m not saying I’d make such a project to show up to an interview and say “hey look, I’m a stock trading millionaire and I solved the market, hire me”. Nah, in fact I’d say that this is being paper traded, and not live. I’d also go on to mention that this project was really just a end to end data science project to get me used to the workflow of ETL>analysis>model dev>deployment. Like I said my aim is to do an end to end project in a domain that I find interesting (statistical finance), to highlight the overall workflow of a data science project. I actually read about this stuff in my free time, so doing such a project in this domain would make me more apt to complete the project than to do it in a domain I’m not interested.",2022-01-20 04:33:46
Getting 'closest' training examples for use in model explainability?,1,s83mh1,https://www.reddit.com/r/datascience/comments/s83mh1/getting_closest_training_examples_for_use_in/,1,1642634212.0,"I'm looking into ways to help business folks better understand/trust a classification model output. I am familiar with things like a visual decision tree diagram, feature importance/coefficients etc - but I was also considering fetching examples from the training data that would be most similar to an observation being scored in the test set/production. 

I'm assuming this is straightforward by doing some distance-based clustering or kNN based on the (non-categorical) features of the training examples vs. the new observation. 

Has anyone ever done anything similar or suggest any caveats?",2022-01-20 01:16:52
High Resolution Monitors vs. Old Ones: Is it worth it to upgrade?,0,s83cdv,https://www.reddit.com/r/datascience/comments/s83cdv/high_resolution_monitors_vs_old_ones_is_it_worth/,7,1642633469.0,"I've recently upgraded my computers, but have had the same old monitors forever.   My laptop is a 17"" 2650X1600.    I usually use one or two 24"" externals, but they're just 1920X1200's.    

I see several options that aren't expensive:   a 2560x1440 in 24"" for $199, a 28"" 3840x2160, and so on.

I'm not a gamer, and don't watch videos on my computer often.   Would I find my working day more comfortable and more productive if I upgraded an old monitor?",2022-01-20 01:04:29
When to feel confident about listing sql or power bi or tableau as a skill?,4,s80rpd,https://www.reddit.com/r/datascience/comments/s80rpd/when_to_feel_confident_about_listing_sql_or_power/,6,1642626949.0,"An online course in the past wasn't  enough. I didn't absorb it. (I worked with a database and sas for years) now feeling  outdated. If I watch videos again, then try and make something  without  peeking ? For now I shouldn't  go for a job that lists something  I'm not good in. I wouldn't  feel confident. Of course  all job ads look hard and feeling  down being  out of work with a family to feed",2022-01-19 23:15:49
Bert for Multiclass Transfer Learning?,1,s80gr9,https://www.reddit.com/r/datascience/comments/s80gr9/bert_for_multiclass_transfer_learning/,3,1642626171.0," Has anyone here used BERT for multiclass classification problems?

I want to perform sentiment analysis on opinions but don't want to manually label many thousands of comments so I figured I'd try my hand at using transfer learning with only a few examples (1-2 thousand). I plan to label opinions on a scale of -2 to 2 (-2 being very bad, 0 neural, 2 very good) and was wondering if BERT with some fine-tuning would fit for this project?

I have never done transfer learning or used BERT before but I've heard the hype and wanted some opinions before I dive into it. Also appreciate any recommendations.

Thanks!",2022-01-19 23:02:51
Ever had a recruiter reach back to you after several months of silence after you accepted another offer?,145,s7w37j,https://www.reddit.com/r/datascience/comments/s7w37j/ever_had_a_recruiter_reach_back_to_you_after/,46,1642615098.0,"Been loafing around as a research assistant on a data science project at my alma mater while prepping myself to do a PhD starting next year as this was always my aspiration. The project itself isn't extremely exciting for me, it's a sociology gig, but it might have a significant policy impact when we're done. On the side I'm also working on a publication with a handful of other people, prior to this I was in data science consulting. Started applying for funded PhD positions in september, no answers at all so I started planning to go back to industry as a plan B.

Mostly interested in positions at companys that have a data analyst *and* data science department/titles like my previous place. Maybe I'm weird but this ensures I won't be stuck just making dashboards and doing dataviz which I absolutely loathe. I respect the business value they bring but I'm fundamentally bad at UX / front-end which is a prereq to make great dashboards and facilitate self-service analysis. Better to give this to someone that is good at it and actually enjoys it. Having both usually means the company is at a higher level of maturity than places that just have data science teams.

My previous place was definitely an option too but that was my plan C, I had a wildcard to come back whenever I wanted within a year. My issue with going back is that the scope of their projects is usually something like customer churn, retargeting, customer segmentation, forecasting etc. Once in a blue moon sales reels in something like predictive maintenance but nearly all DS want to be on that project.

Got a reference from someone I worked with in the past for a DS job. This place checked all my (weird) boxes. They also have a lot of NLP/CV projects in their portfolio which is a big plus for me. I asked all my friends in industry that have worked there/collaborated with them, each of them gave the green light. Decided to take the offer and sign the contract, I'll start as soon as my current engagement is over after the summer.

A week after I sign the most interesting PhD position I applied for ,deep learning research specifically graph neural networks, reaches back to me **AFTER 3 MONTHS** of complete silence and says I can have the job. Honestly I'd have preferred the silence or a rejection.

It's been a week and I haven't formally responded yet to their email mostly because I'm a bit annoyed and I'm still assessing my options. I'm not sure what the play is now. I'm pretty sure I could bullshit myself out of the contract I just signed but idk if that's even wise. I'm also unsure of what option will realistically be a better choice for me in the long run. Salary between both PhD and industry are very similar but the growth potential in the latter is a lot better.

What do you guys think?",2022-01-19 19:58:18
[D] Did you also feel that Snorkel's LabelModel is really slow?,0,s7vw57,https://www.reddit.com/r/datascience/comments/s7vw57/d_did_you_also_feel_that_snorkels_labelmodel_is/,6,1642614601.0,Has anyone here used Snorkel AI's LabelModel for automatically labeling text? Have you found it to be super slow?,2022-01-19 19:50:01
Does it make sense for a financial predictive models to use each day in a time series as a model input?,42,s7vmkm,https://www.reddit.com/r/datascience/comments/s7vmkm/does_it_make_sense_for_a_financial_predictive/,44,1642613913.0,"I know ML models can accept any number of inputs but does too many cause issues? I’m considering taking a time series of a key metric and using every daily value as an input instead of 24 hour change, 7 day change, etc. 

So rather than 10 features I will likely have 1000’s. could this cause issues other than a longer runtime? Would the data become overfit?",2022-01-19 19:38:33
Industry,0,s7u24x,https://www.reddit.com/r/datascience/comments/s7u24x/industry/,2,1642609935.0,What industry do you work in? What do you like most and least about the type of work you do?,2022-01-19 18:32:15
How to characterize similar curve shapes,7,s7a5wf,https://www.reddit.com/r/datascience/comments/s7a5wf/how_to_characterize_similar_curve_shapes/,32,1642545859.0,"Hello, so I wanted to turn to this community to ask about a data science question I am grappling with that is requiring me to find some way to group similar looking curves together in a data set. 

I have multiple time series curves occurring at different times. Some curves look like a plateau, some are wavy, and some plateau and then starting waving. What I am trying to do is assign each of these curves a specific ""shape"" score, so that later I can cluster scores that are close together. The big confusion here, is what characterizes the shape of a curve so that similar looking curves will have a similar score compared to non-similar looking curves. At first this may seem silly, but can be quite tricky to answer when you really think about it.

Ok, so what can characterize the shape of a curve... The number of peaks and valleys, the average value of the curve, the length of the curve, hmmm...

But then you get into weirder territory. I want plateau-shaped curve to be matched to the other plateau-shaped curve, but what if one plateau is much longer than the other? Or another example, I want this wavy curve to receive a shape score close the other wavy curve. However, even though both curves are wavy, one curve has 4 waves, and the other goes on for 10 waves. I want them to be receive close shape scores, but how would they actually be identified to be the same shape?

And so I wanted to ask here if there are any specific strategies I might use to group these similarly shaped curves together. Specifically what I had in mind was some sort of function that could assign some sort of ""shape"" score to each curve, so that similarly shaped curves have close scores, and scores that are far away in value from curves that look much different. I know this is not a language-specific subreddit here, but I am hoping to work in python, since that is the language I am actually comfortable in. Would anyone perhaps have any experience with this? I would be interested in hearing how folks think I might best approach this task. Thank you!",2022-01-19 00:44:19
Custom loss functions for conventional machine learning,1,s788ll,https://www.reddit.com/r/datascience/comments/s788ll/custom_loss_functions_for_conventional_machine/,6,1642540873.0,"Hello All, 

I want to write a custom loss function for decision errors not prediction errors. What resources can I use write my loss functions. I don’t want to write my models from scratch. 

I saw that u can do it in keras or pytorch but i think thats more neural networks

Is it possible to make a custom loss function in sklearn?


Thank you all",2022-01-18 23:21:13
Forecasting different time series as part of your service,3,s75jqy,https://www.reddit.com/r/datascience/comments/s75jqy/forecasting_different_time_series_as_part_of_your/,7,1642533946.0,"There is currently quite an ambitious part of my project where ideally I am able to forecast business-related metrics (like revenue, number of purchases, churned out users, etc) for different businesses. 

Those might have rather different datasets in terms of size and features so it's not the case where I can do clever feature engineering and optimize for one client. 

Have you ever had to deal with such a case? Currently, my default approach is Facebook Prophet which is good enough for at least the current rather limited set of metrics. 

Using more sophisticated approaches like those involving neural networks seems like overkill especially given that there are supposed to be numerous models. 

What approach would you consider in such a scenario?  Another candidate I can immediately think of is just using XGBoost/LightGBM and generating enough lagged and rolling features, as well as extracting as much information from timestamps as possible (by the way, all the forecasts are made on a daily basis).",2022-01-18 21:25:46
What does advanced analytics refer to?,3,s73ban,https://www.reddit.com/r/datascience/comments/s73ban/what_does_advanced_analytics_refer_to/,12,1642528267.0,"Have seen this title popping up more, often in a marketing related role. Is this title usually more like a data analyst or data scientist position?",2022-01-18 19:51:07
UK - more and more badly paid jobs?,41,s72y8e,https://www.reddit.com/r/datascience/comments/s72y8e/uk_more_and_more_badly_paid_jobs/,30,1642527324.0,"Been looking for jobs on LinkedIn now and then. Somewhat shocked at the advertised salary range

I came across one ridiculous one that asked not just for 3-5yrs experience (as an actual data scientist), but also domain specific knowledge from either an MSc or work experience... PhD in said domain is ok in absence of 5yrs work experience lolololol

Minimum requirements,  proven experience applying advanced statistical models/ML/AI to solve big data problems, in depth understanding of machine learning algorithms and ability to write and maintain clean code in Python to process big datasets (pretty much covered in the first point but whatever), not essential but ideal - domain experience working with satellite data etc
 
Personal characteristics, they need to see leadership skillzzz, exceptional work ethic etc etc

Your reward for this is £40-55k pa, prorata of course, because it's a 9mth FTC...but if you do really great they'll consider hiring you permanently

anyway, this was one of the extremes. I've seen plenty others that are comparable. I'm wondering, is the saturated market of underqualified 'data scientists' having a knock on effect on wages? Perhaps too much free money that's gone into funding MSc tuition fees and recruiters thinking they can offer these ludicrous positions?

Bizarrely the salary was included on the post as if it's a generous one

What's your experience been?",2022-01-18 19:35:24
Modelling Network Effects? ABMs or Coupled DEs or Network Optimisation?,2,s716t5,https://www.reddit.com/r/datascience/comments/s716t5/modelling_network_effects_abms_or_coupled_des_or/,4,1642522735.0,"Background: I am a DS in a ride hailing company (think Uber, but local) with a background in Operations Research. Our marketplace matches customers (demand) with drivers (supply). I work in the pricing team, aiming to develop pricing algorithms that optimize for customer experience and marketplace health simultaneously.

 I'd like to know what effect my pricing action at time T leads to in the whole network at later time, and in retrospect, if there was anything better that we could have done. (Optimal pricing strategy given demand and supply, with cascading network effects)

I understand I need to in some way model the supply demand dynamics of the network in some city. How might I go about it? 

Is Agent Based Modelling something to look into? Or maybe system dynamics modelling using coupled differential equations? I understand these are two sides of the same coin. 

Also, if I do have a network model of my system, I can simulate various pricing strategies (and interactions between them) and attribute them to change in business KPIs. Currently, it is very hard to attribute this to a specific pricing strategy, mostly because of confounding. 

I can't help but feel a bit lost here, any pointers would greatly help.",2022-01-18 18:18:55
Watch out for the company MetaSense INC,52,s6y1ax,https://www.reddit.com/r/datascience/comments/s6y1ax/watch_out_for_the_company_metasense_inc/,14,1642513994.0,"Just applied to them and got this email after being shortlisted. It was for a lead programmer. Now it has changed to a personal assistant.....

Just a heads up to anyone.",2022-01-18 15:53:14
[Q] Can’t find the confidence and prediction intervals for predicted values obtained with a nonlinear model,0,s6xtae,https://www.reddit.com/r/datascience/comments/s6xtae/q_cant_find_the_confidence_and_prediction/,1,1642513324.0,"Software is R. Basically, I’m predicting values with two models, one linear and the other one non linear.
If I type:
> predict(linear_model, newdata = predict_data, interval = “confidence”)

and

> predict(linear_model, newdata = predict_data, interval = “prediction”)

it gives me the predicted values with the linear model, however the same code with the nonlinear model instead of the linear one, only gives me the prediction without the confidence intervals and the prediction intervals.
Is there a way to solve this?",2022-01-18 15:42:04
Where to learn non-technical skills?,10,s6wqb7,https://www.reddit.com/r/datascience/comments/s6wqb7/where_to_learn_nontechnical_skills/,18,1642510002.0,"I have been a intern in DA for 4 months now, and had my first 1:1 meeting with my manager where we basically talked about how I am feeling in the company, if I am happy with what I am learning and asked for feedback on him and our team.

He likes how I work, said that the team likes me and that I have the mindset he expected when he hired me.

However, he gave me one negative feedback, my **communication**. 

He said that sometimes he can't understand my ideas well, because I speak too fast or speak in a confusing way.

With this being said, and generalizing the question a bit more, where can I learn how to improve these essential DS/DA skills, which are *non-technical skills*? 

* **Communication** 
* **Being able to summarize 1 hour of meeting with a client in topics of what to solve**
* **Problem solving**

Please avoid answers like ""*Keep doing what you are doing and you will learn a lot*"".

 I know, I'm improving a lot, but I want to improve **even more** hahahaha

**TL;DR**: I received negative feedback from my manager about my communication and now I want to improve my non-technical skills. Any advice?",2022-01-18 14:46:42
Scraping LinkedIn data,7,s6we8q,https://www.reddit.com/r/datascience/comments/s6we8q/scraping_linkedin_data/,7,1642508885.0,"Currently developing a project for university. Let's say I have a list of LinkedIn profile URLs (in the thousands), and I want to narrow them down into a list of people who might be interested in a hypothetical service offering. Would it be possible to scrape their profiles for specific keywords that may indicate interest on their end (mostly from their ""About"" and ""Experience"" profile sections), without making LinkedIn angry (blacklisting your IP address)?",2022-01-18 14:28:05
Where to start Recommender Systems?,2,s6qqyh,https://www.reddit.com/r/datascience/comments/s6qqyh/where_to_start_recommender_systems/,1,1642487126.0,Hi guys my company needs me to about  learn recommender systems. Can you suggest me some articles or courses where the code is in pytorch or scikit libraries. I went through Google's course on their website  but the code was like super clear for me and also it was pretty basic. So yeah,2022-01-18 08:25:26
"Is this '...' standard way of giving path value? I have seen on Kaggle, but when I replicate, I get error.",0,s6pkpw,https://i.redd.it/h800d6i4sdc81.png,5,1642483191.0,,2022-01-18 07:19:51
Opinions on xarray?,5,s6oabd,https://www.reddit.com/r/datascience/comments/s6oabd/opinions_on_xarray/,3,1642479197.0,"I’m told that xarray is much more efficient to work with (especially in cases of big data or scientific disciplines), but converting numpy to xarray is a fucking pain in the ass…

Anyone have thoughts on xarray?",2022-01-18 06:13:17
Interview Presentation,4,s6nskl,https://www.reddit.com/r/datascience/comments/s6nskl/interview_presentation/,4,1642477727.0,"I’m interviewing with a few different companies right now, some of which have required a take-home assignment and/or presentations during the “on-site” interview stage. When a company has both steps, it makes sense to have the presentation be about the take-home. However, one organization just wants the presentation. I’m fairly limited in presenting detailed content from any of my recent projects at my current employer due to privacy. That leaves me with few options for meaningful projects to present on. What are people’s thoughts of using a different organization’s take-home assignment as my presentation? I feel a little weird about it, but it’s possibly more relevant than my current work and can be detailed enough to suffice.",2022-01-18 05:48:47
"Concurrent work on a single dataset, multiple team members",3,s6h8ck,https://www.reddit.com/r/datascience/comments/s6h8ck/concurrent_work_on_a_single_dataset_multiple_team/,4,1642459393.0,"I am facing a seemingly simple workflow issue and I'm almost certain that my current method for handling it is sub-optimal.

I have a single dataset comprising a few thousand rows and maybe 50 columns that is still being built-out, updated, and transformed daily as requirements evolve. Our workflow at the moment includes working with the file in Excel one-at-time and keeping track of who is currently editing via Slack alerts from our ELK stack (checking who downloaded/uploaded it from an internal filehost). The 5 analysts involved all have tools of their choice (with some knowing Python or R) but excel is of course the lowest-common denominator.

Is there a better way for the team to work on the data concurrently? Google sheets is not an option, though the dataset will eventually be ETL'd into a MySQL table. I'm wondering if getting it into SQL now would increase or decrease productivity, because many of the tasks at the moment are tantamount to data entry, and I'm not sure how easy it would be to handle this simple row-level updates with the data in an RDBMS.",2022-01-18 00:43:13
Why is “Data Scientist” such a controversial title?,0,s6h2we,https://scientistemily.substack.com/p/save-data-science,2,1642458996.0,,2022-01-18 00:36:36
Full stack data scientistish jobs?,1,s6f3px,https://www.reddit.com/r/datascience/comments/s6f3px/full_stack_data_scientistish_jobs/,5,1642454124.0,"I am a medior full stack developer that leans towards front end, has dabbled with machine learning. I am fascinated about the power of data and love to work with it. I have worked or experimented with Tableau, D3Js, Tensorflow, React, etc. 

My question is - what kind of job would you have when you do something like this. So far my answer is to become like a freelance data journalist and just do it myself. But I like working in a team and also like the stability and comfort of a job. What are your thoughts about companies, jobs or anything really that could point me in the right direction?

PS - my imposter syndrome is shouting 'just specialize in one thing dammit!' But I am afraid I am too excited about all these things. 

Thanks in advance",2022-01-17 23:15:24
Tutorial: Time Series Cross-Validation,0,s6ed1h,https://www.reddit.com/r/datascience/comments/s6ed1h/tutorial_time_series_crossvalidation/,0,1642452308.0,"## [Tutorial] - Time Series Cross Validation


> **TL;DR:** The code is [here](https://www.kaggle.com/yamqwe/tutorial-let-s-talk-time-series-validation).


Time Series Forecasting can be overwhelming. Especially if you are just getting started. There are many different types of Time Series tasks each differs by the number of input or output sequences, the number of steps to predict, whether the input and/or the output sequence length is static or changing, and so on. In this notebook, we will experiment with **different types of Time Series Cross-Validation Strategies** in order to become familiar with them and understand which works best for what case. 

As written before, Time Series problems can be of different variations, so in order to get a deeper understanding, we should explore each. 

    
* **Variation I:** Number of Input / Output sequences
    * (1.0) Single input and single output with input = output (Univariate with `in` = `out`)
    * (1.1) Single input and single output with input $\neq$ output (Multivariate with `in` $\neq$  `out`)
    * (1.2) Multiple inputs and multiple outputs with inputs = outputs (Multivariate with `in[N]` = `out[N]`)
    * (1.3) Multiple inputs and multiple outputs with inputs $\neq$ outputs (Multivariate with `in[N]` $\neq$  `out[N]`)  

* **Variation II:** Length of Output sequences
    * (2.0) Single-step output sequence     
    * (2.1) Multistep: Predict all steps at once (Single-shot) 
    * (2.2) Multistep: Predict single step at a time and feedback to model to predict for multiple steps (Autoregressive) 

* **Variation III** Type of input sequence
    * (3.0) Static length input sequence (Sliding Window) 
    * (3.1) Variable length input sequence (Expanding Window) 

____


Every different Time Series task have different combination of the above properties. For example, we could have:

One sequence for which we are trying to predict its values for the next 5 timesteps based on the previous 10 timesteps

This would make this task:

Univariate multistep time series forecasting with a sliding window (3.0, 2.1, 1.0)

If plotted it will look somewhat similar to this: 

https://i.ibb.co/0KDFwqC/results-19-1.png

____

Or we might need to

Predict the amount of snow for the next day based on all available past data of temperature and rain

[Take a moment to try and guess the problem types yourself..]

This is a Multivariate single step time series forecasting with an expanding window (2.0, 3.1, 1.3).

If plotted it will look somewhat similar to this:

https://i.ibb.co/WtW3975/results-36-1.png


____


The rest of the notebook goes through 5 Validation methods for Time Series to develop the ""best"" Time Series validation strategy. Then it shows an example of using it for hyperparameters optimization. 


Read the rest of the tutorial [here](https://www.kaggle.com/yamqwe/tutorial-let-s-talk-time-series-validation).",2022-01-17 22:45:08
What are some roles to transition out of DS/DA?,6,s6cwg4,https://www.reddit.com/r/datascience/comments/s6cwg4/what_are_some_roles_to_transition_out_of_dsda/,9,1642448714.0,I don’t like the heavily technical roles. I find it mentally boring. I want a role with multiple hats. I don’t know where to look for transitioning out of this? If you left your analyst or data scientist roles where did you go ?,2022-01-17 21:45:14
Miniconda anaconda licence,6,s69uiw,https://www.reddit.com/r/datascience/comments/s69uiw/miniconda_anaconda_licence/,3,1642441411.0,"Hi guys,

Is miniconda free to use in a business setting or are there licence fees i should consider? I think at least anaconda is not free anymore, but I am not sure.

Thanks",2022-01-17 19:43:31
NLP: Knowledge based vs neural based,2,s6987k,https://www.reddit.com/r/datascience/comments/s6987k/nlp_knowledge_based_vs_neural_based/,1,1642439957.0,"I have been working in nlp with neural language models (W2V,  transformers, etc...) for a while and wanted to expand my skill set to  the knowledge based approaches. Are knowledge based approaches used in  industry and how can they complement neural based approaches?  
Any book/learning material reference is highly appreciated, thanks!",2022-01-17 19:19:17
I'm the Business Analytics Manager who owns Looker for my company. I'm trying to better understand how my Data Scientists can utilize the Explores and Views my analysts build. Can you help me out quickly?,1,s68c6d,https://www.reddit.com/r/datascience/comments/s68c6d/im_the_business_analytics_manager_who_owns_looker/,2,1642437740.0," Hi all,

For context - I run a Business Analytics team with 5 dedicated analysts for 200 person company. We also have a Data Science Team working on similar data.

Our company hasn't had a great handle on managing the data warehouse over the last few years, so I'm helping clean that up. We're currently standing up a process to implement company wide KPIs and we've used 2 Looker Explores to consolidate these metrics.

The KPIs Explores are built of a mix of brand new tables we've built ourselves, and legacy tables that maintain transactional data for our service. Both of these sets of tables live in the same data lake with very little organization around them.

We're in a good spot now from a BA perspective, with a clean, easy to use explore that contains curated and trusted data. This will suffice for general users and analysts, but I'm a bit worried about how to serve this data to Data Scientists.

I'm still learning our teams workflow, but I was under the impression that most Data Scientists would prefer to work with data tables living in our warehouse vs looker. However, I've done some quick searching and it appears that it's pretty easy to connect Looker Explores to common Data Science toolsets. Is that the case?

If so - this pretty much solve all of my problems. I was planning on building out documentation for the Data Scientists to allow them to work directly with the tables populating the looker explores, but that creates its own problem (some logic lives in Looker and some outside of looker). If I can have them connect their tools directly to an explore, it would solve all issues!",2022-01-17 18:42:20
Is it possible to get some kind of freelance job from companies after learning softwares like orange and power BI?,0,s66ccx,https://www.reddit.com/r/datascience/comments/s66ccx/is_it_possible_to_get_some_kind_of_freelance_job/,5,1642432705.0,"Don't know if this is the right sub for this question..

one of my friend suggested me to learn how to use orange and power bi, So that we both can find some freelance work for those who want to visualize their data or something... we both are in collage pursuing CS degree. I want to know weather its a good idea to invest my time or not . 

If it is a bad idea then can u tell any other tool or skill which are needed to get freelance job in data science field. Thanks in advance.",2022-01-17 17:18:25
Mercury: Publish Jupyter Notebook as web app by adding YAML header (similar to R Markdown),223,s64zu0,https://www.reddit.com/r/datascience/comments/s64zu0/mercury_publish_jupyter_notebook_as_web_app_by/,30,1642428977.0,"I would like to share with you an open-source project that I was working on for the last two months. It is an open-source framework for converting Jupyter Notebook to web app by adding YAML header (similar to R Markdown).


Mercury is a perfect tool to share your Python notebooks with non-programmers.

- You can turn your notebook into web app. Sharing is as easy as sending them the URL to your server.
- You can add interactive input to your notebook by defining the YAML header. Your users can change the input and execute the notebook.
- You can hide your code to not scare your (non-coding) collaborators.
- Users can interact with notebook and save they results.
- You can share notebook as a web app with multiple users - they don't ovewrite original notebook.

The Mercury is open-source with code on GitHub https://github.com/mljar/mercury",2022-01-17 16:16:17
Need Help: Removing Mental Block,0,s6411i,https://www.reddit.com/r/datascience/comments/s6411i/need_help_removing_mental_block/,7,1642426054.0,"Hi Everyone,

I am currently preparing for a data science career and I have somewhat of a grasp in coding and currently working on my maths. I am quite good at, but ever since as a kid, I never got great marks in Statistics and Probability. This has created some kind of mental block that I can barely study beyond Bayes Theorem and Normal Distribution without getting anxiety attacks.

Can I please get some advice on how to work on this?",2022-01-17 15:27:34
3D objects,0,s63acg,https://www.reddit.com/r/datascience/comments/s63acg/3d_objects/,10,1642423671.0,"There are softwares that can perform the following: Given a database of CAD models, these software can search 3D CAD models that are similar (say upto 90 percent accuracy) to a desired input model.

For example, we provide it with 3D models of thousands of fasteners like nuts, bolts and washers with different diameters, lengths, shapes and types. Now we ask this software to show from the database, a bolt with similar diameter/type/length to an input model that we choose. The software show all the bolts that exist in the database, which match the criteria.

I would like to know if this could be an application of machine learning, if yes what is it called, and can I find any open source algorithm that is capable of doing such tasks, and also what should I learn, if I want to write code myself to create a tool like this(I am a beginner in ML)",2022-01-17 14:47:51
Is it right to assume that data analysis works in a pull system while data science works in a push system?,2,s61krr,https://www.reddit.com/r/datascience/comments/s61krr/is_it_right_to_assume_that_data_analysis_works_in/,2,1642417624.0,"I've been working as a data analyst for three years and most of my work is based on what the product owners/category managers/etc ask to know about the business, which means that my work always depends on what the business wants (hence the pull analogy). Although I like to work as a data analyst, this is kind of frustrating because most of the time I end up doing descriptive work and I don't get many chances to explore and to take the initiative to find and present something new, which made me look to data science. I might be under wrong assumptions here, but I am under the impression that data science works differently and you have more room to explore and propose new findings and features to the business (resulting in a push system). Do I have the wrong idea? Is this a thing of data analysis vs data science or is it just a thing about business and how the company operates? What is your experience on this?",2022-01-17 13:07:04
"I got dataset already split (train & test). I threw a few models at it and got at best 82.5% test accuracy. On training data, I get 100% accuracy. I tried shuffling all the data (test & train together) to check my suspicions, & now I get 98% accuracy on the test set. Different distributions right?",24,s60fa2,https://www.reddit.com/r/datascience/comments/s60fa2/i_got_dataset_already_split_train_test_i_threw_a/,17,1642413295.0,"After seeing my models get 100% accuracy on the training data but struggle to pass 80% on the test data I found that suspicious, especially after trying several regularization methods and several (dozens of models and NN architecture changes).

I began visualizing the data (it's 500 features, highly correlated) and noticed that some classes in the test set looked very different compared to the training set.

I asked my manager about how this data was generated. He said the embedded systems took measures over 3 full days and then a week later they took a full day. The first 3 days were the training data and the 1 day (a week) later was the test day.

I told him, you can't expect a model that is training on a different time period to be tested on one random day.

I told him we probably need several days sampled at various times, across the year even to get a good representative balanced dataset.

&#x200B;

He said it was impossible and that a competing client got 97.5% accuracy on the test data.

I explained my findings when shuffling the data, but he said we can't do that.

&#x200B;

I'm a tad frustrated now, is there something I'm overlooking here, or am I fundamentally right?

&#x200B;

Most of the datasets I work with are created by my team and I, I rarely ever get a random dataset like this.

&#x200B;

I've tried so many models, from simple to complex NNs, tried a bunch of regularisation methods, tried PCA (made things much worse at 60s% test accuracy), tried data augmentation techniques, clustering (which is how I found the differences between Class A in one dataset vs Class A in the other).

I also suspect some classes in the test data and mistakenly labeled, but he said the client assured him they are not. 

&#x200B;

Thoughts?",2022-01-17 11:54:55
Implementation of audio data augmentation in Python,1,s6004y,https://www.reddit.com/r/datascience/comments/s6004y/implementation_of_audio_data_augmentation_in/,1,1642411671.0,"I’ve published a new video in the “Audio #DataAugmentation” series.

The previous videos tackled the theoretical aspects of #Audio augmentation. In the new video, we switch to implementation.

You can learn how to implement 5 important audio augmentation techniques in Python, which all good #AI #audio engineer should know:

📌 Noise addition (from scratch)

📌 Time stretching (using librosa)

📌 Pitch scaling (using librosa)

📌 Polarity inversion (from scratch)

📌 Random gain (from scratch)

Have fun!

Video: https://www.youtube.com/watch?v=umAXGVzVvwQ&list=PL-wATfeyAMNoR4aqS-Fv0GRmS6bx5RtTW&index=3",2022-01-17 11:27:51
I am not sure if I should stop saying I'm DS or if it is just impostor syndrome.,104,s5vu2e,https://www.reddit.com/r/datascience/comments/s5vu2e/i_am_not_sure_if_i_should_stop_saying_im_ds_or_if/,37,1642396674.0," Hi There!

I'm sharing these thoughts both on the expectation to have a clearer picture and to help others that may be on a similar situation. The thing is: I'm currently on a Data Scientist position, but I'm increasingly starting to think that maybe I'm doing something correlated, not Data Science per se. The thing is, if that is the case, I don't know how to call it, and hence I don't know what to search for when looking for new opportunities.

I have what I believe is a good CV: got a LLB (undegrad in law) in a good school, a minor in applied math, a MSc in public policy where I had intense statistics classes, published two papers (one in a very good Journal) and got a job as ""Data Scientist"" for 2 years now on a NGO.

I use R a lot in my job and most of my work consists on exploring data, writing reports and so on. However, the coding part is done on a very shallow level. I am not recquire to use intense ML, deep learning or anything of this sort. It is usually just manipulating data using dplyr. Most of the time I am not coding, but rather doing a theoritecal job of searching for answers and thinking about hypothesis. Since I got a very good basis on public policy and public management, I am also very good at this theoritecal part. But this does not recquire any advanced knowledge in math / coding. If i had no knowledge on both of these but instead a 16-year-old intern the result would be the same.

The problem is that I have been looking for job positions on some companies as data scientist and I never feel I would fit the job, because my main skill (the theoritecal part) is not recquired while the main skill they ask for I have zero experience (ML). That led me to ask if I should keep looking for DS jobs because there's another name/category for what I'm better suited for or it's just \~\~ImpOstOr SynDroMe and with a 2-week course on Kaggle I can easily be the ML guy companies are asking for.

I appreciate any input on this.",2022-01-17 07:17:54
Who are the data science managers at Google?,5,s5l9f2,https://www.reddit.com/r/datascience/comments/s5l9f2/who_are_the_data_science_managers_at_google/,9,1642366304.0,"I can't find any ""DS manager"" roles at Google, so I'm inclined to believe that they're either (A) named differently, like ""data scientist lead"", which I've seen or (B) fall under another branch, like ""global head of analytics"", which I've also seen. 

Does anyone have first hand experience with DS Google structure and who manages DS lines of effort?",2022-01-16 22:51:44
How much would you charge to build a database?,47,s5h6vn,https://www.reddit.com/r/datascience/comments/s5h6vn/how_much_would_you_charge_to_build_a_database/,37,1642355397.0,"company I work for does all of their work manually. for instance if a price of one item changes, then every item that is related to this one item also needs to change. it is basically a large network of products and prices and orders change constantly. they have a person dedicated to typing in and updating new prices into spreadsheets manually and calculating the new price.  


What I was thinking of doing was creating a simple Microsoft Access database that will have connect all of these different price listings in such a way that once the price of one item changes, the prices for all other items change accordingly and automatically.   


Since this isn't part of my  work responsibility I would have to do this additionally once Im done with my work and Im wondering about how to charge for this.",2022-01-16 19:49:57
Which algorithm can I use for this classification?,5,s5bab3,https://www.reddit.com/r/datascience/comments/s5bab3/which_algorithm_can_i_use_for_this_classification/,4,1642337573.0,"I have a bunch of RAML files (Thousands of em)

Those files contain information about APIs. Their expected request, Their 2xx, 4xx, 5xx responses, headers, etc

I have to identify potentially duplicate APIs

Which algorithm can I try to use for this categorical classification?",2022-01-16 14:52:53
Weekly Entering & Transitioning Thread | 16 Jan 2022 - 23 Jan 2022,14,s5agk4,https://www.reddit.com/r/datascience/comments/s5agk4/weekly_entering_transitioning_thread_16_jan_2022/,167,1642334431.0,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",2022-01-16 14:00:31
Any Other Hiring Managers/Leaders Out There Petrified About The Future Of DS?,314,s548as,https://www.reddit.com/r/datascience/comments/s548as/any_other_hiring_managersleaders_out_there/,343,1642309859.0,"I've been interviewing/hiring DS for about 6-7 years, and I'm honestly very concerned about what I've been seeing over the past ~18 months. Wanted to get others pulse on the situation. 

The past 2 weeks have been my push to secure our summer interns. We're planning on bringing in 3 for the team, a mix of BS and MS candidates. So far I've interviewed over 30 candidates, and it honestly has me concerned. For interns we focus mostly on behavioral based interview questions - truthfully I don't think its fair to really drill someone on technical questions when they're still learning and looking for a developmental role. 

That being said, I do as a handful (2-4) of rather simple 'technical' questions. One of which, being:

*Explain the difference between linear and logistic regression.*

I'm not expecting much, maybe a mention of continuous/binary response would suffice... Of the 30+ people I have interviewed over the past weeks, 3 have been able to formulate a remotely passable response (2 MS, 1 BS candidate). 

Now these aren't bad candidates, they're coming from well known state schools, reputable private institutions, and even a couple of Ivy's scattered in there. They are bright, do well at the behavioral questions, good previous work experience, etc.. and the majority of these resumes also mention things like machine/deep learning, tensorflow, specific algorithms, and related projects they've done. 

**The most concerning however is the number of people applying for DS/Sr. DS that struggle with the exact same question.** We use one of the big name tech recruiters to funnel us full-time candidates, many of them have held roles as a DS for some extended period of time. The Linear/Logistic regression question is something I use in a meet and greet 1st round interview (we go much deeper in later rounds). I would say we're batting 50% of candidates being able to field it. 

So I want to know:

1) Is this a trend that others responsible for hiring are noticing, if so, has it got noticeably worse over the past ~12m? 

2) If so, where does the blame lie? Is it with the academic institutions? The general perception of DS? Somewhere else?

3) Do I have unrealistic expectations? 

4) Do you think the influx underqualified individuals is giving/will give data science a bad rep?",2022-01-16 07:10:59
Why isn't crowdsourced ML/data science more popular?,28,s4z52i,https://www.reddit.com/r/datascience/comments/s4z52i/why_isnt_crowdsourced_mldata_science_more_popular/,9,1642294120.0,"I'm wondering why projects like [OpenML](https://www.openml.org/) haven't really taken off. The idea behind it is that people in science  who have datasets they'd like modeled can upload their data, set tasks  or questions they want to answer, and then let people who want to hone  their ML skills attempt to create predictive models from the data.

It was launched in 2014, but hasn't really gained any traction in the ML and data science world.

Do people here have any thoughts on why crowdsourced ML hasn't caught on?",2022-01-16 02:48:40
"What are common tools to make csvs/excel extracts, presentable (formatting - not viz)",2,s4vtpi,https://www.reddit.com/r/datascience/comments/s4vtpi/what_are_common_tools_to_make_csvsexcel_extracts/,10,1642284911.0,"PYTHON ONLY PLEASE

I'm thinking highlighting, merging cells for visual effect, italicizing/bold, colors etc ...,). 

Basically i get really crude extracts, and i want to write a script to format reports so they come out a certain way as part of my output to a csv/excel.

Thank you",2022-01-16 00:15:11
How often is Stata used in the workplace?,20,s4sun8,https://www.reddit.com/r/datascience/comments/s4sun8/how_often_is_stata_used_in_the_workplace/,48,1642276990.0,"I’m curious as to how often you guys use it/if you’ve used it.

*I’m an economics student and we’re using Stata in my data analytics class",2022-01-15 22:03:10
Change in executive sponsorship - how to navigate next steps?,9,s4ruuw,https://www.reddit.com/r/datascience/comments/s4ruuw/change_in_executive_sponsorship_how_to_navigate/,7,1642274353.0,"So I have worked for small businesses over the past 6-8 years (50-500 people), ranging from 25M to 200M in annual revenue. My experience has been to enter these companies and establish data teams from the ground up, that facilitate reporting, insights, automation, and forecasting for sales, finance, product, and operations. These smaller companies are somewhat volatile, as my average tenure ranges from 1-3 years, most of the time for factors outside of my control. FWIW, prior to my analytics career, I was a finance director.

This most recent stint has been with another small software company with approximately 35M in revenue and 152 employees. My annual analytics spend is budgeted at 30K/ year, and goes towards Fivetran, BigQuery, and Sigma. I have been with the company for 7 months. I’ve made presentations to our executive leadership team, to the private equity group, and to department leaders.

This last Thursday, our CFO and my boss was terminated immediately from the company. She sponsored my position in order to facilitate future due diligence cycles since our customer data is in shambles. I’ve also established a cross functional data governance committee to address these issues.

That former CFO called me that night to explain it came out of nowhere and that she would be a reference for me if I so decided to move on.

My concern comes from the immediacy of the CFOs departure. My understanding is that she was performing well and the department was progressing. The CFO was replaced with someone the next day who has stated they don’t typically hire people for analytics. I’m sensing a lot of red flags.

I’ve since updated my resume and started applying to director roles. Besides enduring the situation while searching for a better leadership opportunity, what else should be done? I have no issue selling the analytics philosophy to the CFO, it just seems they’re viewing it as a luxury at this stage of the company.

Thoughts?

Edit: forgot to mention, the current controller is the one who helped bridge the conversation to add me to the company. That controller was tight with me and the CFO. They’ve all but gone dark since the departure.",2022-01-15 21:19:13
An honest conversation about Kaggle,195,s4p93s,https://www.reddit.com/r/datascience/comments/s4p93s/an_honest_conversation_about_kaggle/,52,1642267460.0,"I have been a data scientist on and off for a few years now. I am also a Product Manager so data science is not all I do so I wouldn’t call myself a hardcore data scientist. Disclosure: I never grew really warm with Kaggle competitions but I have looked at their datasets for other purposes and also competed in a handful competitions. I know there is some debate out there that most of the solutions are not applicable to a majority of real world problems and there is a certain artificiality to them but this is not what I am after here.

I am very curious: How do you utilize and perceive (or have utilized and perceived) Kaggle in your career. In what context have you used it, has it helped you, is it helping you. And most of all: What is your current role/status (student, full time DS with X-many years of experience). Thanks a bunch, super curious to learn more.",2022-01-15 19:24:20
"What data projects do you work on for fun? In my spare time I enjoy visualizing data from my cities public data, e.g. how many dog licenses were created in 2020.",261,s46geh,https://www.reddit.com/r/datascience/comments/s46geh/what_data_projects_do_you_work_on_for_fun_in_my/,84,1642204727.0,,2022-01-15 01:58:47
Are you part of a DS team or do you work alone?,4,s429mq,https://www.reddit.com/r/datascience/comments/s429mq/are_you_part_of_a_ds_team_or_do_you_work_alone/,7,1642193446.0,"I am curious what day-to-days look like for other data scientists / ML engineers. Do you work with teammates to tackle projects, develop models, deploy them? In my current company, I am on my own 95% of the time. Wondering if this is the norm. Thanks.",2022-01-14 22:50:46
Data Science: Your first big project is a start-up?,5,s40oso,https://www.reddit.com/r/datascience/comments/s40oso/data_science_your_first_big_project_is_a_startup/,11,1642189186.0,"Hi guys,

I've been accepted for my first full-time role in a high-growth Finance start-up. Thing is, the company has only 1 technical person (the rest are product, sales, marketing, etc.) and he basically runs the whole operation: Now they hired me as a sort of ,,data scientist'' but they don't really know what Data Science means (since they don't have any technical people in the team!)

Start-up is doing extremely well though and they plan to scale up ALOT this year. This basically translates into lots of customers coming in through registering on our platform (right now 1000+) and we save all of their profiles in our CRM which is just a huge cluttered mess. They expect me to clean it and generate valuable business reports.

Thing is I'm a complete beginner in Data Science but I do love coding and maths. I love writing my own solutions and algorithms to problems. Some things I've done so far.

&#x200B;

* scrape lists of companies on the web via beautifulsoup
* parse data in PDFs and create pandas 
* connect some tables with SQlite3 in order to give me queries 
* Lots of excel sheet handling manually and with libs such as openpyxl, trying to remove duplicates in data sets etc.
* Connect to some APIs to get for example data from the register of companies

I feel like my approach is all over the place though and while there's high expectations on me at my role  I have to learn a shit ton of stuff real quickly. I need some professional guidance - if you guys would start learning data science again and your first project is basically restructuring their whole CRM with 50'000+ entries, how would you do it (I know it's impossible for 1 person! But where should I start contributing? What's the most practical stuff I could learn?)

Thing is I lack a lot of technical skills right now but got the role bascially because I impressed them with my business knowledge (I worked in Sales before and I love interacting with customers).

Can you give me advice such as:

*  forget openpyxl and just get really comfortable with pandas
* learn some data engineering practices for cleaning, structuring data (what's the best method for removing duplicates, etc.)
* Use Tableau, or some Python lib for visualization, or whatnot
* How to manage expectations, make decisions, work with people..

etc..

I'm very grateful for any practical advice,

Valuevow",2022-01-14 21:39:46
Department/Team Question.,1,s3yyy8,https://www.reddit.com/r/datascience/comments/s3yyy8/departmentteam_question/,6,1642184449.0,"Would be so grateful to hear some thoughts: If a company wants all Data and ML to be owned by one Director, what would the team make up look like? I am arguing that this Director should have DBAs, DE’s, MLops, ML Engineers, DS’s all under their org chart. I’m getting some push back on that structure so I’d love to hear other peoples take.",2022-01-14 20:20:49
"Data Representation in Graphs - Sources for Guidance, Examples, ect?",1,s3yt9g,https://www.reddit.com/r/datascience/comments/s3yt9g/data_representation_in_graphs_sources_for/,2,1642184022.0,"*I apologize if this isn't the right sub to post this.  If not, please gently direct me to the correct location.*

I'm running a pipeline system model and need to summarize data in a report.  What I want to show can't fit into a traditional table, so I'm looking for guidance on how best to display the data.  The difficulty is the interdependence of the results on each input.  For example, changing the pipe size in one location could affect the rest of the system.

If I were to somehow create this table, it would need to show, on a given production date (there are three dates), what are the inlet pressures into the system (there are three sources) vs the selected pipeline sizes (there are four different pipelines).  The pipeline size variations are, honestly, limitless, but in this particular case there would be possibly 10 different sizes of pipelines that could be used.  Even if I chose one production date, the variation in pipeline sizes and resulting pressures, well, I can't wrap my mind around how it could be presented in a concise manner.

I guess my first question is, what resources are there for determining how to display data graphically that has so many variations?  Should I post a sample of the data here?  Is there more appropriate subreddit for this question?

Thank you so much for your time and consideration!",2022-01-14 20:13:42
Scientific Literature Review Generation v1.0,59,s3whup,https://www.reddit.com/r/datascience/comments/s3whup/scientific_literature_review_generation_v10/,13,1642177981.0,"Hello ,

I've developed after my PhD a first version of an algorithm to automatically generate a literature review : [https://www.naimai.fr](https://www.naimai.fr/) and many remarks were given. I just deployed a new version with much more papers and I'll be thankful if you have any remarks about it :)

More about the new version here : [https://yaassinekaddi.medium.com/scientific-literature-generation-ii-73628aebd4fb](https://yaassinekaddi.medium.com/scientific-literature-generation-ii-73628aebd4fb)

Hopefully that could be useful for the PhDs (and the non PhDs) !

&#x200B;

Cheers,",2022-01-14 18:33:01
Working as a big data professional in the military,26,s3uke6,https://www.reddit.com/r/datascience/comments/s3uke6/working_as_a_big_data_professional_in_the_military/,81,1642172974.0,"Does anyone have any experience working as a data scientist/MLE in the military? I'm just curious. I am thinking of setting up a sit down meeting with an Army recruiter, as I have been in contact about one with the possibility of a career in the Army after graduation (one cold called me and asked me for my interest, I picked up the phone cus why not, I figured more info cant hurt?) He asked me about my academic background (I am a college senior graduating in May, with my B.S. in business analytics with minors in math and applied stats) and he said I could ask the recruiter questions about possible careers in the Army with my career goals of working in DS.

Has anyone here had this experience? Anything to attest to? If I join, will I even be working with big data or is this all just a ploy to get me to enlist? I never considered the military as a career path but there's definitely the need for our skillset there.

Edit: thanks for the replies everyone! I’m gonna speak to the recruiter again in two weeks to see what the deal is. I’ve been applying to private contractors too, so we’ll see what happens",2022-01-14 17:09:34
"Deep learning developers, what IDE do you use and why?",139,s3tad5,https://www.reddit.com/r/datascience/comments/s3tad5/deep_learning_developers_what_ide_do_you_use_and/,151,1642169513.0,I use Pycharm but have never tried anything else. Thinking about switching but all the blog posts I find on google are quite useless.,2022-01-14 16:11:53
Director of Data Analytics vs Data Science,6,s3rwy0,https://www.reddit.com/r/datascience/comments/s3rwy0/director_of_data_analytics_vs_data_science/,14,1642165557.0,"I have a business/operations background, and I’m a self-taught programmer/data scientist. My years-long pursuit of a transition into data science is finally coming to fruition, as I’ve finally convinced my company to let me start a data science department. 

However, I’ve run into a slight snag. Given that the company has never had this type of role, they aren’t sure what to call it. The working title they are using is Director of Data Analytics, however my scope of responsibility will definitively be “data science”, not “data analytics”.

Is it worth me pushing to change the title to Data Science? Alternatively, is it frowned upon to list my title on my resume and LinkedIn as Data Science instead of Data Analytics? I know that this is a relatively common issue in industry — I just don’t want to be excluded from future opportunities if my title is listed as Data Analytics.",2022-01-14 15:05:57
How to manage yourself in a machine learning project?,11,s3p8jb,https://www.reddit.com/r/datascience/comments/s3p8jb/how_to_manage_yourself_in_a_machine_learning/,3,1642156107.0,"Hello, fellow Data Scientists!

I'm kind of stuck in the middle of a project. We're building several predictive models that will be deployed as a part of our API.   


The Problem: I don't know how much longer to keep doing research, trying different models etc. How much work should go into solving a specific problem?  


And I think the mistakes were made long before now. At the start  of the project we didn't set model performance goals, we didn't set a dead line, we didn't have an ROI in mind. We just talked with our product peoeple, they told us what would be cool to have as a machine learning solution and we more or less said 'let's go'. 

Now, we are two months into the project and the progress is slowing down. I realize that we don't have any framework to make the decision wether to keep on doing research, deploy the models as they are, or stop completely.

So now I feel that before even starting research we should have talked a lot more about what we actually want to achieve and how we will measure success. But how? How do you set goals for machine learning projects? How do you set up a business case with a cost benefit analysis? Are you estimating an ROI?

To give a bit of context: We are two data scientists in a software team that builds an API. We don't have a senior or lead data scientist who tells us when to stop, when performance is good enough or how long research should take. We, ourselves are responsible to answer these difficult questions. And we can't even say that with our models we want to increase API traffic because the API is still work in progress with zero traffic...

Have any of you had the same problem and how did deal with it? I am thankful for every piece of advice you have for me.

&#x200B;

Greetings from Berlin!",2022-01-14 12:28:27
China's advances in general AI,5,s3ojak,https://www.reddit.com/r/datascience/comments/s3ojak/chinas_advances_in_general_ai/,8,1642153341.0,"I know we in the west still see ourselves as AI leaders, and for good reason. Western FAANG companies, along with hardware companies like NVIDIA are pioneering AI research and technical ability.

A few years ago, I went to a talk hosted by Jen Hsun Huan CEO of NVIDIA who forewarned about the upcoming Chinese AI revolution.

In the QA section a lot of the audience disagreed saying how China steals our tech and innovation and if they improve it, it wasn't in any revolutionary way. Jen said he agreed, but he said there was huge movement to push the best students in China into PhD research and he said by 2025 the best AI researchers and tech (even GPUs he said will no longer be monopolized by the West) would be out of China.

Many said India might be a contender, but he said India's best almost always migrate to the West and unless something fundamentally changed he said (and I agree) most of the work produced by India is quite mediocre.

I'm a Computer Vision Deep Learning researcher and it's constantly amusing (and concerning me) that the best (perhaps not yet most innovative) work is coming out of China.

I'm not talking about big paper publishing in journals though many are heavily dominated now by Chinese research. I'm talking about tonnes of dataset deep learning benchmarks are almost always all Chinese in the top-5.

I don't think this is the case in the NLP or general Data Science world yet. NLP is hard to compare though since we'd mainly be looking at English (or western) language datasets not Mandarin or Cantonese. However, I imagine they are making great strides there.

Also, my former Professor who lectured for years at MIT said Chinese companies like Huawei, Alibaba, Tencent, etc. are hiring top western AI researchers as well and have been for the last decade.

The point of this post is tri-fold:

1. I'd like to be made more aware and also corrected if I'm wrong, my evidence is mostly anecdotal and heavily geared towards a few areas in Computer Vision
2. Will China continue to open source a lot of the research and participate in publishing in western journals (CVPR, ECCV etc.)
3. Should the West be concerned with China's advances here? It seems to me that there's almost a silent AI cold war going on.

Thoughts?",2022-01-14 11:42:21
"Inference vs. ML, could use your thoughts",2,s3hx4e,https://www.reddit.com/r/datascience/comments/s3hx4e/inference_vs_ml_could_use_your_thoughts/,3,1642130528.0,"Hello all,

I recently started a job as an analyst and got interested in causal inference. My intention was it would help me set up experiments to improve business units (marketing, finance, product) around my company. I thought it would be interesting and creative work

Recently I’ve read a few articles that make it seem learning DS and how to apply basic ML algorithms would be more beneficial for my career and my impact

I thought Causal inference and machine learning required each other..but it seems I can learn to just apply a few models and do basic fine-tuning? Are these two completely different career paths, and what would they look like?",2022-01-14 05:22:08
Methodology question for classification model,0,s3f89j,https://www.reddit.com/r/datascience/comments/s3f89j/methodology_question_for_classification_model/,4,1642122930.0,"Note: I realize that without some understanding of the data, one can only assume so much, but I am just curious to see if I'm missing something obvious in my approach.

I am building a classification model to predict which label (target variable) will be assigned to a record based on the data available. However, the entire scenario has a few conditions that are very different from anything I have encountered in academia.

For that reason I was wondering if anyone might have some **general** methodology ideas/questions I hadn't considered in setting up my experiment. Given these facts about the scenario:

- binary classification (xgboost, several classifiers tested and no others came close)
    - customer would prefer multi-class but there are over 30 different potential labels, so in V1 of my model we went binary (ANY of 29 positive outcomes v. 1 negative)

- roughly 500k labeled records are available (over the span of 2-4 years) for training, testing, and validation out of millions of records that are added to this database per year (roughly 2% of records are labeled per year.)

- the labels of the training data are HIGHLY imbalanced (over a 10-to-1 ratio of ""negative"" labels v. ANY positive label)
    - **xgboost is current ""most-viable""** classifier, so resampling/scale_pos_weight is being tested to deal with class imbalance, although I'm aware scale_pos_weight is the best practice)

- the current process to select new records to be labeled does include predictions fromy alpha build, but it is a very manual process, and there is no way to quantify how much weight my predictions carry.
    - a test of letting my model unilaterally make selections will likely **never** be an option

- the current record-selection process skips validating/labeling a record if the assumption is that a ""negative"" label will be assigned, so there's really no benchmark to evaluate how well or poor our ability to predict negative labels is, **only positive**

- cardinality of current predictors is so high that one-hot-encoding is not possible (best practice), so categoric variables are not being pre-processed ""optimally"".

- early stopping rounds, multiple evaluation metrics, kfoldCV, and various splits of train/test/val set utilized to try to minimize overfit (tt/ttv-split, yearly/geography [leave one out])

Truthfully, my biggest concern is about what I can do to present a valid confidence level in the predictions of the model. Since such a large % of the population can never be labeled, my training data is heavily biased to the assumptions of the legacy selection process. Additionally, I'm only able to evaluate predictive capability by examining the cross-section of predicted records and records that the business chose to examine. What if the business is just really bad at selecting records?

Given these details, does anything jump out to you? I'd love to know your thoughts to ensure I haven't left an obvious stone unturned. I'm happy with the state of V1 but would obviously prefer to take a statistically significant step forward with V2.

Thanks",2022-01-14 03:15:30
Am I shooting myself in the foot by focusing on DE?,0,s3f5ey,https://www.reddit.com/r/datascience/comments/s3f5ey/am_i_shooting_myself_in_the_foot_by_focusing_on_de/,12,1642122712.0,"Sup folks. I recently started on a company as a Data Scientist, however being a small company most of my job has been related to Data Engineering, which I enjoy and I think is quite important. I just found out that they want to give me even more responsibilities related to DE. 

My ultimate goal when it comes to data is working with ML. Partly because I believe that is where I will be able to maximise salary in the future.

My DE skills are supposed to be complementary to my ML skills, but now I am wondering if I am shooting myself in the foot by focusing so much on DE while barely working with machine learning. That said, in the 3 companies I have worked at (including this one) ML work has been applying someones elses model or constructing a very basic one. It does not seem like I will ever be able to get a truly ml position without a PHD, I hope DE could give me some extra edge.

Is it valuable for someone working in ML to have robust DE knowledge? Do DE make less than their DS and ML counterparts? Is this a smart carrer move or should I carry on with basic, boring ML work?",2022-01-14 03:11:52
"If you are interested in graph representation learning with Graph Neural Networks, then read on",1,s3bhsy,https://www.reddit.com/r/datascience/comments/s3bhsy/if_you_are_interested_in_graph_representation/,0,1642112756.0,"Hi r/datascience,

For the past 1.5 years I have been organizing an online journal club on the topic of [Graph Representation Learning](https://www.thejournal.club/c/club/3/). We meet either weekly or fortnightly via Zoom to discuss a relevant paper.

We are a small and friendly group and we would like to invite others who have similar interests to join us.

We meet on **Thursdays,  6:00pm-7:30pm, Canada/Pacific timezone**, and out next meeting is on January 20, 2022.

You are welcome to join us [here](https://www.thejournal.club/c/club/3/).

Cheers!",2022-01-14 00:25:56
How much accuracy for a “sufficiently good” model,0,s36om0,https://www.reddit.com/r/datascience/comments/s36om0/how_much_accuracy_for_a_sufficiently_good_model/,8,1642100095.0,"I have a very general question. With any real-world dataset with tens or hundreds of features, assuming no benchmark to compare the model with, what accuracy would you consider to be “good enough”? 70%? 90% 

It can be a regression or classification problem using any ML/DL method. I do understand it depends a lot on the dataset but I just want to have a general sense.",2022-01-13 20:54:55
Why do data scientists refer to traditional statistical procedures like linear regression and PCA as examples of machine learning?,355,s36btr,https://www.reddit.com/r/datascience/comments/s36btr/why_do_data_scientists_refer_to_traditional/,141,1642099148.0,"I come from an academic background, with a solid stats foundation. The phrase 'machine learning' seems to have a much more narrow definition in my field of academia than it does in industry circles. Going through an introductory machine learning text at the moment, and I am somewhat surprised and disappointed that most of the material is stuff that would be covered in an introductory applied stats course. Is linear regression really an example of machine learning? And is linear regression, clustering, PCA, etc. what jobs are looking for when they are seeking someone with ML experience? Perhaps unsupervised learning and deep learning are closer to my preconceived notions of what ML actually is, which the book I'm going through only briefly touches on.",2022-01-13 20:39:08
Is the moderation here getting more hard-line?,96,s33tpv,https://www.reddit.com/r/datascience/comments/s33tpv/is_the_moderation_here_getting_more_hardline/,69,1642092643.0,"I've noticed a few threads being locked over the past couple of weeks that don't seem to obviously break any rules and generated a fair amount of discussion - the latest example being a thread about using leetcode in interviews.

I think that's a valid topic of discussion and could potentially generate an interesting debate/discussion. Why was it locked?

I get that mods want to crackdown on the plethora of ""How do I get into Data Science?"" type threads but if we get too hard-line, we're going to end up like r/MachineLearning where there are just endless topics about some incredibly specific technical topic that get 0-2 replies.",2022-01-13 18:50:43
Applied Data Science Conference in Germany (or online),10,s2vqat,https://www.reddit.com/r/datascience/comments/s2vqat/applied_data_science_conference_in_germany_or/,8,1642066973.0,"Hey there,

I was wondering if anyone can recommend a good conference on applied data science in Germany or online. I would like to go on an event which focuses on applied data science, since I want to stay up to date with the latest frameworks, methods etc. Is there anything you can recommend in Germany or as an online event?",2022-01-13 11:42:53
Finding Part-Time DS Work,63,s2m7g3,https://www.reddit.com/r/datascience/comments/s2m7g3/finding_parttime_ds_work/,43,1642035730.0,"Hey guys,

Does anyone know how to find part-time (non full-time) roles in data science?  I am recovering from a health issue and can't handle a 40 hour grind, but could probably work 20 or 30 hours.  However, I don't even know where to begin to find this type of work.  Appreciate any thoughts you have.",2022-01-13 03:02:10
Computing categorical feature importance using SHAP values.,4,s2epy0,https://www.reddit.com/r/datascience/comments/s2epy0/computing_categorical_feature_importance_using/,5,1642015886.0,"So I have a model with a categorical variable encoded with one hot encoding, and I want to compute the feature importance of the categorical variable.

The feature importance is defined as the mean absolute value of the shap values. Then, to get the global importance of a categorical feature, should I just aggregate the values of all the components of the one hot encoding?",2022-01-12 21:31:26
Where to Look for Data Scientist Freelanceres/Consultants?,1,s2ejzg,https://www.reddit.com/r/datascience/comments/s2ejzg/where_to_look_for_data_scientist/,3,1642015457.0,"My company is currently looking into hiring a very qualified data scientist as a consultant for a short term project.  The type of candidate we are looking for ideally has a PHD or 10+ years of experience as a data scientist.  What resources/websites are available for me to look for these kind of candidates?

So far I have looked into toptal, upwork and kolabtree.  Are there other websites or platforms I can look at for potential candidates?",2022-01-12 21:24:17
Is there a way to update an lda model with more passes,1,s2ebsd,https://www.reddit.com/r/datascience/comments/s2ebsd/is_there_a_way_to_update_an_lda_model_with_more/,1,1642014875.0,"For example, run a few passes, save the model and then run more passes over it. I want to do this in chunks because my computer shuts down after a few passes. Maybe it heats up idk. Im using Gensim",2022-01-12 21:14:35
Streamlit App To Compare Text Similarity,245,s2cyt2,https://i.redd.it/2szjenkdtab81.gif,13,1642011467.0,,2022-01-12 20:17:47
How would you calculate expected value of sales leads?,5,s29v6d,https://www.reddit.com/r/datascience/comments/s29v6d/how_would_you_calculate_expected_value_of_sales/,5,1642003741.0,"Simplified situation:

* I have 1000 leads, but can only pursue 100 of them due to limited resources (salespeople).
* Each of these leads can be pitched up to N products, each with its own dollar value and estimated probability to convert.
* Not all customers have all N products available to them, they might only qualify for *n*/N of them.
* A customer can convert on any combination of those *n* products.

How to calculate the expected value of the leads, so that I can prioritize the top 100? If it were a single product I could do $$ x Pconvert = expected $$, but how do I account for multiple products that can be pitched to the lead?",2022-01-12 18:09:01
Employer wants to pay for a Bootcamp,68,s29h1m,https://www.reddit.com/r/datascience/comments/s29h1m/employer_wants_to_pay_for_a_bootcamp/,63,1642002736.0,"Hi all! I was hired as a data analyst at a Fortune 500 with some experience as a business data analyst from a previous role. 

My knowledge on sql is good not great. I don’t have any scripting (python, C#) experience and my employer is offering to pay for a bootcamp to familiarize myself with SQL. They are asking for my input and I mentioned to find some classes that also offer some programming languages in their course because I believe it would be beneficial. My question to you guys is: do you have any recommendations of a bootcamp or advice on educating myself? thanks!",2022-01-12 17:52:16
Data Analyst and Data Scientist labels,5,s29chf,https://www.reddit.com/r/datascience/comments/s29chf/data_analyst_and_data_scientist_labels/,11,1642002401.0,"I usually introduce myself as a data analyst with 8 years experience but I have done statistical modeling, worked with data engineers on setting up the cloud environment, parallel processing, time series analysis, forecasting, data visualization, NLP, mining unstructured text files and messy structured data, supervised and unsupervised learning... So I do have experience with data science but I feel like I am overselling myself or an imposter if I said I am a data scientist. But I could be underselling myself if I said I am a data analyst because I have done a bit more.",2022-01-12 17:46:41
Multiple Time Series with Exogenous Variables - the best approach?,1,s27j9q,https://www.reddit.com/r/datascience/comments/s27j9q/multiple_time_series_with_exogenous_variables_the/,3,1641997640.0,"Hi all,

I have many different stores with their own weekly sales data, let's say 1000 stores. Each store has other time series data, for example ""number of enquiries"" for that week. There's about 5 of these time series that I want to treat as exogenous variables.

I'm trying to forecast weekly sales data based on those exogenous time series variables for new stores coming in.

* 1000 stores with time series weekly sales data.
* 5 exogenous time series data for each store.

Is there an appropriate time series model for this? I looked into hierarchical time series but couldn't see how you could incorporate exogenous variables. I looked into your standard time series and it letting ARIMA have exogenous variables is relatively straight forward in Python, however, in this problem there is multiple time series (1000, for each store).

As an add on, is it possible to add on to the time series other time independent data, for example, location of the store, type of store etc?

Right now, my plan to approach this is by treating it as a regression problem. Using the final week as the outcome variable and the starting weeks to represent growth in the exogenous time series. I think this would capture some of the relationship but it's downside would be losing all the other time data points.

This isn't a huge project and the data set is relatively small.

It would be interested to hear your thoughts!

Cheers.",2022-01-12 16:27:20
How to find companies (on the internet) based on keywords?,1,s25mkd,https://www.reddit.com/r/datascience/comments/s25mkd/how_to_find_companies_on_the_internet_based_on/,3,1641992126.0,"I study Artificial Intelligence and for a project we have to find companies based on a given industry and geographic location like US, Europe, Asia, etc. but I am a bit clueless how. I've searched for databases but either they lack company description or they are not that large. Is there another way to do this?",2022-01-12 14:55:26
Has anybody got experience automating/generating weekly business and sales reports with Python to PDF?,19,s24r83,https://www.reddit.com/r/datascience/comments/s24r83/has_anybody_got_experience_automatinggenerating/,19,1641989151.0,"I work as a Data Analyst in the Commercial Strategy function of a Pharma company. I want a program that prepares an end of week sales report that is then distributed to my stakeholders automatically using AWS Lambda. 

My thinking is that if certain thresholds are met on a given metric, a portion of text will be written, if another condition is met, then other text will be written. You get the idea. I think it will be a lot of if else statements. 

There’s not too much online about this. Anybody got some thoughts?",2022-01-12 14:05:51
If I have a large corpus of really huge documents(say 1000 documents each of 1000 pages). What would be the best method to Custer similar documents. Traditional word vectors and cosine similarly fails in most cases.,0,s236tw,https://www.reddit.com/r/datascience/comments/s236tw/if_i_have_a_large_corpus_of_really_huge/,14,1641983339.0,,2022-01-12 12:28:59
multi-class or one vs rest for classification?,0,s231av,https://www.reddit.com/r/datascience/comments/s231av/multiclass_or_one_vs_rest_for_classification/,9,1641982748.0,"Hi all,

I have a dataset trying to predict which category a person falls into. I have 7 categories. The distribution is quite skewed: 75% or so samples fall into 1 class, another 10% into another and the rest <5% but above 1%. 

I understand that I could fit some multiclass model, or I could fit 1 model for each category, set it the positive class and everything else to the negative class (a so called ""one vs rest""). Are there any rules of thumb for which is best in a given scenario or is it down to experimentation?

I'm thinking that one vs rest with lots of categories will inevitably produce lots of models with high class imbalance, which can complicate things, so perhaps better to go with the multiclass?",2022-01-12 12:19:08
"Normally speaking, what do you do when your model fail after a very long time of training ?",0,s1xvan,https://www.reddit.com/r/datascience/comments/s1xvan/normally_speaking_what_do_you_do_when_your_model/,1,1641963644.0,,2022-01-12 07:00:44
So many opportunities in the job market right now,337,s1u92t,https://www.reddit.com/r/datascience/comments/s1u92t/so_many_opportunities_in_the_job_market_right_now/,155,1641952904.0,"Is anyone else experiencing this too?

Recently applied to a job at Google and was asked if I wanted to be considered for multiple positions and  also got my first interview with Apple! Seriously the best call back rate I’ve had like ever…when I applied in 2019 it was like crickets lol

I’m hearing similar things from friends and former colleagues in the industry too...seems like now is a great time to look for a job opportunity",2022-01-12 04:01:44
"I was asked an interview as to how to extract only the medical terms in a doctor's note(unsupervised approach). When I answered LDA, Tf-idf he wasn't convinced but asked me how I would deal with irrelevant keyword extracted using these techniques. How would you answer these questions?",0,s1s5w3,https://www.reddit.com/r/datascience/comments/s1s5w3/i_was_asked_an_interview_as_to_how_to_extract/,9,1641947094.0,,2022-01-12 02:24:54
Have you had to roll back your ML models in production? Why?,18,s1qmu1,https://www.reddit.com/r/datascience/comments/s1qmu1/have_you_had_to_roll_back_your_ml_models_in/,11,1641942917.0,"I am curious to know how often this happens, how your team handled it, and the particular reasons it happened due to.  In my case, a client made some last-minute (uninformed ) updates to their processes which changed some of the underlying bandwidths of categories in some of the features breaking our ML models.",2022-01-12 01:15:17
Taking a 6 month work break and then returning to analytics,94,s1ohkt,https://www.reddit.com/r/datascience/comments/s1ohkt/taking_a_6_month_work_break_and_then_returning_to/,32,1641937402.0," I'm planning on taking 6 months off of work this year to hike. I currently WFH as a data analyst doing SAS/SQL report coding with a GOV Contractor. I'm going to ask for an extended leave...but if I get denied I'll give notice. Kind of doing this for mental health and to transition geographically.

If I take 6 months away from Analytics work will this be looked at negatively when I'm back in the job market looking for a position?

Would I have better luck looking for contract work vs being a FTE somewhere after the 6 months?

Thoughts?",2022-01-11 23:43:22
Build system for machine learning?,1,s1o0yy,https://www.reddit.com/r/datascience/comments/s1o0yy/build_system_for_machine_learning/,2,1641936239.0,"Hey all,

I'm setting up a new machine learning project and I know I'm going to be collecting data over time (and making model improvements). Is there a best way to set up a build system to generate models using my training script, eval on test data, all relatively automatically?

Curious what other people have tried and liked (or disliked). Thanks!",2022-01-11 23:23:59
Which tool to plot data with searchable dropdown menu other than plotly dash?,2,s1n381,https://www.reddit.com/r/datascience/comments/s1n381/which_tool_to_plot_data_with_searchable_dropdown/,4,1641933894.0,"Hello, 

I do some data science/engineering with measurement data and for the plots I mostly use Plotly since it is very responsive and interactive. The biggest advantage is, that I can share the interactive figures as simple html files. 

Now I want to take things further and want a (or multiple) dropdown (searchable) menu so the user can filter the plot better. Since I want the graph to be portable Plotly Dash is out of question because it requires a server to be run on. 

Could you point me in the right direction what open source tool I could use? I am open to every language.",2022-01-11 22:44:54
I made any SKLearn model (probably) interactive,123,s1mg59,https://www.reddit.com/r/datascience/comments/s1mg59/i_made_any_sklearn_model_probably_interactive/,8,1641932281.0,"I'm sure this has been done before but this is something I've had in my head for so long. 

When you're in a meeting showing off your new analysis to a stakeholder, have you ever wanted to show off how it predicts different scenarios? I used the jupyter widgets library to make this jazzy function: 

https://imgur.com/a/p0ytztB

It's purely a MVP but it can take any model providing you let it know the model, the data, the features and the variable you're predicting. 

It's just a MVP so will break if you look at it funny but it's here:
https://github.com/ChamRoshi/Model_fiddle/blob/main/Interactive%20model.ipynb 
BUT it's not interactive because it's in github.",2022-01-11 22:18:01
Job interview coding challenges?,0,s1lsy1,https://www.reddit.com/r/datascience/comments/s1lsy1/job_interview_coding_challenges/,2,1641930667.0,"Hi,  

I'm prepping for job interview coding challenges for a Data Scientist position.  I'm trying to find some example problems online for practice, but majority of them seem to behind a pay wall.

Can anyone help me out with some free examples?",2022-01-11 21:51:07
Quit master's in statistics or...?,45,s1ip9d,https://www.reddit.com/r/datascience/comments/s1ip9d/quit_masters_in_statistics_or/,62,1641922957.0,"I (25M) started Master's in stats in 2019 and I'm still not near getting a degree. I actually can't decide should I just quit or should I push it. But one thing I do know - I just for the love of God can't find any motivation whatsoever to push myself and start writing the thesis and studying for my exams.

I've worked as a data scientist for 2 years now, and during my bachelor days, I've been freelancing DS/ML (2017 - 2019). That experience brought me an intermediate DS position very early on in my career, the money's been good ever since and I'm just not seeing any source of motivation for a very long time. I tried to put together a list of pros and cons staying so here's what I came up with:

Pros:
1. Higher level of education - potential access to some better payed research or academia positions later on (I'm not even sure If I'll ever want those)
2. Personal satisfaction (but I can't decide if that's truly a personal thing or it's just ""everybody-and-their-mother-have-a-masters-nowadays-so-why-shouldn't-you"" kind of thing)

Cons:
1. Constant pressure on my mind
2. I don't honestly believe that I'll learn anything new in this masters (we just repeat stuff we already learned during bachelor's) and therefore it's not worth it.
3. Scholarships
4. Working & studying at the same time for a title that I can't even decide if it means anything to me.


Some additional context - I can also do data engineering which I did in my former company and actually enjoyed a lot more than DS stuff I had to do. What I also don't like about DS is that it's almost always a ""new thing"" in most companies, a ""research/experimental"" thing so if it fails it doesn't matter. Most of the times you'll just use a pre-trained model for X task and that's good enough. I might leave DS because of this at some point btw.
I'm also a man of many hobbies. I play in a band, I DJ occasionally, I like clubbing/hanging out/staying late etc, so all of this tells me to drop out (don't misunderstand this for slacking at work). Even though the cons list is longer, I can't drop out, not just yet, but I don't know why.




Please do share similar dilemmas and experiences. 

Thanks a lot!


EDIT: I saw some comments about applying DS knowledge to my hobbies, which is unrelated to the subject but it made me think about one thing that irritates me, and that is putting DS/ML where it simply doesn't belong. Think of all those kaggle competitions. There was a bunch of these stupid tasks, but I can remember only 2, something about Titanic survival prediction (seriously?!) and some kind of Pokemon analytics (LOL). I mean COME ON.

EDIT 2: 
Thanks everyone, I decided to go and get it after all. it's a tight schedule with work but I'll do my best to do it.",2022-01-11 19:42:37
Question about column based visuals for dataframes.,7,s1ibu1,https://www.reddit.com/r/datascience/comments/s1ibu1/question_about_column_based_visuals_for_dataframes/,3,1641922037.0,"Does anyone know if there is a package out there to pretty-print univariate analysis of columns for pandas dataframes, similar to how Kaggle datasets have a detail section (example attached). Maybe something that can be used inside Jupyter Notebooks?

https://preview.redd.it/udfm8hp2f3b81.png?width=1184&format=png&auto=webp&s=60602c680d8ed7d11bb9288762d3bbcb95ef3a46",2022-01-11 19:27:17
Creating dashboards with Python? (Dash vs Flask + Plotly vs others),16,s1fa3k,https://www.reddit.com/r/datascience/comments/s1fa3k/creating_dashboards_with_python_dash_vs_flask/,11,1641914309.0,"Hi, I'm joining a team next week where they are developing bioinformatics pipelines on R and using Shiny apps for their dashboards / user input. I'm going to be working on the development of new products strictly on Python, so I'm looking for a new toolset. 

My work so far has been purely academic, running on notebooks, pandas and plotly. I don't really know anything about web developent and I don't want it to become my focus, since I'm a bioinformatician first. But I need to produce user friendly and scalable dashboards to create reports, for this job and for my personal projects. 

From what I've read Dash is very easy to use, but I'm not sure if it can scale that well into the future or incorporate elements from other libraries that are not Plotly. Flask + plotly seems like a safer bet, if a bit more complex to learn. Django seems overkill to learn, but I'm not sure what the limitations on Flask are. I'm open to other options that I havent listed. I assume being able to incorporate some of the work done on shiny would be nice, if that matters at all.

Any suggestions? Thanks!",2022-01-11 17:18:29
What’s the best platform to create a portfolio of all your DS-related projects?,34,s1eg2k,https://www.reddit.com/r/datascience/comments/s1eg2k/whats_the_best_platform_to_create_a_portfolio_of/,31,1641912118.0,Is GitHub the best way to go about this? It doesn’t seem that intuitive towards storing projects to me. Is there an alternative way?,2022-01-11 16:41:58
How to present a potential paper as valuable to my company,0,s1e1de,https://www.reddit.com/r/datascience/comments/s1e1de/how_to_present_a_potential_paper_as_valuable_to/,4,1641911020.0,"So I’m collaborating with a professor that I had for the accounting data analytics grad certificate my co is paying for. We’re in the preliminary stages but I think we’ve settled on “concept drift” as the overarching topic. 

However, we need a source for data. I was considering contacting the newly promoted data scientist about this. Also, the position he was promoted from, (we call analysts specialists at this co, but effectively:) the data analyst, is vacant. 

I was wondering if you all had a good strategy to spin this as a value proposition for my co and if I could go as far as convincing them to also change my position towards data whilst working on this project, it would be incredible. 

I just don’t have any examples of anyone being successful in such a venture. 

Any thoughts and suggestions are greatly appreciated!

Thanks in advance",2022-01-11 16:23:40
Shinyapps.io or another solution?,13,s1dzg4,https://www.reddit.com/r/datascience/comments/s1dzg4/shinyappsio_or_another_solution/,14,1641910878.0,"I am an independent consultant in supply chain data science.  For some of my projects, the end deliverables include a R Shiny app that runs optimization or simulation code underneath the visualization layer. Some of these can be pretty memory and CPU intensive.

Right now, I just have the freebie shinyapps.io account.  I like the ease of launching and debugging apps on the platform.  I'll soon either need to start paying for a higher tier shjnyapps account, or start migrating to another option.  

Curious to hear this subs experience with different shiny apps solutions.",2022-01-11 16:21:18
New clustering algorithms like DBSCAN and OPTICS?,11,s1c4fu,https://www.reddit.com/r/datascience/comments/s1c4fu/new_clustering_algorithms_like_dbscan_and_optics/,9,1641905280.0,"Hello, I am doing some research work. I am looking for clustering methods like DBSCAN and OPTICS (These were introduced in 1996, 1999) which are new and better. Can anyone tell me the names of newer algorithms? If possible, a link to the research paper would be appreciable. If they are already in implementation, please mention.",2022-01-11 14:48:00
Which solution to aim? (data scientists types),0,s19nyg,https://www.reddit.com/r/datascience/comments/s19nyg/which_solution_to_aim_data_scientists_types/,13,1641895882.0,"I am  facing this issue at some project I am working at. I'd love to open a discussion

Which solution should I aim for?

A: solution to a problem with a simple SQL query or simple plot, that will lead to an accuracy of lets say 80%

B: very complex solution (e.g. complex models and thorough representation) yealding to an accuracy of 90%

Is it worth the efford? I know, in some cases makes sense, but also in another cases, solution A takes 5% of the time of solution B. How do you sort out this kind of dilemmas. In addition, I believe that there are 2 kind of data scientist, one aiming first to one kind of approach.

Cheers",2022-01-11 12:11:22
No prediction can be 100% accurate.,0,s16zub,https://www.reddit.com/r/datascience/comments/s16zub/no_prediction_can_be_100_accurate/,17,1641885006.0,"Anyone else have their blood pressure go up when someone says that their predictive model is 100% accurate?  I just can't imagine that being realistic.

[View Poll](https://www.reddit.com/poll/s16zub)",2022-01-11 09:10:06
How to get in Meta/Facebook,0,s16qmt,https://www.reddit.com/r/datascience/comments/s16qmt/how_to_get_in_metafacebook/,8,1641884061.0,"Hello there. I am trying to get a job in Meta/Facebook. If any of you work in this company(or any other big company like microsoft, tesla,google etc.) It will be interesting to share your experience how to get an interview. What should you expect on interview and finally how hard is it to get a job in the company. Also, Im trying to start working on remote. I have 2 years of experience in DS, finished bachelors of computer science and doing masters in applied mathematics right now,  and I wonder if this experience is enough.  Thank you.",2022-01-11 08:54:21
Searching for structure in 2d point data.,2,s11445,https://www.reddit.com/r/datascience/comments/s11445/searching_for_structure_in_2d_point_data/,6,1641866147.0,"I've got a bunch of 2d point data, basically how ever many points I want. I want to look for structure in that data. Imagine that I have hyper accurate cell phone locations for everyone in your town. How would I turn that 2d location data into ""interesting"" spots in your town. Don't need to know (from the point data, at least) that X,Y is the town coffee shop, just that that particular point is interesting. 

What are some things I should google?",2022-01-11 03:55:47
Complex Matching Exercise,2,s0xf2w,https://www.reddit.com/r/datascience/comments/s0xf2w/complex_matching_exercise/,4,1641855936.0,"Hello All,

&#x200B;

I'm not sure which community this fits into as it could fall into a number of them. Please direct me better if you think that there is a community which would rather chew on this problem.

&#x200B;

I have received Database Enrichment data. its 238 rows and about 60 Columns. I need to find matches between this data and existing data we have in the database. I was able to match a bunch with VLOOKUP's in Excel, but, because of simple formatting issues I know that there are more similarities.

The complexity of the situation is as follows:

* The enrichment data is 238 rows by 60 Columns
* The Database data is 72000 rows and up to 940 columns

In this case, I'm looking for unique data points which could be found in the database. This is about 11 columns that consist of phone numbers, emails, websites, addresses, names, etc. In the database there are multiple columns to which either could be matched to, (e.g. phone1, phone2, phone3, email1, email2, email3, etc.). 

Because of this factor I wrote a macro that churns through the data and compares each cell in the enrichment data to each cell in the database. However, that is approximately 29 billion comparisons and is very inneffieicnt. I did try to add some logic to my macro to immediately skip to the next records if the match is found.

Some easy efficiencies I could gain would be:

* Only compare like data-types (phone numbers with phone numbers and emails with emails) - I won't get into why I didn't do that at this point.
* Limit/restrict rows in the database to compare against

&#x200B;

Thoughts? has anyone else done a matching exercise like this? In an ideal world, I would use a modified VLOOKUP that looks like this:

(Lookup this value, in either of these columns, return the value of the first column in the table if a match is found) ",2022-01-11 01:05:36
OCR Spelling Correction NLP,2,s0vtdp,https://www.reddit.com/r/datascience/comments/s0vtdp/ocr_spelling_correction_nlp/,2,1641851952.0,"Hey guys, I was researching about how to auto correct spelling errors caused by OCR misreading things. I read this great article about using a spell checker to detect the incorrectly spelled words first and then run a BERT model to get the predictions for the words. One concern I have is that a common type of misread oftern involves reading letters as number and vice versa. For example an O is often misread as a zero and a S is sometimes misread as a 5. I tried to spell some words like these in microsoft word and see if the built in spell checker actually detects these type of words, but the spell checker in word itself seems to just ignore something like L0rd(Lord) or 5nake(snake). I'm worried about if this approach that I read was actually going to work since it relies on the spell checker. Has anyone done some related past works? Any possible ideas I should look into? Thank you guys for sharing.",2022-01-10 23:59:12
Looks like they just put in all the words they could find… btw although it says 10+ experience… on LinkedIn it’s under entry level job,730,s0uhca,https://i.redd.it/7kiclof7dxa81.jpg,208,1641848564.0,,2022-01-10 23:02:44
"Fellow WFH’ers, how many hours a week do you think you actually work",92,s0t85f,https://www.reddit.com/r/datascience/comments/s0t85f/fellow_wfhers_how_many_hours_a_week_do_you_think/,59,1641845436.0,"For those of you that work from home, how many hours a week do you think you spend actually working?

I’ve found my productivity has been going down the last few months and my anxiety up as a result. I’m spending about 20-30 hours actually doing work in a 40 hour work week (although I spend 35-40 at my desk)

Is anyone else finding it hard to concentrate at home? Is this level of production satisfactory? I still get everything done that I’m asked of but I could definitely go beyond. I feel awful because I used to be so motivated and hardworking.",2022-01-10 22:10:36
Blindfolded ML ???,6,s0q3yd,https://www.reddit.com/r/datascience/comments/s0q3yd/blindfolded_ml/,22,1641837547.0,"I received an unusual request: solve a supervised learning problem on tabular data without data access.

Apparently these data are ""top secret"" and they just cannot be accessed. I am given a YAML file containing metadata and I'm supposed to develop code based on that. Once ready, code will be sent to ""the other side"" and run. Any error messages will be reported back to me so that I can fix bugs, plus I will get notified on key metrics to assess model performance and iterate.

They told me data are ML-ready (i.e. there is a single table with features and target variable). I will take this for granted and pray for it to be true.

This is far from efficient, but looks like I have to run with this.

The YAML file looks like this:

    n_rows: 1000000
    n_columns: 5
    column_names: [id, target, columnA, columnB, columnC]
    id_column_name: ""id""
    target_column_name: ""target""
    column_types: {columnA: scale, columnB: scale, columnC: categorical, target: categorical}
    column_null_values: {columnA: 0.04, columnB: 0.13, columnC: 0}
    column_categorical_values: {columnC: {red: 0.3, green: 0.1, blue: 0.6}, target: {""0"": 0.95, ""1"": 0.05}}
    

• Has anyone ever faced something similar?

• Do you think this process will yield a lower model accuracy with respect to having direct data access?

• How would you tackle this problem?

The first thing I thought about is to generate some synthetic data from the YAML file in order to detect bugs sooner. Using these data will not tell me anything about data relationships, but at least it will lower the chance of receiving an error message due to a ""stupid"" bug.

Feature engineering puzzles me. First thing that comes to mind is brute force. On second thought, maybe I can guess some relationships from column names (tough). What else?",2022-01-10 19:59:07
Could/should Javascript have been the defacto DS language?,0,s0ny2w,https://www.reddit.com/r/datascience/comments/s0ny2w/couldshould_javascript_have_been_the_defacto_ds/,17,1641832070.0,"Specifically, I (possibly naively) wish Python didn't exist and Javascript was used in it's place, but this might be misguided, so I am here to ask for counter arguments. And by Javascript I mean Javascript with a runtime like Node or Deno. 

But why Javascript? Visualisation is a large part of data science, and most libraries seem to use web technologies under the hood, for good reason, since web technologies are powerful and mature, and make sharing visualiations over the web easy. While most libraries provide a Python wrapper which will be sufficient in many cases, I often find it easier to work directly in Javascript, especially when the end product is a dashboard or entire website, rather than a single chart.

In my limited understanding, Javascript is similar enough to Python that it could be used for Data Science in place of Python. The main points/similarities being:

* It has a short, simple, easy to learn syntax which doesn't require annotating types.
* The language itself is not that fast but can easily call C/C++ libraries for the computationally intensive tasks required in DS.
* A flexible, multi-paradigm language which allows libraries to provide an easy to use API without much cermony and boilerplate.
* A REPL.

The difference is that where (to me) it seems Javascript could be used in place of Python for DS, Python could not have been used in place of Javascript as the web browser language, since it is blocking/doesn't run in an event loop like Python. Javascript was purpose built for web browsers. Python was not purpose built for DS.

To me the only reason Python is used for DS is because of it's first mover advantage and the huge third party library ecosystem. Many languages are popular more because mostly because of their ecosystem, and that's fine, I don't expect this to change, but it is just annonying that it seems just Javascript could be used where instead we need to use Python and Javascript. I know people will argue that multiple programming languages are inevitable and you should pick the right tool for the job etc, and I agree, but having to use two languages simultaneously is much more inefficient. Learning the languages themselves is not so bad, but having to learn two different ecosystems, and constantly switch between the languages and remeber the different APIs has a large impact on productivity, for me at least. This is compounded by the fact that Data Scientists are often not the most experienced programmers, where much of the training and experience is dedicated to analysis, rather than simply programming like a developer.

I could make similar, but admitedly less convincing, arguments for Rust replacing the entire C/C++, Python, Javascript Data Science stack but that should be a separate post.",2022-01-10 18:27:50
How to present small size of inference data to a client?,2,s0lhw2,https://www.reddit.com/r/datascience/comments/s0lhw2/how_to_present_small_size_of_inference_data_to_a/,6,1641825528.0,"I am a data scientist. Time to time I represent reports to the clients.

My company has a working model. But, for a specific client, we may have 100-200 data points for inference. Of course, the clients are asking ""is this even a useful analysis? You know it's done based on so small number of data""

I am telling them you can read the findings of the report cautiously. It still has a value. It can be a supplemental argument for another analysis. If you have no idea about what is happening, this analysis still gives a snapshot. We just need to be aware of the weakness. 

How would you sell a report created by a small number of data such as 200 data points?

What would be your potential selling points?",2022-01-10 16:38:48
Don't Look Up pierced my soul,976,s0kndc,https://i.redd.it/pmmw4fyq9va81.jpg,45,1641823213.0,,2022-01-10 16:00:13
Do any data science teams work by taking tasks from a queue?,5,s0kkbf,https://www.reddit.com/r/datascience/comments/s0kkbf/do_any_data_science_teams_work_by_taking_tasks/,6,1641822958.0,"I know there are some engineers, developers, and designers who work by having team members be assigned tasks from a queue system like Jira. Do any data science teams operate like this?",2022-01-10 15:55:58
Meme,0,s0kcgd,https://twitter.com/moderndatastack/status/1478739733308010497/photo/1,0,1641822278.0,,2022-01-10 15:44:38
"In your opinion, what social media platform has the best recommendation/ matching algorithm and why? Do you have any insight into how this works and what sort of data is required for it?",0,s0ikjv,https://www.reddit.com/r/datascience/comments/s0ikjv/in_your_opinion_what_social_media_platform_has/,3,1641816330.0,Also any other nifty applications of data science by social media platforms are also welcome.,2022-01-10 14:05:30
Best way to upskill a DS team?,6,s0gy73,https://www.reddit.com/r/datascience/comments/s0gy73/best_way_to_upskill_a_ds_team/,8,1641810351.0,"Hi all,

I’m looking into different options for upskilling a relatively small team of data scientists. The idea is to provide a general set of flexible options (allowing them to forge their own path to some extent) and to facilitate their transition from Jnr DS > DS > Snr DS. 

I really like the Coursera platform and have personally used it in the past, but I’m also aware that there are a multitude of other options (e.g. Cloud Academy). Does anyone have experience of using any of these platforms in an enterprise context? Do people actually engage with them if given a personal training allowance?

Cheers! :)",2022-01-10 12:25:51
2022 Mood,1460,s0dn5b,https://i.redd.it/s7olw2f01ra81.jpg,90,1641797504.0,,2022-01-10 08:51:44
"Free reliable, global, easily update-able data",0,s0cqct,https://www.reddit.com/r/datascience/comments/s0cqct/free_reliable_global_easily_updateable_data/,2,1641794405.0,"I want to create a predictive tool that could be useful to the most number of people. Weather prediction for example. 
Are there free, reliable, global data that I can start exploring ? I don’t want to narrow my scope by industry to begin with.",2022-01-10 08:00:05
Literary Works sorted by closest matching Story Template?,1,s07ig2,/r/AskLiteraryStudies/comments/rziroj/literary_works_sorted_by_closest_matching_story/,0,1641778531.0,,2022-01-10 03:35:31
ML/AI freelancer ?,22,s05w4m,https://www.reddit.com/r/datascience/comments/s05w4m/mlai_freelancer/,15,1641773962.0,"Anyone here working full time / part time as ML/AI freelancer? I have some questions if you would like to share:
1. Networking is important for freelancing, how did you build your network? Comment if otherwise
2. How matured is the freelancing business with respect to ml?
3. How difficult/easy it is to maintain stable income?
4. Do you suggest team up with some developer to increase chances for projects?
5. Is freelancing worth leaving stable job?
6. Any suggestions for new freelancer?

For my background:
I have 7 years of experience working at FAANG in ml domain and would like to venture into freelancing. I can start with small projects (15-20 hrs a week), then scale. My problem is lack of networking and visibility into freelancing. Any help would be appreciated.",2022-01-10 02:19:22
Time management in ML projects,10,s04fpb,https://www.reddit.com/r/datascience/comments/s04fpb/time_management_in_ml_projects/,4,1641770005.0,"Hi fellow data scientists,

I'm someone with 2 to 3 years DS experience, and have been working in commercial organizations (banking and retail)

Straight to the point, what's the best strategy for setting time expectations on projects? I have to set up jira stories for ML model improvements and so far it has been a disaster. The project was handed over to me by another employee who left the firm and I find that every time I set up an expected time duration for a task, I really cannot get it done in time. I've been very good at time management for engineering tasks, but when it comes to ML models there is so much unexpected stuff going on (crappy data, really crappy results causing me to redo the modeling by adjusting data sources or model assumptions... Rinse and repeat). Due to data size and other issues it takes around 1/2 days to repeat an experiment, but there is no telling what the outcome is or even if I can improve the model in any significant manner. My anxiety levels are over the roof. My boss is a nice guy but he is over optimistic about this model (can't blame him, he has invested a lot on this and it's too big to fail now)

So, in summary how to set up time expectations for ML Projects and hot do strategically deal with non performant models given deadlines?",2022-01-10 01:13:25
Help! Did anyone try fitting models to experimental results using the Symfit python package?,1,s03icc,https://www.reddit.com/r/datascience/comments/s03icc/help_did_anyone_try_fitting_models_to/,0,1641767513.0,"I have been hitting my head on this one for a while. I am trying to fit an ODE model to some experimental results with no success. After reading much, [Symfit](https://symfit.readthedocs.io/en/stable/index.html) seems to be the best python package for the job but still not getting the results I am looking for.

[Here is also the SO question](https://stackoverflow.com/questions/70615240/cant-get-the-correct-parameter-fit-for-a-system-of-odes-using-symfit-and-some-e?noredirect=1#comment124852464_70615240) I posted a couple of days ago if anyone feels like giving it a try.",2022-01-10 00:31:53
Automatic Wordle solving,0,s01cje,https://www.reddit.com/r/datascience/comments/s01cje/automatic_wordle_solving/,4,1641761861.0,"People are looking into solving Wordle algorithmically ([https://medium.com/@yotamyachmoorgafni/automatic-wordle-solving-a305954b746e](https://medium.com/@yotamyachmoorgafni/automatic-wordle-solving-a305954b746e))

Does anyone know of a solution that solves the hard-mode? Any interesting implementations?",2022-01-09 22:57:41
Topological DA for Network neuroscience and clinical psychology - Material,5,rzzw95,https://www.reddit.com/r/datascience/comments/rzzw95/topological_da_for_network_neuroscience_and/,2,1641757998.0,"***Please suggest to me some good places to learn TDA from scratch.***

&#x200B;

I am interested in using Topological DA to study neurological conditions such as classifying autistic subjects from typically developing ones, clustering students having anxiety, assessing psychosis in a community, or detecting depression from audio clips.

Using this method, we can gain insights into the working of various  
brain regions, for example, how we encode our position in space, how the motor cortex prepares and executes a movement, how to understand the representation of abstraction and  
generalization brain. TDA can apply this in researching how inhibitory and excitatory signals that originated in the brain are related. It has already been used to signify how direction is perceived in our brain. As we would imagine the data to be one dimensional, i.e., dependent on one variable, the research confirmed this. Since the topology is about how things are connected and where the gaps are.TDA is well suited for neuroscience, especially analyses involving connectivity networks. TDA can capture global and higher dimensional features where other methods such as graph theory fail.  
 Some pioneering work has shown that topological features extracted from EEG signals reveal relevant information for various neurological disorders.",2022-01-09 21:53:18
Data experts are becoming football best signings,3,rzzoyk,https://www.bbc.com/news/business-56164159,1,1641757441.0,,2022-01-09 21:44:01
6 interview + 8 hour take home assignment for a job lol,6,rzy7qx,https://www.reddit.com/r/datascience/comments/rzy7qx/6_interview_8_hour_take_home_assignment_for_a_job/,38,1641753575.0,Received an offer but I had to do a take home assignment and 6 interviews with a total of 8 different team members to get a DS job in a scale-up. Is this unusual?,2022-01-09 20:39:35
How do you decide when a model just isn't going to work?,8,rzv0if,https://www.reddit.com/r/datascience/comments/rzv0if/how_do_you_decide_when_a_model_just_isnt_going_to/,20,1641744853.0,"I feel like this is asking an artist how they know when they are finished with an art piece...""you just know."" But I'm genuinely curious about this. 

For example., I'm working on a model that's severely imbalanced (94%/6%). At first, I was excited because the accuracy was great...well duh, because it could technically predict 100% ""no's"" and still be 94% accurate. But the confusion matrix, precision and recall, and ROC score are all pretty terrible,  I messed with the threshold, and in order to get TP even close to correct, I have to lower it to .05....which means I get a crazy amount of FP. I tried logistic regression,  Decision Tree and Random Forest, as well as XGBoost (I also adjusted parameters such as max\_depth, etc. on all of these and selected the parameters by creating a list of the different AUC results, for example ). I tried upsampling and downsampling and am fixing to try SMOTE. Getting more data is out of the question. When I output the results on my test set, I either get 98% ""yes"" or 0% yes.

Which is what brought me here. I feel like what I'm trying to predict just can't be predicted with the data we have. Problem is, I'm a team of 1, so I have nobody to bounce this off of. 

So how do you decide that a project just probably isn't going to work out?",2022-01-09 18:14:13
Advice on Anxiety Issues as a Coder and a Data Analyst,324,rztoqy,https://www.reddit.com/r/datascience/comments/rztoqy/advice_on_anxiety_issues_as_a_coder_and_a_data/,163,1641741070.0,"I am a data analyst with less than a year of experience. Ever since I started working, I realized that my anxiety is very easily triggered and it is causing me issues professionally and in my own learning journey. 

For example, even while solving minor issues, I tend to get tunnel vision, preventing me from analyzing all available info, which leads to me asking for help from teammates unnecessarily. This happens much more when working on new environments or tools.

When I self-study, I find myself filled with nervous energy with my brain jumping around causing me a whole lot of panic and not a lot of learning. 

It also pops up when I am trying to quickly process information or when I am put under the spotlight. Once panic gets triggered, I lose focus and make ditzy errors. 

I have had these problems since forever but never really thought much about them, I just thought I was dumb or something. But I feel I am not dumb, these traits are limiting me. Especially now when I am trying to give my 100% throughout the day.

Following things have helped a bit, but I still have a long way to go,

1. Taking a mental break. When I start to panic and tunnel vision, thinking about some random thread for a while and coming back helps a lot. Even if only momentary.
2. Writing. I find describing the error, and the coding I have up to that point, in writing, usually helps center myself a bit.  
3. Mindfulness. Taking a moment to myself when I start to feel like I am losing it.

I wanted to ask whether any of you have or do feel the same, and what you all do about it.",2022-01-09 17:11:10
Weekly Entering & Transitioning Thread | 09 Jan 2022 - 16 Jan 2022,11,rzq7px,https://www.reddit.com/r/datascience/comments/rzq7px/weekly_entering_transitioning_thread_09_jan_2022/,171,1641729630.0,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",2022-01-09 14:00:30
Why learn SQL for ML tasks,7,rzmder,https://www.reddit.com/r/datascience/comments/rzmder/why_learn_sql_for_ml_tasks/,24,1641713793.0,"Should I learn SQL? I mainly do ML tasks and often the data is in the form of things like Numpy arrays, Panda Dataframes, or PyTorch Dataloaders. So why learn SQL? 

Most internship/job apps say you should have some SQL experience.",2022-01-09 09:36:33
How do you keep up-to-date with emerging tech and methodologies?,1,rzcr4w,https://www.reddit.com/r/datascience/comments/rzcr4w/how_do_you_keep_uptodate_with_emerging_tech_and/,10,1641683158.0,"I have a data science degree but I'm I'm working as a data engineer at the moment. While I kind of enjoy the work better than just data science, I don't want to fall behind in keeping up-to-date with the latest advancements, techniques, and methods in the data science field.

What resources do you guys use to keep your knowledge up-to-date?

Links or specific resources is highly appreciated.",2022-01-09 01:05:58
Are there any online journals for data science that don't have publishing fees?,1,rzbwqu,https://www.reddit.com/r/datascience/comments/rzbwqu/are_there_any_online_journals_for_data_science/,1,1641680987.0,And aren't predatory,2022-01-09 00:29:47
Best OS for Data Science + Analytics?,3,rz91ld,https://www.reddit.com/r/datascience/comments/rz91ld/best_os_for_data_science_analytics/,18,1641673416.0,"Hi all,

About to accept an analytics developer position at a Salesforce consulting company – mainly using SQL, Hadoop, G-Suite (Chrome and tie-ins), Tableau, and Tableau CRM with a touch of Python/R here and there. To contrast, in my current role I went with windows mostly for Excel macros and integration with explorer. At the new company I have the option to choose between windows 10 and macOS (intel mac though). I'm fully versed in both OS.

Any thoughts on which would be most appropriate? Some of the companies we consult to might not use macs and likely have CRM data in excel.",2022-01-08 22:23:36
Excel pivot table for 100k rows?,0,rz6szq,https://www.reddit.com/r/datascience/comments/rz6szq/excel_pivot_table_for_100k_rows/,20,1641667652.0,"I’m trying to analyze some data with 100k rows and only 5 columns but inserting a pivot table is taking 5-10 minutes just to process and take me to the pivot table sheet. 

Is this normal or is my computer messed up? I have 16 gb ram.",2022-01-08 20:47:32
How should constant ad-hoc requests be handled by a data science team?,116,rz27tq,https://www.reddit.com/r/datascience/comments/rz27tq/how_should_constant_adhoc_requests_be_handled_by/,54,1641655429.0,"In one of my old jobs, I found that it was hard to make progress on various projects when I would receive a ton of emails from various teams asking different questions about data we were receiving, or asking to pull data from a specific resource.  It was one of the big reasons why I switched into a more engineering-focused job.




Do you think these requests should be handled by a specialized team, or should responsibility be shared across a data science organization?",2022-01-08 17:23:49
The PyMC devs have made their book available free online!,38,rz1rqs,https://bayesiancomputationbook.com/welcome.html,1,1641654187.0,,2022-01-08 17:03:07
Does anyone else get imposter syndrome about their role vs the 1% of data science?,300,ryzzbr,https://www.reddit.com/r/datascience/comments/ryzzbr/does_anyone_else_get_imposter_syndrome_about/,53,1641648874.0,"Been thinking about this after a couple of chats in this subreddit this week. I’m a senior/lead DS and I would say 70% of my job is pretty much analytics with a spin. Wrangling data that pure SQL analysts can’t get, maybe performing hypothesis testing if it’s sampled. Once a quarter there’s a “big” ML project, but even that is usually used for insight/internal monitoring &amp; reporting. 

I think i got into DS to build ML led software that changes experiences for millions of people. After doing several interviews recently, I’ve kinda realised barely anyone is doing that. Hence, why calling it the 1%. Obviously, selection bias here with who I’m interviewing with, but I tried to select across the spectrum of startup to big tech to Fortune 500 corporate. 

On paper, I’m probably in the 1%: truly “big data”, big tech, cloud infra, read academic papers on NNs to keep up to date, do get to play with ML. However I don’t feel like I’m in whatever people decided was the “sexiest job of the 21st century”. Where the imposter syndrome kicks in is like… have I just interpreted the job wrong. Am I doing the job wrong now and at my previous places? Is everyone else out there building Le Cun style things from scratch and deploying to millions &amp; it’s just me?

I love it, don’t get me wrong, but I feel like most people are doing analytics with flavour. What do you all reckon? Am I interviewing in the wrong places? Am I talking rubbish?

Edit: should add, been in data since before _that job article_, I’ve done the FAANG bit. This isn’t a comment on one job, but more what I’ve seen since the early-2010s.",2022-01-08 15:34:34
Advice as an Applied Physics Senior,1,ryrf2f,https://www.reddit.com/r/datascience/comments/ryrf2f/advice_as_an_applied_physics_senior/,5,1641616476.0,"I'm almost done with my BA in Applied Physics. Along the way I've touched a bit of Python, used R once, and used A LOT of excel in lab work. What would anyone think my next steps are to get closer to landing at a minimum an entry level data science job? I've heard a lot about bootcamps and certificates from Google/IBM, but I've always thought experience is better. Would maybe pursuing a MSDA be worth it? 

Another thing, I've posted on other subreddits about advice for pursuing possible careers. I know how marketable a degree in physics can be, and I'm not quite ready to put all my eggs in one basket quite yet. I've nailed it down to between data or medical physics (leaning towards data because I'm starting to get sick and tired of deriving equations, always enjoyed the analysis that comes after work in labs).

&#x200B;

Any advice would be appreciated!",2022-01-08 06:34:36
What are some fields or subjects where Operations Research & ML overlap?,6,ryonzu,https://www.reddit.com/r/datascience/comments/ryonzu/what_are_some_fields_or_subjects_where_operations/,9,1641607830.0,"I notice a lot of people get their PhDs in OR and go work in DS at a big company like Google. I still don’t really understand the explicit intersection of these two skill sets though. It makes sense to me that ML/DS skills can allow you to draw conclusions from data that can then be fed into decision making models, but are there any fields where these two fields directly intersect? Why do companies seem to value this combination?",2022-01-08 04:10:30
"It finally happened, I was asked a brain teaser for my interview.",181,ryo5xr,https://www.reddit.com/r/datascience/comments/ryo5xr/it_finally_happened_i_was_asked_a_brain_teaser/,119,1641606387.0,"I kept hearing about these questions getting asked for Data Science interviews but never experienced myself. I didn't want to lol. But now, I finally have.

I was quite happy with live coding, statistics, ML+business case studies.

What is the point of the brain teaser? Honestly? How can you assess a candidate this way or are you more interested in how they behave when you ask this question?

I am more surprised I was asked this brain teaser and barely any questions about my statistics/ML knowledge. Maybe I was interviewed for shits and giggles. Maybe this belongs in recruitinghell.

Example: How many petrol stations are there in the UK? How many piano tuners are there in Chicago?

Edit: Many people have pointed that this is not a brain -teaser but a Fermi problem or guestimate types of problems.

My two cents:

Edit 2: Thanks everyone for the responses and going into detail about why such questions are asked. I have no reason to argue against these questions being asked but I do think when an interviewer asks this then they should do it well. The beauty of data science is that it is multidisciplinary  and questions like this can be costly for candidates coming from non-traditional backgrounds who may not have been exposed to this way of thinking.

I am not a non-traditional candidate. I have had math/stat classes that asked these but just got thrown off it being asked an interview. I think if an interviewer asks this question then be prepared for the candidate to ask questions and share their thought process. Be clear if you want them to reach an estimate and give you a number.

Edit 3: For those asking, I recently got a rejection. Yaay Saturday!  I don't think it had to do with this Fermi approximation problem though. Let's see if I get any feedback, haha.",2022-01-08 03:46:27
"Data pipeline - alternatives to database table reinsertion for large, post-processed dataset",3,rynt8i,https://www.reddit.com/r/datascience/comments/rynt8i/data_pipeline_alternatives_to_database_table/,8,1641605333.0,"I have a dataset of millions of transactions that I am pulling from multiple data tables. I handle the data query, merge, cleaning & processing in Python when I run a ML script.

Now I also need a way to have the processed data accessible for a BI dashboard. The direct way I can think of is inserting the data back into a data table, but I'm wondering if there are better ways to do this?

1. I'm not sure whether dashboards like Tableau can be set up to read in a Pickle file from a remote server directory but if it's possible this would be easy since my current process exports the data to a Pickle file.
2. I'm not a data engineer by trade, but my hunch was there should also be a way to run the Python data processing code in a data pipeline that would then store the data in a data table that is accessible to my ML code or the dashboard connection. (The benefit being I wouldn't have to run my ML script to get the processed data).",2022-01-08 03:28:53
Finding Airbnb hosts that are companies by analyzing the host about page.,2,rymaje,https://www.reddit.com/r/datascience/comments/rymaje/finding_airbnb_hosts_that_are_companies_by/,1,1641601006.0,"Hi all,

I have a dataset with Airbnb listings of 32K listings. I want to find out which of these listings are managed by companies of people. For now, I know for a fact that 4K are run by companies and I have their about pages. What I want to do is to analyze the companies' host about pages, find what is similar and then compare other host about pages to theirs to find if they are more similar or not - kinda like fuzzy matching, but more powerful.

How can I do that?",2022-01-08 02:16:46
Tips on cleaning data using Python and Excel ?,1,ryldjc,https://www.reddit.com/r/datascience/comments/ryldjc/tips_on_cleaning_data_using_python_and_excel/,4,1641598547.0,"I was wondering what professional data analysts do when preparing data and cleaning it.

Here is what I currently do:

1- remove duplicates

2-handle Null values

3-melt using pandas to make the table cleaner

4-spot outliers and handle them

What more can I do ?

Also I watched someone remove some fields(columns) because they weren't important enough to include, how do people determine what's important to keep and what's not ?",2022-01-08 01:35:47
Can someone help me understand these courses and what is the difference?,1,ryl94z,https://www.reddit.com/r/datascience/comments/ryl94z/can_someone_help_me_understand_these_courses_and/,3,1641598226.0,"I'm considering a few data (engineering courses) and I only get to pick 3.  I'm trying to understand what the biggest difference between the courses are. Are they just different skillsets a data engineer would do given their industry (bad example, but like supervised learning vs unsupervised learning), or is it more of 'different type' of data engineering specialities (person that focuses on ML vs analytics)? So as I pick which classes to take and where I currently work (Big tech), how do I know which one is most applicable?

&#x200B;

**analytics application Engineering**

 This course covers programming components essential to the development of analytics applications. The focus is analytics software engineering. Students learn to develop desktop and client-server solutions. They learn about web-based solutions employing a variety of front-end and back-end system components. The course introduces machine learning operations and engineering. Students use cloud systems to package and distribute containerized computer software. They develop software, working on open-source programming, database, and systems integration projects. They employ best practices in software development. 

**Analytics systems engineering**

 This course introduces design principles and best practices for implementing large-scale systems for data ingestion, processing, storage, and analytics. Students learn about cloud-based computer architecture and scalable systems for data science. They evaluate performance and resource utilization in batch, interactive, and streaming environments. Students review protocols for application programming interfaces. They compare data models, resource requirements, and performance of applications implemented with relational versus graph database systems. 

&#x200B;

 **Real time Interactive Processing and analytics**

 This course introduces application engineering and analytics within an integrated environment and full-stack development process. Students implement client-side, web-based applications using a model-view-controller framework. They use server-side systems for responding to website requests and database queries. They prepare indices for efficient, relevant search across large document collections. They find information in databases and document collections, make service and product recommendations, and detect anomalies or security violations.  

 **Real-time Stream Processing**

 This course introduces application engineering and analytics within stream and event processing environments. Students learn how to work with various data feeds and sources, including electronic sensors, monitoring continuous processes, observing communication traffic and social interaction, and tracking goods through production and distribution. Students implement stream processing solutions, providing high throughput and low latency. They use relational and graph databases. They analyze event logs and business processes. This is a case study and project-based course with a strong programming component.",2022-01-08 01:30:26
Time series problem,5,rykrgq,https://www.reddit.com/r/datascience/comments/rykrgq/time_series_problem/,12,1641596888.0,"Assess whether Price-trend(from seasonal decompose) measure has accuracy in predicting a binary target variable for future price direction over x days or months time  window.

I am not sure what this means and how to do it. What should be my approach?",2022-01-08 01:08:08
Job Hunting Observation: Area of Expertise Shifts Depending on the Size of the Company,5,rykllj,https://www.reddit.com/r/datascience/comments/rykllj/job_hunting_observation_area_of_expertise_shifts/,1,1641596466.0,"To be specific, in the course of my interviews with different sized firms:

**Smaller Companies Expect Generalists**

know a bit of everything, such as a bit of Data Engineering, Data Science and Software Development. For example, if the Data Scientist reports to Engineering, then they're more likely to do Data Engineering/Analytics Engineering and less Data Science role. If the Data Scientist reports to Business/Product, then they're more likely to do Data Analytics/Dashboarding role. However, in both cases, because either the Data Science department doesn't exist or because they have an immature Data team, there's little room to explore more Data Science activities such as experimentation, applied machine learning, or R&D. Being a specialist puts one in a disadvantage because it takes a while to acquire all those additional skills.

**Larger Companies Expect Specialists**

Must be a domain expert for the role one is applying to. For example, technical questions revolve around depth of understanding of the mathematics/algorithms for testing or Machine Learning models. Clearer path for R&D and specialization, but being pigeonholed is definitely a concern (makes it harder to look for other jobs as you are too specialized in a field and focused on a specific skillset). Tough for generalists to enter because they need time to learn certain concepts more in-depth and lack of deep experience in the field may hinder one's application.

**Caveat**

Of course, this is all based on answers by the interviewer when I asked how their Data Science team is structured. So take my observation with a grain of salt.

Given your work environment, do these observations reflect the state of your current organization?",2022-01-08 01:01:06
Best resources for applying DS in business?,9,ryjbqd,https://www.reddit.com/r/datascience/comments/ryjbqd/best_resources_for_applying_ds_in_business/,2,1641593110.0,I was just hired as a Senior Data Scientist at a smaller company. What are your favorite resources (books/websites/etc.) for the questions you have about DS when applying it to business?,2022-01-08 00:05:10
Non-obvious Best Practices?,18,ryhr6l,https://www.reddit.com/r/datascience/comments/ryhr6l/nonobvious_best_practices/,20,1641589134.0,"Context: Former biochemist that starting doing computational bio and is now a data scientist in computer vision. I've learned a lot of things along this unconventional path but have likely missed a lot as well. For example, a coworker today asked for me to change all of my variables to lowerCamelCase which I had never heard of. This took me down a rabbit-hole of finding and reading through PEP8 and trying but failing to get a flake8 linter working on the jupyterlab version I am stuck with on GCP. 

&#x200B;

Question: What are the non-ML related best practices I should be aware of? I at least know what I don't know about certain types of models and I know how to learn more about them, but before today I would never have thought to look into industry standards on where to put spaces. Any resources would be greatly appreciated!",2022-01-07 22:58:54
Good resources on switching from DS to MLE?,87,ryb8zh,https://www.reddit.com/r/datascience/comments/ryb8zh/good_resources_on_switching_from_ds_to_mle/,43,1641572685.0,"Background: BS in math/stats, masters in ops research. Working as a DS for 6 months now. Some experience in software development (wasn't very in depth, I did it for a research project in my undergrad where I built a program for archeologists to use). Have done some small projects here and there like analyzing data from Spotify's API

I have come to realize I dislike the business focus of DS and would rather focus my efforts on the engineering side of the discipline. What tools should be in an MLE toolkit? What are the differences in responsibilities between DS and MLE? Is there a straightforward path to switch from DS to MLE?

Thanks.",2022-01-07 18:24:45
"What would be some real world scenarios where we can use Plotly and Dash over Excel or Advanced Visualization Tools like Tableau, IBM Cognos?",1,ry9m9i,https://www.reddit.com/r/datascience/comments/ry9m9i/what_would_be_some_real_world_scenarios_where_we/,11,1641568417.0," I worked with different charts, visualization and Dashboards that were created in Excel and IBM Cognos, which weren't just visually appealing but also quite flexible and easy to use. 

However, creating the same dashboards in Dash with python would take hundreds of lines of codes. One example would be creating the **waffle chart** in Plotly without using the recently created library: ""**PyWaffle**"", would take lots of efforts. 

&#x200B;

*P.S I don't mean any discredit to Plotly or Dash. Just curious if someone uses it differently or in particular scenario.*",2022-01-07 17:13:37
[Off Topic] Who among you are into couponing?,0,ry968n,https://www.reddit.com/r/datascience/comments/ry968n/off_topic_who_among_you_are_into_couponing/,5,1641567269.0,"Kinda of a weird questions. Being an aspiring DA and getting into couponing is a nightmare! Ordering food literally takes 1 hour of getting back and forth. I caught myself googling ""difference in ounces of meat in leg piece and breast piece of friend chicken."" while thinking maybe I should look into creating a pipeline and using the review of restaurants as a basis of a food ordering model....
But how else can you make an optimum decision when there is multiple different discounts. I thought graphing prices, review, taste, ounces of food would be nice.....

I am hungry, stingy and miserable.",2022-01-07 16:54:29
Questions for freelancers,8,ry8qia,https://www.reddit.com/r/datascience/comments/ry8qia/questions_for_freelancers/,3,1641566056.0,"I'm considering shifting from a large established team to a project-based/freelance style of working.  I'm trying to wrap my head around what this would actually look like.  If you've done freelance DS work, I'm curious:

1. What was the ask/goal of your project?  Was it a one-time question or something that needed to be answered on an ongoing basis as new data came in?
2. What was your project deliverable?
3. What was your experience with this kind of work?  Did you enjoy it?  What was hard about it?

Thank you for your help",2022-01-07 16:34:16
Coding language for front end interface and user interaction?,0,ry73js,https://www.reddit.com/r/datascience/comments/ry73js/coding_language_for_front_end_interface_and_user/,5,1641561200.0,"My understanding is that Python is best for the data processing and ML engineering aspect of DS, but what about the regular SWE side of bringing a DS application to users/stakeholders? Should I use a language like Java for this?

Thanks.",2022-01-07 15:13:20
Top 15 Data Science Trends and Predictions For 2022,0,ry3l25,https://bigdataanalyticsnews.com/top-data-science-trends-predictions/,0,1641547790.0,,2022-01-07 11:29:50
numbers of training dataset vs number of independent variables,0,ry2p7y,https://www.reddit.com/r/datascience/comments/ry2p7y/numbers_of_training_dataset_vs_number_of/,1,1641544214.0,"Understand you should have 10 training data for every 1 independent variable, 

is dummy variables from a categorical variable consider as 1 independent variable, or does each of the dummy variables consider as a new independent variable?",2022-01-07 10:30:14
DATACAMP & Data Leakage Practices,3,ry27fk,https://www.reddit.com/r/datascience/comments/ry27fk/datacamp_data_leakage_practices/,13,1641542251.0,"I must be going crazy. 

Anyone take Datacamp courses and do projects? 

So quite a lot of projects and courses actually apply data preprocessing techniques before splitting data that encourage data leakage. 

I can't believe I paid for their services......

Anyone catch other bad habits that Datacamp encourages?",2022-01-07 09:57:31
The (right) amount of domain knowledge for DS,1,ry26ti,https://www.reddit.com/r/datascience/comments/ry26ti/the_right_amount_of_domain_knowledge_for_ds/,13,1641542177.0,"Hi guys, one of the pros of being a data scientist is that you are somewhat versatile and may work on different domains.

I am realizing however how important is domain knowledge in extracting something valuable from your data, especially in small teams, where you may not be backed up by data analysts and other colleagues.

On one hand, it seems obvious that \*some\* domain knowledge is required, on the other hand, the high demand of domain knowledge required may actually be due to other reasons (e.g. a mismatch in your role or, data readiness...).

Any story to share about this?",2022-01-07 09:56:17
Non profit jobs for data scientists?,6,ry1ybu,https://www.reddit.com/r/datascience/comments/ry1ybu/non_profit_jobs_for_data_scientists/,20,1641541202.0,"I just graduated with a BA in sociology and music, and I really love research and data and want to make a career out of it. I’m eventually looking to get a masters in data analytics and then hopefully a doctorate in sociology but when I read about data science and analytics, there seems to be a large focus on business and big tech, and I know those fields would make me miserable, I’m much more into non profit work and social services. Are there any careers for data scientists in those fields or should I be looking into a different education path?",2022-01-07 09:40:02
Power BI/Tableau vs. Python dashboards,0,ry1hh9,https://www.reddit.com/r/datascience/comments/ry1hh9/power_bitableau_vs_python_dashboards/,5,1641539341.0,When should you use each one? Which one is the common in companies right now?,2022-01-07 09:09:01
"Offered a job titled “graph knowledge scientist”, don’t understand what it is",8,ry103z,https://www.reddit.com/r/datascience/comments/ry103z/offered_a_job_titled_graph_knowledge_scientist/,4,1641537519.0,"Hi, I have been working as a data scientist for about a year, and I hold knowledge in statistics (holds a master’s). I took a class in algorithms and data structures but I am not an algorithmic researcher by no means.

A representative of a small startup in the healthcare domaine that deals with medical texts approached me and said that they are looking for a “knowledge graph scientist/ontology specialist”. They are looking for someone to build their knowledge graph, test it using automated test (and build the tests and apis) and support the data scientists. The team is now being established, and the data scientists they are recruiting are much more experienced than I am (4+ years). 

My main goal is to learn as much as I can in the field, and try to lean towards nlp, I don’t really care about the domain.

Even though they offered me a really good price for my time, I am having doubts.

I know the saying that in startups everybody does everything, but I couldn’t get an understanding from the conversation I had with the cto of the company what ml tasks are expected of me, and I couldn’t find a clear description on how much ML the position involves.",2022-01-07 08:38:39
EEG headband microvolts to frequencies,0,rxzj4a,https://www.reddit.com/r/datascience/comments/rxzj4a/eeg_headband_microvolts_to_frequencies/,2,1641532559.0,"HI people, so I'm testing this muse 2 headband, it's an EEG device that has four sensors, where you can get the raw microvolts data each sensor produces using a javascript library.  I would like to know if you people can give me a bit of guidance as I'm fairly new with data analysis and neuroscience and I'm working on a cool app that needs to process the EEG data.

Basically, I want to get the alpha, beta, and gamma frequencies bands but I only have the microvolts read by the 4 sensors of my EEG headband. 

According to what I have read, I need to use fast Fourier transformation to obtain a set of frequency bands... but how do I feed the data, and if you have a javascript library you would advise using that's going to be brilliant :D 

let me know",2022-01-07 07:15:59
"Trying to get into data science, degree paths and certifications seem confusing.",1,rxzaiv,https://www.reddit.com/r/datascience/comments/rxzaiv/trying_to_get_into_data_science_degree_paths_and/,4,1641531795.0,"Help.  Haha. IDK what degree or certifications I need to pursue in order to land a position using data to drive more sales or leveraging data to do any kind of marketing. It's the most fun for me. 

I'm currently full time in sales,  I have a gi bill I can use. Need to know what path would get me there without taking away too many hours of the day.",2022-01-07 07:03:15
school cs curriculum,1,rxyxli,https://www.reddit.com/r/datascience/comments/rxyxli/school_cs_curriculum/,0,1641530717.0,"I am wondering if the following classes are important for data science, I am debating replacing these with other ones. If they aren't what other classes should i take, so far i have taken discrete math, probs and stats for cs, programming 1 and 2, computer hardware and data structures and algos. Also I'm a specialization in stats, so no need to add more statistics class, cs is my minor.

**COMP 354**     ***Introduction to Software Engineering*** (4 credits)Prerequisite: COMP 352; ENCS 282. Software development process models (e.g. linear vs. iterative). Project management; roles, activities and deliverables for each software life cycle phase. Requirements management: analysis, elicitation, and scope. Architecture, design and the mapping of requirements to design and design to implementation. Traceability. Software quality assurance: verification, validation and the role of testing. Maintenance and evolution. Project. Lectures: three hours per week. Tutorial: one hour per week. Laboratory: two hours per week.

&#x200B;

**COMP 346**     ***Operating Systems*** (4 credits)Prerequisite: COMP 228 or SOEN 228; COMP 352. Fundamentals of operating system functionalities, design and implementation. Multiprogramming: processes and threads, context switching, queuing models and scheduling. Interprocess communication and synchronization. Principles of concurrency. Synchronization primitives. Deadlock detection and recovery, prevention and avoidance schemes. Memory management. Device management. File systems. Protection models and schemes. Lectures: three hours per week. Tutorial: one hour per week. Laboratory: two hours per week.

&#x200B;

**COMP 335**     ***Introduction to Theoretical Computer Science*** (3 credits)Prerequisite: COMP 232 or COEN 231; COMP 249 or COEN 244. Finite state automata and regular languages. Push-down automata and context-free languages. Pumping lemmas. Applications to parsing. Turing machines. Unde­cidability and decidability. Lectures: three hours per week. Tutorial: one hour per week.",2022-01-07 06:45:17
Looking for HPC help,0,rxyit9,https://www.reddit.com/r/datascience/comments/rxyit9/looking_for_hpc_help/,2,1641529444.0,"I am trying to learn to use my organizations HPCs and the documentation, when written, is poorly written. Some script examples in our HPC documentation are just plain wrong. Even after 5 years of Python scripting (on a Windows OS), this HPC business is an entirely different game. I know that each and every HPC is its own special thing, but I am running out of places to turn to. My background is in the natural sciences, and I haven't had the traditional education that many DS / ML experts have. That is, I might not know of some obvious reference material. I thought I should ask for help.

The HPCs in question are run by Linux command line. No problem there; GIT Bash it is. For what it's worth, the documentation has me downloading and installing Miniconda. That's not a big deal either. I want to use the mpi4py Python library as a wrapper for MPI to run parallelized code across the clusters. Running a *pip install* for mpi4py isn't a problem and I can easily enough parallelize my scripts. 

The problem I am having regards figuring out which HPC modules (that is, not the Python modules/libraries but modules for the HPC itself) I need to install and load. Between only having a couple hundred hours on anything Linux and never having logged into an HPC before a couple months ago, I have no idea which modules I need to run ML Python scripts. I've tried asking the HPC staff for help, but they don't respond to my emails.

Does generic Linux HPC documentation exist? Can someone point me toward some reference material? Or is every HPC just too different to have generic documentation?",2022-01-07 06:24:04
Portfolio projects,4,rxxsuy,https://www.reddit.com/r/datascience/comments/rxxsuy/portfolio_projects/,4,1641527272.0,"Hi everyone.

I am a MSCS student and looking for some data science project ideas for my resume. I wanna get into data science so I am planning to apply to summer internships. As I dont have any prior experience I’ll need some projects for my resume. Any suggestions?",2022-01-07 05:47:52
Masters in Data Science or in Artificial Intelligence?,0,rxvsab,https://www.reddit.com/r/datascience/comments/rxvsab/masters_in_data_science_or_in_artificial/,4,1641521476.0,"I am a Masters student. We have to decide whether to go for a specialization in Data Science or in AI, in our M.Tech(Computer Science) program.

Location: India.

Subjects:

DATA SCIENCE:
1. Data Mining and Warehousing
2. Data Visualizations with R
3. Big Data Analytics
4. Cryptography and Network Security
5. Capstone Project

ARTIFICIAL INTELLIGENCE:
1. Artificial Intelligence
2. Natural Language Processing
3. Image and Vision Processing
4. AI for IoT
5. Reinforcement Learning

(These are the specialization-specific subjects. Rest subjects are common to both and I haven't mentioned them here.)

Doubts:

1. I've heard, and seen from job boards that Data Science is hot - there are a lot of jobs. What kind of similar entry-level jobs are there that are AI-specific?

2. My interest is in Computer Vision. But getting a job right now is also a priority. How easy/difficult is it in India (location not an issue) to get started as a Computer Vision Engineer or a Machine Learning Engineer, *for a Masters graduate with no prior full-time work experience*?

Thanks!

PS: ABOUT ME:
Pursuing M.Tech(Computer Science) with specialization in <undecided>,
good hands-on knowledge, 
above average CGPA, 
about to get AWS SAA certification (my first cloud certification), 
completed one research internship in machine learning, 
good grasp over English (IELTS Academic 8.0/9.0),
quick learner.

TLDR: Which is better between Data Science and AI, for specialization during Masters, from purely an employment perspective?",2022-01-07 04:11:16
DS to DE folks and DE to DS folks. Why are you switching?,19,rxv8br,https://www.reddit.com/r/datascience/comments/rxv8br/ds_to_de_folks_and_de_to_ds_folks_why_are_you/,21,1641519944.0,"For anyone that is switching is it aspiring to be one over the other, I’m curious to know why you are switching.  Am considering the switch from DS to DE do just want to hear thoughts. What work were you trying to do less vs what work were you trying to do more?",2022-01-07 03:45:44
Bringing Azure ML to and organization,2,rxtr1j,https://www.reddit.com/r/datascience/comments/rxtr1j/bringing_azure_ml_to_and_organization/,0,1641515894.0,"Hello everyone I work for a relatively large organization with thousands of employees, but in terms of technology we are firmly in the early 2010s. I am working with large climate datasets where I am processing very large NetCDF files from my desktop. I am making a case to my boss for us to purchase Azure ML so that I can actually do my job. 

&#x200B;

I'm looking for advice or just anecdotes from people that have introduced this technology to their companies. I'm also looking for any resources people have used to get quickly up to speed with Azure ML. Currently am the sole data scientist at my company, so I don't really have anyone to lean on to learn this. 

&#x200B;

Thanks all!",2022-01-07 02:38:14
"POWER BI - Can I do dual axis chart with two lines, overlaying a bar chart??",0,rxtbjl,https://www.reddit.com/r/datascience/comments/rxtbjl/power_bi_can_i_do_dual_axis_chart_with_two_lines/,5,1641514713.0,"SO far I can get 2/3 but not all.

I am basically trying to plot the bar chart for Covid cases (y) by week (x).

I have this query merged with tables for vaccinations by week and stock closing prices by week.

I would like this:

1. Bar Chart - Total covid cases that week (cases to date)
2. First line - Vaccinations done that week 
3. 2nd line - Stock closing price at the end of that week

Is this possible?

Also, I now realize I shouldn't do total cases to date but RATHER total new cases that week. Is this possible?",2022-01-07 02:18:33
Has 2FA reached overkill?,0,rxqs12,https://www.reddit.com/r/datascience/comments/rxqs12/has_2fa_reached_overkill/,4,1641507999.0,"I use 2FA to log into the VPN, then into the SSO, then for any given AWS role I need for that project. The AWS and most of the SSO logins are frequently expiring and asking me for another authenticator code.

Really just in the last year, I spend a weird amount of my day authenticating logins on my phone. Is it just me or is this also you? Is it too much, or just the new normal we all need to accept? Should I start a revolt?",2022-01-07 00:26:39
Amazon SDE Intern vs JP Morgan Data Science + AI Intern,3,rxpue2,https://www.reddit.com/r/datascience/comments/rxpue2/amazon_sde_intern_vs_jp_morgan_data_science_ai/,6,1641505492.0,"Hi! I'm currently a junior in college and I'm trying to decide between two internship offers for summer 2022. I have an offer from Amazon for a Software Development Engineer internship and an offer from JP Morgan for a Data Science/AI internship. I ultimately want to become a data scientist so I'm leaning towards JP Morgan, but I have some concerns and I would appreciate some advice.

1. I already accepted Amazon's offer back in September. I applied to both Amazon and JP Morgan in August, didn't hear back from JP Morgan so I accepted Amazon. Then, I got an interview with JP Morgan in October and I got the offer in December. So if I take JP Morgan, I would have to renege on Amazon.

2. Amazon has a better location and higher salary. Those aren't a huge concern for the internship but the location would be a plus if I get a full time offer there. However, I've heard bad things about Amazon's culture so I think it would be better to work at JP Morgan full time.

3. For JP Morgan, I can choose between two teams: HR data and analytics solutions. For Amazon, I don't know anything about my specific team yet but I know that the office I got assigned to has teams that work with devices and ground stations. Both of these sound more interesting to me than the JP Morgan teams, but I would be doing software engineering work instead of data science so there's a tradeoff. I'm also worried that a software engineering internship would make it harder to get a full time job as a data scientist.

Another small thing is that Amazon’s internship is 12 weeks and JP Morgan’s is 10 weeks. Amazon is also paying for housing and relocation. 

Overall, I'm just confused about which would be the better option and it would be super helpful to get any advice from people in the industry. Thank you!",2022-01-06 23:44:52
Advice for (re)learning statistics?,7,rxp3rf,https://www.reddit.com/r/datascience/comments/rxp3rf/advice_for_relearning_statistics/,6,1641503528.0,"I took stats a few years back and didn't do that well in it.  I'm transitioning to a point where I'm probably going to have to use stats more, and I was wondering what the best way to go about (re)learning stats was, short of reading a textbook front to back?  I have all my old stats notes, so I can find how to do a t-test or do things of that nature, but part of why I didn't do well was because we were just given a bunch of equations and no explanation of the underlying context/purpose.  I'm not as interested in the formulas (I would just implement these in Python/SciPy anyways lol) so much as the how/why/when of when to apply the various formulas and when to model what data as what distribution and so on.  Any advice?

I liked Jake Vanderplaas's Statistics for Hackers, but as far as I know that only exists as a 40 minute lecture and not a textbook.",2022-01-06 23:12:08
How to spice up your Data Science journey when you lack motivation?,5,rxp3ex,https://www.reddit.com/r/datascience/comments/rxp3ex/how_to_spice_up_your_data_science_journey_when/,6,1641503503.0,"Hey guys, Happy New Year to everyone!

Following on from the title… I feel as though my data science journey has plateaued a bit of late - I seem to have less motivation for projects and extra curricular bits these days.

In 2020, I had a lot of energy for side projects and courses, leading to me learning a lot and managing to get a new job in early 2021 - which was new and exciting. But I feel as though the learning has tapered off a bit and I am looking for a way to step it up to the next level again.

I’d like to know if anyone has any ideas on how to shake it up a bit and get out of a rut? What projects did you find really motivating / addicting? What re-ignited your love for DS when you felt like you were losing steam?

Things I can think of are either beginning a freelance side hustle as well as contributing to and engaging with the community more through Reddit. But would appreciate your thoughts - thanks.",2022-01-06 23:11:43
MITx MicroMasters in Statistics and Data Science includes nothing on large-scale data processing tools like Spark and Hadoop. Still worth it?,3,rxoqan,https://www.reddit.com/r/datascience/comments/rxoqan/mitx_micromasters_in_statistics_and_data_science/,2,1641502550.0,"Hi all,

I'm a BI professional with 4 years experience working heavily with SQL and various analytics tools. I see data science as a logical extension of this and I have a foundational knowledge of Python and libraries like pandas, matplotlib, scikitlearn, etc...

At this point, I feel like I need some more rigorous training and am enticed by the MITx MicroMasters programs, specifically the one in the title. However, I notice (as I do with most similar programs) a lack of any modules on large-scale data processing tools, NoSQL databases, scaling, etc...

Is this as big of a gap as I'm making it out to be if I want to actually land a job as a data scientist or perhaps a data engineer? If so, any recommendations?

Thanks!",2022-01-06 22:55:50
Where to find some Take Home DS Challenges for practice?,6,rxnbhi,https://www.reddit.com/r/datascience/comments/rxnbhi/where_to_find_some_take_home_ds_challenges_for/,5,1641498810.0,"Context: I am starting to interview for DS positions in Bay Area (not FAANG) and I have an MS in stats with 2 DS/DA internships 

I am not asking about the projects done on toy data sets, but something with similar level of complexity like those you get as the part of interviewing process.",2022-01-06 21:53:30
Recommended software/cloud options for fitting algorithms on ~1.5 TB of data?,1,rxmlqf,https://www.reddit.com/r/datascience/comments/rxmlqf/recommended_softwarecloud_options_for_fitting/,8,1641496969.0,"Hello,

I have collected hundreds of CSVs of monthly loan and economic data, which continues to grow each month. The bulk of the data is the loans and tracks individuals loan performance over time, such as the payment amount made, whether the customer paid off more than they needed to, whether they went delinquent, refinanced, etc. It also has borrower characteristics like FICO scores and DTI ratios. What I would like to do is a build a model(s) to predict prepayments, delinquencies, refinances, etc. with consideration for macro conditions and borrower characteristics. If successful, this model could be implemented at my company to replace our vendor model.

Conceptually I have ideas about how this might work. I have built many ML models with datasets that were small enough to work on my local machine, but the computing requirements of this are beyond that. I am wondering what the lowest cost method would be to store, manipulate, and fit models on this set. First for the proof of concept, and then potentially longer term for running loans through this model on a monthly basis.

Right now I am thinking of simply storing the data on some low cost cloud service like Amazon S3 and using Apache Spark via Databricks to manipulate, analyze, and fit models on it. Is this is a good idea? Or is it more or less than I would need, at least for the proof of concept? I work for a small company that has relatively weak and outdated data support so I am leading this alone but could get a little bit of money towards it.

Apologies if this is outside of the scope of this subreddit.

Thanks!",2022-01-06 21:22:49
Tableau Course,0,rxmjxi,https://www.reddit.com/r/datascience/comments/rxmjxi/tableau_course/,0,1641496840.0,,2022-01-06 21:20:40
Is there a problem with my causal estimates if they are very similar to naïve estimates (e.g. difference in outcome means)?,3,rxm804,https://www.reddit.com/r/datascience/comments/rxm804/is_there_a_problem_with_my_causal_estimates_if/,2,1641495994.0," Apologies if the question is unclear, I'm not too familiar with causal inference.

I've been using a few different methods to estimate causal effects for an outcome variable through Microsoft's DoWhy library for Python. Despite using different methods (propensity backdoor matching, linear regression, etc.), the causal estimates are always very similar to a naïve estimate where I just take the difference in outcome means between the treated and untreated groups. I've used the DoWhy library to test my assumptions through a few methods of refuting the estimates (adding random confounders, removing a random data subset, etc.) and they all seem to work fine and verify my assumptions, but I'm still worried the estimates are wrong due to their similarity to the naïve estimates that don't take into account any possible confounding variables/selection biases.

Does this mean there's a problem with my causal estimates, or could the estimates still be fine? If there's a problem, is there any way to check whether it has something to do with my data (too high dimensionality), the DAG causal model I've created, or something else?",2022-01-06 21:06:34
Is it just me or is SQL critically and chronically underappreciated in the DS community?,846,rxm4ej,https://www.reddit.com/r/datascience/comments/rxm4ej/is_it_just_me_or_is_sql_critically_and/,300,1641495734.0,"I totally get that ML/AI is the sexiest, hype-iest part of DS. But acting like SQL is easy, I'm coming to realize, is just utter nonsense. People tend to think ""SQL, oh yeah, SELECT \* FROM... Easy day!"" Just like ""Statistics, oh yeah, p-values, I know everything about stats!""  

I'm starting to realize that people who know how to wrangle data across tables, warehouses, servers, etc, at scale, efficiently, and know that their approaches are actually addressing the business ask, are incredibly valuable! and they're compensated as such at the FAANGs. 

For some reason, SQL, like stats, became this taboo word in the DS community. Like ""SQL? Oh no, I mean only if I can't get some junior schmuck to do it for me.""",2022-01-06 21:02:14
Methods question: Classic Zoo scenario - What's the name of the method described and/or is there a better model to use in this instance,6,rxkmer,https://www.reddit.com/r/datascience/comments/rxkmer/methods_question_classic_zoo_scenario_whats_the/,12,1641491897.0,"This was the best way for me to describe the challenge we are working with and was hoping for some insight as to best way to approach...

&#x200B;

Let's say I work at a zoo for animal intake. We have a database of all of our animals, past and present and their attributes: Name, Age, height, weight, length, skin type, presenting color, diet, is\_deadly?, temp threshold, species country of origin, previous zoo and a few others....

When we get the information about the animals arriving, we have all the attributes listed above, but not the animal name. Is there a method that would take the attributes for each animal and you could compare against the incoming list and get a probability score of what the animal is? So, take the 30 entries we have for Lions and then run a comparison of that against all the incoming animals. Then take the 50 entries we have for zebras and compare that set against everything coming. 500 entries for snakes etc...In the end, be able to sort each incoming animal by the highest probability score to determine what animal most likely is.

A singular analysis that is batched. Is this a thing? 

&#x200B;

(I'm new to DS (business analyst) and just trying to learn where common sense & proper methods combine and if this is something I can investigate further using proper names...Thanks)",2022-01-06 19:58:17
Moving from public accounting to data analytics,2,rxjmfi,https://www.reddit.com/r/datascience/comments/rxjmfi/moving_from_public_accounting_to_data_analytics/,1,1641489310.0,"Hi everyone, has anyone here ever made the jump from public accounting (auditing) to a SQL based analyst role? I’m looking to do the same right now and I’m looking for some advice, specifically oh how you marketed your experience in accounting in a relevant way during the recruiting phase. Info from your resumes would be especially helpful! And for context, I’m applying for an analyst 1 position with 1yr worth of public experience.",2022-01-06 19:15:10
Anyone here have experience in DS at Doordash?,20,rxix0q,https://www.reddit.com/r/datascience/comments/rxix0q/anyone_here_have_experience_in_ds_at_doordash/,10,1641487467.0,"I have an upcoming final round interview for a DS position at Doordash. Just wondering what the culture is like and if people have had positive experiences working in DS for this company. Any tips for the last interview are also very welcome. 

I'm in a pretty good position currently at a smaller tech company. I haven't been with them long, but I'm satisfied with the comp, culture, and work life balance. I expect the comp (should I be offered a position) to be higher at Doordash, but would love some insight into the culture and work life balance.

Feel free to DM me or discuss here.",2022-01-06 18:44:27
How can I add a little bit of Data Science practices to my Business Intelligence related work? The two are closely related but I'd appreciate some practical tips/use cases that I can implement. Thank you.,4,rxivr6,https://www.reddit.com/r/datascience/comments/rxivr6/how_can_i_add_a_little_bit_of_data_science/,3,1641487375.0,"Hi all,

How can I add a little bit of Data Science practices to my Business Intelligence related work? The two are closely related but I'd appreciate some practical tips/use cases that I can implement. Thank you.",2022-01-06 18:42:55
How do you feel about libraries that build models for you in R/Python?,60,rxh06w,https://www.reddit.com/r/datascience/comments/rxh06w/how_do_you_feel_about_libraries_that_build_models/,40,1641482425.0,"Hey all! Data Analyst here and dipping into the ""machine learning/DS"" world because works wants linear/logistic models. I have learned a good bit about Python and R now, which has been challenging and fun.

In R, I use a library called 'Rattle' to build linear/logistic models. It's been great, user friendly, and really helped me understand the concept of modeling. However, I could not even begin to manually code or make a model like this in Python/R.

I feel a bit like a fraud, and I am wondering how others feel about using libraries for these things. Is it seen as a crutch or used by people with less understanding, or is it smart not to be ""reinventing the wheel.""

Thanks!",2022-01-06 17:20:25
Can I catch up on university courses on data science without a foundation on calculus?,0,rxfshp,https://www.reddit.com/r/datascience/comments/rxfshp/can_i_catch_up_on_university_courses_on_data/,19,1641479138.0,"Hi I'm a highschool student looking into Data science but didn't take calculus in HS. But I'm genuinely interested in the field and have a growing interest in maths in general. The main concern I have right now is I'm afraid i might be too far behind on math in Data science, so it'll either be terribly stressful or I'll just get an F every semester.

Should I apply for the major or look elsewhere?",2022-01-06 16:25:38
LOESS smoothing for a sound signal,1,rxf7fn,https://www.reddit.com/r/datascience/comments/rxf7fn/loess_smoothing_for_a_sound_signal/,0,1641477522.0,"Hello guys, I have to do a research about digital hearing aids for academical purposes, and decided to focus on the denoising aspect in their opitimization.
I firstly thought of using the Kalman filter but it was just too complicated for my actual level, then i wondered if we could use the LOESS smoothing to reduce the noise in an acoustic signal?  Thanks for your answers",2022-01-06 15:58:42
Data science coding & career development,1,rxemle,https://www.reddit.com/r/datascience/comments/rxemle/data_science_coding_career_development/,2,1641475768.0,"Summary: How can I (faster) learn how to translate my thoughts and solutions in code? 


My background: 
I did my bachelor in Economics and Business. I did a master in Marketing Management where I specialised in neuromarketing science and did a bunch of marketing analytics courses. When I graduated, I interned as a marketeer for an AI/Machine Learning start-up and was introduced to this whole new world of data science and programming. 

So I enrolled in another master called Data Science and Marketing Analytics. It was very heavily-focused on concept development, problem-solving, and less on the programming part. They taught R because we did do a lot of statistics and data manipulation for marketing analytics. 

Then I interned in data science for a pretty big company but their data science department is very new. They offered me a full-time role, ""Graduate Data Scientist"" which I'm in for a few months now. I taught myself Python throughout. I consider myself a beginner given I think I only have at most a year of programming experience in R and Python. 

I notice I really struggle to translate my data science ideas/solutions into code. I can code when I'm told what to do, but not when I need to make something up from scratch. This became very clear to me when they hired other data scientists who come from computer science and econometrics and have 4-5 years of coding experience. Literally spitting out models and code in a day which would take me a week to do.

Coding mentorship is not possible at the moment because no one has time. I really like what I am doing and want to get better. I can't help but compare myself with the others, which is not fair. I do have very high expectations of myself. 

Has anyone been in a similar position and if so/even not, do you have advice on how to improve coding skills? 
I try to practise as much as I can through applications in the work projects and some exercises/challenges not work-related. 

I also suffer from burnout and anxiety, so while I feel like I need to quickly get this together for my career, I find it counter productive to force myself to do more on top of what I am doing now. 

Thanks for reading.",2022-01-06 15:29:28
How can you put the knowledge of data science to solve problems related to neuroscience?,26,rxe197,https://www.reddit.com/r/datascience/comments/rxe197/how_can_you_put_the_knowledge_of_data_science_to/,34,1641473949.0,"Hi. I am a recent graduate(computer engineer) currently working in a consulting firm. I have always wanted to solve problems related to the human brain cause there are a lot of unanswered question in that aspect. However, now that I am working and I am seeing that data science is mostly used for solving business problems and not really cognitive problems. I wanted to ask if you guys knew any solution that would help bridge the gap on how can I use the data science knowledge into helping solve problems in neuroscience without letting my computer engineering degree and the data science work experience go into waste? I mean, how can I better use the work experience to solve problems related to brain. Will doing masters in neuroscience help or can I work my way around doing masters in business analytics and then solve problems related to brain?",2022-01-06 14:59:09
Declarative libraries for analysis - where are they?,1,rxa4sh,https://www.reddit.com/r/datascience/comments/rxa4sh/declarative_libraries_for_analysis_where_are_they/,7,1641459804.0,"Hi,

As the title suggest, I find it suprisingly difficult to find libraries where analysis/modelling is done in a declarative way. Say for example I want to train and evaluate a logistic regression model - then I need to split my data in test/train, train it on the train set, predict on test and evaluate. All these steps are usually easy enough to do and have high-level functions, but I'm still manually putting the steps together; describing _how_ to do what I want, instead of just describing _what_ I want. To me this gives a huge uncertainty in my own analysis - yes, I have split my data into test/train, but there's no certainty that I'm actually using them in the correct way. In this simple case it might be easy enough, but add pre-processing, calibration and so on and suddenly the complexity explodes.

This came up for me because I'm used to do this kind of work in R and now have a project in Python. In R there's [Tidymodels](https://www.tidymodels.org/), where especially the package [workflows](https://workflows.tidymodels.org/) is very close to what I want. Workflows is still a surprisingly new for something that I think is neccesary for being confident in your model evaluations and such.

I'm using Scikit-learn in Python but can't find anything similar to that. I think the closest thing is big Machine Learning experiment management like Neptune, but that also seems a bit overkill.

So; where are these libraries? Do they exist and I just haven't searched enough?

Or am I wrong and dumb and missing something for wanting this?

Or am I really just interrested in standarized and validated setups/workflows/pipelines and the ""declarative"" part is actually not that important?

Looking forward to your comments!",2022-01-06 11:03:24
"data scientists of all levels, what was your first internship experience like?",7,rx8iuo,https://www.reddit.com/r/datascience/comments/rx8iuo/data_scientists_of_all_levels_what_was_your_first/,7,1641453478.0,"i'm a freshman in college that was fortunate enough to land an internship at a startup, but 99.9% of the time i have absolutely no idea what i'm doing - dw i'm asking a LOT of questions and generally learning a bunch, but it can be demoralizing at times when business lingo is flying above my head and i don't really know how to approach the vague ass insights requested. ngl i've probably already done/said a bunch of dumb shit my first week.

also got onboarded during a sort of hectic time period so i got a bunch of stuff thrown at me all at once

i'm wondering if any of you have had similar experiences and/or funny stories that can help me get over my imposter syndrome and realize that this should be normal even though it doesn't feel that way and that i'm not a complete dumbass. thanks",2022-01-06 09:17:58
What are the reasons a machine learning/QSAR model might fail?,2,rx7vwk,https://www.reddit.com/r/datascience/comments/rx7vwk/what_are_the_reasons_a_machine_learningqsar_model/,7,1641451054.0,"I've been working on constructing a random forest regression QSAR model using high-throughput screening bioassay data from PubChem using OCHEM, and the results I got found absolutely no correlation and no sense whatsoever with the molecular descriptors and the measured results. From my understanding, QSAR models find a correlation between the molecular descriptors calculations and the results you're trying to get (for example, logP). I'm very new to this and very confused, so here are some details about what's going on with my model, and it would be greatly appreciated if anyone has any suggestions to help troubleshoot!

* The goal of my model is to predict the RFU of a novel compound as if it were tested in the bioassay. All of the compounds in the bioassay for tested for the same purpose.
* There are 350,000 compounds in my data set. I'm only using 1,000 randomly selected compounds, 50% from active compounds and 50% from inactive, because of resource limitations. All of the compounds are from the same bioassay
* The descriptors I checked on OCHEM were OEState and ALogPS, and the method I used was random forest regression
* The measured value that I'm trying to find is the relative fluorescence units (RFU). I inputted the PubChem CID, name of the molecule on PubChem, and the RFU units to train the model
* Some of the RFU values are extremely high for some reason, the active compounds range from around 50.00 to values in the thousands, and I'm not sure if that would be an error
* The training set consists of 80% of the data and test set contains 20% of the data
* Can QSAR models fail just because there's simply no correlation? Is my model basically like trying to predict the number of... milk cartons hoarded by... how many freckles someone has? (as a random example of a useless correlation)

In total, how can I improve my model? Is there anything I can do to ""clean up"" my data, or anything I can do to make it more accurate? I'm super confused, so any help would be desperately needed. If there's any information that would be needed to find the problem, please let me know. Thank you!

Here's a picture of the confusing model:

https://preview.redd.it/mlxh3ngui0a81.png?width=820&format=png&auto=webp&s=ee4a118ffa6cafb2fc446505ba91e59ba6f90ff0",2022-01-06 08:37:34
A 5 million source code file dataset,0,rx7nri,/r/datasets/comments/rvupxk/a_5_million_source_code_file_dataset/,0,1641450238.0,,2022-01-06 08:23:58
Making predictions on streaming data that often have missing features; what is a good algorithm to use?,2,rx62u9,https://www.reddit.com/r/datascience/comments/rx62u9/making_predictions_on_streaming_data_that_often/,5,1641445066.0,"Suppose I trained an algorithm on a dataset with 20 features, which is the maximum possible number of features that may be present in the test set. An example is predicting the number of hours of sleep that will be obtained at night based on biometric data such as caffeine intake, hours of exercise, resting heart rate, BMI, etc. during the previous day.

In the test set, people vary in how many features they choose or are able to submit. What is a sensible algorithm or way to deal with the variable number of features in the test set?",2022-01-06 06:57:46
Everybody working in data science : what are your opinions on non-ml/stats phD’s being your bosses.. Particularly if they got into the field after you?,10,rx5tdl,https://www.reddit.com/r/datascience/comments/rx5tdl/everybody_working_in_data_science_what_are_your/,24,1641444242.0,,2022-01-06 06:44:02
Project Monitoring & Control,5,rx4eps,https://www.reddit.com/r/datascience/comments/rx4eps/project_monitoring_control/,1,1641440133.0,"Hello everyone, happy new year! I have been working as a program manager at an InsureTech company and have been handling data migration and transformation programs across business till mid last year. I have been assigned the responsibility to lead an Data Analytics program. The team constitutes of Data Engineers, Scientists, BA, Head of Analytics. The team has been working without a clear roadmap till date and has just managed barely to keep up with the Analytics requirements till date of generating meaningful insights. I have received a backlog of ML/AI models from the team and our CEO has signed off on having couple of them prioritised for the next two quarters. My CEO expects a roadmap and continuous reporting of the progress of the models and an expected date of getting it in an operational phase. I am getting resistance from my team in terms of giving dates, which is fine, but how should I approach this issue. How can I set up expectations in terms of when can business start getting some value out of these models? I have created milestones for each of these models (Exploration & Cleaning, Training, Tuning, Evaluation) and am trying to track the progress based on that.",2022-01-06 05:35:33
Does anyone here make over $300k? What’s your title what do you do?,127,rx3myo,https://www.reddit.com/r/datascience/comments/rx3myo/does_anyone_here_make_over_300k_whats_your_title/,159,1641438068.0,"Mods, remove if this type of post isn’t allowed. I was just blown away by how many North Cal Software Engineers make (from [another thread](https://www.reddit.com/r/AskReddit/comments/r9ytvl/what_is_your_job_and_how_much_do_you_get_paid/?utm_source=share&utm_medium=ios_app&utm_name=iossmf) ) and I’m wondering if DS has the same type of opportunities.

Edit: welp I am a lazy MFer. I scrolled down two posts and there is a DS salary thread pinned 😵",2022-01-06 05:01:08
Psych major pursuing Stats MS w/ the goal of going into DS?,6,rx1vzb,https://www.reddit.com/r/datascience/comments/rx1vzb/psych_major_pursuing_stats_ms_w_the_goal_of_going/,17,1641430397.0,"Hi, I hope this is the appropriate sub for this. I’m having a bit of a crisis deciding what career I’d like to be in, and honestly, I love stats. I do different analyses in SPSS for my psych degree and will be graduating in a year, with the final semester being a research seminar. 

I wanted to be a Physician Assistant, and I’m still considering it, but I’m not so sure; being able to work on a what seems to be “achievement based” system rather than appointment system in many health care jobs seems nice. Also not a fan of pure coding, though I’d be willing to learn R, Python, SQL, whatever I’d need. I just like data and stats. 

So, I’m too far in to ditch my psych major. I knew I’d end up doing some post-grad stuff, so I’m not too worried about that, but I’m considering an MS in statistics in order to get into the data science field because many people say a degree in DS isn’t really required and others say DS is another term for “statistician” nowadays regarding job posts. 
Also kinda curious about base pay if anyone has any insights, I know ≈65k is average to begin with, but has anyone started off higher? 

Any advice or input is welcomed!! Thank you",2022-01-06 02:53:17
"Thought experiment. If you had to compare 10s of millions of records to a million or so others (about 1x10^13 record cross join), with over 100 columns how would you go about doing it? Is there even a way to accomplish it?",0,rx1mi0,https://www.reddit.com/r/datascience/comments/rx1mi0/thought_experiment_if_you_had_to_compare_10s_of/,17,1641429634.0,,2022-01-06 02:40:34
How to set up a consulting gig?,2,rx1kdi,https://www.reddit.com/r/datascience/comments/rx1kdi/how_to_set_up_a_consulting_gig/,12,1641429476.0,"A previous employer of mine had reached out to ask for my help as an outside consultant. I'm interested but have no experience working as a consultant.

The work will be supporting operational report run, building and automating ETL processes, and likely analysis work. In other words, there will be weekly/monthly deliverables and mid-to-long term projects.

I don't know what's an appropriate rate. Is 1.5x my current hourly salary reasonable?

Also, I don't know if I need to create a company. Is that better for tax purposes/liability, or can I keep it simple and collect a monthly check (like back in the days when I do tutoring) and just claim it as ordinary income?

What else do I need to know? I'm at the I don't even know what I don't know stage and just looking for any information.",2022-01-06 02:37:56
What is the highest job title you can attain in data science?,0,rx1j98,https://www.reddit.com/r/datascience/comments/rx1j98/what_is_the_highest_job_title_you_can_attain_in/,12,1641429392.0,Does it differ by company or is there a general name for it? For a non-manager position. Also curious for what it is for manager positions,2022-01-06 02:36:32
Website/web app in Azure with different Python scripts,1,rx0hkx,https://www.reddit.com/r/datascience/comments/rx0hkx/websiteweb_app_in_azure_with_different_python/,3,1641426616.0,"Hi,

I have no idea if this is trivial or not, but currently at work we are developing some scripts to do different things. Some of executed in Excel, some just locally, and some on a virtual machine for doing scheduled tasks. 

It's working okay, but obviously (for some of the scripts) it would be so much better to have a webpage, where you can use some kind of OAUTH for authentication, and then just create a simple site with a left menu with some links to different ""scripts""/pages which can be reached by everyone (or those who have access) from anywhere, or at least within the VPN of out organisation. And then each of these pages will have some kind of input parameters you can set (like we do locally), hit run, and then it outputs something (regular tabular data, plots, or something else).

I have lots of experience with HTML/CSS/React/Angular etc., so that doesn't frighten me, but I've actually never set-up a web server or anything like that. That has always been done by others.

So basically I am asking: What would be the best approach if I wanted to create something like this (I guess it's some kind of dashboard, although the stuff on each page can be quite advanced in some cases).

It's not like it needs to be super perfect, it's just for my team.",2022-01-06 01:50:16
How do I make the most money in this field?,0,rwzjj0,https://www.reddit.com/r/datascience/comments/rwzjj0/how_do_i_make_the_most_money_in_this_field/,15,1641424143.0,"Hi, I'm a bachelor student who recently got his first job in data analytics. It's not data science (which I had a hard on for before) , but it's still fun and I like my job very much, so I thought damn, I really do not care at all what do I do as long as I have to think a bit, talk with people a bit and my colleagues don't suck.

I'm applying for masters right now (EU, so it's free) and I'm wondering, what should I focus on, where should my path lead, if I wanted to base my decision purely on money. Is it the senior data scientists? Is it the big data architects? Is it the cloud architects? Or do I have to wait a few years to become a tech lead or a project manager and only then become the best paid?

 Any experience is welcome, thank you all and I wish you a happy new year",2022-01-06 01:09:03
Is MODA or management science important for data science/analysis?,1,rwxa6a,https://www.reddit.com/r/datascience/comments/rwxa6a/is_moda_or_management_science_important_for_data/,0,1641418079.0,"I am studying my Master's in Data science & decision support and there are particularly two courses that I find interesting - Management science and Multi-objective decision analysis (MODA). 

I would like to become a data/business analyst in a consulting company. I know these courses are offered for a reason but I am wondering whether there is a direct or indirect implication in the real world? Are there any specific common situation in data science field where the knowledge of the previously mentioned courses will come in handy?",2022-01-05 23:27:59
"Any good data sources for a first time project that uses CSV, web data, postgres, and SSMS in Power BI?",4,rwu3fi,https://www.reddit.com/r/datascience/comments/rwu3fi/any_good_data_sources_for_a_first_time_project/,10,1641408804.0,"I am working on a project and basically just want to get a handful of data sources from several different ways to show it can work together for a demo at an interview. 

It would be ideal to have SSIS get data in from somewhere, clean it, load into ssms. Then ssms connects to Power BI.

In Power BI, it should input from SSMS as well as other sources like  an API, web data, excel, csv., postgres, etc.

DYNAMIC DATA would be great as that would really show what the model is capable of

From there, I will connect al the data sources and visualize in some way in Power BI and publish it to online.

My problem is I am struggling to find data. If I can find some reliable basic datasets for architecture/healthcare/environmental studies/stock data that can somehow be used, that would be awesome!

Thanks, any advice is helpful!!",2022-01-05 20:53:24
Is it worthwhile to make the switch from Scratch to Python for machine learning?,537,rwu29s,https://www.reddit.com/r/datascience/comments/rwu29s/is_it_worthwhile_to_make_the_switch_from_scratch/,136,1641408722.0,"Scratch is what I am most proficient in, and have already completed various AI projects with, but my colleagues tell me it will be worth it to learn how to program in python, even though I will be set back in the short term. Is this true? Or is scratch just as sophisticated of a language for AI? 

My goal is to get into a FAANG company, and am in some talks, so does anyone know if they have a preference?",2022-01-05 20:52:02
Is data structures and algorithms worth spending my time on before I start my job?,7,rwtmzs,https://www.reddit.com/r/datascience/comments/rwtmzs/is_data_structures_and_algorithms_worth_spending/,6,1641407618.0,"I recently signed an offer to start working as a data scientist after the summer. I'm extremely excited as the role is known for being ML + stats + data engineering heavy. Dashboarding type projects will not be part of the role as they fall under the other team(s). 

My background is masters level non-CS so I haven't formally learnt data structures and algorithms. I know the basics of the most important data structures (lists, sets, hashmaps, queues, contigous data structures etc.) and intuitions about their corresponding time/space complexity. They were needed for some advanced courses (e.g. combinatorial optimisation w/ C++) together with some sorting / search algorithms (binary search, DFS, BFS, ...) but here typically only what was needed was covered.

For now until I graduate I'm looking at areas I can improve before I start working. Aside from DS&A I've also identified extra cloud skills (I have 3 entry level Azure certs already but I can go for more) + CI/CD, testing frameworks and web/API skills for model deployment.

I do kind of reason DS&A while writing code but maybe actually formally learning about them would make me a far better programmer. Should I potentially just try and wing it with my current knowledge, what do you think? Are they really *that* important aside from leetcode you get on interviews (which I no longer have to do)? 

In the past I've always avoided self-learning these as I believed my time was better spent on extra math + stat than on DS&A.",2022-01-05 20:33:38
ray-skorch - distributed PyTorch on Ray with sklearn API,3,rwtaql,https://www.reddit.com/r/datascience/comments/rwtaql/rayskorch_distributed_pytorch_on_ray_with_sklearn/,0,1641406757.0,"**tl;dr**: train PyTorch models on large tabular datasets with a scikit-learn (skorch) API

Hi r/datascience,

I'm the principal author of [ray-skorch](https://github.com/Yard1/ray-skorch), a library that lets you run distributed PyTorch training on large-scale datasets while providing a familiar, scikit-learn compatible [skorch](https://github.com/skorch-dev/skorch) API, integrating well with the rest of the scikit-learn ecosystem.

Under the hood, ray-skorch uses [Ray Train](https://docs.ray.io/en/latest/train/train.html) for distributed PyTorch training and [Ray Data](https://docs.ray.io/en/latest/data/dataset.html) for handling and shuffling large datasets.

ray-skorch works only with tabular data. Currently, it can use numpy arrays, pandas dataframes and Ray Data Datasets.

`pip install ray-skorch`

You can switch your skorch code to ray-skorch just by changing a few lines:

    import numpy as np
    from sklearn.datasets import make_classification
    from torch import nn
    # pip install pytorch_tabnet
    from pytorch_tabnet.tab_network import TabNet
    
    from ray_skorch import RayTrainNeuralNet
    
    X, y = make_classification(1000, 20, n_informative=10, random_state=0)
    X = X.astype(np.float32)
    y = y.astype(np.int64)
    
    net = RayTrainNeuralNet(
        TabNet,
        num_workers=2,  # the only new mandatory argument
        criterion=nn.CrossEntropyLoss,
        max_epochs=10,
        lr=0.1,
        # TabNet specific arguments
        module__input_dim=20,
        module__output_dim=2,
        # required for classification loss funcs
        iterator_train__unsqueeze_label_tensor=False,
        iterator_valid__unsqueeze_label_tensor=False,
    )
    
    net.fit(X, y)
    
    # predict_proba returns a ray.data.Dataset
    y_proba = net.predict_proba(X).to_pandas()

More examples, including ones on bigger datasets, can be found here - [https://github.com/Yard1/ray-skorch/tree/main/examples](https://github.com/Yard1/ray-skorch/tree/main/examples)

The package is experimental, and I’d love to hear your feedback - both on the package itself and on the concept of distributed training on tabular data with simple, familiar APIs. Any comments, suggestions or bug reports are hugely appreciated!",2022-01-05 20:19:17
Tech stack for handling multidimensional data with variable number of records,3,rwsgx7,https://www.reddit.com/r/datascience/comments/rwsgx7/tech_stack_for_handling_multidimensional_data/,9,1641404634.0,"Can someone recommend me useful dataframe tools that allow multidimensional with varying number of records. So far going straight with a database seems to be best way to go, as most dataframe tools do not really support such requirements. Any ideas?

A simple example how the data looks like:

n measurements with each measurement being represented by a fixed number of columns while the number of records is different for each measurement and column

&#x200B;

&#x200B;",2022-01-05 19:43:54
Deploy Dash app for free,2,rwrfmk,https://www.reddit.com/r/datascience/comments/rwrfmk/deploy_dash_app_for_free/,4,1641401886.0,"Hello,

I'm sure it's a dummy question but I give it a try just in case. 

I would like to create a Dash app for my team. It is possible to upload it online in a *free & fully protected* way ? My entreprise is fully on Microsoft (SharePoint, PowerBi &co) so I really can't ask for help to my IT department for that. 

I'm almost sure it's not possible (I do need a host server that can't be not free since I can't use a personal computer for that) but prefer to ask. I'd love to learn new skills outside Microsoft tools and it would be a great opportunity for me to do so (also I have quite a lot of free time for now). 

Thanks for any input",2022-01-05 18:58:06
DS Bootcamp Grads: WTF is your deal?,0,rwpwxo,https://www.reddit.com/r/datascience/comments/rwpwxo/ds_bootcamp_grads_wtf_is_your_deal/,60,1641397856.0,"This is now the third time I’ve had a DS bootcamp grad join my team (not by choice) and I’m having disastrous results. 

Do they not teach you how to operate computers or use the command line? How to deploy to anything but one-click PAAS with no IAM? Why is the answer to every business question a cloned repo you found on TDS that uses 42 apis we can’t license? How can you not know SQL or how to set up a local instance? Why is docker such a fucking mystery to all of you? Ever heard of VENV? Yes I know it works on your personal machine because you’re using a web-based IDE our company blocks FOR A REASON.

Like I get it, everyone else in the company is ready to fire the money cannon straight at your face every time you say “neural network,” but FFS learn how to run something, ANYTHING on an actual enterprise grade cloud provider (Az, AWS, or GCP if you must), learn to use Git so I can actually work with your stupid ipynb notebooks, and FOR THE LOVE OF GOD do not keep asking me to call you a data scientist in meetings. You were a barista 12 weeks ago no matter what they told you at General Assembly. 

Sorry for the rant I’m just boggled by what these programs are teaching people and telling them they’re qualified to do after they’ve taken your money. If you’re not walking away from your program without knowing how to at least do a tiny bit of ETL or understanding that not all the data in industry is going to be as clean as the Yelp/Twitter/Kaggle data you’ve been using your little pip install imadatascientist toys on, you’re going to run into people like me who know enough to know you’re a sham, but who won’t tell you so but instead rip you anonymously on Reddit. 

There now I feel better. Love to all the actual data scientists out there. Also I do 9/10 of these things as well but I’m just a dumb product manager so I’m allowed to.",2022-01-05 17:50:56
Node js question: I'd like to do multiple requests to a server over time (every 3 seconds) then take that data and write it to a file. How do I do that? Especially considering that errors can occur and that the file can get relatively large.,0,rwltzt,https://www.reddit.com/r/datascience/comments/rwltzt/node_js_question_id_like_to_do_multiple_requests/,1,1641385806.0,"Right now I just read in the file, parse it to js, add the data, and then rewrite the entire file. Should I use fs.createWriteStream for this instead? My file is small enough to load into memory I think. What is the recommended way? 
What is ""pipe"" actually? 

Based on that data I will need to send follow-up requests to the server later on. Here I also don't understand yet how I can use the CSV in JS to extract the relevant data I need for the subsequent requests. How does that work?",2022-01-05 14:30:06
Is the Insight Fellowship Program done ?,6,rwkjae,https://www.reddit.com/r/datascience/comments/rwkjae/is_the_insight_fellowship_program_done/,4,1641381150.0,Title says it all. I just graduated and had plans to apply for the program if I didn't have any luck in my job search but their [website](https://insightfellows.com/data-science) and the social media accounts seems to all by dead. I can't seem to find something that mentions a break or a timeline for returning. Just looking for any info on this.,2022-01-05 13:12:30
How to simply characterize curve shapes?,1,rwgwde,https://www.reddit.com/r/datascience/comments/rwgwde/how_to_simply_characterize_curve_shapes/,3,1641366728.0,"Hello, so I have a time series dataframe where one column is chronological timestamps, and then next column are unique values in a ""Values"" column, with each value associated with its corresponding timestamp. That's it. Just those two columns in the dataframe. I can then plot this data and produce a plotted curve, with timestamps on the x-axis and values on the y-axis. I can observe how the curve goes up and down, down and up, and how many times the slope changes from positive to negative and vice versa. Now, I have many of these same type of dataframes. Let's say I have 100 of these dataframes, each with a defining curve shape. What I want to do is eventually ""cluster"" these curve shapes, into essentially taking all of the 100 curve shapes and essentially saying Ok, I see we have a curve type A, a curve type B, and a curve type C, etc. and these are the categories all dataframes fall into. I would then assign each dataframe its identified curve type. 

Now, the big challenge I am struggling with is, how do you characterize a curve? What would the characteristics be so that they can be grouped together? I know there are probably some really complex curve shape clustering packages out there, but in my experience, these are very in-depth and complex and can be a bit of a black box. I am looking for a method that is super intuitive and straightforward. For example, one characteristic I can think of is the number of a count of the number of peaks and valleys in a curve. For instance, lets say we have two types of curves, 1) where we see lots of ups and downs, and 2) where there are just a few ups and downs. Just counting the number of peaks and valleys, we could then cluster the curve populations into two distinct curve shape types. 

But what other characteristics, specifically simple and direct characteristics, that could define curves that I could count/calculate and then use for clustering? I am open to suggestions here and would really appreciate any guidance on this! Also, my apologies for this probably not being a clear as could be here, I am really struggling to articulate this objective into the most clear terms and explanation! Thanks!",2022-01-05 09:12:08
Misleading claims of model accuracy,192,rwbkt5,https://www.reddit.com/r/datascience/comments/rwbkt5/misleading_claims_of_model_accuracy/,79,1641349485.0," In a group competition in a Machine Learning class, trying to solve a classification problem, one team claimed to have ""solved the challenge"", which was ""a total piece of cake"" (quote) and to have ""100% accuracy"" (quote too). A very smug attitude. 

 The professor was very skeptical (he designed the challenge) so he went over there and checked out their model. He asked to see the confusion matrix. It turns out that what they meant by ""100% accuracy"" was actually 100% recall, i.e., all the actual positives (labels) were indeed predicted to be positive by their model. The catch? Their model predicted ANYTHING to be positive lol, regardless of the input. So yea, 100% recall... Facepalm. 

 I guess it was at least useful so that the professor could re-iterate how you must balance precision & recall thru F-1, the importance of understanding the performance claims about a Machine Learning model, etc..

 Makes me wonder: how many data scientists out there actually fool (knowingly or not, not sure which one is worse) their business partners under claims of very high accuracy and flashy plots showing 100% of some ill-defined metric? And... Which one is actually worse? Ignorance or manipulation?",2022-01-05 04:24:45
In an Enterprise setting what is mostly used for data visualization?,2,rwbi46,https://www.reddit.com/r/datascience/comments/rwbi46/in_an_enterprise_setting_what_is_mostly_used_for/,12,1641349269.0,I'm starting my data science journey and my question is in an Enterprise setting what is mostly used for visualizations? I know there is Power BI and Tableau but I can also create visualizations in R or Jupyter. Are the visualizations I create in R or Jupyter just for me personally and the other visualization tools are used to present the data to the executives or are they interchangeable?,2022-01-05 04:21:09
Do you use your numpad on your keyboard for data science related projects?,0,rw8l7y,https://www.reddit.com/r/datascience/comments/rw8l7y/do_you_use_your_numpad_on_your_keyboard_for_data/,10,1641340852.0,"Honestly I am just watching for a new keyboard and I like the slick compact design of a shortened keyboard and never got used of using the numpad. Is it worth trying or nah?

[View Poll](https://www.reddit.com/poll/rw8l7y)",2022-01-05 02:00:52
"Request: I need a screen shot of ""data science at work""",2,rw899k,https://www.reddit.com/r/datascience/comments/rw899k/request_i_need_a_screen_shot_of_data_science_at/,11,1641339896.0,"One of my clients wants to create an advertisement for their computer hardware, which they aim to sell to data scientists. And, reasonably enough, they'd like the screen in the photo to show something related to data science rather than a generic swirly-lines picture. (My suggestion, ""How about a cat photo?"" was not received well, for some reason, even though I had a willing cat model.)

So I need an image to include that doesn't raise any issues of intellectual property. The last thing I want to do is talk with lawyers. 

I figure that the best option is an image of someone using an open source data science tool, working on some sort of open data (e.g. a NASA data set).

Could someone indulge me? It'd be groovy if the ""real data science at work"" image looked sexy (with a cool visualization or whatever) but it's fine, too, if it's a screen shot of an open source tool chomping on data. It's going to be in a photo in a not-very-big PDF, after all. Send me to imjur or whatnot, and a private message telling me what the image is and that it's free for anyone to use?

(Besides, I can imagine that a show-and-tell might be fun for the denizens here.)

tl;dr Could anyone give me a screen shot of a real data science project?",2022-01-05 01:44:56
How to convince my team to transition from SAS to Python?,114,rw672d,https://www.reddit.com/r/datascience/comments/rw672d/how_to_convince_my_team_to_transition_from_sas_to/,107,1641334201.0,"I'm currently working as a Data Analyst at a Financial Services company where a lot of the scripts and programs are built in SAS. How should I convince my team to use Python instead as it is free (unlike SAS), and is a much better tool for data handling nowadays?

Any thoughts or advice would be greatly appreciated. Thanks.",2022-01-05 00:10:01
Anyone have experience as a Business Intelligence Analyst? Was told to apply and am feeling under qualified for the interview,0,rw17rp,https://www.reddit.com/r/datascience/comments/rw17rp/anyone_have_experience_as_a_business_intelligence/,5,1641321109.0,"A positioned opened up at my current company and I was encouraged to apply for it by my superior. 

However, I feel extremely under qualified and am not feeling very confident. 

My current role I do almost the same type of work a data analyst does (although my title isn’t “Data Analyst”), and I have heavy experience with PowerBI/Excel etc (use those daily at work, build dashboards, manipulate datasets etc), and I am comfortable with Python (although I don’t use it at work, I use it at home almost daily). 

I don’t know much about SQL or R, but am currently in the middle of a Data Analyst Certificate from IBM which covers SQL. Also, I’m sure I could at least get the basics down on the fly with some quick googling (with SQL, R looks like I will definitely need some time with). 

Other than that, I don’t really know what else to expect in the interview. Not sure if I will be tested or not, or what type of questions they will ask.

I don’t know, doing some research on BI Analysts, they seem far more advanced than what I’m used too, so I’m not really sure why I was encouraged to go for it. Don’t get me wrong, the pay increase would be nice, I just don’t want to embarrass myself in an interview and not know a single answer to any of the questions.

Anyone have experience with this position and can offer up advice? Thank you!",2022-01-04 20:31:49
Are Neural Nets and Artificial Intelligence considered Data Science?,0,rvygvj,https://www.reddit.com/r/datascience/comments/rvygvj/are_neural_nets_and_artificial_intelligence/,22,1641313984.0,I in my last year of a data science degree at my university. I’ve had 3 classes that talk about machine learning in some form or another. I have this professor (head of the data science department) that says he knows people in the data science field that shake their heads at NN and AI and consider them to be apart of something else entirely. He believes data science to be more Statistically driven. Is it true? Is there a divide in the community where AI and NN fall because of their “black box” nature?,2022-01-04 18:33:04
"Those of you who are taking Data Science courses at a university, what's the most memorable moment you've witnessed in a data science class?",265,rvya1w,https://www.reddit.com/r/datascience/comments/rvya1w/those_of_you_who_are_taking_data_science_courses/,149,1641313505.0,"Lots of questions in this subreddit have to do with career advice or discussing the job market, but I want to do something more fun. I'm a senior majoring in Computer Science but have taken a plethora of data science courses offered at the undergrad level at my university (some classes intertwine with master's level courses) and I wanted to share and see if other students have similar, memorable, or fun experiences in their classes.

&#x200B;

For me, last semester, I took a data mining course and in one of our assignments, we were tasked with  using K-means clustering on a dataset of our choice. One group decided to do clustering of k = 6 based off of two explanatory variables: one that I can't really recall (let's just say it was income) and the other one was UserID. Not only did I visibly cringe, but I had to stop myself from facepalming. I couldn't believe a group decided to use UserID and another variable and try to draw meaningful analysis from it. There was a part of me that wanted to raise my hand and ask questions about their cluster but the professor got to them first and went in about how you're not supposed to use UserID in any type of analysis. They had other issues with their presentation and she went into those as well, making it clear that the group wasn't prepared for what hit them and I kind of felt bad. She gave the group an opportunity to make up the assignment and come up with a legitimate cluster with legitimate analysis, so that's a saving grace. 

&#x200B;

If you have similar stories or different yet still memorable or fun stories from your data science classes to share, please share!",2022-01-04 18:25:05
Is it possible to combine Data Science with hacking / IT-security?,23,rvvqo8,https://www.reddit.com/r/datascience/comments/rvvqo8/is_it_possible_to_combine_data_science_with/,23,1641306818.0,"Since I was a kid, \~20 years ago, I was interested in IT security. Even though there was not much information out there, I still did simple stuff like scripting, playing with trojans/viruses, wireless wiretap, hacking computer games etc. . But I had no support / help / person to ask, so it got more and more difficult for my 11 year old brain, and I stopped.

Now many years later I study Data Science, which is a lot of statistics (also with many ML topics like (un)supervised learning, reinforcement learning etc.) with a bit of CompSci topics like Data structures, Algorithm, programming, data bases, SW engineering...

My question: Is there any way to combine this Data Science knowledge with hacking/ IT-security? So that I can specialize in a topic Im really interested in? So far, I really miss the technical stuff in Data Science, which inspires me since I was a kid.  Finding out gaps, errors and weak points in a system is something that really intrinsically motivates me.

Thanks in advance!",2022-01-04 16:33:38
How many concurrent projects is normal?,12,rvvk2m,https://www.reddit.com/r/datascience/comments/rvvk2m/how_many_concurrent_projects_is_normal/,8,1641306301.0,"I've been in the field for 3 years at an expanding startup. I used to work on one or two projects at a time, and their deadlines wouldn't overlap too much. It was very manageable and I was able to produce, thorough, good work. 

But recently, I have been put on 4 projects, all on different teams. Some of them take more time than others, and there is a prioritization for some of them over others. However, they are big clients and important for the company. I am feeling extremely burnt out and exhausted. My quality of work is definitely falling apart, and I can't afford to spend every waking hour of my life to meet the demands of all 4. I am okay working from 9-6, or 9-7 if need be, but more than that is way too much for me. 

Is 4 normal, or the new normal for how many projects a data scientist should be on? I don't know how I can keep up with this job if thats a normal workload.",2022-01-04 16:25:01
Looking for an open-source tool like KNIME & Rapidminer but allows downloading of code of the workflow,0,rvuai4,https://www.reddit.com/r/datascience/comments/rvuai4/looking_for_an_opensource_tool_like_knime/,1,1641302571.0,"I am looking for an open-source tool that allows a user to create workflows by dragging and dropping the operations, making the connections, and then creating visualizations. In the end, allowing users to download the code of workflow.",2022-01-04 15:22:51
Mathematical Analysis of two changing variables affecting an output through an unknown formula?,1,rvt0pn,https://www.reddit.com/r/datascience/comments/rvt0pn/mathematical_analysis_of_two_changing_variables/,6,1641298391.0,"I don't know if this is the place to pose such a question but I'll try my best to describe the problem. Interested to discover if there is a mathematical analytical approach to solving it.

Let's say you have a device in front of you that has a digital number display and two dials **A** and **B** (both dials go from the number 0 to 100). 

Built into the logic of this device there is a formula that takes the output of both dials and generates a number on the display (that number can only be positive), thinks pseudo-random numbers.

Now an objective of using this device would be to turn both dials and find the best combination of both turned dials, to output the **maximum/highest number possible.** 

What makes this more difficult is that the relationship between any one dial's value in isolation, to the output value on the display is not linear, meaning that setting only Dial A or B alone to 100 wont give the highest number on the display.

Meaning, that if you set dial A at 0 and only turn dial B to see that the display shows, that number on the display seems to go up and down ""seemingly randomly but consistent"" whilst turning directly from 0 to 100 on dial B, the same thing on dial A is apparent but with it turned in isolation, shows different values. Although these values shown are repeatable according to the location of the dials between 0 to 100.

Now if this information was simply fed into a computer, it could simply brute force the best combination of both dials by comparing every possible combination and checking the output display. 

**But here is where my question spawns from.**

Without testing both dials in combination, until you find the highest display value, is there a mathematical approach to find the highest value possible from setting both dials in combination but only using the information gathered from each dial in isolation to tell you what those two dails numbers should be.  


E.g   
Setting dial **B** to Zero and Sweeping Dial **A** from 0 to 100 and recording all displayed outputs then

Setting dial **A** to 0 and Sweeping Dial **B** from 0 to 100 and record all displayed outputs.

Then somehow using this data to predict which combination of Dial A (set to a number between 0 to 100) and Dial B (set to a number between 0 to 100) would result in the highest displayed number? without brute-forcing it by setting Dial A to 0 then recording all output values of Dial B (sweeping 0 to 100) then setting Dial A to 1 etc...

Let me know if this is a dumb question, but I don't know how else to describe this problem.",2022-01-04 14:13:11
Curious on the education background of this sub,106,rvmf2y,https://www.reddit.com/r/datascience/comments/rvmf2y/curious_on_the_education_background_of_this_sub/,169,1641273294.0,"

[View Poll](https://www.reddit.com/poll/rvmf2y)",2022-01-04 07:14:54
"Python is ""Language of the Year for 2021"" according to TIOBE (& #1 Ranking!), and am sure the surging popularity of Data Science helped a lot in making that happen!",338,rvj7qq,https://www.tiobe.com/tiobe-index/,44,1641263502.0,,2022-01-04 04:31:42
"How would you define ""Data Science"" in 2022?",3,rviydp,https://www.reddit.com/r/datascience/comments/rviydp/how_would_you_define_data_science_in_2022/,5,1641262802.0,"Seriously. What would you consider the hallmarks of a data science role? What should a data scientist (ideally) be spending their time on? How does that differ from reality? Are those differences a good, bad, or neutral thing?

We've had the field in various forms for several years. Just curious what others' opinions are in 2022.",2022-01-04 04:20:02
Data science and personal finance,4,rvduvn,https://www.reddit.com/r/datascience/comments/rvduvn/data_science_and_personal_finance/,9,1641248730.0,"Have some of you tried to apply AI to your personal finance and investment decisions: whether it be stocks, real estate, cryptos... ?",2022-01-04 00:25:30
"Automated, relevant, business performance insights?",2,rvdra2,https://www.reddit.com/r/datascience/comments/rvdra2/automated_relevant_business_performance_insights/,2,1641248473.0,"Hello, I work in a mid-size tech company and a decent amount of resources is spent on producing weekly insights about business performance (e.g. revenues, engagement, etc.) and its drivers.

The process is fairly manual as what is important/insightful changes all the time. Still, I have been wondering whether there is a better way and I imagine this must be a very common problem. 

1. How is this managed in your company?
2. Are there DS ways to produce automated, relevant insights (something like anomaly detection  plus recommendation)?

Thanks!",2022-01-04 00:21:13
What should I expect for product case study in the interview?,0,rvce7y,https://www.reddit.com/r/datascience/comments/rvce7y/what_should_i_expect_for_product_case_study_in/,3,1641244916.0,"Hello!

This is for the data analyst position in the interview.

What do I need to know about the service offered by the tech company. What questions would I need to consider?

Any suggestions to work on SQL. statistics, and python?

Thanks


edit: The company is tech company that is event management. I don't think it is big N one.",2022-01-03 23:21:56
Helping Business Analysts Understand Data Science and Machine Learning,1,rvb5nt,https://www.reddit.com/r/datascience/comments/rvb5nt/helping_business_analysts_understand_data_science/,0,1641241678.0,"I have been charged with creating a presentation that will help the business analysts (BA) at my company better understand what data science and machine learning is. The BA's at my company are primarily responsible for gathering business requirements and helping software engineers execute on projects. The data science team is a separate team that works to integrate machine learning into our current software algorithms. Right now the relationship between all of these teams is fairly weak and part of the goal of this presentation is to help us all work better together and understand what our different roles entail.

I'm fairly new to the industry and still getting my feet under me, but I'd like to know what you as data science professionals would like BAs to know about what you do and how it relates to what they do. What would you consider basic data science knowledge that BAs should know? What questions do you wish that they already knew the answer to? What's the most important thing you wish they understood about your job? How can BA's best support your efforts as a data scientist or machine learning engineer?

Thank you in advance for your feedback!",2022-01-03 22:27:58
Can you connect PyCharm Community to Microsoft SQL Server?,0,rvad4n,https://www.reddit.com/r/datascience/comments/rvad4n/can_you_connect_pycharm_community_to_microsoft/,2,1641239623.0,"As the title, really. I'm trying to connect PyCharm Community to Microsoft SQL Server but so far I've only seen documentation on how to connect PyCharm Pro to SQL Server. 

The JetBrain documentation tells you to go to View>>Tool Windows>>Database but I don't see Database under Tool Windows.

Edit: removed typo.",2022-01-03 21:53:43
Experienced Data Scientists : On what do you spend your most time on at work?,15,rva6xp,https://www.reddit.com/r/datascience/comments/rva6xp/experienced_data_scientists_on_what_do_you_spend/,21,1641239178.0,"I am curious about the general BAU/Day-to-day activities of a Data Scientist. What do y'all spend your most time on at work? Data Viz? Wrangling? ML?

My apologies if it's a dumb question. I am noob who's trying to break into this field.",2022-01-03 21:46:18
Report Framework - Trying to move away from Excel for report creation and management,1,rv9qt3,https://www.reddit.com/r/datascience/comments/rv9qt3/report_framework_trying_to_move_away_from_excel/,4,1641238011.0,"Originally posted on /r/analytics, but submitting here as I do believe there is a Data Science solution to this problem I am facing.

First and foremost, I am new to Data Science and have no coding experience. However, I am willing to learn anything that will help me solve or simplify my work processes.

**Current Process:**

I work as a Data Analyst within the FP&A team of a large organization. I build and manage the Budget & Forecast reports and other Ad-Hoc analysis reports for the team. I use Excel to build everything - using Power Query to ETL the data received from SAP data dump files, combine it with dimensional data files I have created in other Excel files, and finally pull the data into a table which I use to populate an Excel report template using SUMIFS and XLOOKUPs.

Using this method works fine in the first few months of the year as the raw data files are still small. However, when we reach month 4 or 5, these files have too many rows and columns, leading to these Excel files slowing down dramatically, making the files pretty much unusable. I have begun using Alteryx to perform the ETL instead and saved the files in .csv format to ease the burden on Excel. The problem with this is that I am the only user with an Alteryx license, so when refreshing this ETL workflow, no one other than myself can do that, making this an ineffective solution for the team. 

**Need Your Feedback:**

I would like to streamline (and possibly automate in some capacity) this process and move away from exclusively using Excel for everything. With the start of the new year, I would like to start building a framework to be able to do the following:

1. Create a workflow that ETLs the ERP raw data, but can be run by anyone on the team
2. A way to store all my dimension and fact tables, but also be able to update the information easily (would snowflake be a good platform for this?)
3. Connect the dimension and fact tables to the workflow
4. Populate the Excel template with this information.

I know I am basically describing Excel Power Query and Power Pivot here, but this is the only solution I know. This does not solve my Excel slowdown issues. It also is not a simple solution for the rest of the team as they need to fully understand the data contained within all the files and how to update it for the report to refresh correctly.

You all are the experts, so I am looking for your guidance to solve this problem. This solution would be immensely helpful in many areas of my work and may even assist others using a similar approach to build their reports.",2022-01-03 21:26:51
"Data Scientists working in healthcare, how do you keep abreast of the latest developments?",3,rv8iok,https://www.reddit.com/r/datascience/comments/rv8iok/data_scientists_working_in_healthcare_how_do_you/,3,1641234848.0,"I've been doing DS in a healthcare startup for about a year, and was curious to know what my peers do to keep informed about the latest developments in the field. I'm already keeping an eye on STAT's Health Tech and AI columns, following a bunch of startups on LinkedIn, but would welcome any other resources on what's happening out there.",2022-01-03 20:34:08
"Project, Tried 6/7 models, all give bad accuracy.",2,rv5u4i,https://www.reddit.com/r/datascience/comments/rv5u4i/project_tried_67_models_all_give_bad_accuracy/,12,1641227935.0,"Hi,

I'm in time stress with a project. For last months I have tried 6/7 models on my data, In no way I'm able to get high accuracy for my model. 

Any tips?

Could it be that my X variables just have no correlation with Y at all? 

What should I do..",2022-01-03 18:38:55
NLP: Hybridization of statistical approach and expert system ?,7,rv4ppz,https://www.reddit.com/r/datascience/comments/rv4ppz/nlp_hybridization_of_statistical_approach_and/,2,1641225073.0,"Hi everyone!

I have a question for you. For context, we aggregate on a platform the various AI APIs on the market (GCP, Azure, etc.) and including NLP APIs (keyword extraction, sentiment analysis, NER, etc.). The idea is that a developer doesn't have to create accounts with different providers and can have them all on one API to test, compare and change whenever he wants.

However, many customers ask us how to mix the ""statistical"" approach behind these APIs with expert systems and how to achieve hybridization.

Do you have any idea how to do this?

Thanks,",2022-01-03 17:51:13
Can I get away with using R Studio to run Python code only? Or will I have to eventually switch to a different platform?,0,rv4ils,https://www.reddit.com/r/datascience/comments/rv4ils/can_i_get_away_with_using_r_studio_to_run_python/,9,1641224545.0,"I’m aware that tools like PyCharm and Spyder exist, but I just find R Studio so much cleaner and intuitive to use, plus I love using R Markdown to create documents. Will I run into any roadblocks in my work if I just rely on R Studio for Python? Or will I have to switch eventually? Most of my background is in R, so that could be why I prefer it but I’m not sure.

Edit: I never even checked if I could use Python in chunks in r markdown. So that point is mute",2022-01-03 17:42:25
Data science is just numbers in a sausage machine,0,rv4f5l,https://www.reddit.com/r/datascience/comments/rv4f5l/data_science_is_just_numbers_in_a_sausage_machine/,10,1641224302.0,"Currently working with a director who said the above and then asked me (an analyst/BI consultant) if I could learn python in 2 to 3 days and do the above so they wouldn't need to hire data scientists.

Im pretty sure the ask is ridiculous, immediately in my head I know enough about data science that I need to learn python plus high level of statistics (my data pulling and cleansing are decent) and then data science theory itself to interpret the results I imagine.

2 questions I was hoping you could help with, 1 am I correct in my assumption. 2, how would you eloquently explain why it's not just a sausage machine. He's very arrogant with data and analytics as he's solid with Excel and pivot table and has that vibe where he thinks all other departments and people are idiots so will doubt any answer I give.",2022-01-03 17:38:22
Advice on Freelancing in DS,16,rv3ep7,https://www.reddit.com/r/datascience/comments/rv3ep7/advice_on_freelancing_in_ds/,25,1641221560.0,Has anyone had any luck doing some side work/freelancing as a Data Scientist? I’ve been thinking about starting a LLC and begin trying to reach out to smaller companies. Any advice would be greatly appreciated!,2022-01-03 16:52:40
"Revisiting the ""The Sexiest Job of the 21st Century"" article a decade later: What still remains true and what is no longer true about the industry from the article? And have their speculations bore out?",259,rv1tpg,https://www.reddit.com/r/datascience/comments/rv1tpg/revisiting_the_the_sexiest_job_of_the_21st/,60,1641216817.0,"So it's 2022 which means it's almost a decade since the original ""sexiest job of the 21st century"" article was published by the Harvard Business Review (HBR). Link to the original article is here: [Data Scientist: The Sexiest Job of the 21st Century](https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century). 

The HBR makes some interesting speculations about the field and I think the article is a good snapshot of what data science was like back in 2012 (or at least the aspirations for data science).

I'm interested in revisiting this article and see what still holds true and what doesn't any more 10 years on since its publication. In addition, what changed about data science since then? In other words, what speculations did they get right and what did they get wrong?",2022-01-03 15:33:37
Hey guys!,0,rv0gf5,https://www.reddit.com/r/datascience/comments/rv0gf5/hey_guys/,0,1641212316.0,"Iam facing an issue extracting the datasets for ADNI. I want to extract datasets related to but I can’t seem tk find them!!!

Can anyone help?

It will be a massive favor.",2022-01-03 14:18:36
What are your 2022 goals? And what is your system to reach them?,8,rv09mp,https://www.reddit.com/r/datascience/comments/rv09mp/what_are_your_2022_goals_and_what_is_your_system/,12,1641211640.0,"I have been in Data Science field for 5 years now. I work as a trainer.

First few years I was reading & learning a lot. But since covid, it's been hard to keep up with the changing & constantly growing field.

Difficulty of catching up with abundant information, covid isolation has lead to me burning out and loosing motivation & I am trying to get back the mojo to dive deep in the field again.

I haven't been feeling that into AI for a while (1.5 years), despite achieving a decent amount and earning a comfortable salary. I want to overcome the career plateau I have reached and looking to shake things up. I want to rediscover what I loved about AI in the first place and move into a new subfields which are little more interesting to me.

My plan is:

1. Redo the basics. Andrew NG course and some other classics in Computer Vision and NLP
2. Actually implement some small projects
3. Catch up with the progress made in past 3 years
4. Start a personal project that focuses on combination of NLP + Unreal Engine 5 for effective interactions. Somethng which I feel would be very useful in future.

I don't know if it's pheasible or what things would be better to try or learn?

Thoughts? What are you planning on doing in 2022?",2022-01-03 14:07:20
What's the best Python notebook setup for data analysis?,9,ruyogo,https://www.reddit.com/r/datascience/comments/ruyogo/whats_the_best_python_notebook_setup_for_data/,9,1641205662.0,"- Do you use Jupyter Lab / Notebooks in browser or in an IDE (VSCode / PyCharm / DataSpell)? Or a combination of both?
- What are advantages of each approach?
- Any recommended extensions / plugins?",2022-01-03 12:27:42
Reading scala/spark xgboost model in python,0,ruy59g,https://www.reddit.com/r/datascience/comments/ruy59g/reading_scalaspark_xgboost_model_in_python/,0,1641203574.0,"I have an Xgboost model trained in scala/spark with XGBoost4J package. I want to read it in python for doing some analysis (it can't be done in scala/spack).

Any help will be appreciated.",2022-01-03 11:52:54
Can anyone explain about the difference in scope of work between Data Analyst and Market Researcher?,4,ruy0xd,https://www.reddit.com/r/datascience/comments/ruy0xd/can_anyone_explain_about_the_difference_in_scope/,2,1641203061.0,"I'm just an intern in the marketing and research division, my job is to build a database and doing field research. I'm just puzzled about the limitation, because my users call them with two different things, or are their jobdesk actually the same?",2022-01-03 11:44:21
Has anyone ever dealt with passive-aggressive bullying in the workplace?,12,ruw6x4,https://www.reddit.com/r/datascience/comments/ruw6x4/has_anyone_ever_dealt_with_passiveaggressive/,11,1641195558.0,"I'm a junior-mid level data scientist who works in a small team at a startup. I have a supervisor who also has a supervisor. 

The sense I get from them is that they think I'm not capable for the job. They show it in a very passive aggressive way. My direct supervisor would always be keen to find faults right in the middle of what I'm saying when I'm explaining/presenting/discussing something, esp with other team members. These faults don't even make sense most often and he let's others complete what they have to say without interjecting. 
He tends to point out my mistakes publicly and I feel behind doors he must be even more severe in his criticisms cause his supervisor has started to look at me in the same way.

The whole ""I think you're of inferior intellect and I need to show you your place"" thing really shows when he talks. And there's such a distinct difference from the way he interacts with others vs me, in both what he says and the manner/tone in which he says it.
It in effect makes me respond even dumber out of anxiety.

Whenever I do something well, there's radio silence.

I'm already anyways nervous because I do think they're smarter (also like 5+years older) and I want to learn and do great work. But this anxiety turns it into something ugly and uncomfortable.

The thing I'm scared about is getting fired. I feel they talk about me behind closed doors and barely talk to me about anything. Just adds to the anxiety. And I'm indeed already underperforming in some areas.

I have been applying recently and hope soon I'll be out of this but if you've had such an experience, would love to know how you dealt with it.",2022-01-03 09:39:18
What are the common applications of ML in Fintech companies ?,2,ruve8z,https://www.reddit.com/r/datascience/comments/ruve8z/what_are_the_common_applications_of_ml_in_fintech/,6,1641192461.0,"Would be interested to know what are the things I should focus more on, as I currently do not have much knowledge in Finance, but I'm interested to look for a job in Fintech companies somehow. 

Are there any good recommendations on skills I should focus more on before applying a role in Fintech companies? 

Cheers !",2022-01-03 08:47:41
How to validate data integrity?,1,ruu4qk,https://www.reddit.com/r/datascience/comments/ruu4qk/how_to_validate_data_integrity/,2,1641187977.0,Hi. I'm trying to set up a process for validating data integrity on a month to month basis. Data should be accurate and up to date as of month end. Can any of you experts share how you verify data integrity? Our team updates the database based on the information obtained from email communication and updates accordingly.,2022-01-03 07:32:57
"The data science field is very exhausting and consume much of our time, so what else do you do beside your work or study in this domain, that helps you to give your brain a break from it ?",168,rut3fw,https://www.reddit.com/r/datascience/comments/rut3fw/the_data_science_field_is_very_exhausting_and/,75,1641184686.0,,2022-01-03 06:38:06
What're your favorite tools in 2022? What do you wish someone would build?,4,ruq3vw,https://www.reddit.com/r/datascience/comments/ruq3vw/whatre_your_favorite_tools_in_2022_what_do_you/,2,1641175703.0,,2022-01-03 04:08:23
Do you use Reinforcement Learning in your work as a data scientist ? How ? What are the applications ?,11,ruol4k,https://www.reddit.com/r/datascience/comments/ruol4k/do_you_use_reinforcement_learning_in_your_work_as/,3,1641171466.0,,2022-01-03 02:57:46
Interrupted Time Series (ITS) in Python,5,ruok3r,https://www.xboard.dev/interrupted-time-series-python-part-I,0,1641171385.0,,2022-01-03 02:56:25
Maybe someone looking for a data science job in soccer - AS Roma is looking for a Data Analytics Manager,195,runqoo,https://sportekjobs.com/data-analytics-manager-as-roma/61cdfa127156a1003ddc45a9,26,1641169075.0,,2022-01-03 02:17:55
Is there a lot of writing code in data science?,45,rum01f,https://www.reddit.com/r/datascience/comments/rum01f/is_there_a_lot_of_writing_code_in_data_science/,24,1641164444.0,"I'm coming from web/mobile development background where I write a lot of code, but it's not so challenging mentally. I'm thinking of learning data science and especially machine learning. Problem is that I'm scared I'll be locked in Excel/data visualization hell, where really I care only about writing code, and solving problems.   
I know that with machine learning comes with a lot of math, thinking how to strip data and stuff, but it all seems just like problem-solving I always knew. I just don't want to spend a few months of my life learning it just to leave, because it's not my thing.",2022-01-03 01:00:44
Better refraction methods?,5,rukocc,https://www.reddit.com/r/datascience/comments/rukocc/better_refraction_methods/,0,1641160958.0,"I’m just starting to code larger projects and I’m starting to feel like a lot of the code that I write and clean is unclear and at times confusing. Many times it also feels like what I’m doing in my program should be simpler, or I feel like I should have been able to do it more concisely. 

Does anyone have advice on cleaning and refactoring code for larger projects?",2022-01-03 00:02:38
Recommended service for deploying a model online for multiple users to add to a central database,2,rujm5v,https://www.reddit.com/r/datascience/comments/rujm5v/recommended_service_for_deploying_a_model_online/,6,1641158037.0,"Please let me know if there's a better place to post this question. I'm still a relatively new data scientist. I'm pretty familiar with building models, but we've always handed them off to an MLE for deployment, and I've only ever done that in a work setting, so model deployment is a bit out of my depth. I’ve done a fair bit of research, but nothing I’ve found has addressed this particular use case, and I’m not sure what keywords to include to find an answer.

A friend of mine has successfully sued to have a number of documents released to the public under FOIA. There are thousands of these documents, and the only way to get all of them will be to FOIA a few of them at a time. We want to compile a database of the information in these documents, so our plan is to spread out the work of requesting them across multiple people and combining the information on the back end. (The body we're requesting the documents from definitely won't provide us with a searchable database, as evidenced by the fact that we had to sue in the first place...)

I've put together a model that can extract the information in these documents pretty accurately. Our ideal deployment workflow is that people who FOIA the documents can:
* upload the documents,
* run them through the extraction model,
* manually validate and correct the output, and 
* add it to a central database people can access

What service should I use that can do all of these? Are there any considerations for this use case I should be aware of that I haven’t mentioned?",2022-01-02 23:13:57
Weekly Entering & Transitioning Thread | 02 Jan 2022 - 09 Jan 2022,7,ru89hj,https://www.reddit.com/r/datascience/comments/ru89hj/weekly_entering_transitioning_thread_02_jan_2022/,156,1641124831.0,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",2022-01-02 14:00:31
What is your team function within your organisation?,1,ru5fgg,https://www.reddit.com/r/datascience/comments/ru5fgg/what_is_your_team_function_within_your/,14,1641112368.0,"As title suggests I am interested whether Data Scientists usually sit in a team that provide support to other product teams (support team) or are you part of the product team.

[View Poll](https://www.reddit.com/poll/ru5fgg)",2022-01-02 10:32:48
Anyone here doing cricket analytics? Could you give some good research papers on how to analyze the games?,11,ru5csn,https://www.reddit.com/r/datascience/comments/ru5csn/anyone_here_doing_cricket_analytics_could_you/,6,1641112041.0,"So I have a craze for cricket as a game and I'm looking for better ways to find meaningful insights from the data I have, so if you have research papers that could help me find better techniques that would be appreciated. 


Thanks",2022-01-02 10:27:21
Is medium even proofreading submissions at all?,199,ru4vnt,https://www.reddit.com/r/datascience/comments/ru4vnt/is_medium_even_proofreading_submissions_at_all/,75,1641110028.0,I just read this [medium post about embedding layers](https://medium.com/swlh/embedding-of-categorical-variables-for-deep-learning-model-explained-6aa8a1a04603?source=email-c628f63aeb75-1641093440006-digest.reader-f5af2b715248-6aa8a1a04603----0-59------------------f3834c5c_2723_4830_87be_b1d8d5f43959-1-42b188b7_00ff_42da_8357_2bcb7d450ed2) that was emailed to me as a suggestion: there are so many typos/spelling mistakes it’s hard to understand how it was published. Not to mentioned the questionable omission of one hot encoding as an obvious option to deal with categorical variables.,2022-01-02 09:53:48
Is it ethically right to pirate a course?,0,rtter0,https://www.reddit.com/r/datascience/comments/rtter0/is_it_ethically_right_to_pirate_a_course/,53,1641073588.0,"Well, I have a huge folder with video materials from a very popular course provider I downloaded it for free. In reality it costs a lot of money. Of course I will not get the same mentorship and help as if I bought it, but I still feel weird about it. Now I feel conflicted if it's ethically ok to study with it.",2022-01-01 23:46:28
Partial Least Squares Regression Question,1,rtsp1g,https://www.reddit.com/r/datascience/comments/rtsp1g/partial_least_squares_regression_question/,4,1641071582.0,"Hey everyone,

I am looking to do a partial least squares regression in R using the ""pls"" function. I understand that pls functions similar to PCR in that it reduces data dimensions and uses those reductions as covariates in a regression model. In r, is there a way to save the reduced variables so that you can use them anyway you want? Like, I'm thinking of this in a PCR kind of way in which we reduce the variables into principal components and save those and then regress whichever of them we choose. Is that possible in R? Any help would be appreciated, thanks!",2022-01-01 23:13:02
People have been telling me bootcamps are a scam and they out there just to get your money. I also believed college degrees is the only way until colleges everywhere starting to have their own bootcamps. Are they scamming people in doing bootcamps?,0,rtov1g,https://www.reddit.com/r/datascience/comments/rtov1g/people_have_been_telling_me_bootcamps_are_a_scam/,36,1641060776.0,,2022-01-01 20:12:56
A (semi-snarky) Request: Write better questions!,184,rto1f0,https://www.reddit.com/r/datascience/comments/rto1f0/a_semisnarky_request_write_better_questions/,20,1641058413.0,"This sub has a lot of people asking ""how do I do {thing}?"" This is great! I'm glad you want to learn, and honestly, most of these questions are more interesting than the Nth ""how do I get a job as a Data Scientist/which certificate should I blow my money on/etc"" post.

HOWEVER

The best way for us to help you is to be very clear about:

1) What do you want to do? Sometimes you may not know entirely (eg, ""how do I know if something is causal?""), but the clearer you can be in a question, the more effective we (the subreddit) can be in providing you guidance. Details about the kind of data you have, what you're trying to measure, things you've tried already, all of this can help. ""I have some data and want to see if there's a relationship there?"" Not a great question.

2) What tools you're comfortable with! Are you a Python/Pandas purist? Do you think the Tidyverse is tops? Do you think anything written after Assembly is blasphemous and cheating (if so, wow, I'm not sure why you're here, you probably know more about coding than everyone else in this sub combined)? Are you an Excel wizard, who shudders at the thought of the command line? (No judgement here, everyone has to start somewhere). The more you can tell us about what you're comfortable with, the better our recommendations can be. 

3) What constraints you have! Are you at a FAANG, where you have effectively infinite compute, more money than god, and the ability to simulate the universe in miniature to answer hard questions? Suggestions for you are going to be different than those for someone working locally on a desktop/laptop with limited compute resources. In the latter case, a regex and a logistic regression might be more useful than a high-powered neural network.

4) Whether this is homework or a class assignment. If it is, ask your professor/TA. They can answer your question better than we can.

AND TO THOSE OF YOU ANSWERING:

Please stop suggesting neural networks to solve problems. It's probably not the best solution, and certainly shouldn't be the first.",2022-01-01 19:33:33
Interesting 2021 paper roundup from a CMU econ prof. Lots on forecasting!,77,rtklxg,https://donskerclass.github.io/post/papers-i-liked-2021/,2,1641047846.0,,2022-01-01 16:37:26
Is this subreddit for data analysts or just data scientists?,152,rt4ruy,https://www.reddit.com/r/datascience/comments/rt4ruy/is_this_subreddit_for_data_analysts_or_just_data/,70,1640989276.0,,2022-01-01 00:21:16
How was your graduation project ?,4,rt3tpl,https://www.reddit.com/r/datascience/comments/rt3tpl/how_was_your_graduation_project/,24,1640986396.0,"Hello everyone, curious to know what other people went through in their graduation project.

To me it was a pretty good learning experience cause it made me self learn a lot with almost none hand holding aside from documentation, my grad project was basically an image classification project about detecting deformaties, it was exciting to learn about data science, data mining, model building, some ml techniques and dl models and their architecture.

But it was also VERY exhausting, was basically holding the team together, there were always problems with someone not doing his job correctly, ended up talking with the doctors and professors about it, huge fights, embarrassment in front of the judging doctors for each phase, it was so stressful and tiring but we got through it in the end.",2021-12-31 23:33:16
How to do data pre-processing in production,9,rt2mdq,https://www.reddit.com/r/datascience/comments/rt2mdq/how_to_do_data_preprocessing_in_production/,11,1640982794.0,"I am a software eng traditionally but recently became a data scientist... looking for ideas on how to do data pre processing in production.. the use case is as follows:

1. A new data row becomes available every few minutes

2. It needs to be preprocessed before it can be injested by downstream models.



Creating an OOP-style data pre processor class does not sit well with me because it does not make sense that there is a ""class"" structure here. All of the methods end up being static (or non static but dont end up using the class state so practically static)... so really what is the point of the class? At the same time Python is OOP language making it difficult to structure things in a class-less manner... 

Wondering if anyone faced similar scenarios and what are some good practices here?


Edit: Thank you all!! Awesome responses from everyone that are definitely making me think better about this task",2021-12-31 22:33:14
Classifying the Political Compass - what method?,1,rsza5r,https://www.reddit.com/r/datascience/comments/rsza5r/classifying_the_political_compass_what_method/,3,1640972953.0,"I have a school NLP project that is pretty open ended. I am fairly new to ML so I don't have a very good grasp of what classification method would be right for my scenario.

I grabbed a bunch of flairs off PoliticalCompassMemes and some comments by the users. I want to classify both dimensions (right/left, authoritarian/libertarian). My first thought was to just do 2 separate binary classifications. I am content with this idea, except I don't want to lose the center.

I was thinking maybe I could do binary classification but treat the middle as center, although I'm not sure if this sort of thing would be configurable with the libraries I end up using to make predictions. Alternatively, I could do multilabel classification for each (right/center/left, authoritarian/center/libertarian) but I'm not sure how much this increases complexity and if it actually would give better results.

&#x200B;

**edit:** Seems like this is kinda what I'm getting at [**https://stats.stackexchange.com/questions/258668/adding-a-third-class-0-i-dont-know-to-a-binary-classification-problem-1-1**](https://stats.stackexchange.com/questions/258668/adding-a-third-class-0-i-dont-know-to-a-binary-classification-problem-1-1)",2021-12-31 19:49:13
Create data lake?,1,rslgqn,https://www.reddit.com/r/datascience/comments/rslgqn/create_data_lake/,17,1640925225.0,"To the CLOUD!! Best strategy?

Hi All,

General question about migrating different databases from our legacy erps to the cloud.

The Nirvana state - I want to be able to connect my legacy data to new apps and/or leverage low code solutions like MS power apps. Could I even have it so that when we look at new SAAS, we hold our API Key, targets and data dictionary. We issue them their connection credentials and then it’s on them to write the api to integrate.

Initial Thoughts:
What we think want is a data lake that we could create different data stores(operational, financial) with the sole purpose of integrating best fit or best in class solutions per major work flow. Workflow 1, use SAAS 1, Financial uses Sage or MS Dynamics, etc. Those are the big wins. The little wins are anything we are doing in excel that needs a workbooks with all those macros running replaced immediately with power apps we spin up. 

Legacy framework- one db is in SQL, other in older framework using Delphi though not entirely familiar with how it is really structured

Dirty data- between the 2 dbs we have tons of duplicate entries, years of folks changing the name just enough to be able to enter in the customer info.

Can what we want to do even be done the way we want it?
How do we consolidate the duped data?

What approaches have you seen work or NOT a work?",2021-12-31 06:33:45
Nonlinear Programming in R?,8,rsjx9k,https://www.reddit.com/r/datascience/comments/rsjx9k/nonlinear_programming_in_r/,2,1640920268.0,"Hey everyone,

I am interested in using R to do a portfolio variance minimization problem using nonlinear programming but I only seem to see packages for linear programming problems. Does anyone know of a package for nonlinear programs? Thanks! If there is a package in Python for this, please let me know as well.",2021-12-31 05:11:08
"To the companies that send candidates a 3 hour take-home test, and then say their corporate policy does not permit feedback after one is rejected...",837,rsfdlx,https://www.reddit.com/r/datascience/comments/rsfdlx/to_the_companies_that_send_candidates_a_3_hour/,172,1640906797.0,"Your hiring process is terrible and you absolutely have a terrible policy.

Job hunting is already a crappy, long and unrewarding activity, and at the very least feedback would be helpful to help candidates improve their chances in their job hunt for the next role they apply to.

It's not only the 3 hour test that's stressful, but even before doing the test we have to review and refresh our knowledge because we've all been pigeonholed one way or another at our respective firms. It's a 3 hour test for you, but it's days/weeks of studying, interviewing, holding current job, juggling with shit on our end. And we're trying to re-learn so many things that you claim is ""normal day to day operation"" at your firm for data scientists.

And quite frankly, I call that bs that your day to day ops includes advanced statistics or measuring bayesian probability by hand. Just like how my firm claims the role for our job requires coding in Python and statistics, only to realize that daily tasks are to run reports from Google Analytics/Adobe Analytics.

Like come on...

/rant",2021-12-31 01:26:37
A graceful exit?,9,rsbbjg,https://www.reddit.com/r/datascience/comments/rsbbjg/a_graceful_exit/,16,1640896090.0,"I'm a member of a very small team at my current organization.  There are loads of things I like about my job, but there is no room there for me to take the next step in my career.  I'm looking for a change and have landed a few interviews. I don't want to leave my team in the lurch and burn bridges if another opportunity presents itself.  Have any of you been in this situation? How did it end? What would you do (or not do) again if you found yourself in a similar situation?",2021-12-30 22:28:10
Do portfolios matter if you have > 2 years of experience?,18,rsb6l4,https://www.reddit.com/r/datascience/comments/rsb6l4/do_portfolios_matter_if_you_have_2_years_of/,23,1640895729.0,"Hey everyone, didn't see this topic in the search results.

I'm a data scientist with a little over 2 years of experience and an MS in Stats, looking at changing jobs over the next few months (once I have my Permanent Residence sorted out).

My question is: should I create a portfolio of 2-3 projects for when I start applying for new jobs? I have things I can point to in my CV where I saved $xx,xxx in multiple different instances, and worked on the back end for an app on the side at one of the universities projects. I also have 2 publications where I was a data analyst at the Pscyh department at the same university - I feel this would put me at a disadvantage.

 I'm just nervous that none of the stuff actually sounds that cool, and I didn't end up having to use NNs or anything fancy. Most of the techniques involved are fairly straightforward (logistic regression etc).",2021-12-30 22:22:09
How to deal with feature selection?,76,rs9ggc,https://www.reddit.com/r/datascience/comments/rs9ggc/how_to_deal_with_feature_selection/,30,1640891268.0,"Im quite new to ML, and have had some trouble understanding the best way to select features for a regression problem.

I understand we don’t want multicollinearity between features, but is it just preference which method we use to choose features, Pearson’s, or algorithms like lasso or random forest? Does it matter if we do/don’t use the same algorithm for our model as for our feature selection? 

And finally, this is probably highly subjective and depends on the individual problem, but is there a certain threshold for multicollinearity? I’m not too certain I understand why it’s best to avoid multicollinearity , so if anyone has some intuition to help with that I’d appreciate it! 

Thanks for any help!",2021-12-30 21:07:48
Interesting read about data storytelling: Why You Need to Tell a Story With Your Data,40,rs3dch,https://www.reddit.com/r/datascience/comments/rs3dch/interesting_read_about_data_storytelling_why_you/,14,1640875417.0,"Basil Awartani is a data Storyteller, media analyst, and strategic communication consultant. He wrote an article about storytelling titled: ""Why You Need to Tell a Story With Your Data"".

The article capitalizes on the idea of “Data is Worthless if You Don’t communicate it.” to tackle an issue that is often missed by data experts and researchers.

Check the full blog post here: https://medium.com/bamieh-tech/why-you-should-tell-a-story-with-your-data-a99bcb908262",2021-12-30 16:43:37
How do you reduce information leakage and bias when going from descriptive analytics to prescriptive analytics?,130,rrzswd,https://www.reddit.com/r/datascience/comments/rrzswd/how_do_you_reduce_information_leakage_and_bias/,36,1640864182.0,"Cassie Kozyrkov, Cheif Decision Scientist at Google, wrote a great article about ""Data charlatans""  trying to analyze data and at the same time making statistical tests to pretty much verify the phenomena already seen in the exploration (https://towardsdatascience.com/how-to-spot-a-data-charlatan-85785c991433). The solution to this problem is of course data splitting, in the best cases having a subset for exploration, and other for training, testing etc. 

But what happens when an organisation is far behind the ""analytical ladder"" and is doing descriptive analytics in various reports and with no intention of doing anything else, but then wants to move to more diagnostic, predictive and eventually prescriptive analytics? The data in the analytical reports are probably showing ""all"" data in real-time and several conclusions about the data has probably already been made. 

How can you limit the information leakage when deciding to do more more statistical tests, training and testing? Has anybody had any experience with this problem and found a solution?",2021-12-30 13:36:22
How to find monthly google searches for a specific keyword?,3,rrt76h,https://www.reddit.com/r/datascience/comments/rrt76h/how_to_find_monthly_google_searches_for_a/,3,1640840779.0,"How to find monthly google searches for a specific keyword I have seen people say to use google keywords planner but that needs an AD Campaign I am looking for something else which is free 

I just want to make something like this [https://www.youtube.com/watch?v=y-NeXT689ig](https://www.youtube.com/watch?v=y-NeXT689ig) for just a fun side project, the video has instructions on how he did it in the description but I am unable to find it Thanks",2021-12-30 07:06:19
"The more I think of my data career, the more anxious I become (mid career)",113,rrlw8y,https://www.reddit.com/r/datascience/comments/rrlw8y/the_more_i_think_of_my_data_career_the_more/,56,1640820029.0,"Sorry for the clickbait title but I'm exhausted. This probably isn't the right sub but I need some assistance. I'm also extremely lucky. I make good money, pretty good job, a boss who I get along with, and a lot of autonomy. Data is pretty straight forward (sales, finance, product, marketing data).

The part that exhausts me is reading the data labor market and trying to make sense of trends to plan for what's to come. It's plagued me for two years now, and I cannot infer enough to make a decision for what my next step forward should be due to the ever changing landscape. This ""industry"" is tumultuous and drastically inconsistent to say the least.

I started in BI several years ago after earning a bachelors in accounting and then taking IT courses at a community college, mainly DB and SQL centered classes. Up until 2019 or so, I hadn't really worried about what's to come because I often felt like my skill set was enough, so I just kept going deeper with SQL, dbs, and BI tools. I figured that I would top out as BI Director and then decide what I should do next. Well, next is now. For the past two companies, I have worked as an individual contributor director (yes, in the start up technology space, we unfortunately exist). SaaS/Technology is the industry I prefer since it aligns with my interests. 

The fact of the matter is, since everything continues to evolve, I fear I'll eventually fall behind because I don't have the formal technical nor quantitative credentials when going for the next role (whatever that should be). 

I've looked into DS roles, but I haven't ever built a ML model. Haven't put any into production either because any forecasting/prediction I've come across was handled by FP&A. No one in product has given a damn about analytics because they SWAG everything. Everything in Finance goes by their rules, not by statistics. Sales is the same, they have a set of rules they abide by. I've tried thinking in terms of using statistics, but it seems very rare to find someone who cares about them, or how it would lead to something other than a nice to have.

On the technical side, everything except for the EDW is built out. I spend 95% of my time on SQL and 5% of dashboarding and visualizations. I work on jobs in the EDW, work on modeling, reports, etc. I've sped up business processes that took days down to hours (from F300 companies to these start ups). It seems CS and Stats knowledge is on the fringes at best.

What am I supposed to do? As I approach my 40's, I'd like to have a masters degree as a signal that I'm either formally educated to where if I encounter DS topics in BI, I won't just SWAG it. I feel like the CS part is the safest bet, since I can always fall back in BI dev or data/analytics engineer type roles, but I lose out on statistics. Similarly, if I go statistics, I feel like I will never use the knowledge or that it's overkill for what I do.

Does anyone else, especially those who work in data science, encounter this kind of existence? I saw a post the other day where there was a category of data monkey and I thought, I'm the director of data monkeys. 

Any help is appreciated, just to help ease my mind.",2021-12-30 01:20:29
Is Topological Data Analysis useful for time series data?,2,rrh6uh,https://www.reddit.com/r/datascience/comments/rrh6uh/is_topological_data_analysis_useful_for_time/,2,1640808101.0,"Today I came across [this](https://arxiv.org/pdf/1703.04385.pdf) paper claiming to use TDA to predict early warning signs of market crashes. Although their methodology makes sense, I really don't see any way how these results are better than a simple volatility check. 

Does topological data analysis provide any useful information in this case (other than just being a glorified version of clustering)? Is it still relevant today or it was just a fad started by Ayasdi?",2021-12-29 22:01:41
Does anyone know a good resource for making the map in this New York Times article?,7,rrfk82,https://www.reddit.com/r/datascience/comments/rrfk82/does_anyone_know_a_good_resource_for_making_the/,8,1640804066.0,"Here's the article: [https://www.nytimes.com/interactive/2021/12/28/us/covid-deaths.html?smid=fb-nytimes&smtyp=cur&fbclid=IwAR0chy3\_E-IPSKew9hUTPcs-ilZqbdOWA5DE5rDeXnRS8Gj0IG9EC6mFpA4](https://www.nytimes.com/interactive/2021/12/28/us/covid-deaths.html?smid=fb-nytimes&smtyp=cur&fbclid=IwAR0chy3_E-IPSKew9hUTPcs-ilZqbdOWA5DE5rDeXnRS8Gj0IG9EC6mFpA4)

I'd love to know if anyone has found a good resource for making these kinds of maps.",2021-12-29 20:54:26
"The PyMC developers wrote a book! "" Bayesian Modeling and Computation in Python"" Detailed ToC screenshotted, link to publisher's page in first photo",82,rrchxx,https://www.routledge.com/Bayesian-Modeling-and-Computation-in-Python/Martin-Kumar-Lao/p/book/9780367894368,11,1640796400.0,,2021-12-29 18:46:40
I made a modern data catalog tool for anyone using a word document or excel sheet as a data catalog. I’m curious if anyone would like to try it out.,31,rrbmaz,https://www.reddit.com/r/datascience/comments/rrbmaz/i_made_a_modern_data_catalog_tool_for_anyone/,49,1640794125.0,"At my old job, it seemed like I'd have a new project with a new dataset every few weeks. The hardest part of my job was understanding the data not completing the project.

Last year, I built a data catalog using the no-code platform bubble and shared it here. We ended up with quite a few people testing it out and using it on personal projects. In the last 12-months, I took the original platform I built and leveraged some open-source platforms like Amundsen to rebuild a modern data catalog focused on making data documentation transparent, collaborative, and straightforward for anyone or company.

We have a sandbox environment with dummy data that we're looking for user feedback on. If anyone is interested in giving it a spin, please let me know! We're planning to release a public version for anyone to use early next year.

Happy New Year, and I appreciate anyone willing to give it a try.",2021-12-29 18:08:45
really feel like Data Science gets romanticized and people don't talk about the support aspect.,196,rraolv,https://www.reddit.com/r/datascience/comments/rraolv/really_feel_like_data_science_gets_romanticized/,44,1640791663.0,"I am not a Data Science person by trade. I did it for a little over 2 years because our Data Analyst left and I was the DBA. I am an systems engineer. I didn't have time to roll out PBI, Push Reports, etc. I did a lot of my stuff as canned SPs that I could modify quickly. We got bought and I handed all of that off to a real Data Team with the right tools and knowledge. But from time to time I get asked something and it is easier for me to run point so I can just get the info directly from whoever and sort it out faster than a back and forth with a lower tier of Reporting Support.

Yesterday afternoon I got asked about a problem where a user said a report was ""missing"" information. And to me - that just meant they expected something, not that anything was missing. Which is a huge part of DS  - managing expectations. Something I don't think people realize is a huge part of the job going in.

So I sift through the info and talk to the person reporting the ""problem"". Between them and the Reporting Support tier 1, I realize the problem is - they are looking at a Maintenance page and comparing that list to the report. They were concerned the report didn't have everything the Maint page had.

I needed to confirm this with the user reporting to establish y baseline. I send them the exact link to the Maint page and say, ""You're looking here and seeing claims that aren't on the Claims Status report on the customer side right?"" They say, ""No, I am looking at the Customer Side."" and send a screenshot of the report. I say, ""Right, but in order for you to feel like that report is missing Claims, you must have another list or data source you're comparing it to. Is it this page on the admin side. ""No, I'm on the shipper side."" Sends same screenshot of report. Me, ""I understand, but what are you looking at to make you think Claims are missing."" Him, ""Joe Blue confirmed on the admin side."" Me, ""Okay, where on the admin side did he look to confirm - how did he confirm?"" Him, sends a screenshot of the page I linked 5 minutes before asking if that was where.

Thank you all for doing the job so I don't have too. And I know there are a lot of you out there over qualified not getting paid enough because people don't factor in the above situations and how needy people are - especially Sales. So they don't think far enough into it to pay you to make dealing with that worth it. They think pay should be based on skill set alone, not an incentive to endure nonsense.

I'm patient, but I'm not that DS patient.",2021-12-29 17:27:43
Friendly reminder to just go ahead and set up git on everything,34,rra7t0,https://www.reddit.com/r/datascience/comments/rra7t0/friendly_reminder_to_just_go_ahead_and_set_up_git/,10,1640790396.0,"Or whatever version control you use.


Had a small script I would use for ad hoc data cleaning that I didnt bother adding it to the repo, well now it's not so small and it needs to be added. I just dislike adding new local directories to the repo and wish I had just set it up from the start instead.",2021-12-29 17:06:36
"Does it make sense doing stats tests (like ttests, chi-square etc) to better select the predictors in a supervised model?",10,rr8i51,https://www.reddit.com/r/datascience/comments/rr8i51/does_it_make_sense_doing_stats_tests_like_ttests/,16,1640785440.0,"I mean, it makes sense to me, but I don't see many of the Machine Learning tutorials on internet performing those tests when doing feature selection.

Is it a good practice? Or there's a catch?

Thanks!",2021-12-29 15:44:00
A simple and effective way to go from beginner to intermediate level of ML knowledge,513,rr7cn2,https://www.reddit.com/r/datascience/comments/rr7cn2/a_simple_and_effective_way_to_go_from_beginner_to/,29,1640781749.0,"Read the [scikit-learn user guide](https://scikit-learn.org/stable/user_guide.html) from top to bottom.  This is not even a joke, it contains many examples, tips and teaches you to work with their API, to avoid common pitfalls, actually explains (part of) the underlying math and links to relevant books/papers.

By reading it you'll come into contact with a ton of methods you probably never heard of as a beginner like gaussian process, kernel ridge regression and tons of methods in robust statistics. I encourage you to take notes, watch video's and learn about these methods. You may want to start with chapter 6 first but that's up to you. I'd highly recommend you to have covered some (upper) BSc / MSc  equivalent intro to machine learning course though.

When you're done you can (attempt to) do the same thing for [statsmodels](https://www.statsmodels.org/stable/user-guide.html) (especially the TSA api) but that will be considerably more painful.",2021-12-29 14:42:29
Transitioning from corporate to Bioinformatics Research,8,rr6rtt,https://www.reddit.com/r/datascience/comments/rr6rtt/transitioning_from_corporate_to_bioinformatics/,5,1640779797.0,"I'm a full-stack developer at a US based company. I have completed my bachelor's engineering in Computer Science and Engineering in 2020. At that time I wasn't sure about what I really wanted to do with my career. In last 1+ year I've been trying different technologies and fields to figure out what I would love to do for the rest of my life. And few months back I realised that I want to ""apply machine learning and deep learning techniques in biology or healthcare field"". One more thing that came to my mind after thorough observation is that I love exploring new things and have a genuine curiosity about how things work, what can we do to improve something or how can we find something or some way that could solve a problem. This lead me to the fact that I should follow the career of a bioinformatics researcher or a data scientist focusing on healthcare.
Given my current scenario, I've to get a master's degree in healthcare informatics or bioinformatics, then go for a PhD and then getting enrolled in some institute as a research.

From this discussion I'm looking to address following questions:

What do you think should be the path that I should follow in order to make this transition? 

Is it a good idea to leave a highly paying profile to into research world where the pay will be a bit lesser?

What areas I should explore before making this shift?

What in your opinion I should expect from this change?",2021-12-29 14:09:57
"What's stopping data scientists from applying to remote-only roles in a high cost of living, high-paying locations like California and living in a low cost of living location?",42,rqzpl1,https://www.reddit.com/r/datascience/comments/rqzpl1/whats_stopping_data_scientists_from_applying_to/,57,1640753988.0,"Right now, remote work is more popular than ever, especially due to the recent delta and omicron variants. California and New York pays by far the most for data scientists, but the high cost of living there offsets the high pay. But if a data scientist were to be working for a company in California remotely with the same salary, while living in a state with a lower cost of living, his purchasing power with his income would be huge.

So why wouldn't every data scientist be clawing to get the remote positions in such high-paying companies?",2021-12-29 06:59:48
"Looking back on what you know now, what concepts took you a surprising amount of effort and time to truly understand?",101,rqz1lp,https://www.reddit.com/r/datascience/comments/rqz1lp/looking_back_on_what_you_know_now_what_concepts/,100,1640751855.0,,2021-12-29 06:24:15
What is the data science and ML job market like in Australia?,13,rqysab,https://www.reddit.com/r/datascience/comments/rqysab/what_is_the_data_science_and_ml_job_market_like/,11,1640751054.0,"I know that the job market for data science and machine learning probably sucks compared to the US (I mean, where isn't?), but I'm curious what the job market is like down in Australia. Is it a large and fast-growing sector? Is there a lot of cutting-edge ML tech in the sector? How is the pay? What cities is the ML/AI sector concentrated in? Thanks!",2021-12-29 06:10:54
"Which data science/ML development processes would you like to see more automated (i.e., have a Python library for)?",0,rqy5te,https://www.reddit.com/r/datascience/comments/rqy5te/which_data_scienceml_development_processes_would/,2,1640749157.0,"What parts of ML projects do you find really tedious, and do you think  should be wrapped in a Python library? Looking for project ideas.",2021-12-29 05:39:17
Soft Skills/ Calm down a unhappy client,14,rqqxwk,https://www.reddit.com/r/datascience/comments/rqqxwk/soft_skills_calm_down_a_unhappy_client/,8,1640728933.0,"Beginner Data Analyst here,

A internal department was requesting some data and when I went to ask the higher ups where the data is they said they do not know, then sent me a bunch of tables that might have what I’m looking for.

After reviewing all the tables and organizing what I could, I sent it to the department.

I informed them that there is a decent chunk of information missing from the report, after doing a very thorough review of all the information I had.

Not being able to find everything is not uncommon at my job (since there a lot of transitions happening right now) so I thought they would have some understanding. They’re not happy about it at all and are completely surprised that the data is not as organized as they thought.

While I can’t answer the additional questions they are asking how would you suggest calming them down?

I feel like I might run into this reaction again in the future, so what is the general rule on how to handle this?

All the discussion is via email.
All of the people with the answers are on vacation until after new year.",2021-12-29 00:02:13
Help using Metaknowledge for bibliometric analysis,1,rqnz3n,https://www.reddit.com/r/datascience/comments/rqnz3n/help_using_metaknowledge_for_bibliometric_analysis/,1,1640720882.0,"I am enrolled in a Data Science course at my university, and are currently writing a thesis for my exam, where I am doing a bibliometric analysis. My supervisor mentioned the package called ""Metaknowledge"", which should be very helpful for doing bibliometrics. However, according to the documentation, it currently only accepts plain text files from pages like Web of Science, Scopus, PubMed etc. My problem is, that even though I am uploading a plain text-file (with authors, references, titles, year of publish, citation count etc.), downloaded directly from Scopus, Metaknowledge does not recognize it as a Scopus file, and I am therefore not able to use the functions of the package. I have tried reading futher in the documentation and searcing on stackoverflow, but without success.   


Does anybody have experience using Metaknowledge, that might shine a light on my problem? Thanks!",2021-12-28 21:48:02
Search: interesting topic in data quality assessment,1,rqin2x,https://www.reddit.com/r/datascience/comments/rqin2x/search_interesting_topic_in_data_quality/,0,1640706211.0,"Hello, do you know some interesting topics and research questions for a research essay about data quality assessment?

I am new in this field. A link to industrial applications would be nice but isn’t necessary. 

I would be really thankfully about some inspiration. Cheers",2021-12-28 17:43:31
What kind of analysis I should conduct to see impact from multivariate time-series data?,31,rqhe0k,https://www.reddit.com/r/datascience/comments/rqhe0k/what_kind_of_analysis_i_should_conduct_to_see/,7,1640702645.0,"I'm able to spot some pattern (trend + seasonal) from my data, which has multiple series that are correlated (e.g. sales / order / selling price). However, would love to hear some approach to do further analysis about 'impact', perhaps it's causal inference?  any resources I should check?",2021-12-28 16:44:05
Best websites (paid) for historical tick data for Equities/ETFs/Indices,1,rqfxhd,https://www.reddit.com/r/datascience/comments/rqfxhd/best_websites_paid_for_historical_tick_data_for/,2,1640698226.0,"If anyone could comment below the best reliable and accurate websites for 1min-5min intervals of ETFs/ Indices/ Equities. Paying is not a problem since it is for work. 
Ive looked at QuantQuote, AlgoSeek, and KiBot but trying to list as many as possible. Thanks in advance….",2021-12-28 15:30:26
"how do people from linguistics, law, humanities and biology end up in data science and make the jobs market crowded? how do they do it? why?!",0,rqdm87,https://www.reddit.com/r/ProgrammerHumor/comments/rptqd7/python/,13,1640690245.0,,2021-12-28 13:17:25
Is Data Science 90% boring and 10% mega-interesting?,241,rqdlmi,https://www.reddit.com/r/datascience/comments/rqdlmi/is_data_science_90_boring_and_10_megainteresting/,109,1640690173.0,"Hi. Sorry for the catchy title...

&#x200B;

Anyway, I am a first-semester AI student working part-time in an insurance startup-like company. I have been a software engineer before and enjoyed it a lot but then I decided to go into AI because I was fascinated by neural networks. And now I am starting with Data Science in my company as the first one to ever do datascience there, so I have a lot of possibilities and freedom in work.

A few days into the new data science role I am kind of bored. From what I have experienced, 90% of the work is just cleaning data which is not the most interesting work for me. It is okay, but it sure does not excite me.

10% on the other hand are modelling, training, evaluating which are absolutely fascinating in my opinion.

&#x200B;

But also troubleshooting a model is more like alchemy than engineering. Coming from software engineering where debugging is straight-forward, the trouble shooting in data science is also such a bad experience.

&#x200B;

From this I kind of regret my choice of getting into AI/Data Science.

Is this a general observation or do you think different/had different jobs?

&#x200B;

btw. biggest reason for this post: I restarted a jupyter notebook 1 hour ago.... still waiting to finish processing (no training - only data processing, ...)",2021-12-28 13:16:13
legalities of collection and Redistribution of information from APIs or web scraping.,6,rqd7ep,https://www.reddit.com/r/datascience/comments/rqd7ep/legalities_of_collection_and_redistribution_of/,2,1640688608.0,"When working with data that is collected from API's or web scraping where are the legal boundaries?

I've been working on projects where I would like to Store and Share data from web scraping and APIs but don't know if its technically allowed or what problems I could encounter when doing so. I've seen sources saying that if it violates terms of service or user agreements the website may block your IP or ban you but can't pursue legal action as long as the information is publicly available, but I've also seen individuals saying that you can get in legal trouble for redistributing information from APIs.

&#x200B;

Does anyone have some tips, advice, or even good resources for the legalities of collection and redistribution of information form APIs and web scraping?",2021-12-28 12:50:08
This paper is a little over my head but I am excited about quantifying non-monotonic associations between variables. What's your take?,8,rq7jam,https://arxiv.org/abs/1909.10140,4,1640668272.0,,2021-12-28 07:11:12
"What's the deal with ""manual entry"" job applications?",22,rq3p2g,https://www.reddit.com/r/datascience/comments/rq3p2g/whats_the_deal_with_manual_entry_job_applications/,8,1640657014.0,"In my experience applying to data science jobs over the past several years, it seems that most companies rely on one of three basic protocols for enabling potential candidates to express interest in a job opening:

1.  Employing an internal or external recruiter to browse public profiles on sites like LinkedIn and Hired.
2. Advertising open positions on public forums and allowing people to easily apply by uploading their resume or submitting a link to their profile.
3. Advertising on forums but then requiring candidates to enter all their contact info, employment history, education, references, and cover letter manually on the company's website.

I tend to do extremely well with the first type and decently with the second type but after five years, the time I've spent tediously filling in page after page of tiny form fields hasn't led to a single interview. Sometimes, I'll get a boilerplate rejection email but more often than not, there's no response at all. 

Because these applications are such a pain in the a\*\*, I typically only bother if I think the job is a particularly good fit for me and when I do, I try to go the extra mile--adding thoughtful details about why my experience makes me well-qualified, why I would be a good cultural fit, even running a keyword comparison to make sure I'm giving their resume bot everything it's ever dreamed of and more.

Is there some special trick for succeeding with this type of application? The best explanation I can come up with is that companies that have this also have real human beings contacting people proactively and that this self-service manual entry system exists primarily for auditing purposes (so they can say they considered a wide range of candidates before making a decision). 

Sorry for the rant but I'm curious to hear what other people's experiences are. If I'm right, that would mean we should all stop wasting time on these applications and should instead put all our efforts into networking with people at the companies we want to work for.  On the other hand, it's certainly possible that I just don't look that good on paper and my success mostly comes from my ability to talk myself up.",2021-12-28 04:03:34
Is decision science really a thing? Or is it more marketing buzz?,126,rq0y5g,https://www.reddit.com/r/datascience/comments/rq0y5g/is_decision_science_really_a_thing_or_is_it_more/,73,1640649044.0,"I work in BI and have read about decision sciences (especially the chief decision scientist at Google, go figure) and was wondering if this is a growing function? Seems to me that’s what BI and analytics are meant to cover.

Anyone with experience or “insight” into decision science?",2021-12-28 01:50:44
COVID case data and US airline travel data together in a panel regression. 😱🦠,9,rpvvh5,https://lospi.net/data/statistics/covid/cdc/r/2021/12/26/covid-travel-mashup.html,0,1640635202.0,,2021-12-27 22:00:02
Books on Model Deployment,135,rprvb4,https://www.reddit.com/r/datascience/comments/rprvb4/books_on_model_deployment/,29,1640624476.0,"Hi everyone, 

I was reading [DS Book Suggestions/Recommendations Megathread](https://www.reddit.com/r/datascience/comments/8jneyb/ds_book_suggestionsrecommendations_megathread/). Although model deployment is a crucial skill for a data scientist, all books in the thread are about statistics and machine learning. Then, I did a quick research on past posts. I could only find the Practical MLOps by O'Reilly.

Therefore, I would like to create a post about model deployment books. 

Please post model deployment books that you have found particularly interesting or helpful for learning during your career. Include the title with either an author or link. 

Thank you very much,",2021-12-27 19:01:16
Android tablet for data scince,1,rpmlvr,https://www.reddit.com/r/datascience/comments/rpmlvr/android_tablet_for_data_scince/,14,1640608501.0,"Hi,

I am a data scientist and spend my time with numpy, scipy, scikit, pandas and tensorflow (and a million other packages). 

I am searching for something light and cheap, top do some work on the side. I mostly develop some code, do some beta testing and let the a server do the major work. So, I do not wnat to the latest and greatest machine, only something light and portable to do work on te go.

So here's the question.

1) Can I use an android table with a keyboard and pydroid 3?  Or something close to anaconda? Does it work?

2) I love spyder as ide and absolutely hate Jupiter. What ide can I use?",2021-12-27 14:35:01
Model agnostic feature importance,13,rplch6,https://www.reddit.com/r/datascience/comments/rplch6/model_agnostic_feature_importance/,19,1640603807.0,"Hi All,

Wanted to check if there is a technique to estimate feature importance which is model agnostic? 
Thanks!

Edit1: to give more context, i have multiple datasets, for each i have to run multiple models where each dataset might have a best model and it will be different from others. Hence, I think if there is a way to perform model agnostic feature importance I can perform this step for all the datasets in parallel and then feed to different models. If there is an elegant way, please suggest that as well. Please note that all these different models are not easy to interpret as well.
Thanks",2021-12-27 13:16:47
Optimising and minimising ML models,0,rpkf6m,https://www.reddit.com/r/datascience/comments/rpkf6m/optimising_and_minimising_ml_models/,3,1640600113.0,"1) Give me two ways to minimize ML model error?

2)  How would I optimize a linear regression?

For 1) is this a question about error metrics or about techniques to improve accuracy?

For 2) is this to do with gradient descent or something else?",2021-12-27 12:15:13
Is Tableau a good software to become Data Visualization Designer without learning to code?,5,rpd2to,https://www.reddit.com/r/datascience/comments/rpd2to/is_tableau_a_good_software_to_become_data/,17,1640574365.0,"I'm a brand designer for almost 10 years and I had a client from a VC-Backed Data Company that needed help to redesign its charts and graphs to their new brand identity.

It was a ""simple"" task for me, however, they pay great. This got me into Data Visualization Design and stuff and it would be interesting to learn a new skill for the entire 2022.

I found Tableau a very helpful software to apply data visualization without learning to code and it helped me adapt fast. It feels it like it’s the Canva version of Photoshop.

To all professionals here, how's your career with this software? Do you think this skill is a great combo for brand/graphic designers that worked with Adobe softwares for more than a decade without learning to code?",2021-12-27 05:06:05
I'd like to find a large sample of accounts on Twitter that tweet around a certain subject. How would you approach this without paying too much for API access?,2,rpcxqs,https://www.reddit.com/r/datascience/comments/rpcxqs/id_like_to_find_a_large_sample_of_accounts_on/,6,1640573968.0,"I could start by taking some known users and then checking who they are following and so on. But it quickly gets out of hand. some of them follow 700 people. So if I then check each of them, it will be a huge operation. Is there a better way?",2021-12-27 04:59:28
EliteMini HX90 for data science. Any thought?,0,rp9q08,https://www.reddit.com/r/datascience/comments/rp9q08/elitemini_hx90_for_data_science_any_thought/,1,1640564171.0,"I am going to buy a computer for data science/analysis work. I ran into the EliteMini HX90 which has good specs given the price. Has anybody used this for data work or else? any thoughts and experience would be much appreciated. 

Here is the link to the product:[https://store.minisforum.com/products/hx90?variant=40508847259809](https://store.minisforum.com/products/hx90?variant=40508847259809)",2021-12-27 02:16:11
How did you advance your NLP career?,2,rp9hw4,https://www.reddit.com/r/datascience/comments/rp9hw4/how_did_you_advance_your_nlp_career/,8,1640563493.0," Dear all,

If there are any NLP/ML engineers, DS, or researchers out there, I could really use some advice.

I am graduating from my MS in Economics with a full-time job lined job as a DS at a well-known fintech company. However, it is driving me crazy to find a clear path forward to pursue a more NLP-involved job down the line.

Here is what I currently have that can be classified as NLP ""experiences"":

1. Past Internships! I have done anything from Product management intern for data products powered by NLP to Management Consultant doing research on the data collection strategies that a client could take to improve their NLP classification outcome
2. Research! I am writing a paper with researchers from NLP for applying NLP techniques to public policy related documents and is due to publish in the next couple of months
3. Current job! The team that I am currently on and hired into (that I have been interning on) uses a lot of NLP for insights discovery. We also plan on launching a large scale NLP product down the line which I will be very involved in given our very lean corporate structure

Why I think I will have a hard time advancing in the field:

1. I do not have a CS undergrad or MS in CS
2. My background in economics dictated that I am good at math but not at linguistics
3. I do not come from a hyper prestigious school like Stanford or MIT but a mid-tier school in the East Coast (US)

I feel everyone in the field is so overqualified for what they are doing (granted people may just be very good imposters)! I have no clue what to do ???

Should I go get an MSCS to compete down the line? How does moving up in NLP careers work? Can any folks shine some light on a very confused young person!

I will literally take any suggestions or advice haha. thank u y'all!",2021-12-27 02:04:53
What IQ do you need to have in order to be a data scientist?,0,rp2zzm,https://www.reddit.com/r/datascience/comments/rp2zzm/what_iq_do_you_need_to_have_in_order_to_be_a_data/,24,1640544102.0,"So I am looking for serious answers. I have heard that data science is hard(obviously) and IQ plays a big factor into it. The average IQ of a data scientist is around 130. But it has been told there's other factors into it such as conscientiousness but that is about 5% of success in data science. What is required? As someone who doesn't have extremely high intelligence, what should I do?",2021-12-26 20:41:42
GoLang or Rust -- Do they have a place in Data Science?,5,rp2o74,https://www.reddit.com/r/datascience/comments/rp2o74/golang_or_rust_do_they_have_a_place_in_data/,13,1640543157.0,"I am curious what this communities opinion is about either GoLang or Rust for Data Science.  Is anyone using them?  Does anyone anticipate either language overtaking Python or R in the future?  What opinion does anyone have of either language in this practice?  If I were to choose one of these languages to learn, which would be a better choice?",2021-12-26 20:25:57
What algorithm am I looking for here???,0,rp1h1v,https://www.reddit.com/r/datascience/comments/rp1h1v/what_algorithm_am_i_looking_for_here/,7,1640539788.0,"I have a fixed bunch of cluster centers, and a bunch of points I want to assign to these clusters. However, each cluster has a certain limit for # of points that can be assigned to it, i.e. 100. This 100 is not a hard limit; with more points over the limit assigned to the cluster, it should be increasingly difficult.

This is a modified nearest neighbor search problem or a kmeans cluster with fixed center. I however can't think of any way dealing with the constrain part except iteratively recalculate the distances between points and center with some sort of distance penalty function applied. 

Any tips?",2021-12-26 19:29:48
Data Science Practice Sites,69,rp07ol,https://www.reddit.com/r/datascience/comments/rp07ol/data_science_practice_sites/,2,1640536071.0,"1. Hackerrank -> Great for SQL and Python Practice (www.hackerrank.com)
2. Kaggle ->  ML Competitions and Tutorials (www.kaggle.com)
3. DataCamp 
4. AceAI - Data Science Interview Prep (www.aceainow.com)
5. Coursera/Udacity Courses",2021-12-26 18:27:51
What Companies think AI looks like vs What Actually it is,1970,rozxuk,https://i.redd.it/mu7cm5ztvw781.jpg,69,1640535235.0,,2021-12-26 18:13:55
Weekly Entering & Transitioning Thread | 26 Dec 2021 - 02 Jan 2022,9,rovmty,https://www.reddit.com/r/datascience/comments/rovmty/weekly_entering_transitioning_thread_26_dec_2021/,94,1640520031.0,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",2021-12-26 14:00:31
I finally figured out K's nearest neighbors...,979,roufb5,https://www.reddit.com/r/datascience/comments/roufb5/i_finally_figured_out_ks_nearest_neighbors/,36,1640514551.0,They are J and L,2021-12-26 12:29:11
Blue light glasses?,0,ropeyk,https://www.reddit.com/r/datascience/comments/ropeyk/blue_light_glasses/,7,1640493516.0,Silly question - but any experience with/recommendations for blue lights glasses? Finding myself having trouble falling asleep and experiencing some eye strain when on laptop for 11+ hours a day.,2021-12-26 06:38:36
Good way to segment a/b test results for insight or narrative?,11,rokx20,https://www.reddit.com/r/datascience/comments/rokx20/good_way_to_segment_ab_test_results_for_insight/,7,1640477929.0,"Hey y'all! 
Does anyone here has a good way to find decent density segments that performed well/badly in the test that you could highlight to non-ds partners? 

Some background: I've been using heterogenous modeling for a/b tests to find which users respond better to the treatments (CATE). Even though I have scores for every user, I want to point out several segments that were responsive. For example, ""...android users in south america and users who play mobile games between the ages of 18-24 responded really well to this change and make up 90% of the uplift"".  

So far I've been doing this by looking at feature importance or fitting a simple uplift decision tree, but I'm trying to get something that isn't as hierarchical based.",2021-12-26 02:18:49
Altruism and data science,29,rok3um,https://www.reddit.com/r/datascience/comments/rok3um/altruism_and_data_science/,29,1640475267.0,"So I just saw the social dilemma on Netflix. Although I know Netflix likes to dramatise a lot of things in documentaries I do believe there is a lot of truth in the topics covered in this particular documentary. The documentary is about how the AI behind social media platforms is essentially harming the society and health of its users for profit-maximisation/self-interest. Are the engineers that created these social media algorithms/AI to get us addicted to our screens also considered data scientists? If so, what are some examples of data science companies/projects that do not exploit others for individual-interest only. With my knowledge on data science jobs, the top-tier jobs are always at the big companies like Google, Facebook, Netflix, Amazon; people will say you have made it when you get into such a company. 

I am actually looking to get into data science/AI after my current studies. However I am not excited to get a job at any of these big companies at all. I feel like I will just help them obtain/analyse even more data to exploit even more people/exploit people even more. What are some more altruistic jobs for a data scientist that still pays decently?

What is your opinion on this anyway?",2021-12-26 01:34:27
How do I prepare to manage/lead teams? Little experience doing this,118,rohqcy,https://www.reddit.com/r/datascience/comments/rohqcy/how_do_i_prepare_to_managelead_teams_little/,46,1640467265.0,"Been an IC for ~4 years, now will be ""analytics manager"" in a new firm with 1-2 folks eventually reporting under me. What resources would best prepare me?",2021-12-25 23:21:05
The best way to make decisions about the accuracy of data,8,roa7z6,https://www.reddit.com/r/datascience/comments/roa7z6/the_best_way_to_make_decisions_about_the_accuracy/,5,1640440514.0,I am currently working on a project and I have found two different data sources for my research. I would like to do a comparative analysis between the two of them to determine which one of them is more accurate before I continue. Can you suggest me what would be the best way to do this? Thanks in advance!,2021-12-25 15:55:14
How to transition to manager,23,rnww09,https://www.reddit.com/r/datascience/comments/rnww09/how_to_transition_to_manager/,32,1640386663.0,"I’ve got a PhD and have been at data science for 5 years professionally in a contributor role. I feel ready to try to get into management, but it doesn’t seem likely I will get people to report to me within my current org.

There are informal mentorship, teaching, and project management opportunities as a contributor, but is this the same as having people reporting to you?

How does one successfully transition from contributor to manager? I get paid very comfortably and just started 9 months ago here. I don’t want to leave for a few more years.",2021-12-25 00:57:43
Quick Primer: players in the hiring process,23,rntzu8,https://www.reddit.com/r/datascience/comments/rntzu8/quick_primer_players_in_the_hiring_process/,12,1640377063.0,"A lot of people here are early in their careers and may not understand who all fits into the hiring process - and how.

So here's a quick primer.

The hiring manager is the person in charge of deciding who ultimately gets hired. 98% of the time, this will be the person who manages the candidate being hired. The hiring manager is responsible for defining what they want in a candidate, what they will be doing, etc. The way they do this is by writing a *job description*, which outlines the skills and experience a person should have as well as what they will be doing.

The HR comp department will then take a job description and grade it, i.e., decide how much someone in that role should be paid. This is the team that says ""if you want someone with 3 years of experience and a grad degree, they should get $Xk a year"".

Then comes your HR business partner. As a hiring manager, you don't normally talk to the comp team directly. Your HR BP is the one who coordinates everything, and they can also be the one to give you insights into how a JD may influence comp. Example, they may tell you ""if you make a grad degree optional, the max they will approve is $100K-$140K, if you want to go higher than that, you'll need to require a grad degree"".

Then there's the recruiter aka talent acquisition. These are the people that find candidates and do the initial screening on them - reading resumes and conducting an initial interview.

Important callout: a data science recruiter likely has no experience with data science. However, if they are good recruiters, they understand what data scientists do *and how they talk about it*. Having said that, they're only screening - they are mostly making sure that what you said you did is legit, and that it generally matches what the hiring manager wants.

Most of the rest of the process is handled by the hiring manager, with HR primarily helping administratively - setting up meetings, sending emails, etc.

HR doesn't make decisions (other than screening and grading). HR is there purely to carry out their process.

Points of conflict between hiring managers and HR:

1. Bad grading: you put together a reasonable job description, and the grading comes $50K under what you expected. Normally this happens when companies use bad comparison points (e.g., to find comparable salaries to DS they use ""IT professionals"", or instead of using data in your high COL city using state-wide data). That can lead to ""job description padding"", when you make the job description much demanding than what you're willing to hire so you can pay what you want. 

2. Bad screenings: your recruiter filters out people because they have a MS in biostats instead of stats, or they just don't know that operations research is a relevant discipline. Or they will let people through that don't have the right experience. 

3. Lazy recruiters: recruiters do two things to find candidates - look at who applied, and actively look for candidates who may be passive. Lazy ones don't do the second part.",2021-12-24 22:17:43
"No, just because you don't understand how they work doesn't mean nobody else does",0,rnqutu,https://i.redd.it/e6ei48n40j781.png,25,1640367122.0,,2021-12-24 19:32:02
"I started self learning data science 2 years ago, and this where I’ve gotten. Advice for beginners.",405,rnpwik,https://www.reddit.com/r/datascience/comments/rnpwik/i_started_self_learning_data_science_2_years_ago/,80,1640364142.0,"Compensation-wise: about 30% more than I was being paid before I started. I actually have what most high achieving people would consider, a good job. I was already at a fairly good job before if you’re wondering why only 30% increase.

Future-outlook: A lot better. I certainly feel more respected at work, and more confident in my career. The industry is still at it’s birth, so if you study the right things, there are a lot of opportunities to accomplish what you want compared to most fields/industries.

Advice for beginners: the first 3-6 months are the hardest. You’re really new in the space, opportunities will not come easily then. Just keep LEARNING. Consider applying to other jobs that are easier to get but have the opportunities to interact with data people. Like internships, data entry jobs, volunteer work, etc. Heck, I’ve interacted frequently at work with people from customer support, sales, product management, etc. whom we were able to get setup with their own data environment because they were interested in learning and pulling the data they need. If you’re not sure where to start, there are great blogs, quora posts, cheap online platforms, etc. It may seem like an endless amount of information, but I’ve found that most information is useful and can lead you to other information.",2021-12-24 18:42:22
Tips & Tricks of Deploying Deep Learning Webapp on Heroku Cloud - KDnuggets,0,rnp5t8,https://www.kdnuggets.com/2021/12/tips-tricks-deploying-dl-webapps-heroku.html#.YcXvNigcF58.reddit,0,1640361817.0,,2021-12-24 18:03:37
Which job develops ML models more DS or ML engineer?,26,rnkm98,https://www.reddit.com/r/datascience/comments/rnkm98/which_job_develops_ml_models_more_ds_or_ml/,40,1640345886.0,Perhaps the Industry blends titles too much. I can't tell who works with ML models more or who gets to develop them. Do you just have to look at the job description and talk with the company? Seems like the roles are not well defined.,2021-12-24 13:38:06
For data tools do you prefer a desktop or a web version?,47,rni0jb,https://www.reddit.com/r/datascience/comments/rni0jb/for_data_tools_do_you_prefer_a_desktop_or_a_web/,31,1640335023.0,"Hi folks! Happy upcoming holidays! 

My team is building a data transformer and we wonder are you used to having desktop or web versions of the tools for data operations? 

It will help up a lot, so thank you in advance",2021-12-24 10:37:03
Can I use standard deviation to turn a predicted value into a range?,30,rnhow6,https://www.reddit.com/r/datascience/comments/rnhow6/can_i_use_standard_deviation_to_turn_a_predicted/,37,1640333649.0,"I have a (maybe naive) question regarding the predictive quality of a given ML regression algorithm:

Can you take the standard deviation of the difference

    error_pred = y_pred - y_test

from your testing data and use it to turn your predicted number into a range?

Say you predict the material property of a new compound based on your trained algorithm. You get a predicted value and you get the standard deviation from your testing data:

    value = 500
    sigma = 8

Could you give your result as:

    value +- 3 sigma 
    [476 .. 524]

and claim that based on the available data you have a 99.7% probability of the compound property being in this range?

Is this meaningful? Are there problems with this thinking? Am I missing something? This feels too simplistic and my gut tells me that there probably are issues with it but I can't put my finger on what it is exactly. I'd appreciate any pointers you could give me. 🙂

Many thanks and Merry Christmas!",2021-12-24 10:14:09
Should I stick to the same company?,6,rngw9r,https://www.reddit.com/r/datascience/comments/rngw9r/should_i_stick_to_the_same_company/,11,1640330487.0,"To preface. I'm currently a data scientist at a reasonably successful and fast growing MNC. I have a masters degree that I finished recently and this is my first job. I'm wondering if I should look into other careers and places because the work I do for my current company is EXTREMELY specialized. It's still data science but very little of it is building skills that are transferable.
My question to the more experienced ones amongst you. Is it bad to get bogged into a career that's too specialized (to the point that it's an industry of one company), or is it better to move around and experience more roles? I might get promoted to senior data scientist within the next few years but I'm afraid that might be too early and then I won't get a senior data scientist role anywhere else. Any advice is helpful.",2021-12-24 09:21:27
How to get Cloud experience for Solution Architect role?,6,rne09j,https://www.reddit.com/r/datascience/comments/rne09j/how_to_get_cloud_experience_for_solution/,1,1640320215.0,"Thinking of a career change towards a Solution Architect role at AWS or Microsoft. My current day to day consists of creating reports/queries in SQL, Excel, and Power BI to support day to day operations.

A lot of these Solution Architect roles require cloud experience, such as AWS or Azure. I currently am having a hard time finding these types of project experiences at work. Any advice how I could find cloud experience/solutions architect experience to put my best foot forward when applying for those roles elsewhere?",2021-12-24 06:30:15
"Need career advice, imposter syndrome kicking in after 7+ years",8,rn9f0m,https://www.reddit.com/r/datascience/comments/rn9f0m/need_career_advice_imposter_syndrome_kicking_in/,4,1640305323.0,"I graduated from an analytics masters program about 7 years ago and got  my first 6 figure salary as a DS level 3 in a non-tech industry. Fast  forward to now, I'm still at the same position and level and ready for a  change of scenery.

The problem is  that in the last 7 years here as a 'Data Scientist' I've mainly worked  on creating dashboards, ad-hoc reports, and very minimal data analysis  projects. I've became complacent and comfortable with this 'light' work  load that it's catching up to me.

I  like creating dashboards and visualizations that I'd like to move to a  more BI/Product/Business Analytics focused position. My 2nd problem is  after several years of applying to jobs (on and off), I have not  received any offers, even though I think I'm qualified if not over  qualified for some of these positions.

**My questions is:**

\-What is the best way to move forward while trying to keep my compensation and past experience relevant?

\-Also, am I not getting any offers because I'm too expensive (\~130k) for Sr. BI/Product/Business Analytics roles?

In  2022, I'm ramping up my SQL, python, communications skills.  I'm  planning on applying to more job but hoping to be more strategic and  better prepared. Also asking for feedback if I get rejected.",2021-12-24 02:22:03
DS Books on Kindle?,7,rn7fny,https://www.reddit.com/r/datascience/comments/rn7fny/ds_books_on_kindle/,2,1640299432.0,"Are there any worthwhile books to read on data science (or statistics or data engineering…) that are well suited to a kindle?  What I mean here is that there not too many color graphics or plots, math formulas, long code snippets, or pictures, as none of these tend to show up very well on my kindle. I am thinking of a well written narrative on how to choose a model, or how to approach working on a new problem, or anything high level like this. 

I like to read in bed after my wife falls asleep and this is the least disturbing option to level up for 20-30 minutes before I doze off.",2021-12-24 00:43:52
Does anyone know what's up with 2020 census data?,0,rn5yec,https://www.reddit.com/r/datascience/comments/rn5yec/does_anyone_know_whats_up_with_2020_census_data/,7,1640295245.0,I've had a lot of requests for simple demographic type stuff recently. Am I missing where 2020 data is available or has Census just not gotten around to releasing it yet? I see some basic state level stuff but nowhere near all variables and you can't drill down to census tract or other geographies that would be useful for me.,2021-12-23 23:34:05
Does anyone know of an article or blog about the Zillow fiasco from the viewpoint of a data scientist on the team?,22,rn3ety,https://www.reddit.com/r/datascience/comments/rn3ety/does_anyone_know_of_an_article_or_blog_about_the/,16,1640288054.0,"I'm guessing C-suite MBAs pushed this hard and didn't listen to the technical experts on why this was a bad idea, but I could be wrong!  Anyone know of a good resource from someone on the team who wrote about it?",2021-12-23 21:34:14
Jupyter Notebook not giving any output?,0,rn2zns,https://www.reddit.com/r/datascience/comments/rn2zns/jupyter_notebook_not_giving_any_output/,2,1640286902.0,"Beginner here. Reinstalled the notebook a bunch of times, changed locations, changed browsers, kernal is infinite and interuppting or stopping kernal does not work. What's the solution?",2021-12-23 21:15:02
"What skills would a ""full stack"" data scientist have?",42,rmzn8c,https://www.reddit.com/r/datascience/comments/rmzn8c/what_skills_would_a_full_stack_data_scientist_have/,37,1640277791.0,"The other day at work we were talking about the difference between our development and data science teams. We are in the process of hiring people for both and some of the people applying for our development team describe themselves as full stack programmers. On the DS team we don't really have a term for someone who could take a project from inception to production. 

Is their a term for that and what skills would you expect a ""full stack"" data scientist to have? 

We aren't looking for for a full stack person, it's just an interesting discussion. I'm also not going to be posting anything about the positions. I'm not the hiring manager.",2021-12-23 18:43:11
How can I help my new-hires understand the company's DB? I basically want to translate to plain english what each table actually contain. Hadn't realized how hard this actually was for someone unfamiliar with the db.,3,rmxxho,https://www.reddit.com/r/datascience/comments/rmxxho/how_can_i_help_my_newhires_understand_the/,10,1640272945.0,"These new hires are NOT technical and are not on the data team, but we're a startup so I'm doing their onboarding :)",2021-12-23 17:22:25
Anyone else work in agriculture?,54,rmwair,https://www.reddit.com/r/datascience/comments/rmwair/anyone_else_work_in_agriculture/,36,1640268045.0,"I've recently been hired as a data scientist at an agricultural firm specialising in cattle ranching. I feel like I'm the only person working in this field, I don't do any fancy modelling, just regression models. Anyone else work in 'weird' fields.",2021-12-23 16:00:45
What tools do data scientists use to manage their time?,0,rmw5w7,https://www.reddit.com/r/datascience/comments/rmw5w7/what_tools_do_data_scientists_use_to_manage_their/,13,1640267648.0,"Hi there,

I'm not a data scientist, I develop a time management / productivity software that aims to reduce meeting load.

I'm focusing on data scientists because it seems that data scientists get too many requests for meetings or other requests on their time than what they can realistically fulfil.

Does that observation ring true to you? Why or why not?

How do you deal with meeting requests or generally manage your time? Specifically, do you use any tools or methods? Have you tried any that didn't work out for you?

Thanks for your answers!",2021-12-23 15:54:08
"Is there any online courses, books, articles, for helping me learn the basics of A/B testing?",18,rmvow8,https://www.reddit.com/r/datascience/comments/rmvow8/is_there_any_online_courses_books_articles_for/,4,1640266105.0,,2021-12-23 15:28:25
"Which course would you suggest to opt for first, Machine Learning or Data Mining?",0,rmndar,https://i.redd.it/0n1jxe9228781.png,4,1640234604.0,,2021-12-23 06:43:24
2021 Biggest Data Hurdles,0,rmn3ec,https://www.reddit.com/r/datascience/comments/rmn3ec/2021_biggest_data_hurdles/,9,1640233742.0,"Talking data at scale: knowledge layers, distributed file systems, keeping elasticsearch alive, learning HDFS and all the Java crap, parallel processing, network issues.. timeouts, indexing speeds, data status & state, etc. Go!",2021-12-23 06:29:02
What are some misconceptions of being a data scientist?,21,rmju1x,https://www.reddit.com/r/datascience/comments/rmju1x/what_are_some_misconceptions_of_being_a_data/,39,1640222154.0,"For an average person like me, it sounds like a cool, sexy, and unsaturated job. Although, I’m pretty sure that it’s not what I think it is.

What are some common misconceptions of being a data scientist?",2021-12-23 03:15:54
How to deal with non technical manager’s approach that I disagree with?,13,rmj8a2,https://www.reddit.com/r/datascience/comments/rmj8a2/how_to_deal_with_non_technical_managers_approach/,25,1640220275.0,"First time working with non technical manager whose domain is industry knowledge and not data/statistics. Most days they know what they don’t know, but sometimes they want to drive some analysis in questionable ways to me.

For example, they asked that I remove 20%+ of the random sampled data so that we could build a perfectly smooth curve fit for only <80% of the data. By eyeballing the visuals. I explained to them that these data points, though not fitting well visually on their “ideal” curve where the majority of the dats is, are not definitionally outliers. They were randomly sampled by our chief DS, there was no data entry errors and they belong to our target population. By removing them we make the data seem more predictable than it actually is, and invalidates conclusions. To no avail.

In similar veins, another time they asked for another “perfect” curve based only on averaged data, which removes all variability in our raw data. I found a post describing exactly what they wanted to do [here -  they want to do chart #2 instead of #1](https://www.reddit.com/r/AskStatistics/comments/d5w6ht/linear_regression_all_data_vs_averaged_data/?utm_source=share&utm_medium=ios_app&utm_name=iossmf) - which explains consequences of doing so (“Ecological fallacy”). I ran both analyses, showed them that the first approach generates a curve that is closer to what chief DS expects. But they say the curve through all individual data points must surely be skewed by the 20% of data points that don’t fit the curve as perfectly/closely. 

I have <5 years of experience, top undergrad in Econometrics and am completing my Master’s in DS. They have 30+ in industry. I’m within my first year working with them so I’m at a loss of what to do.

For more context: I’m junior, so my model isn’t the primary moneymaker here. We produce one out of many inputs that go into business decisions. I guess in that sense, their approaches don’t automatically endanger the business, their or my job. But they will present this to upper people at some point. Their priority is to show a clean and easy to understand “model” as the audience is also non technical. Even so, if it’s the way it currently is, I feel that I shouldn’t have my name on it. 

Thoughts on how to deal with this situation diplomatically? Thanks.",2021-12-23 02:44:35
Data modeling for GPS / location?,6,rmi41w,https://www.reddit.com/r/datascience/comments/rmi41w/data_modeling_for_gps_location/,6,1640216871.0,"Hello - I’m curious if anyone can direct me towards resources, course names or  tutorials for learning the type of data schemas and modeling that go into location tracking. I’m thinking apps like bike sharing - you show where a record (ex: bike or scooter) is physically located at a specific time, and it can change, v the stations are set locations. I’d love to learn more about the data structures involved in an app like that. Thanks!",2021-12-23 01:47:51
Help selecting a gift!,1,rmgpo8,https://www.reddit.com/r/datascience/comments/rmgpo8/help_selecting_a_gift/,6,1640212704.0,"My partner is a data scientist and is incredibly type-A! He enjoys building things (Lego, puzzles), watching the stock market, and is always learning more about his job/field of work. I am quite the opposite and I am having a hard time with part of his gift. I do design work (industrial, floriculture) so I would love to be able to design it or get inspiration from something. I know a lot of people may say Galton Board but I’m not sure if he would actually enjoy that or not. He is super minimalist and doesn’t buy things just to have them, it has to be something he really wants! Anyway if you have made it this far thank you so much and I would love to hear any ideas! (Not for Christmas, just planning for his birthday in the coming months). Happy holidays!!",2021-12-23 00:38:24
What are your thoughts on Azure AutoML (or any other auto ML platform)?,5,rmf9jm,https://www.reddit.com/r/datascience/comments/rmf9jm/what_are_your_thoughts_on_azure_automl_or_any/,10,1640208509.0,"Apologies, probably been asked plenty of times.

Being relatively new to ML, I can’t really see a reason why auto ML isn’t viewed as anything other than a really useful tool. Just from my impression online, it seems most people involved in ML don’t rate it.

Surely being able to test loads of models is a time saving thing? And the ability to tune hyper parameters and cross validate automatically. I personally don’t yet have the ability to tell which model would be most appropriate, so I’ve enjoyed using it and seeing what models work well (I haven’t deployed a model from there yet though)

I see one downside it being a bit like a black box and it doesn’t feel very science-y to use.

Appreciate any thoughts on this!",2021-12-22 23:28:29
Is there a place for non-professionals to ask questions about data science in society?,1,rmecha,https://www.reddit.com/r/datascience/comments/rmecha/is_there_a_place_for_nonprofessionals_to_ask/,2,1640205888.0,"Is there a place for non-professionals to ask questions about data science in society? I see that this is mostly for pros to talk to pros, and there are other places like r/learndatascience, r/LEARNDATASCI, r/learnpython, etc., for students to talk to everyone. But is there somewhere for randos to talk to everyone?

Maybe my best bet is to find a community based on the particular data science application I'm wondering about, e.g. ask in a biology community if I have a question about data science in biology, etc.",2021-12-22 22:44:48
[D] Where do you get your news on advancements in DS/ML,7,rme5cf,https://www.reddit.com/r/datascience/comments/rme5cf/d_where_do_you_get_your_news_on_advancements_in/,5,1640205303.0,Where do you get news on advancements in AI/ML that aren’t focused on the major buzz topics like transformers?,2021-12-22 22:35:03
Building an Edge API Gateway with Fauna and Securing It with Auth0,0,rmd7rg,https://www.reddit.com/r/datascience/comments/rmd7rg/building_an_edge_api_gateway_with_fauna_and/,0,1640202664.0,"In this tutorial, we’ll explore architecting REST APIs in a fully serverless manner by leveraging Fastly’s Compute@Edge, Fauna, and Auth0.

[Read more…](https://auth0.com/blog/building-an-edge-api-gateway-with-fauna-and-securing-it-with-auth0/?utm_source=reddit&utm_medium=sc&utm_campaign=fauna)",2021-12-22 21:51:04
Notes From Stats Class,0,rmd4kn,https://i.redd.it/w64axydce5781.jpg,2,1640202407.0,,2021-12-22 21:46:47
HBR says that data cleaning is not time consuming to acquire and not useful 🤣😆😂,1296,rmcgwt,https://i.redd.it/a57zypsj85781.png,291,1640200517.0,,2021-12-22 21:15:17
"Need to learn some data science for work, out of these 3 books what would you guys recommend",4,rm83xy,https://www.reddit.com/r/datascience/comments/rm83xy/need_to_learn_some_data_science_for_work_out_of/,6,1640188586.0,"Background: 

Electrical engineer working with large datasets

Learning python and SQL (learned C in school so this is going pretty quick)

Weak foundation in statistics, which I've recognized and am trying to correct (see: [https://www.reddit.com/r/statistics/comments/rm7wf9/q\_statistics\_book\_recommendations\_for\_an\_engineer/](https://www.reddit.com/r/statistics/comments/rm7wf9/q_statistics_book_recommendations_for_an_engineer/)) 

Three books have caught my eye, they are: 

Python for Data Analysis by Wes Mckinney

Python Data Science by VanderPlas 

Data Science from Scratch by Grus 

I am thinking of going with Python for Data Science by Mckinney and pairing it with Practical Statistics for Data Scientists by Peter Bruce 

Although given my limited knowledge, I was thinking data science from scratch may be more appropriate? 

What do you guys think?",2021-12-22 17:56:26
Supply Chain Data Scientists - How do you all predict lead time/promise times for your online products?,5,rm7p59,https://www.reddit.com/r/datascience/comments/rm7p59/supply_chain_data_scientists_how_do_you_all/,2,1640187406.0,"Looking to start a discussion on different models and methods people use to predict lead times for products. This is more of an online retailer question as a caveat. But I am wondering what predictors you all use, the level of accuracy, scaling it out to your respective product (website)? 

What're some of the biggest roadblocks you have faced? 

Where can I read up on models regarding this business problem?",2021-12-22 17:36:46
Cheat Code for breaking into any field,551,rm6f7i,https://www.reddit.com/r/datascience/comments/rm6f7i/cheat_code_for_breaking_into_any_field/,98,1640183599.0,"A lot of people are trying to get into data science related fields and frequently ask similar questions along the lines of ""what do I need to know"" or ""I'm doing XYZ, does that make sense?""

That's a backwards way to think about it.

The way to do it is to look up a few dozen job postings for the role you want. From those postings, narrow it down to only the jobs you're interested in (data science is such a wide and non-standardized field that not all postings are applicable to you).

With the postings you're left with, identify which skills are common to most of those posts. Of those skills, some you will already have, so play them up in the experience of your resume. The ones that you don't have are ones that you should go learn.

This is a personalized process because of the breadth of the field, nobody in the world has expertise in the laundry list of skills people claim you need in medium or towardsdatascience articles.",2021-12-22 16:33:19
DataIKU vs. Azure ML,3,rm3a1o,https://www.reddit.com/r/datascience/comments/rm3a1o/dataiku_vs_azure_ml/,4,1640172360.0,"Hi,

At my company we are currently looking for new tooling regarding our strategy for Management of DS  Projects (Including experiment tracking, unit testing of the published model, creating audit trail) and a MLOps strategy. Currently we have only a few algorithms in production but the intention is there to make some big leaps in the future. 

Currently we are looking at DataIKU and Azure ML (in combination with Azure DevOps). 

For me it feels like both options give the same features. To me Azure ML feels a little bit more professional and is cost-wise more scale-able.  

Could someone explain to me which tool is the better option considering Project management, Testing, MLOps but also the costs?

Thnx!",2021-12-22 13:26:00
"A Forbes article from 2019 stated ""we just passed the peak of inflated expectations with data science and we are about to enter the trough of disillusionment."" Do you believe this to be true or not?",20,rly6xk,https://www.reddit.com/r/datascience/comments/rly6xk/a_forbes_article_from_2019_stated_we_just_passed/,17,1640151661.0,"[Forbes article ](https://www.forbes.com/sites/forbestechcouncil/2019/02/04/why-there-will-be-no-data-science-job-titles-by-2029/)

In 2021, I'm seeing more random Google articles with headlines like ""the data science bubble"" etc. 

Are these sentiments true or just headline grabbers?",2021-12-22 07:41:01
Funky Logit Model Output,1,rlue5e,https://www.reddit.com/r/datascience/comments/rlue5e/funky_logit_model_output/,10,1640139114.0,"I'm working on a project featuring a Logistical Regression that indicates difficulty on paying a mortgage.

1) When I look at a KDE showing Estimate vs Actual, my Target = 1 is way over estimated for a couple features, but looks good when Target = 0.

[https://imgur.com/mpoXUOD](https://imgur.com/mpoXUOD)

2) My R-Squared is negative, which is puzzling me.

3) My confusion matrix is heavy on the False Negatives

[https://imgur.com/cjtMVQu](https://imgur.com/cjtMVQu)

I can't quite figure out where I am throwing things off. The model seems like nonsense but it is still about 70% accurate. I tried removing outliers.

I hope you don't mind the screenshots

Thanks",2021-12-22 04:11:54
Promoting Data Driven culture in startups,3,rlucy4,https://www.reddit.com/r/datascience/comments/rlucy4/promoting_data_driven_culture_in_startups/,8,1640139011.0,"I am curious to hear what are some of the common methods used by startups to foster a data driven culture. Currently, we have a good set of dashboards and we schedule weekly reports.  
However, I think we are not great at sharing insights. We do a lot of analysis, but it is very siloed and only focussed on certain teams.

I am looking for some creative ways to get stakeholders interested in data.  
Perhaps a news letter, scheduling analysis?",2021-12-22 04:10:11
Drug testing in this field,6,rlr6ku,https://www.reddit.com/r/datascience/comments/rlr6ku/drug_testing_in_this_field/,32,1640129404.0,"Odd question. Some backstory: My fiancée and I have never done any drugs in our life mostly due to professional reasons. I’ve been in my position for about 2.5 years and honestly don’t remember my drug test or if I even had to do one (I did in my jobs prior). She started her own private practice a year and a half ago. We’d like to try out some edibles to see what it’s like.

My question: what were the drug tests like for your company (if you had to take one).",2021-12-22 01:30:04
Advice for Public Policy Work?,3,rlqb1h,https://www.reddit.com/r/datascience/comments/rlqb1h/advice_for_public_policy_work/,2,1640126841.0,"I’m graduating in May with my masters in applied math, half of my course load was statistics courses. I’m pretty sure I want to do public policy statistical work. Does anyone have any advice on how to get there? (Something happened to my previous post)",2021-12-22 00:47:21
"""Using data science as a force for good"" environmental modeling workshop",178,rlnia8,https://www.reddit.com/r/datascience/comments/rlnia8/using_data_science_as_a_force_for_good/,47,1640118761.0,"I'm developing a weekend workshop marketed to data scientists that want to work or volunteer for environmental causes. My goal is to help data scientists without a background in environmental science or conservation biology learn what databases are out there and, more importantly, how to build connections to find work with non-profits and academic scientists.

I'm a biologist that uses statistics pretty extensively in sustainability and conservation research. I've been impressed with what my friends who went into data science, data engineering, and machine learning can do. There are some ""big questions"" in the world of conservation and the environment. But many research groups simply do not have the skills available to come up with answers, but I'm convinced many data scientists do. Nobody gets rich doing this work, but I can attest its rewarding and fascinating.

I would love some tips on where to market such a workshop. As I said, my target audience is NOT other biologists - I know plenty of those. The workshop would be hybrid and hosted at the border of upstate New York and Connecticut, USA, approximately 1.5 hours from NYC.

I hope this doesn't break the mod rules! I am not doing this for profit, just to help an organization I work with.

&#x200B;

Edit: Thanks for the positive feedback already! I will post an update after I have time to do more planning. Given the scope of the workshop's potential topics, it will be good to focus on a single set of related subjects in the domain of expertise of my guest speakers.",2021-12-21 22:32:41
Do you tend to forget your fundamentals?,39,rll9q3,https://www.reddit.com/r/datascience/comments/rll9q3/do_you_tend_to_forget_your_fundamentals/,18,1640112440.0,"Do you ever get the feeling that your fundamentals are either trash, or shaky or just need revision (which is often very fast when you learned well)? This is currently personally bugging me a lot in the domain of statistics, and to a lesser degree most math. 

If you experience something similar occasionally, what do you do about it and how do you tend to think about it?",2021-12-21 20:47:20
I'm beginning to think that the data science job I want doesn't actually exist,207,rlku58,https://www.reddit.com/r/datascience/comments/rlku58/im_beginning_to_think_that_the_data_science_job_i/,128,1640111191.0,"I'm beginning to think that the data science job I want doesn't actually exist...

I've had three roles in in the DS industry and I've come to believe that there are three DS archetypes:

(1) the Researcher; these are the guys/gals who invented Fb Prophet, for example. Their work is all about R&D to bring a tool that could support many, hypothetically infinite downstream problems, and performance on benchmark tasks is emphasized. Without a PhD, it's hard to get considered for these sorts of roles.

(2) the Engineer; these are the folks who seldom invent truly novel models but more often train and deploy established models as a service. They're not inventing the next world-class language model, they're using transfer learning on BERT to build an MLaaS product. I've had these roles before but find them unsatisfying; the answer is almost always 'more data' or 'better hyperparameter tuning' but understanding the inner-mechanics of the model takes a back seat to knowing how to integrate a model into a production environment (CS-heavy, which isn't my background.)

(3) the Statistician; these are the data scientists who are interested in understanding the user-product ecosystem. Their output isn't a deployed model but articulating 'who, what, where, when & why.' Their output is tangible and 'unblocks' executives when a decision needs to be made.

My current role by far is most aligned with the Statistician archetype (DS product analytics at Meta.) My personal interest area is in Bayesian statistics. I find hypothesis testing to be reductionist and view Bayesian methods as holistic models that better answer 'who, what, where, when & why.' Yet, Meta has a very fast-paced, impact-oriented culture.

Sure, I could do regression analysis to infer the interaction of age and gender on product usage. But it's an unspoken rule that I'm discouraged from doing so. It's preferred that I visualize relationships, formulate a hypothesis and generate some confidence intervals, using our experimentation platform. Nobody cares about quantifying the magnitude of the interaction; they're much more binary (significant or not? Decide.) The cadence is so fast that there isn't an appetite for a fully Bayesian approach.

I feel that my dream job might not exist. I'd love to take a real problem, draw up a diagram of relevant variables, define a model in PyMC3 or Stan, use MCMC simulations, and visualize the posterior to better understand 'who, what...'

Any thoughts on this? Do you agree with my archetypes (would you add/remove/modify any?) And any hints on where I might look for the flavor of DS more aligned with my pitch?

I'm very close to saying 'F it. I'm making cash/stocks at a growth company, my dream job isn't worth giving up a good deal.'

&#x200B;

Edit 1: Yes, the data donkey is definitely a relevant archetype. And if I'm honest with myself, my role is some combination of statistician and donkey... currently, pulled more in the donkey direction.

I think this is actually the job I want, as others have noted, it's literally labeled ""statistician"": 

[https://www.linkedin.com/jobs/view/2827092936/?alternateChannel=search&refId=hN2%2B5mvQT33fyi7IdUqZaw%3D%3D&trackingId=fv2Mkzpx0bI4J1pK8s5FEA%3D%3D](https://www.linkedin.com/jobs/view/2827092936/?alternateChannel=search&refId=hN2%2B5mvQT33fyi7IdUqZaw%3D%3D&trackingId=fv2Mkzpx0bI4J1pK8s5FEA%3D%3D)",2021-12-21 20:26:31
How can I find recurring instances in time series data?,2,rlh1zv,https://www.reddit.com/r/datascience/comments/rlh1zv/how_can_i_find_recurring_instances_in_time_series/,1,1640100651.0,"Suppose the data is an annual bank statement, how could I go about finding things such as salary, credit card payments, insurance premiums, subscriptions and the likes?

Salaries would be mostly fixed, but the date can vary by a few days. CC payments could be fixed by date but probably not by amount. And yet these transactions happen every month.",2021-12-21 17:30:51
We scraped data from 2021 End of Year Salary Sharing thread and make an interactive notebook with analysis,8,rlf0d2,https://www.reddit.com/r/datascience/comments/rlf0d2/we_scraped_data_from_2021_end_of_year_salary/,7,1640094344.0,"We scraped data from [2021 End of Year Salary Sharing thread](https://www.reddit.com/r/datascience/comments/re46xx/official_2021_end_of_year_salary_sharing_thread/) and build an interactive notebook.

Raw CSV data is available at [GitHub](https://raw.githubusercontent.com/pplonski/mercury-demo-notebooks/main/reddit_salary_data.csv)

Notebook with code at [GitHub](https://github.com/pplonski/mercury-demo-notebooks/blob/main/Reddit_2021_salary_analysis_with_code.ipynb)

Interactive Notebook at [link](http://mercury.mljar.com/app/1)

Interactive Notebook with code at [link](http://mercury.mljar.com/app/2)",2021-12-21 15:45:44
"help with eer diagram, point out mistakes and/or what can be done better. Ill delete this post if this isn't allowed in the subreddit",0,rletfz,https://www.reddit.com/r/datascience/comments/rletfz/help_with_eer_diagram_point_out_mistakes_andor/,0,1640093736.0,"I have to translate this text into a enhanced entity relationship diagram. 

    This database is used to be able to persist train stations. A train-
    station is uniquely identified by a name (e.g. 'Ypres'). In addition,
    for each station also a unique coordinate pair is stored, consisting of the
    latitude and longitude. A distinction is made between internal
    national and foreign stations, in the sense that for foreign stations the national
    code of the country in which the station is located is stored (e.g. 'fr' for
    France) and not for domestic stations. For domestic stations,
    the unique name is always displayed in Dutch, but may be
    several translations of this name. This does not apply to foreign
    stations. A translation of a station name logically consists of the translation
    as well as from the country code of the language to which the translation belongs (e.g. 'Ypres' is the
    ‘fr’ (English) translation of ‘Ypres’). For each country code, a maximum of
    times 1 translation.
    
    The NMBS also has different types of trains available with a unique
    generic name (e.g. 'IC', 'P', 'BUS', . . . ) each of which refers to exactly one category of connection.
    hear (e.g. “high speed”, “regional”,…). These train types can be
    placed on several routes. Each trajectory has a unique name and is linked
    to all train types that travel this route. For example, the trajectory with
    name 'Blankenberge -- Gent-Sint-Pieters' linked to the train types with name
    'IC' and 'IT'.
    A trajectory is carried out one or more times a day. The implementation of
    a route in which a train of a certain type stops at a fixed sequence
    5
    stations (stops) at a fixed sequence of times is called a trip. every
    first of all, trip has a unique code, a maximum capacity of travelers
    that can take place on this trip and a collection of dates on which these
    trip is performed. In addition, it is necessary to save before every trip
    at what time (regardless of the dates) a train arrives and departs
    a specific stop (with the exception of the first stop which has no arrival information
    matie and the last stop that has no departure information). Of course you can
    trains only depart from a stop when they have arrived there first. Additionally
    In this case, it is necessary to indicate whether this is an arrival and departure
    time falls on the day of the original departure of the train (before midnight),
    or on the day after the original departure of the train (after midnight). like a train
    arrives at a stop after midnight, it also departs after midnight.
    Conversely, a train will certainly arrive at a stop before midnight if it is there too
    leaves before midnight.
    Because the departure and arrival times are not necessarily unique for a trip, but
    the order of the stations must be known, every stop where a train is
    stops a unique stop number per trip (with the first stop being numbered 1).
    The order of the stop numbers per trip should of course be consistent with the
    arrival and departure times of the same trip. This means that the arrival
    time of a train at a stop must be (same or) later than the departure time
    at stops with a lower stop number and the reverse should also apply. for ie-
    other stop on a trip for which departure information is known (i.e. all stops except
    the latter), an expected passenger occupancy should also be stored.
    Of course, this expected occupation may never exceed the maximum capacity of the trip
    exceed.

&#x200B;

[this is my third iteration of my eerd](https://preview.redd.it/vjvzji43fw681.png?width=320&format=png&auto=webp&s=999da8c091b26f6283764269bbe6b62d5e76893b)",2021-12-21 15:35:36
What is your strategy when interviewing for jobs?,17,rld603,https://www.reddit.com/r/datascience/comments/rld603/what_is_your_strategy_when_interviewing_for_jobs/,18,1640087900.0,"I've been interviewing for jobs, but with already a full-time job that is burning me out, I can't do more than 2 jobs at a time. These end up being lengthy processes that take up months at a time, only to say no or ghost me at the end. I also almost always end up to the very end of the process in pretty much all of them (8 years of experience, so I guess naturally they will give me a shot all the way down).

I'm starting to think that this strategy isn't working in order to change jobs, but applying for more jobs at once is also difficult as I don't think there's enough human time to deal with all of them. 

Some context would be that I'm working as a regular Data Scientist and looking to get a senior role directly in my next job, the focus would be more on statistics than an Analytics Engineer role, although my skills in that direction are also pretty good. 

So what do you do in terms of applying with the conditions mentioned?",2021-12-21 13:58:20
how to analyze raw text data?,7,rl80hy,https://www.reddit.com/r/datascience/comments/rl80hy/how_to_analyze_raw_text_data/,8,1640067258.0,i have a raw text file separated by lines that i want to analyze and i am not sure how to go about this. my end goal is to make some visualizations like word clouds and charts. how should i work with the text? i also want to know what this process is called so that i could look into to some projects completed by other people.,2021-12-21 08:14:18
What academic path should one take in order to learn GPT-3 and everything about natural language processing in higher education?,0,rkvbzq,https://www.reddit.com/r/datascience/comments/rkvbzq/what_academic_path_should_one_take_in_order_to/,5,1640029300.0,,2021-12-20 21:41:40
Product Data Science Materials Recommendations?,29,rkuans,https://www.reddit.com/r/datascience/comments/rkuans/product_data_science_materials_recommendations/,5,1640026429.0,"Hi all,
Anyone have any favorites or recommendations of training courses, books, videos, etc. on product data science?

Just to add some details if it helps, I came from a more risk management finance background and looking to break into a startup focused in data science for product/marketing.

Thanks in advance!",2021-12-20 20:53:49
Help Categorizing Text using Custom Categories in R,2,rkstgj,https://www.reddit.com/r/datascience/comments/rkstgj/help_categorizing_text_using_custom_categories_in/,6,1640022338.0,"Hello!

This question will likely end up being moved to StackOverflow but for now, I am looking for assistance finding a good R Package for this. And I did spend a long time trying to google for this and I found many results, too many.

I am trying to create a project in R that will allow me to take in my own transaction history using CSVs from Mint and label the merchants from the description. This seems like a simple if statement but it is actually far more complicated for two reasons. First, Some companies (like Target) use a custom description for every transaction ""Central Checkout \[ID\]"". And second, if I go to a brand new store I would like the model to attempt to determine the store from the description (and I can correct it if needed), so I don't have to update the list of potential merchants every time I go somewhere new.

I have a very large dataset of all my transaction descriptions for the past many years, and I put my merchant on about 40% of them by hand.

Any advice on an R package to explore to try and accomplish this custom categorization?",2021-12-20 19:45:38
Is someone with a masters capable to working on difficult and in-depth research projects?,0,rks6os,https://www.reddit.com/r/datascience/comments/rks6os/is_someone_with_a_masters_capable_to_working_on/,5,1640020634.0,"I know the biggest thing that distinguishes a PhD from a master’s is that the PhD teaches you how to conduct very in-depth and involved individual research, which is very appealing to employers and also very prevalent is data science. There’s also the element of being able to learn something complex on your own. 

So my question is, would a masters holder be able to work on in-depth projects, too (especially if they did a masters thesis)? Would they be able to learn complex statistical topics on their own, or keep up with current literature? Or would they have to turn to a PhD for some of that? I understand that these would be easier for a PhD but I wanna know if the difference between masters and PhD in such cases is significant.",2021-12-20 19:17:14
Need help with data viz,0,rkp40r,https://www.reddit.com/r/datascience/comments/rkp40r/need_help_with_data_viz/,4,1640012248.0,"Hi guys I need your advice please, 
I'm working on a project presentation and I would like to visualize the Evolution of 2 variables through time (some kind of scatterplot with a time evolution), I don't know what type of graph should I use or if it's even possible to do so. 
Thank you all.",2021-12-20 16:57:28
"Export large set from SQL to csv and plug in to BI tool, or connect BI tool directly to database?",4,rkoeqb,https://www.reddit.com/r/datascience/comments/rkoeqb/export_large_set_from_sql_to_csv_and_plug_in_to/,12,1640010219.0,"I need to pull a few tables of transaction data from a Postgres database to analyse. I also have some external transaction datasets (>10) that I need to connect to the data. It's a one of analysis.

The data from the DB is a few million rows. The external data only a few 100.000. 

I'm not sure what the best way is to connect the datasets to my BI tool. Generating individual CSV files trough SQL and connecting these to the BI tool seemed like an idea. Or connect the BI tool to the DB directly, but I expect very slow response time. Or pull the data in a Panda's dataframe and make Python do the work.

Any advice would be appreciated.",2021-12-20 16:23:39
Research Project - Showing Causality in Non-Linear Data,0,rknw6y,https://www.reddit.com/r/datascience/comments/rknw6y/research_project_showing_causality_in_nonlinear/,11,1640008791.0,"Hi, 

I'm doing a project and I have non-linear data. Any tips on where I can look to show causality?

I have not done this before for non-linear data. I found many non-parametric Granger Causality tests but they are not so common and there are no python packages that help me to get results.

Any tips would be appreciated.",2021-12-20 15:59:51
"List of over 150 Biases (Belief, decision-making & behavioral, Social, Memory).",245,rklxmb,https://www.reddit.com/r/datascience/comments/rklxmb/list_of_over_150_biases_belief_decisionmaking/,25,1640002315.0,"These biases affect belief formation, reasoning processes, business and economic decisions, and human behavior in general. 

I've compiled a list (pdf) of over 150 biases (mainly from Wikipedia). Maybe this is useful for some.

The pdf can be downloaded for free here:   [A List of over 150 Biases (Belief, decision-making & behavioral, Social, Memory) ](https://murat-durmus.medium.com/a-list-of-over-150-biases-belief-decision-making-behavioral-social-memory-a51204bcaaf2)",2021-12-20 14:11:55
Language related data science,6,rkk4qp,https://www.reddit.com/r/datascience/comments/rkk4qp/language_related_data_science/,9,1639995424.0,What are some jobs for data scientists most related to language? Is there a specific job title where the scientist’s job is to analyse textual data as opposed to numeric to discover important information?,2021-12-20 12:17:04
"Is there a platform other than Github where data analysts and data scientists can store code, and edit it all for free?",82,rkebgt,https://www.reddit.com/r/datascience/comments/rkebgt/is_there_a_platform_other_than_github_where_data/,25,1639973510.0,,2021-12-20 06:11:50
Have missing values for the length of YouTube transcripts and trying to predict these using the video duration but am getting some negative values with a linear regression,0,rkc8pc,https://www.reddit.com/r/datascience/comments/rkc8pc/have_missing_values_for_the_length_of_youtube/,10,1639966778.0,"Around 200 of the videos in my dataset don't have transcripts available so I was unable to get the length of these. I've found a strong correlation between transcript length and video duration which makes sense logically as well. So I tried running a regression to estimate the missing transcript lengths but I'm getting some negative values.

Not really sure how to handle this issue so if anyone can offer some advice on what the cause is that'd be greatly appreciated :)",2021-12-20 04:19:38
"[D] In image segmentation, how are segments labelled?",4,rk9znt,https://www.reddit.com/r/datascience/comments/rk9znt/d_in_image_segmentation_how_are_segments_labelled/,2,1639960045.0,"In image segmentation, how are the targets in the training data set labelled? I'm new to this but I imagine every pixel should have a label and I highly doubt this is done by hand.  


Also, how is this done for bounding boxes? Does someone manually define the locations of the vertices by hand?",2021-12-20 02:27:25
Could I consider myself a data scientist?,34,rk4zcr,https://www.reddit.com/r/datascience/comments/rk4zcr/could_i_consider_myself_a_data_scientist/,20,1639945698.0,"I’ve been learning on the job a lot and I’m wondering how appropriate it would be for me to look at data science roles, and particularly say I have data science experience when applying for them. 

My current title is optimistation engineer, working for a small electricity generator/retailer. My main roles at the moment are modelling and predicting improvement opportunities by looking at historical data. Ie revenue modelling from historic weather, under increased capacity scenarios. I also look for improvement in operational decision making and build dashboards to track efficiency improvements. 

I’m doing data work with sql and python mostly, then excel and power bi for presentation and sharing. 

What else would I need to be familiar with to easily fit into a data science role somewhere else?",2021-12-19 22:28:18
Employer/career question: How do you genuinely find out whether a company is going to be a good place to work or not? What are the best ways to get quality information on a workplace? Not sure if Glassdoor etc are reliable.,9,rk14r7,https://www.reddit.com/r/datascience/comments/rk14r7/employercareer_question_how_do_you_genuinely_find/,10,1639934215.0,"Hi all,

Employer/career question: How do you genuinely find out whether a company is going to be a good place to work or not? What are the best ways to get quality information on a workplace? Not sure if Glassdoor etc are reliable.

My role would be data related and am interviewing at various places and this is one of my key things I look for (ie. a good work place).",2021-12-19 19:16:55
The results of my job search in the UK as a DS with 2 YOE,539,rjzooe,https://i.redd.it/y3xng5tvvi681.png,82,1639929873.0,,2021-12-19 18:04:33
What's the difference between results and insights?,9,rjyi38,https://www.reddit.com/r/datascience/comments/rjyi38/whats_the_difference_between_results_and_insights/,9,1639926265.0,"I have a project coming up and we are to produce 5 visualisations. For each one you're meant to write the results and insights. Just curious on the difference between the two, so I can give a better answer. Thanks.",2021-12-19 17:04:25
Weekly Entering & Transitioning Thread | 19 Dec 2021 - 26 Dec 2021,11,rjvdsf,https://www.reddit.com/r/datascience/comments/rjvdsf/weekly_entering_transitioning_thread_19_dec_2021/,98,1639915230.0,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",2021-12-19 14:00:30
Books recommendation,8,rju0o8,https://www.reddit.com/r/datascience/comments/rju0o8/books_recommendation/,7,1639909380.0,Hi guys. I'm a high school senior having an interest in DS. I just started researching a bit about DS and just wonder whether you guys could recommend any academic books that every newbie must get to know before delving into the field? Thanks for all of  your recommendations,2021-12-19 12:23:00
Confidence intervals in a business setting,9,rjtm59,https://www.reddit.com/r/datascience/comments/rjtm59/confidence_intervals_in_a_business_setting/,22,1639907574.0,"Hello everyone,

I'm looking for examples where I can see the application of confidence intervals in a business setting.
I'm specifically looking into finding some (Powerpoint) slides on the web that can give me a somewhat realistic insight into how such numbers would be presented by say a data analyst to a non-data person during a meeting.

All theory is grey but examples rock. They help me understand the application.

Alternatively, if there's no (free) slides available, would you share some technical points from your own experience? What kind of data were you talking about, who were you presenting to, what kind of graph/plot did you use and how did you visualise and communicate the confidence intervals?

Many thanks and stay healthy.

[Edit: thanks everyone!]",2021-12-19 11:52:54
I've interviewed more than 50 people this year. Here's a mistake that most candidates make,1165,rjg6ng,https://www.reddit.com/r/datascience/comments/rjg6ng/ive_interviewed_more_than_50_people_this_year/,138,1639860304.0,"They don't give business context when I ask about a project that they're proud of. They immediately jump into details and start talking about models, improvement in accuracy, and other things.

Just explain the problem first. Tell me why it's an important problem. Why did you start working on it in the first place? 

And then start talking about technical details.",2021-12-18 22:45:04
Help Transitioning to a Data Science Career,3,rjdz46,https://www.reddit.com/r/datascience/comments/rjdz46/help_transitioning_to_a_data_science_career/,12,1639853817.0,"I graduated with a bachelor's degree in mechanical engineering and have been working as a mechanical engineer in biomedical product development for about 6 years here in Boston. I'm wondering what it would take for me become a data scientist/engineer. 

I have a little experience coding (Python and MATLAB), but not many projects to show off and I know I need to learn much more before I can even get a junior data scientist position. I realize I will be taking a pay cut to switch fields like this. I'm ok with that because I have a great interest in the field and I think I might make more than I do now as a mechanical engineer once I get 3-5 years of experience. I am hoping I can just take some online data science courses (Udemy, etc.) at night while working as a mechanical engineer rather than getting a formal education (master's degree). 

What are your suggestions for making this career transition? What type of education/training should I seek? Also, how do I get my first job? Even the junior data scientist jobs seem to ask for 1-2 years of experience.",2021-12-18 20:56:57
Job Market from a Hiring Manager's point of view,291,rjat6u,https://www.reddit.com/r/datascience/comments/rjat6u/job_market_from_a_hiring_managers_point_of_view/,173,1639844495.0,"TL;DR: this is the most candidate friendly market I've seen for people with literally any level of actual experience - but the most brutal I've seen for people with no experience. If you have to, make it a priority to get *any* experience - even if non-DS related.

I've been a hiring manager for several roles over the last 4 years. In every case, I was looking for people with some experience - small teams, so I wasn't really in a position to take on a candidate to raise myself - I needed someone who could function pretty independently.

It has been hell. Everyone who has even 1 year of experience as a data scientist is going to be inundated with offers, and now that remote work has fully opened up, even in average COL cities you're fighting companies offering East/West coast salaries. 

On the other hand, every job ad I've put out has been inundated with applications from people with 0 experience.

What does that mean?

* When choosing an academic path, focus on something that will make you stand out - not on the path of least resistance. Example: I see a lot of people go routes like ""I got a BS in humanities, so I don't want to try to get into a MS in Stats because I'd need to cover too many prereqs, so I'm gonna do a bootcamp"". That is the wrong mentality. That will land you in the really long list of candidates that look like that. By contrast, someone with a legit humanities background and a legit MS in Stats will look *a lot* more interesting. 

* Evaluate programs based on how well they place students into jobs. This is especially true for MS in DS programs who normally put a lot more effort into it. Go on LinkedIn and see where their grads go work and in what roles. For example: a lot of programs will send their grads to entry level DS roles at companies where DS = Data Analyst. Which isn't bad - but it's a different baseline than starting out as a legit DS. As an example: I tried to recruit Texas A&M's stats department for MS and PhD students and most of them had offers lined up from FAANGs or NYC ad tech/fin Tech jobs. 

* As soon as you hit the 1 year mark at your job, start applying for your next job. I don't know how long this era will last, but right now companies are desperate to hire and they know they need to pay up to do so. Take advantage of that. This is not the era to sit around and hope your company will give you a raise higher than inflation. Go apply for jobs. 

* If you're not getting call backs and you have either a) a strong academic background (e.g., grad school from top 30 school with research publications), or b) any legit DS experience in a full time job, immediately assume that your resume needs work. Seek help, and not from academics, but from people in industry or professional resume writers. This sub can be helpful too.

EDIT: Two caveats here:

1. This doesn't apply to those on F1 visas. Getting a job on an F1 visa is going to be 10 times harder than if you already have a green card or you're a citizen. No way around that. 

2. If you suspect your resume may be an issue, listen to this podcast episode and look at the sample resume attached. If you want me to help you out, do that step first so we can speak the same language. https://www.manager-tools.com/2005/10/your-resume-stinks

* if you're having trouble landing the DS job you want, find a DS adjacent job and then move into DS in a year. Having even 1 year of real world exoerience will make hiring managers a lot more likely to hire you.",2021-12-18 18:21:35
What can I use as a proxy for the YouTube dislike count in my dataset?,2,rj8wct,https://www.reddit.com/r/datascience/comments/rj8wct/what_can_i_use_as_a_proxy_for_the_youtube_dislike/,4,1639838675.0,"With the dislike count now removed from the public site and API, I'm looking for an alternative metric that I can use.

So far I have the like/view but I was wondering if there's a more accurate measure I could possibly use?",2021-12-18 16:44:35
[DS Project] Calculating Ad Pricing in an e-commerce website,2,rj7982,https://www.reddit.com/r/datascience/comments/rj7982/ds_project_calculating_ad_pricing_in_an_ecommerce/,4,1639833216.0,"Hey Guys!

I have to do a project where I have to calculate the Ad pricing (banner, in-grid) for an e-commerce website. I have historical data of over 2 years. I have Page Views, CPC, CPM, historic ROAS, total campaign cost and lot more data.

I want to correctly set or predict the CPM pricing on different ad spaces on website. CPM should not be too high or too low and we should be able to show an ROAS > 2

Wanted to check if someone has worked on a similar problem and any idea how to approach it.

Thanks!",2021-12-18 15:13:36
Is reaching out to data scientists on LinkedIn even a thing?,48,rj5lqg,https://www.reddit.com/r/datascience/comments/rj5lqg/is_reaching_out_to_data_scientists_on_linkedin/,70,1639826785.0,Hello. I wanted to speak with data scientist so I can learn more about the careers. I reached out to some on LinkedIn who also happen to be alumni of my university. My profile is updated. So far I have received no response and honestly I feel embarrassed for even reaching out. Are informational interviews uncommon for people who want to learn more about data science?,2021-12-18 13:26:25
Dealing with Business People,3,rj3kja,https://www.reddit.com/r/datascience/comments/rj3kja/dealing_with_business_people/,17,1639818176.0,"Hi all!

I am currently switching from software engineering to data science in my company and in fact I am the first to do data science. There is great potential, but...

The Product Owner does not want me to connect to the database in production but instead he wants me to use another database which is used by the finance team to do acoounting and reporting. The data there is already transformed, some columns (which would be important for me) are dropped and it is also less data I think. Obviously I can not achieve the expected result with that data, because garbage in -> garbage out. 

I already thought about cloning the production databse, but 240gb would take quite a while and in the end it would just be more rational to use the production database I would argue.

&#x200B;

Although I do only have permissions for reading the data he still is worried that my queries might slow down the production system.

&#x200B;

How should I argue with him to access the real database, i.e, how do you deal with such situations?",2021-12-18 11:02:56
Are there good models to investigate which node in a network contributes most to an effect?,3,rj12li,https://www.reddit.com/r/datascience/comments/rj12li/are_there_good_models_to_investigate_which_node/,5,1639807900.0,"Are there good models to investigate which nodes in a hierarchical network contribute most to a response? If not network, then hundreds of nominal or ordinal features?

I work with materials that have a very large number of batch produced sub-components, which may be used in multiple ""lots"" of end goods (Preclinical Pharma). I have attempted to use random forest weightings, but they weren't very successful in cases with highly unbalanced data, or with materials that have highly correlated sub-components.

I usually hand investigate sub-components via domain expertise, but was hoping there are better solutions to generate investigative leads. 

I don't think I really have the ability to use something like Shapley values, as testing with / without is cost prohibitive. One-hotting doesn't seem to work well either as it turns hundreds of columns into ten thousand.

Also are there any good hierarchical network tools generally? I'm thinking something like Maltego but geared towards industrial investigation instead skip tracing.",2021-12-18 08:11:40
Is SAS an outdated tool? Career suicide?,31,rixdi6,https://www.reddit.com/r/datascience/comments/rixdi6/is_sas_an_outdated_tool_career_suicide/,31,1639795090.0,"I’ve been working the past couple years in the banking industry with SAS as the software that we use for everything from data pulls to modeling. I’ve become an advanced SAS programmer but my R coding and even pure SQL skills have diminished greatly. I can still code in SQL, but the SQL used in SAS is not pure SQL and I often find myself using data steps or macros to pull the data instead.   


Is this going to diminish my value in the job market? I do not see myself working in the banking industry my entire career. Should I move into a different role that utilizes tools like Python and R before it’s too late?",2021-12-18 04:38:10
Are commission-like pay schedules common in the data industry?,2,rivr4d,https://www.reddit.com/r/datascience/comments/rivr4d/are_commissionlike_pay_schedules_common_in_the/,10,1639789873.0,"I'm currently interviewing for a big data engineer role with an IT consulting company. The data engineers are responsible for securing clients for projects, paying some housing fees if travel is required for work, and for interviewing for future projects. Pay is determined by the number of projects secured and hours spent on each. Is this common? I'm unsure what to make of the possibility that I could go weeks without pay, even though they've assured me that's never happened.",2021-12-18 03:11:13
Do you know what book it is?,5,rivkfh,https://www.reddit.com/r/datascience/comments/rivkfh/do_you_know_what_book_it_is/,18,1639789301.0,"I found this chapter from some statistics (most likely) book on the internet. I really like how this chapter is written and would like to read the entire book. I tried very hard to find which book this chapter belong to, but couldn’t. Does anyone recognize it? Here is the link to the chapter: [Chapter 29. Multiple regression.](https://www.stat.berkeley.edu/~brill/Stat131a/29_multi.pdf)",2021-12-18 03:01:41
Jesus it's hard to get a job in this field,235,riup34,https://www.reddit.com/r/datascience/comments/riup34/jesus_its_hard_to_get_a_job_in_this_field/,216,1639786630.0,"I have almost one year of experience, an MS degree from a good college, two internships, apply everyday and rarely get calls from any medium sized firms. 

Only startups call me up - and they have sky high expectations and super low salaries. Man this is so demotivating. If I were in CS I could have landed a job yesterday.",2021-12-18 02:17:10
Guidance needed,1,rithw9,https://www.reddit.com/r/datascience/comments/rithw9/guidance_needed/,9,1639782960.0,"I'm 16 and have always been interested In data science, I know a fair bit about excel, SQL and are quite well versed in about 10 programming languages. I want to go into a data science job but don't know what path to take. currently taking computer science at secondary school and want to go to college but unsure on what to take there.",2021-12-18 01:16:00
Which is better for automating process inside a company (python or SQL)?,3,risho4,https://www.reddit.com/r/datascience/comments/risho4/which_is_better_for_automating_process_inside_a/,25,1639779921.0,"I have a very basic knowledge about SQL and would like to spend the next 6 months to learn either SQL or Python. 

The reason ? 

I would like to automate part of my job. 

My job: everyday I receive 35 files from 35 different firms via email. I have to open those files and copy some data from them then move them to other excel sheets to do some calcs for settlement. 

I would like to automate this process (if not the whole process, at least large part of it). 

***Of course I will have to make sure that all the files received are consistent and in the same format. 

Going back to my question: which language is better for my need ?

Edit: thank you everyone for your answer and support",2021-12-18 00:25:21
"Efficiently keeping a ""moving window"" of records in Pandas",3,ripzdn,https://www.reddit.com/r/datascience/comments/ripzdn/efficiently_keeping_a_moving_window_of_records_in/,5,1639772527.0,"Hi,

I have a use case: There is a Kafka topic emitting messages continuously, and I want to keep the last X minutes of messages (based on some field timestamp in the schema) in a Pandas data frame, and of course update it as new messages arrive (i.e. by removing older messages). The goal is later to run queries on the data frame using DuckDB.  


Now of course I can simply append new messages to the data frame and remove the old ones using a Pandas filter. But is that efficient/the most efficient one? Is there some way to ""index"" that timestamp field to make things faster? Or even better, keep the data frame ""sorted"" on that field? What do you do for such a use case?  


Please note that the final ""data structure"" needs to be something supported by DuckDB which I believe leaves us esssentially with Pandas only.    


Many thanks

Best",2021-12-17 22:22:07
Am I being underpaid? When should I look for something more?,4,rim14g,https://www.reddit.com/r/datascience/comments/rim14g/am_i_being_underpaid_when_should_i_look_for/,34,1639761072.0,"I’ll do my best to provide some context here - I work for a very large performance based call center. My title is not officially Data Analyst but just Analyst. However, based off what I’ve read online, a lot of my tasks are very similar. I am required to understand and execute relatively complex SQL queries, work with Power BI, Excel, and I will soon be asked to work with Python. I started at the bottom of the food chain as someone who made the calls and worked my way up. I don’t have any formal education but have only a few classes left for my associates in computer programming. I do have formal education in databases and Python. A lot of my tasks include but are not limited to:

- Create outbound call/email/text lists with various parameters that have included millions of clients
- Compiling both internal & external call stats for various reports, KPI’s, and associate scorecards
- Integrating and managing internal sites that are utilized by lower level employees for stats & rewards

Some of these tasks are somewhat high risk considering the fact that a lot of places have certain laws against receiving calls during different times, reasons, etc. As well as putting together scorecards for people that make the calls since this will ultimately quantify their performance for managers/supervisors to make decisions on raises & bonuses. So there is very little room for mistakes with some of my tasks. 

My annual salary is about $48k in the Midwest region of the US. I have a total of 4 YoE working for the company, but only a few months in this position with no other experience as an analyst. At first I was okay with the compensation (not being much more than what I was making on the phone) because I wanted the experience. But after reading about some peoples jobs & salaries making 6+ figures and working half as much as I do, I’m not so sure. And maybe I’m just being bitter, but I always have and always will strive for something that’s better if I can. 

Does anybody have any advice? Should I stick it out for a while and continue to climb the corporate ladder here or look for somewhere else to go? I definitely wouldn’t mind some new scenery.",2021-12-17 19:11:12
"Seems both my ACF and PACF both cut off, anyone able to help on what could possibly be wrong?",4,rikrhg,https://www.reddit.com/r/datascience/comments/rikrhg/seems_both_my_acf_and_pacf_both_cut_off_anyone/,13,1639757508.0,"Just trying to determine a model to best predict some stock data for a project and not sure how to interpret this output on my stationary series.

https://preview.redd.it/6uz08pxwm4681.png?width=976&format=png&auto=webp&s=4c76d862ef102872395106c1087f0869c5c9d1a4",2021-12-17 18:11:48
I'm looking to analyse YouTube videos for a project. Would you recommend getting videos from every category or a select few categories?,5,rik2xj,https://www.reddit.com/r/datascience/comments/rik2xj/im_looking_to_analyse_youtube_videos_for_a/,6,1639755557.0,"Doing a data analysis project where I need to ask some interesting questions about my dataset. My aim is to get \~200 videos from each category then look for trends within and across these categories such as how likes/view varies with other variables.

But this is the first time I'm doing a data project like this so not sure if it makes more sense to limit the scope to fewer categories or pull videos from all available categories then see where the interesting trends are?

Any advice on how to approach this would be great",2021-12-17 17:39:17
How important is knowledge in web technologies for DS roles?,12,rij425,https://www.reddit.com/r/datascience/comments/rij425/how_important_is_knowledge_in_web_technologies/,21,1639752812.0,"Assuming a good knowledge in conventional DS skills (DSA, SQL, stats, ML, etc.), how important is knowledge of web development? I can barely keep up with the former, let alone attempt to understand another field people spend their entire careers attempting to master. 

An alternate phrasing: how little web dev. knowledge can I get away with to not seem like a fool in interviews?",2021-12-17 16:53:32
The Science of Visual Data Communication: What Works,0,rig9bq,https://journals.sagepub.com/stoken/default+domain/10.1177%2F15291006211051956-FREE/full,0,1639743601.0,,2021-12-17 14:20:01
"Does high pay = harder work, longer hours?",265,ri6sa6,https://www.reddit.com/r/datascience/comments/ri6sa6/does_high_pay_harder_work_longer_hours/,168,1639708196.0,"How many of you are making 110k+, working 30-40 hrs a week, and generally have a low stress job?

I've got a cushy job. I work about 35 hrs/wk, managing 3 analysts who do excel and SQL+Tableau. I make 75k, low cost of living area, fully remote, unlimited PTO. I could actually do my job passably in 20 hrs a week--only my pride and desire to advance keeps me working. 

I've got a Master's in Analytics, and could start down a path of data science ""proper""-- building and deploying predictive models, building SWE skills, etc. But my  work+life balance rocks. I'm afraid to give up this job and then never find another like it. 

With 6 YOE, management experience, and a MS, I could easily make 6 figures somewhere. What are the odds that if I switch jobs a couple times, I'll eventually find something like what I have now, but with better pay?

Would I be crazy to leave what I have?

Edit: thanks for the comments, please keep them coming. Thus far, Mostly people telling me that it is doable--you CAN have it all. Dissenting opinions welcomed.",2021-12-17 04:29:56
How do you go about coming up with ideas for personal projects?,20,ri49bx,https://www.reddit.com/r/datascience/comments/ri49bx/how_do_you_go_about_coming_up_with_ideas_for/,16,1639700461.0,"I'm hoping to take some time over the holidays to start a new and (hopefully) interesting personal project. I've never tried to create a project outside of an academic setting before, and I'm a little lost on where/how to start coming up with ideas.

A bit of Googling showed the same few project ideas coming up (credit card fraud detection, road sign classification, etc) and ideally I'd like a fresh take rather than a recycled idea. 

I'm hoping that this would be a good chance to learn/practice new tools or skills that would be helpful in either academic or professional settings (I'm an undergrad statistics student) and have something nice to add to my Github as a bonus.

If anyone has tips or suggestions, I'd really appreciate it. Thanks in advance!",2021-12-17 02:21:01
What are the chances to get an H1B after I transition from academia to data science?,1,ri3som,https://www.reddit.com/r/datascience/comments/ri3som/what_are_the_chances_to_get_an_h1b_after_i/,5,1639699087.0,"Hi guys, I'm trying to plan my nearest future and I am curious about my chances to get an H1B visa from employer. I'm currently in a researcher position in university. I'm planning to transition to data science field within a year or two. Thank you!",2021-12-17 01:58:07
does anyone know how to view ancestry by location using American Community Survey data?,6,rhzzv0,https://www.reddit.com/r/datascience/comments/rhzzv0/does_anyone_know_how_to_view_ancestry_by_location/,4,1639688144.0,"I am trying to recreate the ethnic enclaves in dearborn plot [here](http://www.drawingdetroit.com/highest-arab-hispanic-populations-found-in-wayne-county/)

I think they used the equivalent of this survey data I am accessing through the [census website](https://data.census.gov/cedsci/table?t=-A0%20-%20All%20available%20ancestries&g=1600000US2621000)

but for the life of me I cant seem to figure out how to make that map. Has anyone worked with this data?

I have a lot of programming experience so even the raw data without a web tool would help. If I could do dominant ancestry by zipcode in dearborn (lebanese, yemini etc) that would be great. Even more granular than by zipcode would be better Thank you",2021-12-16 22:55:44
"For those who game and do deep learning, do you use the same PC for both?",2,rhzkvi,https://www.reddit.com/r/datascience/comments/rhzkvi/for_those_who_game_and_do_deep_learning_do_you/,13,1639686969.0,"A bit of an alternative question. I've been doing some research and can't figure out if there's specific parts I would only want for a gaming PC or only a deep learning machine, or if I'd be good using the same PC for both. Any recommendations or resources from your personal experience would also be much appreciated!",2021-12-16 22:36:09
"Alteryx - Opinions, experiences & alternatives",2,rhzboi,https://www.reddit.com/r/datascience/comments/rhzboi/alteryx_opinions_experiences_alternatives/,14,1639686235.0,"We are thinking of using Alteryx for one of our projects. What are your thoughts on Alteryx. Has anyone found a better alternative, if so why?",2021-12-16 22:23:55
"How value, relevant or absolute is SCIEM in the Data Science process?",6,rhz7om,https://www.reddit.com/r/datascience/comments/rhz7om/how_value_relevant_or_absolute_is_sciem_in_the/,1,1639685925.0,"I'm going through a rather large data set and with this many TB to start, I recognize a familiar feeling. There has to be a more efficient, effective and economical beneficial process for this, it kind of hit me one day that while there is a PEMDAS for the Order of Operations in algebra, what is there for algorithm choice when doing data science work?

There is PEMDAS for the algebra stuff = 100% efficient ! Since 1898

There is SCIEM for the stats/data stuff = XXX% efficient ? Since 1983

There is CRISP-DM for the MBA-ish stuff = XXX% efficient ? Since 1996

There is My-Process for a smattering of all three = X31% efficient over 6 years

Is there a unified theory for all of this and my initial findings is that there doesn't seem to be a single obvious, nor one that is unified theory for Data Science... yet?

PEMDAS was drilled into me by the schools and this is computationally 100% totalitarian dictator enforced and there are no dissidents allowed.

I walked across SCIEM, which stands for Split test, Misc Cleaning, Impute Missing Values, Encode/Scale, and Modeling the data; Has a locus of for math or algorithmic model for data processing.

Then you have CRISP-DM which is for Business understanding, Data understanding, Data preparation, Modeling, Evaluation, Deployment; Has a locus of process for MBA-ish data management

While I have 6 years working in finance as an advisor we used heavy amounts of analysis to understand the customers goals, risk tolerance, event horizon analysis, and how much time or effort they wanted to put in. We had a heavily defined process that came from regulation and we have millions of case studies showing that this specific process was heavily weighted in success. I mean it was so ridiculously displayed in the data that it was practically newtonian in the reliability, that it looked familiar but I couldn't quite recall where I saw it first. It was so effective that those of us who just followed this process and logged it independently in excel noted a simple wave pattern emerged and the frequency became quite obvious, it was logarithmic.

So when we met clients we had an incredible amount of confidence in our probability of success, so clients frequently said yes. We gathered data, asked a trainload of questions ended that meeting, scheduled the next and went to input data. Subsequently we used heavily modified Monte Carlo and HMM plus a smattering of other algorithms but always there was a process that BlackRock software had us enter the data in. Then we progressed to the next step, check our assertions vs a backtesting application and then go back into optimization in a sort of hybrid efficient frontier.

The output of all this was incredible and I never had one client come back to say they had gotten a better analysis by Schwab, DA Davidson, LPL, Fidelity, Prudential, Vanguard, JP Morgan, Allianz... but the constant outlier that amazed me was Goldman Sachs. Every freaking time they had an additional edge, tweak or an ensemble of things and we almost always had a less effective model in their >$375,000 assets projections.

So I said all of that to show that in some fields they absolutely have found a process, or THE PROCESS and deviating from it was economic suicide or at least a glutton for punishment.

Is there a process to all the algorithms that we use in data science in general?",2021-12-16 22:18:45
Learning resources for incorporating PySpark into machine learning project?,1,rhxib5,https://www.reddit.com/r/datascience/comments/rhxib5/learning_resources_for_incorporating_pyspark_into/,14,1639681247.0,"I'm trying to incorporate pyspark to parallelize an existing logistic regression model that's based off the sklearn library to drastically speed up the model. For the time being, I'm mostly interested in learning how to convert an existing pandas dataframe into a spark dataframe and from there use it to train the model and then feed a prediction dataset.  


I'm wondering if anyone would be able to recommend recent and up to date learning resources for pyspark. From what I understand, things are changing and improving quite rapidly in the spark ecosystem and a decent chunk of existing materials are becoming out of date. The spark\_sklearn library seems to be deprecated but I'm not sure what it has been replaced by.

I think from there I'll experiment with using it for the transformations, filtering and other data pre-processing steps that occur, from what I can tell koalas would be a good starting point for that aspect.",2021-12-16 21:00:47
Anyone have examples where they've had success accurately predicting business type metrics over a long period of time?,19,rhw51l,https://www.reddit.com/r/datascience/comments/rhw51l/anyone_have_examples_where_theyve_had_success/,19,1639677368.0,"For example. Is it possible to accurately predict CLV based on purchase history (and other commonly available customer data)? I'm fairly confident that objective data inputs are generally solvable such as identifying a chair (especially if it's a specific chair) in an image but am far less sure about other scenarios.

The concern is that for CLV you do not have a ton of data on that specific individual and there are a ton of factors that drive purchase volume such as competition, macro economic forces, and ongoing business changes. So any CLV prediction essentially has to assumes that all these external forces are constant (which is never the case).

Any good rules of thumb that help determine if this is even a good type of problem for data science to accurately solve?",2021-12-16 19:56:08
Are there any branches of applied mathematics that have a significant place in advanced analytics?,1,rhw0zj,https://www.reddit.com/r/datascience/comments/rhw0zj/are_there_any_branches_of_applied_mathematics/,4,1639677039.0,"Asking the question this way to deliberately focus on the business side of data science, ostensibly ""advanced analytics"". Not referring to machine learning mode development or implementation.

And as far as applied mathematics, I'm grouping simulation, optimization, graph theory, stochastic modeling, combinatorics, etc. I'm leaving out statistics and probability as it's understood that those are relevant to analytics.",2021-12-16 19:50:39
"Hearing from today’s real world data leaders (episode 44 = Gillian Doherty OBE, CEO of Data Lab Scotland)",1,rhvjv3,https://open.spotify.com/episode/5fKYtd3cvuTkCJTGd0Pfpr,0,1639675676.0,,2021-12-16 19:27:56
Synthetic time series data generation,1,rhv1xi,https://www.reddit.com/r/datascience/comments/rhv1xi/synthetic_time_series_data_generation/,2,1639674280.0," I  want to generate time series tabular data. Most of generative deep  learning models consists of VAE and/or GAN which are for most part  relating to images, videos, etc.

Can  you please point me to relevant tutorial souces (if it includes code  along with theory, all the more better) pertaining to synthethic time  series data generation using deep learning models or other techniques?",2021-12-16 19:04:40
[D] Deep Bayesian Networks,12,rhtzw1,https://www.reddit.com/r/datascience/comments/rhtzw1/d_deep_bayesian_networks/,4,1639671255.0,"Has anyone here done research or worked with deep deep Bayesian networks?

I’ve just begun studying Gaussian Process Regression and Bayesian Linear Regression and, having focused on DL the past 2 years, I began to wonder about applying the Bayesian concepts to the parameters in a neural network (getting joint distributions for each parameter in the network).

Now I imagine Bayesian Networks are limited in practice due to intractable integrals and computation but haven’t gotten this far down the rabbit hole yet. Before I do, has anyone here worked with them? If so, what would be some key points and advice you’d like to give? I’m really trying to understand if they’re any better than GPs or if there is a frequenting style approach of getting a good uncertainty estimate that might be quicker than using a Bayesian approach.",2021-12-16 18:14:15
Modeling user selections of a product on a webpage,0,rhtqxn,https://www.reddit.com/r/datascience/comments/rhtqxn/modeling_user_selections_of_a_product_on_a_webpage/,0,1639670553.0,"I’m trying to model a binary outcome, whether a person chooses a particular product offering or not. 

We list like 10 of products ranked by cost in ascending order that are similar (think something like subscriptions to a gym) each one has a gym name, monthly cost, and subscription length (month to month, 12 months, 24 months etc)

How should I set up my feature? Should I have columns for every subscription plan and characterstic? Gym_1, cost_1, length_1, gym_2, cost_2, length_2

At this moment I’m more concerned about the product characteristics, I know user characteristics and demographics will probably be better features but I’ll add those in later

I’ve been in the industry for a while but I wanted to revisit a seemingly simple and common but actually complex and nuanced problem

I should add that this is a imbalanced dataset, as many of you know online conversions are heavily imbalanced",2021-12-16 18:02:33
Advanced Online Coding Bootcamp (SQL),0,rhtan2,https://www.reddit.com/r/datascience/comments/rhtan2/advanced_online_coding_bootcamp_sql/,4,1639669182.0,"I have an upcoming ""data science"" technical interview, being described as:

""Your interviewer will share a HackerRank with you and you will be working through questions related to data manipulation (mostly SQL). Ideally, the goal is to create code that can actually run but minor syntax issues can be looked over. If it doesn’t run, pseudo code will also work to get the idea across. Your interview will mainly focus on data munging/wrangling, as well as SQL syntax.""

I'm pretty advanced in SQL, I use it frequently for hours in my current job, but I've had trouble passing these technical interviews in the past. Can anyone recommend an ""Online Coding Course/Bootcamp"" for SQL that is more geared towards these HackerRank interview assessments?",2021-12-16 17:39:42
What are some Python books equivalent of Hadley Wickham’s R for Data Science?,132,rhncxj,https://www.reddit.com/r/datascience/comments/rhncxj/what_are_some_python_books_equivalent_of_hadley/,38,1639647659.0,"I’m mostly a R user, although a new job will require me to be a Pythonista!

For the most part, I can find some R-Python cheatsheet (for example R tidy verses to Python’s Panda equivalent).

But it feels a bit unnatural because it feels more like a R to Python translation exercise instead of thinking in Python.

Hadley Wickham’s R for Data Science is my favorite book that helps me to think in R to tackle data problems (basic transformation, data wrangling, data visualization, data modeling, etc)

I think I would benefit the same if you the Pythonistas can recommend me some good books I can follow through so that I can think in Python.

Thank you 🙏🏻!",2021-12-16 11:40:59
"Data scientists that have moved into a more ""businessy"" role: what do you do and do you find your DS skills useful/transferable in. your role? Do you wish to eventually move back into data science?",10,rhij3q,https://www.reddit.com/r/datascience/comments/rhij3q/data_scientists_that_have_moved_into_a_more/,18,1639629081.0,,2021-12-16 06:31:21
How to group similar curve shapes together?,5,rheni8,https://www.reddit.com/r/datascience/comments/rheni8/how_to_group_similar_curve_shapes_together/,6,1639617009.0,"Hello, so I have encountered a problem where I somehow need to find a way to group separate curves from different plots together within a dataset to see which curves appear most similar. I will explain this problem in more detail.

I have a dataset with a dataframe that looks like this:

                 Date          ID     Value 
    ----------------------------------------
    0      2018-11-14 11:30     1        43
    1      2018-11-14 11:31     1        43
    2      2018-11-14 11:32     1        44
    3      2018-11-14 11:33     1        43
        ... 
    134    2018-11-14 12:22     2        44
    135    2018-11-14 12:23     2        46
    136    2018-11-14 12:24     2        49
    137    2018-11-14 12:25     2        51 
        ... 
    245    2019-11-14 14:11     3        44
    246    2019-11-14 14:12     3        42
    247    2019-11-14 14:13     3        39
    248    2019-11-12 14:14     3        39
        ...
    356    2019-11-14 15:19     4        37
    357    2019-11-14 15:20     4        37
    358    2019-11-14 15:21     4        36
    359    2019-11-14 15:22     4        40
    ...

This toy dataset shows water consumption values for a single household, with a data-providing water meter attached to the water line. Now, this dataset shows us at different timestamps throughout a day, in chronological order, how much water is being used per each use of water. The ""ID"" column attaches assigns a unique ID to separate each water use event. The ""Value"" column shows a value attributed to the rate of water being used at that timestamp (just made up here). A key assumption this conceptual example relies is that there can only be one water use event at a time.

And so, through python, I group this dataset by ""ID"" and create a separate plot for each ID, as a data subset. And so I have a plot of data showing a curve of water use rate ""Value"" over the course of time duration for each water use event, last anywhere from say 5 minutes to 15 minutes. Now, some of these curves might actually be represent someone washing their hands, or washing produce in the sink, or taking a shower, etc., but we don't actually know! Still, we can hypothesize that each of these types of water use events will be roughly categorized by curves that look similar, when you have a high enough sample size of water use events to analyze. And so first I want to group all like curves/subsets together, such as to say ""hmmm ok these two curves go up a bit, then waaaay up, then flatten out, then go up a bit more, and then shoot down, yeah these two both look like that. And this is waaay different looking than the shape of that other curve, that one must belong to a different group. And so from this I would create this dataframe:

                 Date          ID     Value     Curve_Shape
    --------------------------------------------------------
    0      2018-11-14 11:30     1        43               1
    1      2018-11-14 11:31     1        43               1    
    2      2018-11-14 11:32     1        44               1
    3      2018-11-14 11:33     1        43               1
        ...                       
    134    2018-11-14 12:22     2        44               2
    135    2018-11-14 12:23     2        46               2
    136    2018-11-14 12:24     2        49               2
    137    2018-11-14 12:25     2        51               2 
        ...                              
    245    2019-11-14 14:11     3        44               1
    246    2019-11-14 14:12     3        42               1
    247    2019-11-14 14:13     3        39               1
    248    2019-11-12 14:14     3        39               1
        ...
    356    2019-11-14 15:19     4        37               2
    357    2019-11-14 15:20     4        37               2
    358    2019-11-14 15:21     4        36               2
    359    2019-11-14 15:22     4        40               2
    ...

And so we can see this new column ""Curve\_Shape"" attributes an ID number to curves that resemble one another, where all water use events with ""Curve\_Shape"" 1 resemble one another, and all water use events with ""Curve\_Shape"" 2 resemble one another. That is where I want to get to. And so my question is, how can I use machine learning or any other data science method to group my data subsets (water use event IDs) by what their corresponding curve looks like? I am thinking I would need some sort of machine learning alogrithm to discern which curves follow similar patterns. I would appreciate any guidance on this problem, thank you!",2021-12-16 03:10:09
Being honest with yourself about why you want to be in DS is good for your career growth and mental health,72,rhbves,https://www.reddit.com/r/datascience/comments/rhbves/being_honest_with_yourself_about_why_you_want_to/,27,1639609006.0,"In this post, I want to share why I got into data science and use it as a platform to solicit others' stories. It's taken me three roles in the industry to really zero in on why I'm here, but I finally stumbled on it: *I like solving puzzles, it's fun to me*. 

Your reason might be you want a dependably high salary for the remainder of your working career, you want the prestige/attention that the role garners in the media, you want to anchor yourself to a growth technology and feel that any combination of stats/ML/AI isn't going anywhere, or maybe you just want a job where you can put your headphones on, code, and be left alone for about 50% of the day. There's really no wrong answer, but I think knowing your motivation for entering and/or staying in the field is vital to avoid burnout. 

For me, every one of my three roles has been vastly different. I've trained and deployed models, who were architected by other folks in the org (J1), used transfer learning to build an NLP-based product feature (J2), and most recently, I use stats and experimentation to optimize product-market fit (J3.) Frankly, I found training, deployment, and transfer learning to be a little unfulfilling. It was the hottest area of the new hot thing, and...I felt pretty empty. 

It wasn't until job3 that I realized that I like solving puzzles. Understanding what users want, how they interact with the platform, and why they keep coming back-- it's a really fun puzzle to me! 

Anyway, the DS space is freaking massive, it spans from business analyst to AI researcher. If you're not honest with yourself about what's fun to you, you could spend a few years chasing the hottest thing only to realize that it was a little underwhelming, just another 9-to-5. 

What's your story-- Why did you come to DS, have your motivations evolved over time, and what's the next step for you?",2021-12-16 00:56:46
Thanks to Everyone on this Sub,63,rh6ccg,https://www.reddit.com/r/datascience/comments/rh6ccg/thanks_to_everyone_on_this_sub/,5,1639594397.0,"Just wanted to give a big thanks to everyone that posts guides, walkthroughs, career advice, and other resources on this sub. I’ve slowly been collating the information this sub provides and applying it to my career search. With that said I’m really happy to say that after serval rounds of grueling interviews (and many that I flat out failed) I’ve recently gotten an MLE position! I’m really excited to kick off my career and I could not have gotten as far as I did without the resources you all provide! 


To everyone that is struggling and really stressed about jobs, you can get through it! It’s a process though and it’s not easy, but don’t give up. I always say that you should be the absolute last person to lose faith in yourself when it comes to what you want to achieve!",2021-12-15 20:53:17
Marketing Mix Modelling,5,rh5wnp,https://www.reddit.com/r/datascience/comments/rh5wnp/marketing_mix_modelling/,1,1639593251.0,"Hey there,
I am currently working on a Marketing Mix Model.
I am having doubts on my modelling approach. 
I didn't find any sources which fit my idea and I want to know if my approach makes sense to you or what could be the caveats with it.

I have ad spend data for two marketing channels for multiple years.
I have around 30 different entities with the according revenue. 
I know that this is panel data. 

My initial approach is to aggregate the revenue over all entities and model this with the ad spend for the two channels for each entity. This gives me 60 variables measuring the ad spend for each channel in each entity for each point in time. I cannot aggregate the ad spend over the entities as I need to know how each channel in each entity contributes to the total revenue. 
A problem with this approach could be that especially for smaller entities their effect on the total revenue could get lost in the noise due to aggregation. 


Other approaches could be to train a model for each entity on it own but some entities are really small and don't have much variance in their ad spend which could be a problem. Also this is tedious as I have to evaluate many models.

Other than that I should probably look into Panel Regression/ Linear Mixed Models.

What do you guys think? 
How did or would you implement a model with data like this?",2021-12-15 20:34:11
How do you organize your DS machine to reduce clutter,3,rh41qa,https://www.reddit.com/r/datascience/comments/rh41qa/how_do_you_organize_your_ds_machine_to_reduce/,4,1639588511.0,"So clutter becomes part of a fast moving industry and when I think about this I get a quote from Demming ""Make quality part of the process"" which basically means clean as you go.

This sounds great but over time there is more and more files, folders of info I need to analyze, and my personal archive of data, files, documents, research is somewhere in the 15Tb region which is connected to 260+ GitHub repos. My research library is 1,000+ eBooks and I don't even want to think about my music/video/photo archive right now. 

Now all client data goes back to them, gets deleted or just stays with them, this is data I found, sourced and used for research to work on models that I delivered and got to keep the code but its a hydra that needs a leash.

How do you organize code that is in multiple stages, yet git is a big help, but what about the data associated to each project. Do you store that in one central SQL server or break it up... and saved where?

How long do you keep training data you were sent by a client, how do you document your process in some kind of [README.md](https://README.md) file or a central index somewhere.

I've asked a few friends and waiting to hear back but I thought lets check with Reddit people.

How much data do you have, how many different repo's do you interact with and how do you keep it all organized?",2021-12-15 19:15:11
Multiple Regression in ~40 Petabytes of high dimensional space,3,rh2ubj,https://www.reddit.com/r/datascience/comments/rh2ubj/multiple_regression_in_40_petabytes_of_high/,19,1639585364.0,"A few months ago I had a meeting that I never expected to actually happen, where an employee at a client meeting brought up ""how hard can it be"" to just start running Machine Learning against their databases one at a time and that the ""IT"" department just wasn't wanting to put in the work.

I asked him if he was willing to put in the work for a generalized solution and said ok ""I'll send you a paper, please read up on that and report back what you find"" the following week I sent him this paper. [https://link.springer.com/article/10.1007/s11222-019-09914-9#code-and-data-availability](https://link.springer.com/article/10.1007/s11222-019-09914-9#code-and-data-availability) At subsequent meeting he isn't as verbose or hostile against the IT department for being lazy. 

My initial reply was to ask how much data all three of their primary data centers had collected, including the archives, the Oracle Cloud, Google Cloud, both of the failed Azure setups and including their growing AWS presence. How much data in total they had, when was it acquired, how was it cleaned, how often was it used in analysis each month and he looked at me with the ""me not know what you say"" look I see way to often.

So the answer after much back and forth, checking totals, provisioned vs in use and inclusive of non empty folders only is somewhere north of 34.12 Petabytes and somewhere south of 61.3 Petabytes of data. Ok there were little to no data sanitation records, they had about 7% of it had been documented as ever having been analyzed. This data is somewhere between a few hours old and they have information going back to the 1930's in a massive micro-fiche database, then news papers before that and accounting records to the 1700's.

I had this joke in my head about, lets run a regression, of the regression. Then it evolved into turtles all the way down but I kept digging and maybe found something, maybe.

Looking at that much data is just to quote Judith Viorst's book ""the Terrible, Horrible, No Good, Very Bad Day"" series of nearly impossible tasks like shoveling sand at the beach to sort it by shape or color etc. There is just too much to run any type of analysis without rethinking the problem which lead me to a few papers I read years ago. This cannot be a new problem, in fact as NTT data has also found its a forever problem. Ok this is starting to sound more fun.

Then I found this paper and somewhere past section 3.1 I can't follow the logic or math to understand what they are saying [http://wrap.warwick.ac.uk/112513/7/WRAP-multiple-influential-point-detection-regression-spaces-Leng-2019.pdf](http://wrap.warwick.ac.uk/112513/7/WRAP-multiple-influential-point-detection-regression-spaces-Leng-2019.pdf)

Question: On page 386 of the journal article when they say ""leave-one-out"" that refers to a concept like dropout for training ML where you leave holes in your backtesting to see if the model catches itself and doesn't make the error or makes the error and needs fixing?

Has anyone here mucked through this much data before while looking for?

1. Correlation to customer satisfaction that leads to additional purchase
2. Correlation of a customer purchase that leads to said customer referring another
3. Since an aspect of this company is publicly held they are looking for impacts on market price
4. If we go down this road, what can I advise or recommend we do while we are (potentially) looking at this much data. I'm thinking some sort of meta tagging system that would be like time\_series, purchase, market\_segment, net\_promoter\_score, lifetime\_revenue, and so on.

My current plan is to recommend they start by classifying all of the data, one folder or one table of each database at a time programatically with an ensemble of methods. Then expand from there, but there has to be a better method than boiling the ocean.

So this is a medium sized planet of customer time series purchase analysis but while I've done stuff that spans centuries and countries with maybe 30 + variables this is a new species of data analysis.",2021-12-15 18:22:44
I’ve made a search engine with 5000+ quality data science repositories to help you save time on your data science projects!,801,rh22z9,https://www.reddit.com/r/datascience/comments/rh22z9/ive_made_a_search_engine_with_5000_quality_data/,25,1639583379.0,"**Link to the website:** [**https://gitsearcher.com/**](https://gitsearcher.com/)

I’ve been working in data science for 15+ years, and over the years, I’ve found so many awesome data science GitHub repositories, so I created a site to make it easy to explore the best ones. 

The site has more than 5k resources, for 60+ languages (but mostly Python, R & C++), in 90+ categories, and it will allow you to: 

* Have access to detailed stats about each repository (commits, number of contributors, number of stars, etc.)
* Filter by language, topic, repository type and more to find the repositories that match your needs. 

Hope it helps! Let me know if you have any feedback on the website.  ",2021-12-15 17:49:39
Probabilistic Alternative to the Gower Distance,1,rh1xvp,https://www.reddit.com/r/datascience/comments/rh1xvp/probabilistic_alternative_to_the_gower_distance/,3,1639582979.0,"Hello,


The Gower distance, or Gower similarity coefficient, is the main recommendation when dealing with mixed data attributes (numerical and categorical).
The following note proposes an alternative that relies on the distance between the probabilities of the attribute values. The idea is relatively simple: has it been tried before? And if yes, what are its main drawbacks?
It seems that such a probabilistic distance should have some advantage over the Gower distance: less outlier distortions and natural extension to ordinal types.

https://www.researchgate.net/publication/357051016_Probabilistic_Alternative_to_the_Gower_Distance_A_Note_on_Deodata_Predictors


Thank you",2021-12-15 17:42:59
I got a data science job interview that I am under-qualified for. What can I do in one month to maximize my chances?,385,rgyy8m,https://www.reddit.com/r/datascience/comments/rgyy8m/i_got_a_data_science_job_interview_that_i_am/,83,1639574430.0,"I just got a job interview for a data science position that requires data science experience. The position offers double my current salary but asks for experience that I lack. If I can get it, I'll be over the moon. Luckily, because of the holidays, I was given an interview in mid-January and was wondering if there is anything I can do in a month to maximize my chances of getting it.

To provide some context, I am a marketing data analyst (with less than a year of experience in the industry) who just completed a 6-month data science course. I learned a lot from the course, but don't have enough practical experience. This position asks for experience in two ML algorithms  (boosting, clustering). I am willing to grind for the next month if it meant that my chances of getting this position would increase. What can be done?

Edit: For those who think that I ""faked it"", I never wrote anything that isn't accurate on my resume. It's the first interview I've got after many rejections. Just because someone gets an interview for a position that requires more experience, it doesn't mean that they lied in their application.

Edit #2: I'm thankful for all the support I'm getting from this community. I'll definitely be going through those and working through them. As mentioned, even if I don't get the position, at least I would have gained a decent amount of experience that would help me in future opportunities! Thank you, everyone. 

Edit #3: I didn’t get it. Thanks for your help everyone.",2021-12-15 15:20:30
More experienced data scientists: how important is the model deployment aspect for you?,16,rgvsmh,https://www.reddit.com/r/datascience/comments/rgvsmh/more_experienced_data_scientists_how_important_is/,39,1639562784.0,"Hey everyone,

so I recently got rejected after a pretty long take home (10 days) for some tech unicorn, which sucks of course because I'm doing this next to work and my own research, but hey things can't always work out.

I have 4 YOE and a research background in time series and econometrics. I've worked with some NLP + classification tasks, but would not consider myself an expert here. Since everything is machine learning nowadays I'm brushing up my knowledge currently. I'm studying ISLR, and more advanced literature if I want to dig deeper, but I'm wondering if that's the right move atm. I don't have a lot of time so I have to think carefully about my priorities :/

The feedback I received from the company got me wondering a bit. I'm working as a data scientist in one of the big 4 companies (but you know, these auditing companies, not tech). For several reasons I would like to switch into a more tech oriented company.

In my job I've been exposed to a pretty wide range of projects, everything from explaining regressions to Karen from accounting to providing the model component for large projects that are deployed in some cloud and get out to the customers.

However, I usually understood my role to be more focussed on the actual modeling part, i.e. we have some data source and we have a problem that we want to solve, what's the best model and what insights can it provide? And then usually I team up with engineering and they would make sure this model is deployed e.g. in Kubernetes.

This specific position was for a senior data scientist and the reason why they rejected me is that they weren't convinced of my software engineering skills and thought that my assignment indicated a lack of experience in putting things to production. Fair enough, whatever.

The good thing about being in a consultancy is that I can easily find new projects if I want to develop certain skills, but now I'm wondering if those are very role specific requirements or if I misunderstood my role so far / the role that senior data scientists have. While it's of course always a good idea to learn new skills, they also mean project and time commitments in which I can't focus on other skills.

I would be very happy to learn how important the deployment component for you guys on the more experienced side usually is. Do you work in teams with engineering, do you actually handle it yourself and are part of the production team? Ofc this can't be generalized but hoping for some discussions and experiences anyway!",2021-12-15 12:06:24
What are good alternatives to zip files when working with large online image datasets?,3,rge2ru,https://www.reddit.com/r/datascience/comments/rge2ru/what_are_good_alternatives_to_zip_files_when/,3,1639507146.0,"We are hosting image datasets on our [platform](https://labelflow.ai) and until recently the stored datasets were relatively small (several hundreds of images, few GB) so we only offered the possibility to export zip files containing images and labels in the COCO or YOLO format. As the average size of the datasets is growing, it's not convenient anymore to export a zip.

What solution have you used that you like as a data scientist when working with large datasets? Any standard python API to access the data? Other solution? If anyone has used [https://github.com/activeloopai/Hub](https://github.com/activeloopai/Hub) or other similar API I'd be interested to hear your experience working with it!

Thanks!",2021-12-14 20:39:06
What industry is for me? Bayesian Stats. Phd,15,rgdtfq,https://www.reddit.com/r/datascience/comments/rgdtfq/what_industry_is_for_me_bayesian_stats_phd/,25,1639506460.0,"As the title says. I have complained about my situation in a different thread and it has only worsened since then. I want to change jobs and possible industries. I did a PhD (in Germany) in Bayesian applied methodology and need some guidance on where my profile could fit. I know e.g. pharma hires statisticians but the thing is that I somewhat like the data sciency aspects of my current role (but not much more) and wonder if it is possible to find a career that connects these things ((Bayesian) Applied Statistics and Data Science). One problem that comes to mind is that while I do program a lot  (in R) and nowadays in Python, I do not really have this SWE perspective many potential interviewers may ask for. Is there hope or should I just stick to the classical statistcs industries?

Thanks a lot.",2021-12-14 20:27:40
"Do you ever get ""EDA block"" (like writers block, but for EDA?)",32,rgd2nx,https://www.reddit.com/r/datascience/comments/rgd2nx/do_you_ever_get_eda_block_like_writers_block_but/,14,1639504508.0,"I'm not sure if i'm the only one that has this, but when given the task to do EDA on a large dataset (purpose is to understand and explore the data, and not necessialry to look for 1 or 2 specific things), I get this anxiety and uncomfortable feeling and it is hard to get started or get in the flow.

I liken it to a writers block where you stare at a blank piece of paper and dont know what to write down. For me, it's a blank excel sheet with a lot of data ready to explore....

&#x200B;

any thoughts on how to overcome?",2021-12-14 19:55:08
A piece of advice I wish I gave myself before going into Data Science.,1007,rgb80b,https://www.reddit.com/r/datascience/comments/rgb80b/a_piece_of_advice_i_wish_i_gave_myself_before/,115,1639499404.0," And here it is: you will not have everything, so don’t even try.  


You can’t have a deep understanding of every Data Science field. Either have a shallow knowledge of many disciplines (consultant), or specialize in one or two (specialist). Time is not infinite.  


You can’t do practical Data Science, and discover new methods at the same time. Either you solve existing problems using existing tools, or you spend years developing a new one. Time is not infinite.  


You can’t work on many projects concurrently. You have only so much attention span, and so much free time you use to think about solutions. Again, time is not infinite.",2021-12-14 18:30:04
Improving xgb prediction times on a single core,4,rg6wmf,https://www.reddit.com/r/datascience/comments/rg6wmf/improving_xgb_prediction_times_on_a_single_core/,21,1639486582.0,"Hi All, wondering if anyone has any tips for speeding up xgboost predictions in prod without resorting to more resources. I'm deploying R containers containing large xgb models (around 35Mb, 1000 trees), and don't have the budget to just double resources as we've a lot of these models running. The calls are currently taking >100ms for a single row of data (\~40 cols) and becoming a major bottleneck in our calls to prod.

Any suggestions on how this could be tackled? Are different algorithms (lightgbm or similar) likely to offer better results? I'm struggling to reduce the size of the xgb due to accuracy tradeoffs.",2021-12-14 14:56:22
solution for visualizing implementation / data sources,0,rg4xiy,https://www.reddit.com/r/datascience/comments/rg4xiy/solution_for_visualizing_implementation_data/,3,1639478864.0,"Hi everyone, i am data integration process. Basically preparing all events and customer data for CDP collection, parameters and ids needs to have consistent across all events, product feeds, customer attributes. 

I am doing all of that in excel, but my question is, do you know any better solution for this? i have idea of something like printscreen my website, and add arrows to menu - there we will track clicks, add arrow to footer - there we will track emails ... etc.

Any better solution for this? or any tool for something like this? this is something like data modeling, but data is only from one website, maybe from offline store in future (not important)",2021-12-14 12:47:44
AI/DS in traditional industries,1,rg37br,https://www.reddit.com/r/datascience/comments/rg37br/aids_in_traditional_industries/,5,1639471416.0,"I have been working in the field of AI/DS for a while and in my current company we try to focus on the more traditional industries like construction, infrastructure, maintenance, water treatment, etc. We belief there must be value in applying modern AI/DS techniques in these business processes.
After several years I get the feeling these traditional industries are pretty efficient, and the gain margins are very thin. Does anyone has a different experience with this? Can you elaborate?",2021-12-14 10:43:36
Minitab is expensive garbage with no use outside of academia.,223,rftt5a,https://www.reddit.com/r/datascience/comments/rftt5a/minitab_is_expensive_garbage_with_no_use_outside/,132,1639439414.0,"There are a dozen different tools that do every single function that Minitab does and yet we had to pay money for the software that we used in five assignments.

The instructions and the version of the professor wanted us to have was about four years out of date from the instructions that Minitab gave us for their own software.

Then once we figured out how to access the software all of the Mac users in the class couldn’t access it so they had to use a different version as a web version that didn’t have all of the same functionality and different menus.

It taught us nothing more than how to point and click different menus and it wasn’t open source so we couldn’t integrate it, the output was sketch and we couldn’t sync this up with changed data.

Does anybody actually use Minitab in the real world what purpose does this serve other than to teach people poor menu design choices in stats class in college?",2021-12-14 01:50:14
"How can one help out with data cleaning, in a charitable way?",3,rftpt5,https://www.reddit.com/r/datascience/comments/rftpt5/how_can_one_help_out_with_data_cleaning_in_a/,1,1639439139.0,,2021-12-14 01:45:39
"Why isn’t linear programming more popular (or, viable) in analytics and business intelligence?",31,rftlpb,https://www.reddit.com/r/datascience/comments/rftlpb/why_isnt_linear_programming_more_popular_or/,45,1639438803.0,"I know this question isn’t specifically related to data science (perhaps in the broad term), but for those coming from OR, why hasn’t there been a rise in linear programming and optimization as it relates to analytics and BI? Is this more in line with decision science?",2021-12-14 01:40:03
"Compensation negotiations stalled, need advice.",1,rfp95o,https://www.reddit.com/r/datascience/comments/rfp95o/compensation_negotiations_stalled_need_advice/,15,1639427350.0,"I recently started a brief negotiation for a salary increase after being offered a 6% increase. I believed strongly that I am deserving of more but management maintains that I haven't had enough of an impact to justify the increases I requested.

Instead of my request for a 60% increase, that is appropriate for title and YoE, along with a doubling of ownership, I received a doubling of the offered raise with no change in ownership. My manager thinks in 6 months after our Series A funding, we can re-evaluate my compensation. As a result, I requested a written contract with certain goals as listed by my manager that if I meet, I will get a more appropriate compensation, possibly title change. We still have to agree on the compensation but it's nearly a guarantee I will meet every goal within the next 2.5 months without any rushing.

I'm feeling jerked around a bit and that the founders a being a bit stingy. The employee ownership pool is capped at 5% for all future employees and they seem unwilling to open that up anymore and don't want to give me anymore than I have now.

I should probably negotiate the terms of the contract first before deciding what to do but I'm feeling pretty undervalued compared to my responsibilities. I understand it's a startup but I think this is setting a bad precedent they won't value their engineers in the future.

If I were on the outside looking in I'd probably tell myself to start looking for a job and I'm being taken advantage of but idk. Maybe I'm just being a whiny child.

EDIT: Failed to include compensation and title as mentioned by /u/BoostedGradient. Nice name btw.

Title: Data Scientist in name only. I'm more appropriately designated an ML Engineer
Compensation: $80k + 45k shares amounting to 0.38% ownership at $0.17 a share
Compensation after raise will be about $90k, no increase in ownership
YoE: About 2.5 years experience, previous employment in industrial analytics as an ML Engineer

Requested: $130k with 0.8% ownership,  I knew they couldn't match this but I was really expecting to get at least $100k in return.

EDIT: All include some of my responsibilities for more context.

I am employee #1 and I have transitioned their matlab codebase to python and am In the process of setting up the ML pipeline. I am developing the primary models that are used in the only current product. I am building the official internal API for use by future analysts/data scientists/ml engineers. I am contributing significantly to the data pipeline in general and specific to modeling. I played a key analytics and model development role in the only revenue generating endeavor so far. I am planning and researching at least 2 future projects. I am active in 6 repositories simultaneously stepping each forward incrementally. There are only 2 other engineers, a backend and front end dev.",2021-12-13 22:29:10
How to evaluate on-line performance of a lead ranking model,2,rfp5h8,https://www.reddit.com/r/datascience/comments/rfp5h8/how_to_evaluate_online_performance_of_a_lead/,5,1639427083.0,"Hi everyone,

I’m considering building out a lead conversion model with the goal of ranking leads for our sales team. What I can’t quite wrap my head around is how I can make sure it’s working well? Since the leads will be ranked according to the probability to convert, how can we be sure someone didn’t convert due to getting more attention at the top of the list? 

Do any of you have any experience with removing this element of bias? Any help would be appreciated!",2021-12-13 22:24:43
Python Logo Candy (wallpaper download link in the comments),78,rfoujp,https://i.redd.it/zemxboread581.png,11,1639426298.0,,2021-12-13 22:11:38
Job offer in tech vs promotion in current role,5,rfn1bb,https://www.reddit.com/r/datascience/comments/rfn1bb/job_offer_in_tech_vs_promotion_in_current_role/,8,1639421625.0,"Hi All, I've a dilemma on which way to go,  : 

current role: only technical person on a business team, doing a lot of building and deploying models on structured data. The role is full-stack which is great but also very low-tech. we're not using any cloud services except where we host our containers, everything else is done offline, on local machines, nothing but R and SQL, and there's a lot of repetition in the models we're building (churn,ltv models).

offered role: full stack DS within a modern tech stack, working across whole business on a variety of structured/unstructed data. I'd be on a big team of DS and MLengineers so lots of knowledge sharing etc. the company seems to be in the sweet spot between startup and massive cog-in-the-machine size, with lots of new interesting projects to work on.  Cant find much info in terms of work life balance etc. 

I'm being offered a promotion in my current role which would add a bit more responsibility, but overall would leave me with a big pay rise and all i could ask for in terms of work life balance. I get on with the team and don't dislike anything about the company. The tech company is offering a matching salary, but with all the unknowns in terms of culture. 

My main reason for thinking I should leave is that  my cv is becoming far too narrow, and essentially I'm being left behind as DS and becoming more of a domain expert with no breadth in terms of tools and skills. Essentially if I don't leave now I'm worried I never will, and the technical side is what drives me most in my work. 

Any thoughts welcome, especially if you've faced this problem in the past. Sorry that was some rant..",2021-12-13 20:53:45
What estimator is the fastest to use in RFECV for feature selection?,0,rfg103,https://www.reddit.com/r/datascience/comments/rfg103/what_estimator_is_the_fastest_to_use_in_rfecv_for/,2,1639403025.0,"I wanna ask since I've been using Random Forest Classifier and SVC. I've been waiting for 12 hours now and it still has not been rendered. :( A little help, please",2021-12-13 15:43:45
Regarding salaries in and out of the US,102,rffm97,https://www.reddit.com/r/datascience/comments/rffm97/regarding_salaries_in_and_out_of_the_us/,146,1639401740.0,"Hey there fellow redditors,

So I have been monitoring and even participating in the [2021 Salary Sharing Report](https://www.reddit.com/r/datascience/comments/re46xx/official_2021_end_of_year_salary_sharing_thread/) thread and as a Europe Data Scientist I gotta say that I am beyond impressed. Some more details there, but personally I moved from Spain to Switzerland because pay is good here (and love the country). Not to confuse, very happy with my lot, but in terms of salary it pales in comparaison to the US compensations that are circulating around.

I know that you guys got all the big tech HQs over there, but even in research labs a la DeepMind or Google/Meta/Apple that exist in Zürich the bang for your buck is not so hefty for what I take that will be a similar type of work.

So my intention with this thread is to spark some debate on the potential reasons for such a huge wage gap between the US and the rest of the world. Did some superficial scouting in Glassdoor and even in places like Hong Kong, Singapore, well-to-do EU countries and so on the pay is dim when compared.

Any ideas? Also, for non-US Data Scientists, feel free to share your experiences!!! I think that the job market is quite different there. I have read horror stories of folks with 100s of applications that got nothing and this has not been my or my colleagues' experience at all.",2021-12-13 15:22:20
How real is Burn Out in the data/BI profession? Two team members resigned on the spot due to being work overloaded and lack of representative compensation.,69,rffhew,https://www.reddit.com/r/datascience/comments/rffhew/how_real_is_burn_out_in_the_databi_profession_two/,22,1639401323.0,"How real is Burn Out in the BI profession? Two team members resigned on the spot due to being work overloaded and lack of representative compensation.

As usual companies are making money hand over fist while telling their employees there is no money. Mental health seems to be public lip service by them but in reality things are much worse inside.

Curious how you see things.",2021-12-13 15:15:23
Reusing data in meta-models,3,rfb1rw,https://www.reddit.com/r/datascience/comments/rfb1rw/reusing_data_in_metamodels/,5,1639384191.0,"I have a problem which I'll try and explain through a football (soccer) example..

Let's say I was predicting the results of a 5v5 game, the first thing I do is build 8 individual models for each player (one person is the goalkeeper) to predict how well they'll perform. 

I then want to take the performance predictions for each player (all 8 predictions), alongside some other team-based factors to create a meta-model which predicts the result of the game. 

The question I have is whether I can train both the meta-model & the individual models on the same data - or if I should train the individual models on one set, then use them to predict unseen data which is then used to train the meta-model? What I'm concerned about is whether the former technique would compound the overfitting? I can't seem to find any resources online dealing with the same problem.

**Note:** the reason I don't just train one model is because a) features going into the individual models are about the specific player, I wouldn't want certain ones interacting together across players b) the ""coach"" would want to see individual players performance predictions, as well as a game prediction

Any help at all is much appreciated, even if you don't know the answer fully!",2021-12-13 10:29:51
Best way of finding correlations with lag between 2D data,0,rf7o9d,https://www.reddit.com/r/datascience/comments/rf7o9d/best_way_of_finding_correlations_with_lag_between/,13,1639371578.0,"I made a post yesterday asking for help determining how to find relationships between two datasets, but didn't include enough useful information in the post.  I'll fix that issue here.

I have two datasets, one has data on the yearly change in ""Harshness Index"" - a measure of how difficult a place is to live in.  The other has data on the yearly change in human development index.  Both datasets have 1000 observations, each observation corresponding to a subnational region (ex: US states).  Each observation contains data on the yearly change from 1991 to 2019, for a total of 29 points of data per observation.

What I want to determine is the correlation between increase in Harshness Index and increase in Human Development Index.  I know that there will be some sort of time lag, although I am not certain how large that time lag is, and it is likely somewhat different for every region/observation.

My desired final output is a single value, corresponding to how much change in Harshness Index presumably affects change in HDI, as well as a measure of how significant this affect is.

&nbsp;

My biggest confusion is regarding what method exactly to use to compare the two datasets as a whole.  One method I looked into was using cross correlation, but that leaves me with a list of correlations for each observation, but beyond there there isn't much I can figure out what to do.

Edit:  [Snapshot of one dataset](https://imgur.com/a/SGZyhAm) the other dataset looks very similar.",2021-12-13 06:59:38
[Official] 2021 End of Year Salary Sharing Report,195,reyysx,https://www.reddit.com/r/datascience/comments/reyysx/official_2021_end_of_year_salary_sharing_report/,46,1639345084.0,"Was interested in scraping all the responses to the [\[Official\] 2021 End of Year Salary Sharing thread](https://www.reddit.com/r/datascience/comments/re46xx/official_2021_end_of_year_salary_sharing_thread/?utm_source=share&utm_medium=web2x&context=3) so I did.

**Check it out on Data Studio** [**here**](https://datastudio.google.com/reporting/658d6323-8389-4da0-8064-14b14d4fa6e2)**.**

There may be some errors here and there, I opted for fast and dirty with my scraping.

And thanks to [Zscore3](https://www.reddit.com/r/datascience/comments/re46xx/comment/ho6e5r8/?utm_source=share&utm_medium=web2x&context=3) for the spark:

>Please tell me someone's going to scrape this thread.

&#x200B;

[I tempt you with my bold purple gradient, don't resist.](https://preview.redd.it/h1147zpwk6581.png?width=2176&format=png&auto=webp&s=b41aeb26c4c401f8c4172390d5caa39398fda7f3)

**!! Update !!** \- implemented some changes based on the comments/feedback:

* Switched from GBP to USD currency (My bad!! I had to convert everything to a single currency so I just used what was familiar to me. )
* Included total comp figures - good shout!
* Included tenure figures
* Quality-controlled experience & tenure scrapes (de-coupling tenure from experience)
* Fixed an embarrassing error placing California in the UK 🤷‍♂️",2021-12-12 23:38:04
Choosing a group within a large company for intervention,0,rexlb9,https://www.reddit.com/r/datascience/comments/rexlb9/choosing_a_group_within_a_large_company_for/,14,1639341118.0,"Hey everybody! Got an applied statistics / data science question for you all. I have some ideas, but I want to see what people have to say. **The question here is specifically ""what statistical or analytical procedures would you use to choose what group to target for intervention?""** 

So we’ve got this dataset that shows diversity ratios - race and gender - for a big list of company teams at both employee level and manager level. We have data all the way down to the employee level. These teams are all different sizes, and we want to find a larger team to target for a diversity improvement intervention at the manager level. For each team, we have diversity data for hires, promotions, terminations, and headcount.

I’m curious what kind of statistical analysis you guys would do! Also wondering if there are any high quality resources you’d point me to for best practices.

Some additional detail:

Our goal is always to increase representation of either women or nonwhite employees at the manager level. Ultimately, the workforce should match the hiring pool from a demographic standpoint.

We are only targeting groups where representation of either women or nonwhite employees at the management level is below the proportion in the hiring pool. For this discussion, we can assume the hiring pool is the same as the US, demographically. However the truth is, at higher levels, the hiring pool is highly limited for each specific position.

Targeted interventions include:

a. Improve representation in the applicant pool for that role (Assume other talent acquisition related interventions are off the table for now).
b. Improve retention at employee level, with the aim of promoting some from the employee to manager level. Train for manager skill set.
c. Improve retention at manager level

We have buy in from the top, and can show effectiveness or non effectiveness of an intervention over time. However in this case I want to consider for which groups to do interventions.

Thanks for giving input!",2021-12-12 22:31:58
[D] Enhancing image classification with non-image features?,0,rexcby,https://www.reddit.com/r/datascience/comments/rexcby/d_enhancing_image_classification_with_nonimage/,5,1639340399.0,"I was working on a classification task in the past where I had to predict what birds could be heard in an audio clip. I did this by transforming the audio data into a spectrogram image and then built a CNN classification model.

An important thing to note is that the data set I had contained birds from all over the world and I had the location of where the audio clips were recorded at. Surely the location would have been valuable in predicting the class since not all species of birds can be found anywhere in the world.

I ended up running out of time on this project but pondered the idea of introducing non-image feature to my model after the convolution layer. What are your thoughts? Would this work? Would you do something differently? Would love to hear your thoughts!",2021-12-12 22:19:59
Is datascience usable for predicting stock/crypto prices?,0,rex7si,https://www.reddit.com/r/datascience/comments/rex7si/is_datascience_usable_for_predicting_stockcrypto/,32,1639340023.0,"I myself am interested in the stock/crypto market and this year I started learning data science (python). I have done some projects but nothing related to this interest. So I wondered if applying data science or an predictive model could be used for predicting stock/crypto prices or are those prices too news related and not really usable for prediction models? Would one of the two be the better option or should both/neither be used in this kind of way? If not an good project, what would be a better way to include the stock/crypto market in my data science learning process?

&#x200B;

edit: As some of you have said this wasn't an great idea, I was mostly looking into combining datascience with the stock/crypto market and price predictions really isn't the way to do it. Either way not looking to put the money in but are just looking to learn. If someone would know a related project, I am open to sugestions.",2021-12-12 22:13:43
Simple question: how to use lagged target variable as feature in regression problems?,9,reuqjs,https://www.reddit.com/r/datascience/comments/reuqjs/simple_question_how_to_use_lagged_target_variable/,10,1639333002.0,"This is probably a stupid question, apologies if it’s been asked before.

How can a lagged target feature I.e the value of the target yesterday or a rolling average ie the average of the past 7 days, be used as a feature to predict a value?

For instance, in predicting 14 days into the future, we won’t have yesterday’s value for the 13 days. Or if we use train test split, we will contain actual information of the target in our test, so it will overestimate accuracy?

Just getting started in ML, so I’ve probably misunderstood something!

Thanks for any help!",2021-12-12 20:16:42
Creating a map of multiple isochrones (distance traveled in given time from given point)?,5,reqgw3,https://www.reddit.com/r/datascience/comments/reqgw3/creating_a_map_of_multiple_isochrones_distance/,2,1639320538.0,"
Does anyone have any resources or ideas on the best way to calculate and plot multiple isochrones on a map (I’m talking around 500 points) 

What I’ve been following so far has been quite slow, so I’m not sure if it’s just going to be an inherently slow process, or if there are better ways of doing it.

I do want to do it entirely in python from scratch.

Here’s some links of the kind of things I’ve been recreating.

https://towardsdatascience.com/how-to-calculate-travel-time-for-any-location-in-the-world-56ce639511f

https://geoffboeing.com/2017/08/isochrone-maps-osmnx-python/#comments

Thanks for any help!",2021-12-12 16:48:58
How bad does it look to MS out of a phd program,0,reqffe,https://www.reddit.com/r/datascience/comments/reqffe/how_bad_does_it_look_to_ms_out_of_a_phd_program/,43,1639320408.0,"

Third year stats undergrad who wants to go to an MS stats program after college. I don’t have the ability to pay for it myself, so ideally I want to get a funded MS program. The issue is, 70% of the schools on my list just do not provide funding for an MS program. The alternative I have heard of was to apply to the phd programs, and then master out of them after 2 years. While I have heard of people doing this, I don’t know if this looks good, or if it is burning bridges and breaking a connection with professors. What do you all think? Anyone who mastered out, did things go okay? How realistic is it to get a funded MS anyway?",2021-12-12 16:46:48
Am I too old to do this?,0,reo3gd,https://www.reddit.com/r/datascience/comments/reo3gd/am_i_too_old_to_do_this/,30,1639312222.0,"This may be a bit longer, but maybe someone will get through it and give me some useful advice, because I am pretty desperate at the moment.

When I was in high school, I was good at everything (science, math, languages... ) and since all my parents ever told me was ""get good grades and everything will be OK in life"" I never bothered much with questions such as ""What will I do in life?"" or ""What will my future be like?"" as a teenager. Graduation came quickly and suddenly I had a ""full"" week to decide what college I was going to apply for. 

Since the areas I was best at were science, mathematics and computer science I eventually decided to study nuclear engineering abroad. At the time it felt like a great decision. I would learn more about science, utilize my love of math and coding and I would be able to say that I am a theoretical physicist (The Big Bang Theory just started airing and I certainly identified with the concept). 

I feel this has been the biggest mistake of my life. What I didn't know was that the university I applied for has a 5% graduation rate. Meaning that out of 300 people that enroll no more than 15 manage to get their masters (it was 12 people that actually managed to finish in my year). I was struggling with every subject except mathematics which I found easy compared to other physics subjects. 

Despite all of this I was hanging on for 3 years. The last subject I needed to get through the undergraduate program was object oriented programming (funny that it was actually programming not math nor physics that sealed my fate). The instructor was notorious for failing people for the most ridiculous details. After I failed the exam twice (you had 3 tries) by a very narrow margin, I became very suspicious to the nature of the tasks. Not only they were testing some concepts that were never discussed in a classroom, but also the time and complexity seemed completely out of whack even for this university's standard. After an afternoon of googling  I learned why, the tasks the teacher was giving us were exactly the same tasks that were featured in a doctorate programming competition. I knew this was unfair, but I had a plan. All the assignments from the previous years (there were about 20 of them) also had a very detailed solution. So for the next two weeks I learned and understood all of those. 

The time of my last try for the exam came and for the first time I felt truly ready. When I saw the assignment I could not do anything but smile, it was one of those I had studied. I finished in record time and I felt I nailed everything, even the bonus questions. Getting through the oral part of the exam was supposed to be a breeze, you only discuss your solution and why you chose it. The next day only 2 people out of 30 that took the exam passed and I was sure I was going to be the third. The teacher told me to sit and then he told me we were not going to discuss my test because it was obvious that I had cheated. Apparently nobody had ever scored so highly, so it is the obvious conclusion for someone that had failed the the exam before. I tried to explain what happened but the teacher did not listen and told me to get out. He also said he would tell other teachers of me, so they would be sure to be extra strict with me in the future. This broke me, I never felt so wronged in my life.

So this was the day I dropped out of college. I managed to find a job as an English teacher (I do not know how exactly but over the years of reading books, watching films and playing games I managed to get a relatively high English level despite not being a native English speaker). Two years went by in a flash and I couldn't feel anything but regret that I could not live up to my potential. I made a decision that as a 25 year old I was going to try to finish college. I knew what my strengths are and what I want to do in the future at this point. I applied for another university for ""applied mathematics and statics"". It took 5 years but I managed to get through it. So at this point I had a masters degree in mathematics with the focus on data analysis (by the way I was the only person who managed to finish in my year, the school was still really hard, but at least fair). 

When I started to look for a job as a junior data analyst, covid hit. People were getting laid of one after another, lockdown after lockdown and paired with some unexpected health problems of mine (it seems there is something wrong with my kidneys, I was also in a car accident and I have an upcoming surgery to reattach some of my muscles), together with my mom being diagnosed with cancer...it just did not seem like the best time to move to another town and look for a job.

 At this moment in my life I was glad to get ANY job in my small town I live in (again as an English teacher). A year went by and the situation has normalized a bit, but here I am. A soon to be 33 year old with virtually no experience in the field. I always thought that it would work out somehow but I am starting to lose hope. The other day one of my students in my English class asked me about a math problem, she is also studying at university and she did not understand how to do a 2-factor ANOVA. ""Easy"" I thought, but after over a year out of school it took me good 2 hours to review the stuff. Just the basic definition of variance, expected value, cumulative distribution function, F-test... At this moment I am not very sure about the things I have learned and with each day I feel I remember less and less. 

I was thinking about enrolling into some online course to review my knowledge but there are so many of them and some of them are not exactly cheap. I am also not sure about what to write on my CV... I am probably 10 years older that most other applicants that have the same level of experience (meaning none). I am not afraid of hard work, so I would totally go over some extra skills to learn but each job opening has different ones. Some want R, some want Python, others talk about Numpy. Others mention things I have never even heard of...experience in back end development, signal analysis etc.

I am currently not hurting for money, because my English teaching job is above averagely paid, also during my second university I started to gamble online using Nash equilibrium, combinatorics and other tools to beat alternative poker variants. That has always been a very nice secondary source of income. That being said, I would like to change my career and grow as a person, but I am not really sure how to best do that at the moment. I have a killer English teacher CV, but not a good data analyst CV. Thanks for reading this far, I guess I really needed to rant for a bit. If you have any advice for me...I am all ears, I could really use it right now.",2021-12-12 14:30:22
Weekly Entering & Transitioning Thread | 12 Dec 2021 - 19 Dec 2021,10,rennkb,https://www.reddit.com/r/datascience/comments/rennkb/weekly_entering_transitioning_thread_12_dec_2021/,177,1639310430.0,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",2021-12-12 14:00:30
suggestion on what to focus on before I get laid off,5,relrhr,https://www.reddit.com/r/datascience/comments/relrhr/suggestion_on_what_to_focus_on_before_i_get_laid/,16,1639302300.0,"I have been working as a data scientist for around 1 year, mostly working with medical data, computer vision and data analytics in general.  The startup I was hired in November has been sold last week, which means that I will be laid off end of January ( FML). The upside is that I have a month at a good salary (maybe more) to basically do nothing except look for jobs. I was thinking of improving my profile by preparing small GitHub repos & medium posts on relevant topics. This is also a way to study new things, not just show off my current skills. 

I am looking for ideas on what to focus on. Ideally this would be something relevant for most domains and that would impress a recruiter.  For now what I have on my list is:
- building a mlops environment on AWS with Infrastructure as code
- collection of functions to evaluate different ml models for classification,  regression and image segmentation 
- graph databases and graph ML (not sure about this)

would you have any other suggestion oh mighty community?",2021-12-12 11:45:00
"I want to help my local restaurant analyze their data, need second opinions",19,rel6ml,https://www.reddit.com/r/datascience/comments/rel6ml/i_want_to_help_my_local_restaurant_analyze_their/,22,1639299813.0,"I'm in the budding stage of my data science learning/career and have been applying to internships for next summer as a first year at community college. With over 100 applications, and 4 interviews total, I was just rejecting from my closest chance yet, so I have decided that I need to create my own internship. My thing has always been that I need to get my hands on real-life data, particularly data that involves transactions or money, and since I live in a small town, offering to analyze local restaurants' data seemed like the perfect opportunity to learn and potentially make some money in the future.

  

I live in a town with \~30,000 people. Suffice to say, there are a lot of small/medium-sized and mom-and-pops restaurants/shops in town. We have a bustling downtown scene, so there are a lot more restaurants and boutiques than one would normally think for a town of our size.

  

The premise that I have so far is that I would approach 1 or 2 mom-and-pops restaurants (would start with the local pizza place that I live a couple blocks from) and offer to analyze their data for general insights/trends that they could capitalize on to make more informed decisions. I would offer the first one or two consultations for free, and if I recognize that I'm knowledgeable/confident enough and they think what I do can benefit them, then we would ideally start working contractually.

  

I am aware that this would qualify more as DA/BI, because the extent of my ML knowledge is classification and regression. I imagine that time-series forecasting would be the modelling most relevant to restaurants, and is something that I may look into in the future.

  

So far, in terms of my value proposition, I have:

* Dish popularity/menu analysis
* Price adjustments based on trends
* Customer demographic analysis
* Inventory management/food waste analysis
* Discount/loyalty analysis
* Seasonality trends/insights
* Payroll/staffing analysis
* Delivery analysis (since they do pizza delivery)

  

**I won't dive deeper into each of the points here, but what I would like from this post is:** 

1. Is this a good idea in the first place
2. Are there any red flags that you see in this idea/process
3. What can I do to build upon this idea
4. To what extent is this plan anything other than just building dashboards",2021-12-12 11:03:33
"How do I tag persons' names from my own photos? Software developer here, knows absolutely nada about AI/ML.",0,rek7vb,https://www.reddit.com/r/datascience/comments/rek7vb/how_do_i_tag_persons_names_from_my_own_photos/,2,1639295726.0,"Think it's something interesting to play with. I have thousands photos taken for the family on OneDrive. I'd like to download all of them and store on a local server, meanwhile, hand pick a few to train a model and categorize multiple persons eith the output, then assign names, say myself, wife, son, daughter, use these as input, continue run through all photos, at the end I'll have a database table: photo1 is myself and son, photo2 is wife and daughter, etc., of course I can also edit the EXIF info on the photo and attach these tag information, later I can search for photos that're tagged with my son. 

A different way would be to run all photos altegother, output would be person1 on photo1, person 2/3 on photo2, etc., then I can assign names from the final output, which could be a simple mapping in database, person1 -> myself.

Not sure I'm making any sense, how do I get started?",2021-12-12 09:55:26
Is FAANG or big tech worth it?,128,rejq5n,https://www.reddit.com/r/datascience/comments/rejq5n/is_faang_or_big_tech_worth_it/,80,1639293656.0,"I'm currently a senior data scientist and have worked at multiple startups ranging from 15 to 500 people. I thoroughly enjoy the hectic and constantly changing environment that startups entail. Furthermore, I love that I get to have a large amount of responsibility and impact with my work.

With that said, I know I can be paid substantially more at FAANG or other big tech companies. My concern is that they would be ""golden handcuffs"" where I'm trading in my love for startups for being a highly paid cog in the machine.

I have interviewed at such places before, so I know it's not a matter of ""if"" I can get in. Rather, it's if I want to commit to preparing for the interview gauntlet for such companies.

For those that have worked in FAANG or other big tech companies, what was your experience like? Was it worth it to you?

Edit: Thank you to those who provided thoughtful comments. I greatly appreciate you sharing your perspectives!",2021-12-12 09:20:56
Microsoft Excel World Championship happening now!,39,rehfsz,https://www.pcworld.com/article/559001/the-future-of-esports-is-microsoft-excel-and-its-on-espn.html,9,1639284876.0,,2021-12-12 06:54:36
Using AMD Radeon with TF in Anaconda Spyder,3,regtta,https://www.reddit.com/r/datascience/comments/regtta/using_amd_radeon_with_tf_in_anaconda_spyder/,5,1639282713.0," Hello,

I understand that Tensorflow is geared towards proprietary NVIDIA Cuda, but is there a workaround for AMD Radeon GPU? I'm on a Macbook Pro with an AMD Radeon 580 external GPU card.",2021-12-12 06:18:33
"""I'm gonna make him a Neural Network he can't refuse"" - Godfather of AI",701,refiro,https://i.redd.it/r5ihrf2x11581.jpg,15,1639278177.0,,2021-12-12 05:02:57
What projects are you currently working on? What is your role in them? What languages/things do you use to complete them?,1,re5obc,https://www.reddit.com/r/datascience/comments/re5obc/what_projects_are_you_currently_working_on_what/,1,1639247347.0,,2021-12-11 20:29:07
[Official] 2021 End of Year Salary Sharing thread,378,re46xx,https://www.reddit.com/r/datascience/comments/re46xx/official_2021_end_of_year_salary_sharing_thread/,635,1639242936.0,"See [last year's Salary Sharing thread here](https://www.reddit.com/r/datascience/comments/klvb55/official_2020_end_of_year_salary_sharing_thread/).

**MODNOTE**: Originally borrowed this from [r/cscareerquestions](https://www.reddit.com/r/cscareerquestions/). Some people like these kinds of threads, some people hate them. If you hate them, that's fine, but please don't get in the way of the people who find them useful. Thanks!

This is the official thread for sharing your current salaries (or recent offers).

Please only post salaries/offers if you're including hard numbers, but feel free to use a throwaway account if you're concerned about anonymity. You can also generalize some of your answers (e.g. ""Large biotech company""), or add fields if you feel something is particularly relevant.

* **Title:**
* **Tenure length:**
* **Location:**
   * **$Remote:**
* **Salary:**
* **Company/Industry:**
* **Education:**
* **Prior Experience:**
   * **$Internship**
   * **$Coop**
* **Relocation/Signing Bonus:**
* **Stock and/or recurring bonuses:**
* **Total comp:**

Note that while the primary purpose of these threads is obviously to share compensation info, discussion is also encouraged.",2021-12-11 19:15:36
"Is there any danger that UUIDs will start duplicating as databases start hitting pedabytes, exabytes, etc?",1,re3vu3,https://www.reddit.com/r/datascience/comments/re3vu3/is_there_any_danger_that_uuids_will_start/,2,1639242032.0,"The Law of Large Numbers has to win eventually, right?",2021-12-11 19:00:32
Why are data centers so large?,11,re2xzv,https://www.reddit.com/r/datascience/comments/re2xzv/why_are_data_centers_so_large/,20,1639239219.0,"I have never been presented the opportunity to tour a data center, but whenever I see a picture of one, I always wonder why they are so massive. You can fit a terabyte of data on a flash drive. So what is taking up all that space? What is the main bottleneck? Are data centers getting smaller and smaller over the years? Will all the data in the world theoretically be able to be stored in a spare bedroom one day?",2021-12-11 18:13:39
Current state of Conda on Apple M1,5,rdxs31,https://www.reddit.com/r/datascience/comments/rdxs31/current_state_of_conda_on_apple_m1/,5,1639221613.0,"Hi everyone.

I am looking around to pick a new laptop, and the M1 MacBooks are quite appealing due to the long battery life and all that stuff. (I know, they are probably going to announce new models, but time is quite tight)

However, I'm a bit concerned about compatibility with data analysis tools. I'm not going to use advanced stuff and I don't need deep learning packages. However, I need the basics (Numpy, Scipy, Matplotlib, Jupyter, Pandas and maybe Sklearn) to work without hiccups. Possibly without Rosetta. (Though, I'd like to learn ML as a hobby, so I'd hope that other packages work, too)

I am working in computational physics, so I'll have to analyze data locally on my laptop.

It seems that most issues have been ironed out (even Tensorflow works natively now), but I can't find up-to-date opinions and reviews about it. Anaconda does not officially support Aarch64 yet, and miniforge must be used instead. Overall, the number of posts with workarounds to various issues is not encouraging, but for all I know they may have been fixed already in the meantime.

Does anyone here use a M1 Mac for work? How was your experience with it so far?",2021-12-11 13:20:13
How do you guys work data as large as 25million rows?,182,rdxra4,https://www.reddit.com/r/datascience/comments/rdxra4/how_do_you_guys_work_data_as_large_as_25million/,155,1639221516.0,"This is the first time I'll be dealing with such data. I have no clue how to clean this data. Are there any free libraries available to clean such data? I found a library named Terality. It has a limit of 200gb per month usage. 

Also, how can I produce cleaning at individual cell level? Like I wanna split the string ""xyz (1994)"" to different columns one containing the string ""xyz"" and other containing the number 1994.  I have a lot more functions to use to clean the data at individual cell level. 

I am just a beginner in this field so I don't have any clue about handling such data. Any help would be appreciated

Edit:

You guys are so wonderful. The responses were so amazing. And with your help I cleaned a data of 25 million rows (Although by comment section, I can say that for most people, the size is their daily driver) for the first time.

I did so by creating chunks of the dataframe each of size determined by categorizing the data. Then I cleaned the data at individual chunk level which was much much faster and worked like a charm

Now I plan to create some samples of the data for eda and probably merge all the chunks into one dataframe and create a CSV file for getting insights from the data as a collective.

Thanks for all the help and much love to everyone <3",2021-12-11 13:18:36
Job title switched between application and offer letter…,11,rdpri1,https://www.reddit.com/r/datascience/comments/rdpri1/job_title_switched_between_application_and_offer/,19,1639191077.0,"I applied and got a new job. The job I applied for was Manager level, but the offer letter stated “Associate” manager… No one mentioned anything about the job being at the associate level during the interview process. Any tips on handling this since I like the job but at the same time, I don’t want to take a step backwards in my career since I would be leaving an associate position to begin with?",2021-12-11 04:51:17
Imagine what historians will say about naming convention for pre trained models in 50 years…,246,rdmmcd,https://i.redd.it/7i4rfcxk2t481.jpg,29,1639181472.0,,2021-12-11 02:11:12
"Why do hierarchical models (or MCMC) improve individual-level estimates? Specifically, for BTYD models",3,rdih8d,https://www.reddit.com/r/datascience/comments/rdih8d/why_do_hierarchical_models_or_mcmc_improve/,9,1639169956.0,"Hi!

I am reading about the [Pareto/GGG](http://www.reutterer.com/papers/platzer&reutterer_pareto-ggg_2016.pdf) BTYD bayesian model, which represents an improvement on a previous model called Pareto/NBD.

I understand the rationale behind both methods and their assumptions, but Pareto/GGG claims to produce better estimates for individual-level parameters because of its use of MCMC. Quoting:

>To achieve the parameter estimation for the Pareto/GGG, we formulate a full hierarchical Bayesian model with hyperpriors for the heterogeneity parameters, then generate draws of the marginal posterior distributions using a Markov Chain Monte Carlo (MCMC) sampling scheme. This comes with additional computational costs and implementation complexity, compared with the maximum likelihood method available for Pareto/NBD, but we simultaneously gain the benefits of (1) estimated marginal posterior distributions rather than point estimates, (2) individual-level parameter estimates, and thus (3) straightforward simulations of customer-level metrics that are of managerial interest.

Which I don't understand.

I get that in hierarchical models you try to infer the behavior of a group (the heterogeneity params) given the observations you have at individual level (that is, each individual's behavior is a sample from the group/heterogeneity distribution), but **why using MCMC to ""generate draws of the marginal posterior distributions"" help to improve the estimates for the individual level parameters?**

I understand the meaning of ""MCMC"", but I am not well-versed on its workings, so if that's why I am not understanding this and someone could point me to a good learning resource where I can read about it (and that focuses on the claim on individual estimates), it'd be really helpful. I found [this article](https://jkkweb.sitehost.iu.edu/articles/KruschkeVanpaemel2015.pdf) (which I have not fully read) explaining a bit of the intuition on the second page:

>A hierarchical model may have parameters for each individual that describe each individual's tendencies, and the distribution of individual parameters within a group is modeled by a higher-level distribution with its own parameters that describe the tendency of the group. The individual level-level and group-level parameters are estimated simultaneously. Therefore, the estimate of each individual-level parameter is informed by all the other individuals via the estimate of the group-level distribution.

But it confuses me a little bit as leaves out the part of MCMC, but it's what I've got so far.",2021-12-10 22:59:16
Data scientist without a “home”,66,rdet5e,https://www.reddit.com/r/datascience/comments/rdet5e/data_scientist_without_a_home/,21,1639160126.0,"I want to know this is situation is endemic or if I am failing in some way. I’m on my second role like this. I was hired into a company as the only data science individual on a team. I work on a few projects, and everyone talks about my awesome skill set and how useful it will be but in the end, no one really utilizes me much and I get transferred from team to team, manager to manager. My question is, is this something others have experienced being the only data science person on a team? Is there something I could do to be better utilized? Or perhaps, for my next role I should look for a team of data scientists to work with?",2021-12-10 20:15:26
Kobo Toolbox - Can it retrieve existing data records?,1,rddymb,https://www.reddit.com/r/datascience/comments/rddymb/kobo_toolbox_can_it_retrieve_existing_data_records/,0,1639157839.0,"Hi folks, I'm new to Kobo Toolbox and I suspect that what I want is not supported but would love any other more experienced users to correct/confirm if possible.

In short: I want the users uploading data in the form to be able to 'see' previous data associated to an entity upon which they intend to append a new entry. e.g. If the agent places in the User-ID, the forms get automagically populated with the data already known about the User-ID.

Related: Beyond 'seeing' the data, would it be possible to create logic rules that reference properties of the entity that have already been saved? (e.g. the agent adds a kid to the family and the form confirms this by indicating that this takes the total kids in the family to 3, based on previous entries)

Is this possible? Thanks!",2021-12-10 19:37:19
Data for each region in Italy,0,rddxz0,https://www.reddit.com/r/datascience/comments/rddxz0/data_for_each_region_in_italy/,1,1639157790.0,"Hi.

I have tried several sources, but have not managed to find data of each regions in Italy regarding GDP per capita, C02 Emission, energy consumption. I would like to get it from 1960-2019. 

Can anyone help? I'm writing a project assignment.",2021-12-10 19:36:30
What are the best certifications for data analysis(my company will pay)?,5,rdbeaq,https://www.reddit.com/r/datascience/comments/rdbeaq/what_are_the_best_certifications_for_data/,10,1639150947.0,"So I am a self taught data analyst currently working for cybersecurity company in nyc. I'm only 23 years old and didn't have much prior experience(my finance degree helped but nothing else). My company will pay for any certifications within reason(but not grad school). What are your most recommended certifications? I'm looking for things to give me more access to python, and intro to SQL(never needed to use before). I know certifications aren't 100% necessary for learning, but if my company is willing to pay, I'd be a fool not to add anything to my resume.",2021-12-10 17:42:27
Is Numpy always more efficient than Pandas? And how much should we rely on Python anyway?,196,rdao7c,https://www.reddit.com/r/datascience/comments/rdao7c/is_numpy_always_more_efficient_than_pandas_and/,96,1639148879.0,"Hi all, intermediate programmer here, pondering script efficiency and how to improve ETLs.

Like many data programmers, I've been using Pandas for awhile. But some of you mentioned here that Pandas has too much overhead and eats up memory compared to NumPy.

I also worked with a software engineer this year who felt strongly that people should learn NumPy properly and not use Pandas as a crutch.

I'd love to hear more views and considerations on this. I've been developing ETLs for low-volume data pipelines so it probably doesn't matter much now, but if we scale up then I want to lay the groundwork properly.

Side note: most of our data is **text, not numbers**. So then does that mean NumPy vs. Pandas doesn't matter?

Add to this a **Python vs. SQL** vs. other tools question that I've been thinking about. I want to do more OOP - love the elegance and efficiency - but I believe that Python is always gonna be slower than SQL (we're using Redshift - definitely a bigger, stronger engine than Python scripts). Throw your two cents in if you like!

Edit: Yes, I'm aware that NumPy runs under the hood of Pandas! Good to know for newbies though. 

Also: Some good informative responses. Others seem to think I'm saying ""NumPy is better than everything else all the time and I love it"". No. Obviously there are many considerations, and that's why I wanted to ask for your input.",2021-12-10 17:07:59
"As someone who lives in a country with no BI or Data Visualization scene, how can I build a network online with people in North America or Europe?",0,rd9hdi,https://www.reddit.com/r/datascience/comments/rd9hdi/as_someone_who_lives_in_a_country_with_no_bi_or/,9,1639145425.0,"Non-native English speaker here.

I live in Bangladesh and there are no business intelligence or data visualization jobs here. The extremely rare few openings that are there, take in only those with a Bachelors in CSE. I have a BS in Economics and MBA so I don't qualify for those.

Now I am looking for remote fulltime jobs that I can do from Bangladesh.

My biggest challenge is networking. Without networking, I cannot build up a client base for finding a steady stream of BI and Data Visualization work in order to make a living off of a career in BI and Data Visualization.

So my question is, can anyone provide suggestions on how I can network virtually over the internet with the Business Intelligence and Data Visualization community in the Western world, particularly in the USA, Canada, Europe?",2021-12-10 16:10:25
How to approach associating two different data sources to individuals,3,rd960r,https://www.reddit.com/r/datascience/comments/rd960r/how_to_approach_associating_two_different_data/,7,1639144508.0,"I am trying to figure out a way to associate two data sources to individuals. I have a data source that uses wireless access points in the workplace that returns name of individual employees but I only know that they are within a large area. I also have occupancy sensors that are very granular to the point of knowing if a person is sitting in a seat or how many people are in a conference room. I am scanning the work space every five minutes so I may be able to associate the name of person being picked up on the wireless with some new sitting in a seat. There maybe times when multiple people arrive at the same time and sit in the same area at the same time. To complicate things more, the occupancy sensors can have latency of up to ten minutes so this would need to be accounted. I am investigating the use of cosine similarity as a potential solution but wanted to the thoughts of others on how to approach this problem. Ultimately, I am trying to answer what groups prefer what types of newly created work spaces and understand how people collaborate with each other. Thanks!",2021-12-10 15:55:08
Trying to find a holistic framework of data science corporte use. What am I missing?,57,rd6sym,https://i.redd.it/5umbn18rbp481.png,48,1639136343.0,,2021-12-10 13:39:03
Comment,1,hxutpvv,,0,1645465256.0,"Agreed. It's easy to say ""oh just learn these things on the side on your free time"" but that's a lot easier said than done. And the truth is that no employer is gonna wait for you to learn all these things on the job. They will expect some level of experience in some of the technologies you mentioned. If you say to a hiring manager, ""I don't know any of tensorflow/pytorch, git, SQL, containerization, pyspark, airflow, mlflow, or AWS, but I know how to derive the MLE"", you are not getting hired, bruh. Knowing mainly theory but not being able to do practical real-world problems is a good way to get fired real quick.
 
I feel like too many people on this sub is expecting data science jobs to be waaay more theoretical than it actually is. People are setting themselves up for disappointment.",2022-02-21 19:40:56
Comment,1,hxutngw,,0,1645465230.0,"Yeah, it’s more-or-less a sufficient but not necessary condition. I’ve known very good PDE solvers (meaning the people not a computer program) from back in my grad school days who couldn’t stand functional analysis and didn’t believe it could be relevant. My only beef with them was that they will sometimes make mistakes analysis would have seen coming but still deny it’s relevant. But as long as they aren’t so ideological about it I fully believe you can have a practical understanding and just prefer iterative improvement to theory.",2022-02-21 19:40:30
Comment,1,hxut4wo,,0,1645465028.0,It's with images.,2022-02-21 19:37:08
Comment,1,hxusr86,,0,1645464880.0,"Yeah--I love the background I have.

I have an undergrad in Financial Economics so I learned the business side and accounting along with solid applied analytics (econometrics).  Adding in the rigor of the Applied Math was amazing and it gave me the ability to teach myself--not just in implementing algorithms in Python/R, but in teaching myself the underlying intuition of the mathematics.",2022-02-21 19:34:40
Comment,1,hxushxd,,0,1645464780.0,"This is exactly what is done for a commercial financial product of some importance that my employer builds.

But what’s hasn’t been discussed here and is an important consideration is the interaction between the loss function and the class frequencies, original vs resampled.

Especially in rare class prediction, the business value of the predictions/scores is not uniform over all implied probabilities.  The specific choice of loss function in optimization (which isn’t always exactly aligned with business value for technical reasons) interacts with the class ratio and the details of the model.  Changing class frequencies by sampling or weighting will change the tradeoff of which points in space or score bands are predicted better and which are worse.",2022-02-21 19:33:00
Comment,1,hxusbn8,,0,1645464711.0,"Hi everyone, I graduated UC Davis in June of 2021, took three month to enjoy myself, build a portfolio/learned basic SQL and in January landed a job. I am Rev. Cycle Data Analyst and making $75k in LA. My plan is for the next 6 month is to get this job on my resume, better my SQL and look for another job that pays higher and is actually in data analytics team.",2022-02-21 19:31:51
Comment,1,hxus8qr,,0,1645464679.0,">Additionally, we probably don't want to be doing classification  
 anyway, we mostly want to be accurately predicting risks for the   
outcome (risk of churn, risk of click through, whatever).  Ensuring our   
risk estimates are accurate vis a vis calibration and proper scoring   
rules allows for an appropriate risk threshold to be selected for   
decision making.  When you resample, all you're doing is forcing the   
model's probabilities to change in order to make your arbitrary decision  
 boundary look appropriate.  You're putting the cart before the horse.

Well put. I'm always shocked in industry to see how little respect people give to the problem of **probability estimation**, and awkwardly zero in on (often arbitrary) classification. The former is much more useful from a decision-making perspective and allows you to incorporate more information (e.g. the expected revenue/margin of product A vs product B, instead of just spitting out which product a customer is most likely to purchase)",2022-02-21 19:31:19
Comment,1,hxus1db,,0,1645464599.0,Sure I’m aligned with this viewpoint. But I also think it means that you don’t necessarily need to be capable of proofs to have “deep” understanding. I’ve met people (not me) who have the intuitive grasp of ML hacking in the same way Tony Hawk has an intuitive grasp of physics. But neither them nor Tony Hawk can write proofs,2022-02-21 19:29:59
Comment,1,hxurwqv,,0,1645464548.0,This! Please fix title.,2022-02-21 19:29:08
Comment,1,hxur20e,,0,1645464213.0,You tune hyperparameters during validation? Doesn’t that mean you are guaranteeing the model performs worse on new data since you’ve used information about your validation data to change the model?,2022-02-21 19:23:33
Comment,1,hxuqxgn,,0,1645464164.0,I was arguing about which Ms program content was more useful,2022-02-21 19:22:44
Comment,1,hxupr69,,0,1645463703.0,exactly.,2022-02-21 19:15:03
Comment,1,hxupmzt,,0,1645463655.0,"Education is about learning to learn. That's why a good Computer Science science degree will teach you programming *principles*, not programming *languages*. For example, you will learn to use C++ to understand what object-oriented programming is. C++ itself is irrelevant and/or ephemeral.",2022-02-21 19:14:15
Comment,1,hxunqd6,,0,1645462894.0,"I agree with Masters. I have a stats degree pretty much (actuarial) and some of the actuarial exams cover masters level stats. 

phD is where the real knowledge comes in. I know some phD stats DS and they are really really good at forming solutions without relying on a black box algorithm.",2022-02-21 19:01:34
Comment,2,hxun6th,,0,1645462680.0,"The calibration argument is pretty weak, because your guarantees of getting a well-calibrated model using standard learning technique are pretty bad. If your use case requires that your model scores be well calibrated probabilities, then you better be running a calibration process for any model.

Since you should calibrate anyway, the sampling issue doesn't matter. If you can get better model performance (for some definition of performance) through sampling, you should do that.

The idea that models produce correct probabilities in the absence of sampling is a fantasy and shouldn't be repeated. The reality is that you almost never meet the required assumptions for models that allow that and most gradient descent algorithms don't allow probabilities to behave nicely.

I think the best reason not to upsample classes is the overfitting risk.

Downsampling classes carries a much reduced overfitting risk, so is much less problematic.",2022-02-21 18:58:00
Comment,1,hxum1v9,,0,1645462229.0,ohh okay. That does make sense. My bad. I won't go through with it. I had a huge misunderstanding,2022-02-21 18:50:29
Comment,1,hxum14j,,0,1645462221.0,"Isn't true with tree-based models, dont need to account for imbalanced data?",2022-02-21 18:50:21
Comment,1,hxuldih,,0,1645461962.0,[link](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/reviewing-changes-in-pull-requests/commenting-on-a-pull-request),2022-02-21 18:46:02
Comment,1,hxukjjs,,0,1645461636.0,"Are you American? If so, the equivalent of CStat is the PStat award conferred by the American Statistical Association.",2022-02-21 18:40:36
Comment,3,hxukbgg,,0,1645461547.0,"> treating the class weights as a hyperparameter that I tune during validation.

This creates the same problem that resampling does, namely biasing the prior probability estimates. I'm all for adjusting the error metric tho.  For a binary problem [we can take into account the cost of the error to decide what the decision threshold should be](https://stats.stackexchange.com/questions/368949/example-when-using-accuracy-as-an-outcome-measure-will-lead-to-a-wrong-conclusio/368979#368979).  This supports the idea that so long as probabilities are well calibrated, our decisions should be good.",2022-02-21 18:39:07
Comment,2,hxujzen,,0,1645461416.0,"> It seems to me that in both methods you're biasing the prediction to undervalue/overvalue samples based on their class frequency.

Correct.  Resampling biases class priors.  No reason to think ""tuning"" the prior frequency would be any more correct.

> class weighting strategies

This is similar to up/down sampling.  If I re sample the minority class, then the model will make the same prediction for the repeated observations, hence weighting it more by virtue of it appearing more than once.

> The consideration there is that deep learning models may completely ignore any features related to predicting the rare class if the imbalance is high enough.

It might be worth considering if deep learning is the right approach for this problem them (if its images, then I'd be willing to recant slightly.  Frank Harrell mentions why in the linked blog post)",2022-02-21 18:36:56
Comment,1,hxujl04,,0,1645461256.0,Publicly available doesn't mean its free for you to sell.,2022-02-21 18:34:16
Comment,1,hxuj7yi,,0,1645461112.0,"Is class weighting any less problematic than sampling-based methods for class imbalance? If so, why? It seems to me that in both methods you're biasing the prediction to undervalue/overvalue samples based on their class frequency. I generally have only used class weighting strategies for imbalanced datasets in deep learning models. The consideration there is that deep learning models may completely ignore any features related to predicting the rare class if the imbalance is high enough. In which case, you will not be able to compensate for this by adjusting the threshold for classification.",2022-02-21 18:31:52
Comment,3,hxuj5lp,,0,1645461086.0,"> Bootstrap all you damn well want!

now that's a title i can get behind",2022-02-21 18:31:26
Comment,1,hxuj2qm,,0,1645461054.0,"I'm not familiar with those awards, so I couldn't give you an immediate opinion.",2022-02-21 18:30:54
Comment,1,hxuixsr,,0,1645460999.0,"Would you go through it again? Not OP, at a place to getting additional education in either CS or applied math (focus on computation).",2022-02-21 18:29:59
Comment,2,hxuiqn6,,0,1645460918.0,"To clarify, you mean:

* Up/down sample your data
* Construct a model
* Re calibrate this model using the data which reflect true frequencies?",2022-02-21 18:28:38
Comment,1,hxuikfy,,0,1645460849.0,Personally I would manually label as many as you can first to get an intuitive idea of what the buckets are. Having data intuition is really important in anything before theorizing different classification methods.,2022-02-21 18:27:29
Comment,1,hxuigjd,,0,1645460806.0,">Clean Code

Thank you for this recommendation. I'm going to check it out.",2022-02-21 18:26:46
Comment,1,hxuifdl,,0,1645460793.0,I came.,2022-02-21 18:26:33
Comment,3,hxui6iw,,0,1645460697.0,"Yea, whoops, meant up/down sampling.  Bootstrap all you damn well want!",2022-02-21 18:24:57
Comment,2,hxui57l,,0,1645460682.0,"> when you memorize and understand something, it changes how you think.

Does it? Do you have evidence for this claim? How long does it change how you think? Permanently? Temporarily? To what degree? A little? A lot?

What about forgetting? So, people never forget what they learn?

> You can spot parallels you otherwise would not be able to.

This is soo unbelievably vague...'you learn to see differences in things', how insightful

I'm sorry, but this sounds like bullshit that is sold to children taking out $50k loans who have never actually worked.

>Long term memory does not clutter short term memory.

Source?

>If you need to store several concepts about an algorithm in working memory, you will not have enough working memory to do the programming.

Source? People can just recall all this information exactly when they need it? From 10 years ago?

What a load of garbage lol

Everything you said (1) helps no-one and (2) makes you sound smart. And that's why you said it.",2022-02-21 18:24:42
Comment,1,hxuhich,,0,1645460426.0,"Yeah, my default has been to write a million comments but I feel like that's just messy and useless to most people.",2022-02-21 18:20:26
Comment,1,hxuhhjt,,0,1645460417.0,"Naw I mean it's just one of those thing that like a HR person might write or something. Like ""coding wizard"".",2022-02-21 18:20:17
Comment,1,hxuhcxw,,0,1645460365.0,Thank you! Does this advice cross the stream into the data science side as well?,2022-02-21 18:19:25
Comment,1,hxuhcv7,,0,1645460364.0,What do you think of professional awards such as GradStat (graduate statistician) and CStat (chartered statistician) conferred by The Royal Statistical Society? Would you respect a degree that the RSS has deemed to have sufficient statistical content to qualify for designations such as GradStat or CStat?,2022-02-21 18:19:24
Comment,1,hxuh42j,,0,1645460266.0,"Thanks, great tips!",2022-02-21 18:17:46
Comment,1,hxuh2z3,,0,1645460253.0,You can get coaching services from a wide variety of generic resources like Rooftop Slushie from Blind. My company (Interview Query) specializes in data science coaching but it's on the more expensive end because most of the time it's done with professional FAANG data scientists (https://www.interviewquery.com/coaching). We do career coaching sessions where the coach can review your resume though!,2022-02-21 18:17:33
Comment,1,hxuh0av,,0,1645460222.0,">From the comment section of your pullrequest :D

What does this mean? Angry developers leaving comments?",2022-02-21 18:17:02
Comment,2,hxughqc,,0,1645460014.0,Thanks for sharing the style guide. My work is going to be a ton of SQL so I'm happy to learn how to write un-sloppy SQL code.,2022-02-21 18:13:34
Comment,6,hxugew2,,0,1645459982.0,"I don’t know why I never thought about class weights as a hyper parameter, but that sounds like a great idea!",2022-02-21 18:13:02
Comment,1,hxug8t2,,0,1645459912.0,Thanks for these resources! I'm going to put some work into unit testing today. I've literally never heard of it until I asked this question and this looks like a great place to start.,2022-02-21 18:11:52
Comment,1,hxufyeh,,0,1645459793.0,You don't like writing bomb-ass code?,2022-02-21 18:09:53
Comment,1,hxufxh0,,0,1645459782.0,">Some day if you remain in the field I hope you realize how cringe-worthy these words might sound to a more experienced programmer.

Haha you're not wrong, but this is a casual forum, not a formal job presentation, and I'm very familiar with code-switching for my audience.

>There is one habit for maintainability that will raise you above all others, but you will not do this.

What does this mean? Like it's additional work so data scientists are not likely to do this? I strive hard for mastery for whatever field I usually pursue so I'd like to be able to implement best practices when and where I can. I understand some comes through experience and some through proactively working to be good at what I do.

>Books might help at first but they get stale real fast. Contrary to others' comments, for resources I would advise you to look at other projects that are in production - ones that have actual people using them - and not books. Use them as examples and compare according to your growing understanding of what's easy and not so easy to maintain.

Good advice - what would you recommend the strategy is if the company doesn't have a good codebase for this? My role is at a pretty well known org so I'm pretty confident that this is not the case and the reason why I picked this place over a smaller org was because of the presumption a larger org would have a well-established network of people I could learn from.",2022-02-21 18:09:42
Comment,7,hxufoku,,0,1645459678.0,"just for clarity, when you say resampling, you are referring specifically to up/down sampling approaches when dealing with class imbalance, yes? if so, the point is well taken, and I've had to argue this stuff before when assessing projects with other data scientists regarding calibration.

but bootstrapping and cross validation are resampling methods, and i don't think you're making the case that we shouldn't be using these in the classification setting. https://en.wikipedia.org/wiki/Resampling_(statistics)

your title threw me for a loop for a minute, at least",2022-02-21 18:07:58
Comment,5,hxuecg3,,0,1645459122.0,"Oversampling is indeed one of the worst practices I have seen! It introduces a plethora of different assumptions, which rarely every generalize to unseen test data. But worse than that, it opens doors for incompetent researchers (or people acting in bad faith) to make fundamental mistakes in their methodologies to inflate their metrics and get published in top venues: [https://www.reddit.com/r/MachineLearning/comments/erx7d2/r\_oversampling\_done\_wrong\_leads\_to\_overly/](https://www.reddit.com/r/MachineLearning/comments/erx7d2/r_oversampling_done_wrong_leads_to_overly/)

&#x200B;

Just use weighted loss functions or collect more data.",2022-02-21 17:58:42
Comment,1,hxue3sc,,0,1645459022.0,"Reposting: 

I'm entering the data field and my first offer has been a lateral move in pay. But it's a large recognizable company and my first real data job especially with big data. Is taking a lateral move in pay worth it for the sake of entering the field? I would be looking to make another jump about a year in",2022-02-21 17:57:02
Comment,1,hxud4z1,,0,1645458618.0,"Hi all,

I'm currently thinking about improving my pay check prospects - my current job is a public sector accountant. I want to move countries (UK -> US, dual citizen so visas a non-issue) and earn more so I'm thinking of moving into data science. My plan was to take a few courses (Introductory and otherwise) and apply the knowledge from those in my current workplace (deeply inefficient), and build up a portfolio of experience, maybe get an inbetween-esque systems accountant job, and then either move from there into DS or some other type of position.

Does this sound feasible? Would I be too weird a candidate for most jobs? Should I be looking at something else?",2022-02-21 17:50:18
Comment,2,hxucn5r,,0,1645458412.0,"Thompson sampling might be a bad example because any self respecting ML focused CS/ML masters will have at least one course dedicated causal inference / bayesian ML. In practice every single other course also had a large bayesian component, from Bayesian NN's to least-squares SVM's. From that perspective they might be on a par here but for other things a stats grad will certainly win out.

The meat of my argument was the diminshing returns of it all. A decent CS/AI program will give you enough of the fundamentals to pick up whatever you need along the way. You don't even need to implement anything from scratch, usually intuitions are enough for industry aren't they?

That being said I'm mostly playing devil's advocate here. I will most likely go back in 2-3 years and actually get a MS in stats. :)",2022-02-21 17:46:52
Comment,1,hxucikx,,0,1645458360.0,"Yes, don't resample nearly as often as you do

But proper scoring rules have the problem that they are only statistically proper but very much so improper for most application domains

* log likelihood is unbounded, it can tell you that one misjudged example outweighs millions of other data points, well... no... it doesn't...
* Brier score is bounded, but it still assumes symmetric misclassification costs, and when you have imbalanced datasets, that's just the one assumption you should not make",2022-02-21 17:46:00
Comment,1,hxuch3w,,0,1645458342.0,The day I see bomb ass code in a job posting is the day I shoot myself,2022-02-21 17:45:42
Comment,3,hxuc78z,,0,1645458226.0,Also ive never had SMOTE be an improvement and never heard of it improving someone elses metrics. I am super suspect on that paper,2022-02-21 17:43:46
Comment,1,hxubpno,,0,1645458023.0,"You are there to learn the rigorous foundation of math underlying data science. I personally would not hire a data scientist without a proper training in statistics. I don’t want a person whose intellectual depth is importing built-in packages and interpreting results without critical thinking.

There is no real world value only because you cannot connect the dots. Proofs look complicated and theorems look irrelevant because you do not have a structure around them.

p.s. Imagine a high school dropout telling you that learning how to solve linear equations is completely useless. What’s the point of learning?",2022-02-21 17:40:23
Comment,3,hxubop8,,0,1645458011.0,"I don’t know if you can figure out the directionality of the bias induced by it, but if you look at the SHAP theory here: https://christophm.github.io/interpretable-ml-book/shap.html, you are essentially creating a new dataset where for each row a new dataset with random subset of the features is selected to have the values as observed and the other ones are randomly sampled from their marginals repeated times. Then you are getting a prediction and basically fitting a weighted lm() to this and the coefficients give you the shapley values for that row in the original data. 

Because you directly rely on the model’s probability prediction as the new target in the weighted lm(), the probability you plug in itself needs to be unbiased.",2022-02-21 17:40:11
Comment,1,hxuboon,,0,1645458011.0,"Hi u/jade_mlc, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 1 karma.",2022-02-21 17:40:11
Comment,3,hxubjl4,,0,1645457951.0,"Calibration performed a posteriori  with an unsampled dataset  of a model trained with a sampled dataset, give better results for a highly unbalanced dataset than fitting a model straight into a highly unbalanced dataset",2022-02-21 17:39:11
Comment,2,hxuash1,,0,1645457632.0,"I hear what you’re saying. My perspective though is that the point of degree is to prepare you with the fundamentals so you can pick up new techniques easily. Our field changes super quickly.

You can’t tell me that a cs grad can implement Thompson sampling as easily as a stats grad.",2022-02-21 17:33:52
Comment,1,hxuabrw,,0,1645457433.0,"I assume if you want to use JS as you main tool the functionalities will be very limited due to having not the same amount of libraries then in python. I have never heard of anyone using JS only for data science specifically. But I guess at the end of the day the answer depends on ur goal, if you think the JS libraries will work for what you have planned to do go ahead, you can always apply the knowledge you got from it to other languages afterwards. I still think if you want to become a proper DS in a company you have to expand your languages inventory but as long as your JS libraries do what you hope they do go ahead. 

Python over the recent years became very popular, therefore the supply for python libraries increased and therefore python nowadays has a huge inventory of libraries. It's also fairly easy to learn (assuming you have some object oriented languages experience) because the Syntax is the simplest.",2022-02-21 17:30:33
Comment,2,hxu9yzl,,0,1645457280.0,Would you expand on this a bit? I'm relatively new to SHAP and need to randomly downsample the majority class quite often (I work in natural resource modeling). I'd be curious to learn how that downsampling is skewing my SHAP results.,2022-02-21 17:28:00
Comment,1,hxu9wz0,,0,1645457256.0,"Oh, thank you so much!",2022-02-21 17:27:36
Comment,1,hxu9vcb,,0,1645457236.0,"Three issues with portfolios:

1. Most of them suck - not because most candidates suck, but because most candidates suck at putting together a portfolio. And some of the best candidates don't even bother putting one together. 

2. I have no way of validating that you and only you worked on those projects. Maybe you copied and pasted someone else's github repo. Maybe it was a group project. Maybe it was a project that your professor guided you through.

3. Recruiters (the first person who filters resumes) aren't going to look through 1000 github repos. So if your resume isn't interesting enough at a high level, your repo won't even get looked at. 

So no, repos don't generally hold more weight than your degree. They may have a greater impact once you've made it through to a hiring manager interview, but that may be too late.",2022-02-21 17:27:16
Comment,9,hxu9lw7,,0,1645457122.0,Came here to say that I was coming here to say “came here to say this” but then I saw you already came here and said this,2022-02-21 17:25:22
Comment,2,hxu98w9,,0,1645456967.0,"I have a MA in Applied Mathematics.  In terms of practical skills...worthless.

In terms of giving me a deep understanding of statistical thinking and giving me a broad overview of topics in statistics, it has been priceless.",2022-02-21 17:22:47
Comment,2,hxu8z2m,,0,1645456850.0,Business economics. I know it sounds like it isn't rigorous but in the first semester you learn markov chain steady states and OOP in Python. Made majoring in data science and transitioning to MS AI down the road very easy. Could've done MS stats instead but I chose not to.,2022-02-21 17:20:50
Comment,1,hxu8typ,,0,1645456788.0,"I have a BS in Astrophysics and it's been worth its weight in gold. Physics programs offer a nice combination of rigor, application, and coding along with numerical work and data analysis. Not to mention all the creativity ane critical thinking that comes with the subject. All packaged into something that sounds strong beside your name on a CV.  You are exposed to maths, statistics, programming... reporting... hell, I now realize we were literally doing Data Science in several of my labs.",2022-02-21 17:19:48
Comment,1,hxu8tor,,0,1645456785.0,"I see your point but, surely, the candidate's portfolio (GitHub, Kaggle etc.) holds far more weight than the level of prestige of the university from which they got their degree. If a candidate has a strong portfolio, the prestige of their degree should be irrelevant, right?",2022-02-21 17:19:45
Comment,1,hxu8nsb,,0,1645456714.0,"Bandits were super simple math but the issue with them is that they belong in the  ""unknown unknowns"" for a lot of folk so you can't learn something in less than one day that you don't know exists with in the first place. Otherwise you're 100 % correct.

EDIT: For clarity's sake, that's how I feel about a lot of concepts in statistics as well. Learning some of them might not be super difficult but disturbingly I just don't know certain things existed to begin with.",2022-02-21 17:18:34
Comment,1,hxu89hp,,0,1645456539.0,"If you have a solid background in math stats you should be able to pick up bandit algorithms in less than a day. The actual algorithms are just wrapping around a ton of causal inference, probability theory, Bayesian inference, etc.",2022-02-21 17:15:39
Comment,1,hxu886z,,0,1645456523.0,"""_ignoreFinal_feb20_revision4_noForRealActually_3.ipnyb""",2022-02-21 17:15:23
Comment,1,hxu866t,,0,1645456498.0,What’s your BS in?,2022-02-21 17:14:58
Comment,1,hxu72u4,,0,1645456010.0,Same here,2022-02-21 17:06:50
Comment,1,hxu71tn,,0,1645455998.0,"Thanks. This is about as much as I gathered from reading online.  
So is the main reason for using python that there simply are so many libraries and anything you could want in data science exists?   

Basically, if I find libraries for my use case in javascript - nodeJS (usually they either seem to make them from the python libraries or heavily inspired by them), is there still another reason not to do it all in javascript?  

I'm not really looking to become a data scientist in general, where I can easily see it would make perfect sense to use the most widely used solutions.",2022-02-21 17:06:38
Comment,3,hxu71pi,,0,1645455996.0,"The point I’m trying to make is a little more specific.

Being able to carry out calculus formulas does not imply full “understanding.” One — though by no means the only — way to demonstrate fuller understanding is to be able to write analysis proofs. This especially in basic real analysis where proofs are basically just describing what happens in a limit.

I already believe that Newton understood calculus. Mainly because he invented it, but secondarily because he described limiting behavior in Principia. If someone could go back in time and show him how we would be writing rigorous analysis a few hundred years later, I very much doubt he would have had trouble figuring translating the thoughts he did write down to our modern format.",2022-02-21 17:06:36
Comment,8,hxu6f4e,,0,1645455717.0,Its pretty bad—another issue is if you apply SMOTE and use SHAP to interpret your model. Since SHAP relies on the probabilities which are miscalibrated  here it won’t be valid,2022-02-21 17:01:57
Comment,1,hxu5t0m,,0,1645455444.0,Lol,2022-02-21 16:57:24
Comment,1,hxu59vt,,0,1645455205.0,"Sure, but you're confusing two things here: curriculum and value.

The GaTech program has actually developed a really good reputation for being relatively rigorous. The UT programs (and I say this as an alumn) have not.

Why does that matter? Because as a hiring manager I care about three things when looking at your schooling:

1. The topics you studied
2. The depth of how those topics were taught
3. The level of rigor with which they were taught - i.e., what assurance do I have that you actually learned what was taught.

Why do I care about the last one? Because in a normal interview process I get maybe 6 hours to evaluate you. And there is no way that I can pressure test everything you theoretically learned.

This is why a program's brand matters. Because it tells prospective employers ""trust us, this person is legit"".

If that message comes from a program that hasn't been around long, then that statement doesn't carry a lot of weight.

The biggest issue I have seen with MS in DS programs is that they're not particularly rigorous. They're like MBAs - everyone is going to pass every class. In addition to that they're normally targeted at people who don't have a BS in anything data science related - sometimes not even stem related.

The signal that sends me is ""yes, you may have some good candidates, but I don't feel particularly strongly that your average grad is particularly qualified for an entry level DS role"".",2022-02-21 16:53:25
Comment,1,hxu590v,,0,1645455194.0,r/datasets,2022-02-21 16:53:14
Comment,1,hxu52b4,,0,1645455108.0,"Those days are done when you needed a degree in CS to be good in tech . These days , you can  do bootcamps , nano degree programs or practise text books  or simply do a YouTube course to be good in tech stack for DS  which includes  : python , numpy , scipy  , pandas etc .",2022-02-21 16:51:48
Comment,1,hxu4l6u,,0,1645454890.0,"R is superior for statistical analysis and is widely used in especially research, Python is not as specialized but can be used for everything like stats, visualizations, web-development and analysis. There are ofc other languages but they don't offer such a wide variety of libraries and features like python and r do. C# and C++ for example are a lot faster in calculations but there are a lot less data science and stats libraries then in r and python, although some python libraries use C++ internally to conduct those calculations.

Javascript will become useful if you want to represent your data on web apps. But even for this example you can use python flask + docker to build some web apps. One other language you should be familiar with is ofc SQL for database management. 

I myself love python in every way because you can literally use it for every case and it's wonderfully applicable to any business cases and companies.",2022-02-21 16:48:10
Comment,2,hxu46t4,,0,1645454704.0,"I see, were you going for research scientist stuff without a PhD (or with one)? 

Some of that stuff actually I am familiar with from my stat program, like using LSE or just taking logs before summing and exponentiating the answer, thats why even R has log=… in all the density functions. BP was harder for sure and ive only ever done it in a CS PGM class where we had a good amount of guidance with the code skeleton for a Markov Net. I thought the implementation was still easier than any sort of actual proof about tree-structured nets. I didn’t have any DSA background when I took that class but the programming exercises were still easier than theory.",2022-02-21 16:45:04
Comment,0,hxu456z,,0,1645454683.0,haaaahhaah,2022-02-21 16:44:43
Comment,0,hxu42zp,,0,1645454654.0,"damn............

I wasted a lot of time on this 

RIP",2022-02-21 16:44:14
Comment,1,hxu3r2b,,0,1645454500.0,its publicly available data,2022-02-21 16:41:40
Comment,0,hxu3otb,,0,1645454470.0,its publicly available data. and its not personally identifiable,2022-02-21 16:41:10
Comment,1,hxu3nut,,0,1645454457.0,"In some ""no code"" modelling solutions, resampling is the default for classifiers and the predictions come out completely miscalibrated. I feel like this plus someone inexperienced using the tool is going to cause problems somewhere down the line.",2022-02-21 16:40:57
Comment,1,hxu3nq0,,0,1645454456.0,"I've seen some good graduate degrees in DS, too. For example, there's UT Austin's MSDSO and Georgia Tech's OMSA. Both around ~$10K and the curriculum looks good.",2022-02-21 16:40:56
Comment,5,hxu3dtb,,0,1645454327.0,Came here to say this.,2022-02-21 16:38:47
Comment,1,hxu39g4,,0,1645454269.0,That’s the default method for financial risk forecasting in consumer lending.,2022-02-21 16:37:49
Comment,4,hxu2s1w,,0,1645454036.0,">There are tons of new programs popping up that are specific to data science (and mathematical finance - think Brownian motion).

The math finance/financial engineering programs have been around for decades starting at places like CMU, Berkeley, Chicago, Baruch. As you note, the emphasis was originally to create derivatives pricing quants and had lots of emphasis on stochastic calculus. In past several years (10+) more emphasis is being placed on statistics and data analysis given the needs of employers.",2022-02-21 16:33:56
Comment,29,hxu2lsw,,0,1645453953.0,"From a practical perspective, I’ve tried resampling for unbalanced classes on a few different problems and it hasn’t helped much.

At this point, I almost always work around unbalanced classes by carefully selecting my error metric to reflect what is important to the problem and then treating the class weights as a hyperparameter that I tune during validation.

This way, you can allow the model to focus on the minority class to whatever extent is appropriate to optimize your objective (minimize FP, FN, both equally, etc.).",2022-02-21 16:32:33
Comment,28,hxu2fyl,,0,1645453874.0,Downsampling worked for me much better (and faster) than any up-sampling/ resampling tecnique.,2022-02-21 16:31:14
Comment,16,hxu2a0h,,0,1645453793.0,"If you can understand logistic regression, you can understand calibration.  This is not a graduate level topic.",2022-02-21 16:29:53
Comment,0,hxu25m1,,0,1645453733.0,"I appreciate the post, but this is going to go over many peoples heads likely anyone that hasn’t taken graduate level stats classes. Also you a fighting a losing battle IMO, I think the majority of the industry is so obsessed with prediction that many orgs don’t care if you understand what is going on or why you did it as long as your test error rate is lower than before. It’s honestly a sad state of affairs but it is what it is.",2022-02-21 16:28:53
Comment,1,hxu1w2t,,0,1645453603.0,Reported.,2022-02-21 16:26:43
Comment,5,hxu1hhb,,0,1645453403.0,"Class based sampling /resampling is one of those things I see constantly recommended in reddit posts or medium articles, and which I have tried over and over again, but I have never once had it improve a properly constructed validation metric.

At some point I became convinced that people who think this has helped them either aren't validating properly, or aren't re-tuning their hyper parameters before and after introducing resampling.",2022-02-21 16:23:23
Comment,15,hxu0z2t,,0,1645453152.0,"SMOTE in combination with some perturbations can be a great way to explore if getting out of your way to collect more data would help, given a dataset and target architecture.

A more common problem is people mindlessly applying resampling and leaking labels between train / test / validation sets.",2022-02-21 16:19:12
Comment,1,hxty9pf,,0,1645451769.0,">Your 4th point is just ridiculous. How on earth does a degree become ""defunct""?

When the degree no longer exists. 

> If you want potential employers to know what you studied in uni, just show them your transcript. 

I posted a Jr. DS role on Friday at 7pm that has 60 applications as of today. Potential employers a) sure as shit aren't going to look at your transcript, but more importantly b) are forced to make some snap judgements on candidates to get through backlogs that may by 500-1000 candidates deep *per role*. 

Im not saying the knowledge you acquired is obsolete. I'm saying the degree - and the marketing value that comes from the title - do get heavily impacted if the degree is defunct. 

>I'm currently doing my bachelor's in DS and it's just maths, stats (theory and applied), CS (algos, data structures, computability etc.) and ML/AI. In what universe do these skills ever become ""defunct""?

I should have clarified  that this point applies to MS degrees - not really to BSs. At least not nearly as much.",2022-02-21 15:56:09
Comment,1,hxty5u4,,0,1645451712.0,"Education programs teach you the tools to understand what is happening and equip you to make your own metrics. While the theory is long winded and frustrating, I trust the work of people who go this route far more than otherwise. I have horror stories of cleaning up the mess of data scientists coming from non stat backgrounds.",2022-02-21 15:55:12
Comment,1,hxtxwka,,0,1645451576.0,"How do you aquired this data? Did you entered a contract with the provider, even something implicit like ""who ever downloads the data enters a contract...""?

I for myself would consider any data, which i don't collected myself, as someone elses. The risk for me especially for commercial use would way to big. And legal consequences could be quite serious.",2022-02-21 15:52:56
Comment,1,hxtxubl,,0,1645451544.0,"Bro. It's not you, it's them. Your process is spot-on, you're doing most of the things as I would do them. Personally I think the main ""problem"" for now is the relocation and work permit situation, some companies are just too lazy to do that. I don't think the word of a random Redditor counts for much but keep going, you'll surely get there eventually.",2022-02-21 15:52:24
Comment,2,hxtxub7,,0,1645451544.0,"I agree with all you said plus one more possibility, OP may just not be qualified for a promotion. 

They aren’t just given away after X years or completing Y tasks. You have to show depth of ability, aptitude and well kiss ass to get them. The company would be perfectly okay with you sitting in your role with zero change for the rest of your life. Either you stand out in a big way (hard to do) or you go looking for more opportunity (internally or externally).",2022-02-21 15:52:24
Comment,2,hxtxtlm,,0,1645451534.0,Isn't all this data available right on data.cms.gov via direct download or api? Seems silly to charge for it.,2022-02-21 15:52:14
Comment,5,hxtwzfr,,0,1645451084.0,"“ Why is learning it now based on the miniscule probably you'll actually use it better than learning it later in the scenario when you have to use it?”

(1) when you memorize and understand something, it changes how you think.  You can spot parallels you otherwise would not be able to.  If somebody applies a model in a way that is stupid, it is of no help that there is a book somewhere that shows it is stupid.  You need to recognize it as stupid when you see it.

(2) memorization frees up working memory.   Working memory is incredibly scarce and is is integral to performance iq.   Very smart people can do 9 or 10 digits backwards.  Average people can do 6 or 7.  In both cases it is not very much.  Long term memory does not clutter short term memory.  If you need to store several concepts about an algorithm in working memory,  you will not have enough working memory to do the programming.",2022-02-21 15:44:44
Comment,1,hxtwatu,,0,1645450707.0,"Hello everyone,
I am a senior business student majoring in Business Analytics and minoring in Marketing.
I need some real-life project ideas that I can work on as my graduation project;
Anyone who has any idea or a source that can help, please do not hesitate to share it with me.
That will help a lot;
Thank you so much, everyone.",2022-02-21 15:38:27
Comment,1,hxtvnzh,,0,1645450357.0,What's the good university you speak of?,2022-02-21 15:32:37
Comment,1,hxtvei3,,0,1645450210.0,"Hi u/ryukakaria, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 5 karma.",2022-02-21 15:30:10
Comment,1,hxtun7c,,0,1645449779.0,My guess is op web scraped it and thinks that’s worth a price.,2022-02-21 15:22:59
Comment,1,hxtu3hx,,0,1645449468.0,"It is always, always, the last half of your last sentence. They'll find money to replace someone if they leave...it's not a high enough priority to them to deal with fighting to keep you.

At big companies, I mean - small companies may not have the money. And, to be fair, it's not always worth it to keep someone. They are not always making that decision incorrectly.",2022-02-21 15:17:48
Comment,3,hxttyd3,,0,1645449384.0,"As someone who works with that kind of data day in day out, whether it’s private or public data, it’s worth a big fat 0$ :)",2022-02-21 15:16:24
Comment,1,hxttvvr,,0,1645449341.0,"To master matplotlib, just need these 2 tutorials:

- [OOP API](https://nbviewer.org/github/jrjohansson/scientific-python-lectures/blob/master/Lecture-4-Matplotlib.ipynb)
- [Using MATPLOTLIB effectively with pandas](https://pbpython.com/effective-matplotlib.html)",2022-02-21 15:15:41
Comment,1,hxttvhi,,0,1645449335.0,"There's a very weird fetish for overly esoteric and theoretical stats knowledge I'm seeing here. I nearly bursted out laughing when people were mentioning sigma algebra, that's a dead giveaway they're still in school and not working. 

Usually intuitions of something matter and not being able to solve huge problem sets or know 200 proofs indeed. You will definitely forget the proofs along the road, all you'll be left with within heck even 1 year are those high-level intuitions and it's debatable you had to go through the proofs and derivations for that. 

For example, before learning about the geometric and algebraic derivations of L1 and L2 reguralisation I knew ""makes weights small and makes weights sparse"". The derivations just made me go ""hmm cool..."", it didn't give me anything extra of practical value.

To finish it off, I ""learnt"" so much cool stuff in my masters like topic modelling, LSI, an entire hoard of graphical modelling but it was all theory and math like training LDA with gibbs sampling by hand. I can't say in good faith that I'm good at stuff like NLP because 10 page problem sets do not teach you s h i t.",2022-02-21 15:15:35
Comment,3,hxttm6r,,0,1645449179.0,"It depends. If you believe that winter and summer are two separate clusters whose intracluster variance is caused by the same factors, this approach gives you better certainty on those other factors. Assuming absolutely no pooling (that is, building two separate models), you'll get wider standard errors on both of your models.

As a related problem, if there are some common factors between the two clusters, building two separate models will reduce the predictive skill of both models. Keeping everything in the same model and adding a random intercept (or even a few random slopes) reduces MSE by letting you take advantage of various shrinkage techniques.",2022-02-21 15:12:59
Comment,2,hxtt7ba,,0,1645448929.0,"Awesome! That's a great suggestion indeed!

Feel free to create an issue or PR if you want to! :) Otherwise, I'll probably look further into this somewhere in the near future.

My (only) remark atm; users still need to call `.show_dash` instead of `.show`. And as `.show_dash` has (somewhat) different parameters than `.show`, I'm not really keen on wrapping the `.show` method as well. So in the end, if the user should call `.show_dash`, he or she can also wrap the figure in the same line of code...

I also wonder whether we could even go further and optimize the plotly.express interface. Instead of adding the data as `x` and `y` (and thus suffering from the very slow constructor) you could possibly create an empty px figure and add the large data as `hf_x` and `hf_y`?",2022-02-21 15:08:49
Comment,3,hxtsnrn,,0,1645448599.0,"that’s what they say…
and the next day you wake up without kidneys",2022-02-21 15:03:19
Comment,5,hxtsjr7,,0,1645448531.0,"Don't worry, I'm in Europe too, stats masters aren't job training at my alma mater - not at all. I agree with everything you said 100 %, that's exactly how I feel about it as well and why I have two masters. 

The reason why some posts trigger me is that they kind of imply one masters is better than the other for data science when imo they're just different and they are actually complementary. My previous workplace had mostly quantitative business and CS masters working as data scientists. There was a huge cross pollination of knowledge between both groups.

I will most likely do a master in stats somewhere down the road myself, not because I need to but because, as you say correctly, it's about intellectual enrichment.",2022-02-21 15:02:11
Comment,1,hxtsfmu,,0,1645448460.0,"Is this approach good enough to capture the differences though? Can one variable actually be that good at separating the data, or would it make more sense to have two models, one for summer and one for winter?",2022-02-21 15:01:00
Comment,1,hxtsfj4,,0,1645448459.0,">Do you know what geom function produces a visualization like this one? I belive this one will tie in nicely with what I want to show.

  
`library(ggplot2)`  
`dd <- structure(list(`   
`states = c(""A"",""B"",""C"",""D"",""E"",""F"",""G"",""H"")`   
`,values = abs(rnorm(8)))`   
`,.Names = c(""states"", ""values"")`   
`,row.names = c(NA, -8L)`   
`,class = ""data.frame"")`  
  
`ggplot2::ggplot(dd)+`  
  `geom_col(aes(x = states,y=values))`",2022-02-21 15:00:59
Comment,1,hxts5ue,,0,1645448291.0,"It is part of data science. This stuff is hard. I look at what types of errors the model is making and see if anything in those rows can offer some clues. 

I also experiment with model types to see if it helps. Sometimes you just don’t have the right features to be able to predict accurately.",2022-02-21 14:58:11
Comment,7,hxts3sm,,0,1645448256.0,most states collect this data PUBLICLY for researchers to use. fuck off.,2022-02-21 14:57:36
Comment,0,hxtrow0,,0,1645447996.0,"> Plus if you ever want to go for researchy positions or a PhD the theory will come into play.

Why is learning it now based on the miniscule probably you'll actually use it better than learning it later in the scenario when you have to use it?

>The tools are easy to get on ones own but the theory isn’t.

This entire thread wreaks of people who have never worked at a real company where you have to get the tools to work in the company's environment with other people on board. As if everyone is a genius who is going to apply an arcane theory from his mathematical stats course perfectly when the time arrives.",2022-02-21 14:53:16
Comment,1,hxtrlzr,,0,1645447946.0,"While that filter is weakening, there is certainly still an ""HR filter"" out there in many organizations where a graduate degree is necessary to be considered for data science positions. 

If you have the prerequisite skills necessary to operate as a data scientist in private industry, I think there's probably still a value in getting a graduate degree for a material portion of the workforce. But, I think a value-conscious ones programs that are in the $8-12k total cost of attendance range like the Georgia Tech or Texas programs are the leaders in this front.",2022-02-21 14:52:26
Comment,21,hxtr1l1,,0,1645447590.0,"I appreciate the optimism here, but I strongly disagree.

> Learn hadoop, spark, dagster, airflow, prefect, trino, hive, tensorflow, keras, mlFlow, guild.ai, rabbitmq, kafka, kubernetes, etc etc on your own time.

How about OP, in a MS stats program doing ~10 page practice sets in mathematical statistics *just learn Hadoop/Hive in his free time*, no big deal.

> **Sure you can solve real world problems,** but you will lack the understanding if you end up in a company that wants to use more novel algorithms as you would be expected to understand the actual math before you can implement it.

Solving real world problems is almost entirely what matters.

>Trust the process OP and learn all those integrals and theorems as it will sharpen your brain

There is very little strong evidence in educational psychology that [transfer of learning exists](https://en.wikipedia.org/wiki/Transfer_of_learning). Psychologists have been researching this for a hundred years and the evidence is bleak (learning Latin does not making learning Spanish that much easier). Turns out when people take Ancient Greece 101 most of what they retain from that 5 years later are high-level basic facts about Ancient Greece, not some 'higher level of understanding' whatever that is.

I have never once found a use for Green's Theorom.

All this wreaks of optimism (sales) trying to justify high price tags of universities teaching borderline useless content. The reason these programs are taught as purely mathetical stats is because the professors are tenured and have no idea how to program/code and it's impossible to get rid of them.

If you end up in a situation where you need a specific theorem go find that theorem then and there. **There is only one way to get to Carnegie Hall, practice.**",2022-02-21 14:46:30
Comment,2,hxtpybb,,0,1645446885.0,"I strongly disagree.

> Doing the hardest version of whatever you're trying to do is never a waste of time.

The idea that 'learning how to learn' happens has little empirical base ([see the transfer of learning research](https://en.wikipedia.org/wiki/Transfer_of_learning)).

>how are you going to verify the work is actually any good?

By statistical analysis (regression/casual inference) on actual data and external validation.

>Which you'll be able to breeze through

Strongly disagree. 10 years from now the idea that he went through 1 out of 200 proofs ten years ago will have little value -- writing up code to integrate RabbitMQ with python and leaving it on github absolutely will have value.

I'm sorry because this isn't considerate, but there is absolutely no way you've ever built a working data product at a company.

Maybe you're actually in a more frontier tech company (myself datascience at FT200 big bank), but this advice is terrible for the average smart person who needs a job.",2022-02-21 14:34:45
Comment,1,hxtppqg,,0,1645446732.0,"I'm not a stats major, I'm a phd student who basically uses applied stats in everything I do... but I'm lucky that my school and program is flexible enough to allow me to learn BOTH applied stats and theoretical stats. I wouldn't really call myself a data scientist, but as someone who uses data science and a little ML, you do wanna have working knowledge of WHY the LASSO gives sparsity and what regularization IS anyways from a math standpoint.",2022-02-21 14:32:12
Comment,1,hxtp8k3,,0,1645446408.0,"Failing is only relative to a baseline, so make sure you have a good baseline. How good would a randomly performing model do? If your model replaces a human, how good would that human do given the same amount of time and data?",2022-02-21 14:26:48
Comment,1,hxtp55g,,0,1645446342.0,"It’s actually genius, OP’s ROI will be literal infinity. You’re just mad you didn’t think of it first /s",2022-02-21 14:25:42
Comment,4,hxtoa8e,,0,1645445749.0,"Most companies I’ve worked at use an annual performance review - merit/promo cycle. Once a year employee’s performance is formally “evaluated” and recorded and then used to help inform merit decisions (what % salary bump) and promotion decisions. When this annual process occurs normally it is called “in-cycle” and when it occurs at some other time it is “out-of-cycle”, as in “our Sr. DS got an offer from our competitor, so the director promoted him to Lead DS out of cycle”. In my experience, out-cycle raises/promos usually happen because of (a) somebody X is going to quit so they give X a bump in salary/title to keep them; (b)  somebody X does quit, transfer, get promoted and as a result they need to promote person Y to replace X. A related annual or semi-annual process is used to establish salary bands for roles/levels - I’ve been working with HR/compensation to help establish this at my own company. Basically compute the salary distribution across roles and geographies and use this to inform new offers, but it can also be used to compute annual salary adjustment (to offset inflation, job demand, etc.). I’ve worked at very large companies (and it sounds as if you may as well), and their HR/compensation & general corporate processes can be very slow making it bothersome to quickly re-level our add a new role to a job family. But as far as promoting somebody from level n to n + 1 for an existing role, that is easy and is done all the time, but as in all things business it always comes down to money (is there enough of it?) - to me it sounds like your department doesn’t have enough existing budget surplus and the director feels they would unlikely be able to beg money for your promo from the hire ups. The “positions need to be available” is code for they don’t have the money or they don’t want to spend it on you.",2022-02-21 14:15:49
Comment,7,hxtnpok,,0,1645445334.0,"Data, I'm your father",2022-02-21 14:08:54
Comment,1,hxtnmz8,,0,1645445278.0,"> There's basically no working with data. How can you train in statistics without working with real data? There's no real world value to any of this. My skills as a data scientist/applied statistician are not improving.

[The Case Against Education](https://www.amazon.com/Case-against-Education-System-Waste/dp/0691174652)

MS Applied Economics here -- such much calculus and a ridiculous waste of time.

Every transaction benefits both parties, often asymmetrically. In this case, the professors with vast knowledge of rarely useful mathematics benefit greatly...you much less so.

Do your best to re-do all the questions/problems in python (what I did in my MS).",2022-02-21 14:07:58
Comment,1,hxtnk9a,,0,1645445223.0,You’re arguing a point I didn’t make.,2022-02-21 14:07:03
Comment,19,hxtn0ch,,0,1645444819.0,"I know things are a bit different in the US, especially because you're paying so much for school, and the history of the institutions is different, but I feel like my stats masters in Europe is not about job training, it's about intellectual enrichment. You get to sit in class and work on questions which are interesting and fun. I think most university degrees give you a huge toolset that you only use 25% of directly, but you won't know which 25% you're going to want to use later. Not every skill you learn needs to be put towards making someone else money later, some of it can just be for you",2022-02-21 14:00:19
Comment,1,hxtmnyr,,0,1645444561.0,Is your data labelled?,2022-02-21 13:56:01
Comment,2,hxtml3i,,0,1645444502.0,I am sorry I don't know what that means.,2022-02-21 13:55:02
Comment,1,hxtmkuj,,0,1645444497.0,I work for a very big company so the process is highly formalized.,2022-02-21 13:54:57
Comment,1,hxtmfso,,0,1645444391.0,"Your 4th point is just ridiculous. How on earth does a degree become ""defunct""? If you want potential employers to know what you studied in uni, just show them your transcript. If your degree doesn't provide you with a strong math foundation for statistics, then you haven't really been studying data science, and that will be evident in the transcript.

I'm currently doing my bachelor's in DS and it's just maths, stats (theory and applied), CS (algos, data structures, computability etc.) and ML/AI. In what universe do these skills ever become ""defunct""?",2022-02-21 13:53:11
Comment,15,hxtmdnf,,0,1645444346.0,You're saying that you want to charge me for data that I can obtain on my own for free?,2022-02-21 13:52:26
Comment,3,hxtmbmj,,0,1645444304.0,What is the data's lineage?,2022-02-21 13:51:44
Comment,2,hxtlqfr,,0,1645443854.0,I will DM you!,2022-02-21 13:44:14
Comment,-2,hxtlpvl,,0,1645443843.0,100% legit. Its completely legal,2022-02-21 13:44:03
Comment,-5,hxtlnwc,,0,1645443801.0,100% legit my dude,2022-02-21 13:43:21
Comment,-9,hxtlncv,,0,1645443790.0,"well, its publicly available and perfectly legal. DM me if you wanna know more. I don't wanna divulge a lot",2022-02-21 13:43:10
Comment,-2,hxtllyw,,0,1645443760.0,no its not identifiable. And its completely legit.,2022-02-21 13:42:40
Comment,6,hxtlksi,,0,1645443736.0,Hey man if you let me take a look at it first i can give you a reasonable quote 😉,2022-02-21 13:42:16
Comment,3,hxtlcdr,,0,1645443553.0,"That makes sense. All recent grads I’ve worked with, had BSc.

Yeah I’ve noticed that version control isn’t a norm with data science and data analysis people. In my first job (data analysis) we weren’t using any version control. 
All analysts were sharing code through slack messages, multiple people working on multiple versions. Stuff breaks and you don’t know why and who did what. It was a nightmare.

After working together with engineers, I suggested to my manager that we should learn how to use git. But he didn’t think that is that important and we could “look into it” when we finish multiple projects that required us to write code SQL.

Now I work as engineer and seems weird that it isn’t a standard as it saves so much trouble and is really easy to use (at least the basic git workflow)",2022-02-21 13:39:13
Comment,10,hxtl3z8,,0,1645443368.0,"If it’s identifiable $0

If you can’t share the source $0

If it’s legit claims data $0",2022-02-21 13:36:08
Comment,2,hxtl11g,,0,1645443303.0,🍿,2022-02-21 13:35:03
Comment,4,hxtk61g,,0,1645442632.0,"Distributed systems is a mandatory course in the MS CS at my alma mater. I expect the same from any self respecting CS masters. Other courses such as large scale ML and/or data mining which you can take in an MS AI cover the fundamentals but not everything.

Clean code is something you learn through doing, not upon graduation but honestly the bar is low compared to stats people. I got praised in several posts for recommending to use git. That shows how ridiculously low the technical ability of the people in this sub, which seem to be predominantly stats folks, really is. If I wrote that in any sub where CS folks are in the majority, heck even r/MachineLearning I'd be downvoted into oblivion for stating the obvious. Barely anyone is taking anything to prod here as well, I get the sense that it's just models in notebooks.",2022-02-21 13:23:52
Comment,8,hxtjddd,,0,1645442001.0,$0,2022-02-21 13:13:21
Comment,1,hxtj1gp,,0,1645441738.0,"the issue is that CS grads don’t know how to write clean code and from my experience, they don’t know much about distributed system design.

clean code people learn on their own and if they work in an environment where those practices are enforced and more senior colleagues mentor more junior members.

For distributed systems, I am not sure how much grads know about this either. I dont have CS background, but from fre ca grads I’ve worked with (BSc), none of them knew much about it.
People usually buy tectbooks and learn that stuff on their own (at least this is my case and what I notice from colleagues)",2022-02-21 13:08:58
Comment,6,hxtiy9o,,0,1645441664.0,sus,2022-02-21 13:07:44
Comment,1,hxtirk0,,0,1645441511.0,"Hi u/StunnerBI, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 11 karma.
* **Videos are not allowed.** Submissions from youtu.be are not allowed on r/datascience.",2022-02-21 13:05:11
Comment,1,hxtip05,,0,1645441452.0,"Hey,

I'm a DS with 2 years of experience under my belt and am currently looking for a new position but am having trouble re: interviews.

The process is usually quite simple, I apply for jobs I find on LinkedIn via the company website if possible, move on to HR interview, then get given a hiring manager interview / take home task / 40min screening quiz.

I'm currently struggling at this point and I feel quite stuck. I feel like something may be wrong with my preparation methods and I wonder if anyone could give me any advice.

For the hiring manager interview I usually prepare by looking at what projects the company is working on, either via the job listing or by looking at their DS staff on LinkedIn and going by their listed projects. And from there I prepare some notes about projects I have worked on that seem to relate, including any tools I've used and why. This usually helps me out quite a bit and short of being asked a very specific question about an algorithm I feel quite prepared. However even if this interview goes well I usually don't get to the next stage.

For screening quizzes I do a few LC questions a week to make sure I am prepared, as well as some consistent SQL revision. Often for these I can answer all the questions and have time to spare, however when given specific questions i.e. if lasso regression should be used in x situation and what difference would there be if I used ridge instead. What are p, d, q in ARIMA. etc. I fail to write answers I'm confident with, even though I have used these methods in my working life. How can I best prepare myself for these situations short of memorizing ISLR word for word? I revise frequently and have made some flash cards but I still lack the confidence.

Take home tasks are a mess as well as often you receive little to no feedback (most recently I had feedback that I had a spelling error in one of the comments ???). I'm curious as to if there is a standard to how these tasks should be completed. They're often a dataset, some vague questions and then some more in-depth questions. Currently my working process is to work out of a Jupyter notebook, do some EDA, basic modelling, comment everything, make proper functions so that it's not just a messy notebook. Focusing on choosing the right model for the given scenario, answering the basic questions with proper explanations and then hashing out the in-depth questions making sure I've covered all my bases. I'm often quite confident for this round but I'm not getting any further so there must be something wrong.

&#x200B;

I'm getting a little frustrated and would like to fix any mistakes I'm making. I understand that there are other candidates that are more educated / more experienced than I am and want to know what I should improve in but the feedback loop isn't there.

I'm a non-US / non-EU citizen and the positions I'm applying for are based in the EU and offer relocation when I bring it up during the HR interview. It also worries me that because of the extra effort needed to hire me I will really have to be head and shoulders above the rest before I am even considered.

If anyone has any advice I would be very grateful.",2022-02-21 13:04:12
Comment,6,hxtiod9,,0,1645441438.0,Yep sound sus,2022-02-21 13:03:58
Comment,13,hxtil0d,,0,1645441365.0,Where did it... come from?,2022-02-21 13:02:45
Comment,1,hxtibpt,,0,1645441156.0,"They are widely used in scenarios when number of true negatives is unknown or can't be even defined, for example in image detection. Lets say lake contains rocks of all different sizes down to the size of sand.  You're not sure how to even count them: is 1 cm enough to call it a rock? Is 2 mm enough? Should you count every grain of sand?  For which depth?",2022-02-21 12:59:16
Comment,1,hxti0zd,,0,1645440910.0,"Hi u/StunnerBI, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 11 karma.
* **Videos are not allowed.** Submissions from youtu.be are not allowed on r/datascience.",2022-02-21 12:55:10
Comment,1,hxthmte,,0,1645440583.0,"Also ROC curve is Recall vs FPR graph, where FPR = 1  - specificity. So ROC is basically upsidedown sensitivity vs specificity graph.",2022-02-21 12:49:43
Comment,1,hxth6h0,,0,1645440210.0,"Imho harmonic averages behave closer to minimum of the two, rather their mean. And it is exactly the reason why they use harmonic mean instead of arithmetic one: it is easy to get 100% recall (capture everything without even looking), or very high precision (reject almost everything, and only keep the very obvious). Both of the strategies will score about 50% average for a complete garbage classifiers. But if you use minimum of the two, or harmonic mean, the score will be near zero, making the fact that classifier is a garbage more evident.",2022-02-21 12:43:30
Comment,2,hxtgpkl,,0,1645439820.0,"If you're just going at the city level there's no geo-spatial component. If you want to get more granular than that, between the neighborhood and the street corner, you can treat it as a graph; if you need to also include distances, a weighted graph should suffice. It's only when you need to get even more granular than the city block where a discretized locational model might not be as useful as a continuous one.

Refine your requirements.

Also, I recommend directing your questions to data scientists specifically working for companies such as Waze or Lyft, as they would have more experience than me in this regard.",2022-02-21 12:37:00
Comment,1,hxtgf8k,,0,1645439583.0,"I usually use criminals analogy: 90% recall, 60 percent precision means system can detect 90% criminals, but if it captured a person, there is 40 percent chance that person is innocent. So such system is good for mass screening, but bad for accusing, just like gate detectors in shops. 10% recall 99 percent precision means that system will find only a small fraction of criminals, but if it alarms at someone, you're almost certain that you captured a criminal, just like a random chemical analysis drug test at airport security.  I like your analogy more, however.",2022-02-21 12:33:03
Comment,1,hxtge6j,,0,1645439559.0,"Generally you should be able to see a curriculum that shows the courses and their subject matter. I'm not really sure how you'd filter out statistics programs that are more applied because from my experience they almost never have been, but perhaps you could look for mentions of ""capstone projects"".

Econometrics definitely tends to be more applied than statistics subjects, and that's where the applied portion of my PhD's coursework focus was. I would always recommend a DS/Analytics program over Statistics, unless you are going into some research heavy DS field that requires you to read and understand academic papers to innovate or invent something different. In the latter case, a computer science program would probably be better supplemented with some electives in Statistics.",2022-02-21 12:32:39
Comment,1,hxtffy5,,0,1645438758.0,"I did a MS in Stats and the required courses were mathematical and proof based, but there were plenty of application focused electives. Perhaps your program is the same. Btw, the rigorous mathematical stats and probability courses have helped me in learning new topics on my own. But that is just my experience.",2022-02-21 12:19:18
Comment,1,hxtdvry,,0,1645437462.0,"Any real experience is valuable for getting hired, so whatever you can get your hands on is great (research, industry etc). But as the others said, for your own learning and growth, industry experience is more valuable. Once you leave academia and get a full time position, you’ll rarely if ever talk about your research in further interviews (as employers will care about your actual experience), or reference anything you did (except the basics or learning tools/ processes)",2022-02-21 11:57:42
Comment,1,hxtca81,,0,1645436110.0,"Hi u/pontificating_panda, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 1 karma.",2022-02-21 11:35:10
Comment,1,hxtc1mi,,0,1645435915.0,"If you're only going to read one book about good software practices, read [The Pragmatic Programmer](https://www.amazon.co.uk/Pragmatic-Programmer-Andrew-Hunt/dp/020161622X). It's language-agnostic and teaches you more about the *why* of good practices than the *how*, which are often language specific, e.g. PEP8 for Python.",2022-02-21 11:31:55
Comment,1,hxtazd1,,0,1645435028.0,"do not confuse causation and correlation, please",2022-02-21 11:17:08
Comment,1,hxt9tv8,,0,1645434063.0,Thanks for your suggestion,2022-02-21 11:01:03
Comment,2,hxt9h7v,,0,1645433770.0,The computational data science program is 100000x better.,2022-02-21 10:56:10
Comment,3,hxt9et0,,0,1645433716.0,People who can only do theory and not code are either the most advanced pure math/stats phd or pretty useless. Maybe you are Terence Tao but I am just trying to give the rest of us some more sensible advice,2022-02-21 10:55:16
Comment,1,hxt92oc,,0,1645433440.0,"You don’t have to be working on torch source code to run into numerical optimization issues; belief propagation algorithms naturally run into numeric issues from dealing with arbitrary small probabilities and as of 2 years ago I was unaware of any reliably tested and performant libraries for them. And I remember the mcmc library had a lot of issues as well. 

But such libraries would be useful and necessary to anyone doing research in the space. If ur a stats major and you want to do research here, your coding has to be pretty sharp as well as your math. Unfortunately, my coding abilities just didn’t cut the mustard for that level and that’s why I regret not prioritizing cs earlier.",2022-02-21 10:50:40
Comment,2,hxt8k9p,,0,1645433021.0,You're right that was shitty of me.,2022-02-21 10:43:41
Comment,8,hxt85ol,,0,1645432685.0,Well newton made calculus during the plague of his day :) so it would be more accurate to say he got calculus from Covid,2022-02-21 10:38:05
Comment,4,hxt84kf,,0,1645432660.0,"I think it’s quite strange to consider the counterfactual as you suggest. If I was instructed on X, no matter what X is, I believe I have a decent chance of telling you about X. That’s a measure of smartness, not a measure of understanding. Point is, Newton didn’t understand modern analysis, so the criteria of requiring someone to understand modern analytical proofs today to say they “understand calculus” does not ring true to me.

I trust most CS degrees could understand moment generating functions if they were forced to take a semester long course on probability theory.",2022-02-21 10:37:40
Comment,3,hxt80lo,,0,1645432568.0,"Biostat job opportunities tend to be worse though, especially if you don’t like writing. It is harder also to get a DS job with a biostat degree than a stat degree. The industry stereotypes the field as a SAS/regulatory/clinical trial degree even if that isn’t the case. Basically Biostat is defined differently in industry vs academia.",2022-02-21 10:36:08
Comment,4,hxt7w0t,,0,1645432462.0,"""Learn hadoop, spark, dagster, airflow, prefect, trino, hive, tensorflow, keras, mlFlow, guild.ai, rabbitmq, kafka, kubernetes, etc etc on your own time"" - Yeah sure thing bud! If you are in a competitive MSc. in Statistics you barely have time to get done with class projects, let alone learn also all this (and many more frameworks, libraries). When you start in industry it will be even harder to find free time on your own to learn all of them.  Truth is a Masters in CS, and learning the Stats on your own would be much more efficient use of time. Plus Data Engineering, Dev Ops, MLOps etc. are much more sought after skills in the industry - Sure a master's in statistics would not be bad if you pursue PhD, postdoc and move on to more specialized positions like R&D or academia. But truth is , what is the market share for those positions requiring such a skillset, as compared to the ones I mentioned. In the end it boils down to what OP is interested, but this is just my 2¢",2022-02-21 10:34:22
Comment,1,hxt7i38,,0,1645432140.0,"As another graduate from pure math degree, I agree. A first level course in probability and statistics is more than enough. This is what all of engineering department including CS learned at the university. Lot of ML/AI stuff used in industry is actually taught in a good CS program with rigor.",2022-02-21 10:29:00
Comment,1,hxt7gua,,0,1645432112.0,Added in description now,2022-02-21 10:28:32
Comment,1,hxt7fah,,0,1645432075.0,"So much DL research is still just building models in PyTorch though, which is far different from building PyTorch itself. Have you actually heard of people having to say modify the autograd/computational graphs or mess with the compilers in DL research? Is that where the field is headed?

Thats the place where a CS background can help for sure, but otherwise if coming up with a new architecture/layer, loss fn, interpretability method, or application those papers just seem to use PyTorch basically as a fancy calculator with the main focus being the other stuff.",2022-02-21 10:27:55
Comment,1,hxt7bi1,,0,1645431987.0,"Excellent, thanks so much for the explanation, this is very helpful. I actually just implementing mlflow tracking for the positive and negative class in train and test set.  Thanks for the tips, they will not go unused!",2022-02-21 10:26:27
Comment,1,hxt78v1,,0,1645431928.0,"I think economics can be the perfect masters for data science, if the program/department has a strong focus on applied econometrics. You learn applied statistical methods for answering questions, and if your program is good you will be taught to how to approach the results with a critical eye",2022-02-21 10:25:28
Comment,2,hxt6uuf,,0,1645431604.0,Impossible to make that decision without seeing the course content.,2022-02-21 10:20:04
Comment,1,hxt6m7i,,0,1645431408.0,"Im a lawyer in my 40s and I am interested in developing a product or service that relies on data but not sure what aspect of data science I should get into. What I want to achieve is to develop some program that could make sense of data in a particular field (i.e. let's say, the legal profession) and make a business out of it. I don't have a particular idea in mind, just the field I want to get in to, and I am hoping by learning about Data Science and its potential, I can have an AHA! moment. 

&#x200B;

I am not looking to get hired as a data scientist (a data scientist lawyer? maybe)I am looking at online courses and most that I see are targeted for those a) looking to get hired as entry-level data scientists or b) those targeted to heads of business on how to harness data for their business' success. Neither fit me. I am not looking to be employed as a data scientist nor do I have a business from which to build on. I want to develop a product using data, so I want to educate myself. I wonder what I should learn to understand it's potential, but also comprehensive enough to come up with a viable product.

&#x200B;

I am not sure if I should learn all aspects of data science, from learning programming, R, python etc. Even if I learn these, I don't imagine I can code better than someone who has been learning since college. I'd probably hire coders for that anyway. At the same time, I think if I don't understand some aspects of data science then I cannot get ideas or conceptualize my plan.Any advice on what subject matters to focus on given my situation?",2022-02-21 10:16:48
Comment,1,hxt64jm,,0,1645431010.0,"Hi u/Throwmandown, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 3 karma.",2022-02-21 10:10:10
Comment,1,hxt50q2,,0,1645430132.0,"I mixed it up, but optimization itself can have root finding for the derivative since you set it to 0. I meant some function optimization that isn’t a likelihood would just be math. 

I guess there is no way to formulate a likelihood without probability though you could formulate a loss function like least squares without probability. And then it turns out that it is the same as the MLE of the normal distribution",2022-02-21 09:55:32
Comment,1,hxt4znl,,0,1645430108.0,"Unsure how historical your summer data is, but do you have features that describe the overall economy and or stock market like CPI or lags of S&P Returns? Winter loans may very well have seasonal characteristics, but the past few months have also been fairly lackluster from a market and inflation standpoint, which could impact credit quality/credit demand.",2022-02-21 09:55:08
Comment,2,hxt4umn,,0,1645429995.0,"Thanks for sharing. I was thinking about getting a MS degree in Stats, but no more.",2022-02-21 09:53:15
Comment,2,hxt4eyv,,0,1645429659.0,"Okay let me try:  
So you have different points in space and time where a departure can happen. In my example every point is a historical observation of a customer requesting a taxi to a given place at a given time.  
Those requests are city based, for example New York.  
If we now look at it really simple we can sum up all requests happening in new york at a given time. Lets resample them by hour. So now we have how many requests we have in new york per hour. Using this we could use aan LSTM to forecast requests in new york in the future. We also could include temporal features such as weather, if the day is a holiday and what day of the week the request happends.  
Now to take things further since predicting demand for the whole city may be not very beneficial we cluster the depatures by space. So for example we group the data by neighborhoods. Now we could simply train a LSTM per neighborhood. So we would have one model per neighbourhood.  
Doing this however, we loose all the information about demands happening in the bordering areas.

Furthermore introducting space features could also be benificial. So to make it even more interesting we also could include the number of people living in the neighbourhood and the number of restaurants.",2022-02-21 09:47:39
Comment,2,hxt45sh,,0,1645429459.0,"Doing biostats atm, can confirm this. We derive and go over theory, but all our actual work and assignments are fully applied.",2022-02-21 09:44:19
Comment,1,hxt2nnm,,0,1645428300.0,Microseconds from UNIX epoch,2022-02-21 09:25:00
Comment,3,hxt1fxj,,0,1645427413.0,"I can agree with all of this actually.

However in the spirit of remaining nitpicky, ISLR more than good enough with ESL as a reference when you need a more in-depth view on some things. There are serious diminishing returns on going too deep into the theory. That extra time you spent reading ESL/PRML should/could have been spent actually using these algorithms on say a kaggle dataset because that's personally where the theory really sank in. Reading these books is nothing in comparison to actually using the algorithms in practice.

I don't treat my models as a blackbox but that doesn't mean I need to remember every single detail of quadratic programming before I fit an RBF SVM. Often times intuitions are enough. You have to scope yourself in terms of what detail you're approaching learning ML. I think I can see a few of the mistakes I made in the past and I'd urge you not to make them is all.

The treating models as a black box thing is also a bit naive. They are fundamentally black boxes unless you read the source code, which may have parts implemented in Fortran or C++ because there's different routines and ways to implement a single algorithm. An example is sklearn's implementation of cart, it's definitely different than what you find in a standard textbook. In the spirit of not treating models as black boxes I sometimes read the source code. Think about it, this is what not treating models as black boxes means, not just reading PRML/ESL which provides a cookie cutter way of doing it. The time save of reading ISLR instead allows you to do this. I urge you to separate theory from reality for a second and do this as well.",2022-02-21 09:10:13
Comment,3,hxt1cfh,,0,1645427342.0,"Google SOLID coding principles. All of us SWEs swear by it, and ruthlessly mock juniors who ignore it.",2022-02-21 09:09:02
Comment,5,hxt1aft,,0,1645427302.0,"> Optimization wouldn’t be stats to me if you were just deterministically finding the roots to some equation.

This example feels off because root-finding is neither optimization nor stats. Also “formulating the likelihood function probabilistically” seems redundant; is there a way to define likelihood that isn’t probabilistic?",2022-02-21 09:08:22
Comment,0,hxt0ifp,,0,1645426755.0,Disgusting,2022-02-21 08:59:15
Comment,1,hxszzuc,,0,1645426390.0,"Well if your interested in academia generally, a paper is only going to help, and multiple papers even more so. And its not going to hurt a DS career 🤷‍♂️",2022-02-21 08:53:10
Comment,1,hxszhqv,,0,1645426049.0,"For me, the getting into grad school thing isn’t a concern. For personal reasons I’m staying at my (admittedly) lower tier university for grad school and I’ve already accepted an offer. I am excited to be able to do more though.",2022-02-21 08:47:29
Comment,1,hxszcy7,,0,1645425959.0,I appreciate it. Thank you for your thoughts,2022-02-21 08:45:59
Comment,2,hxszai9,,0,1645425913.0,"I think a PhD has a less emphasized benefit that others can apply to their education: as a PhD student, I was able to select courses in Stats and ML which were relevant to formulating and solving research problems, without getting bogged down by compulsory courses that offer little benefit for becoming a data man. Specifically, I took statistical learning, mathematical statistics, timeseries, and ML 1. With that foundation in place, I then did some couse materials from Stanford’s NLP and GNN course. I also did plenty of Pandas and PyTorch monkeying on the side. This basically amounted to a “short cut” to get to a point where I had the chops to do some interesting ML projects with the appropriate tools. I think it all comes down to tailoring your coursework to get to your desired end state.",2022-02-21 08:45:13
Comment,1,hxsz6y4,,0,1645425844.0,"See, I think you're misinterpreting. Running another A/B test again doesn't mean running the same computer model again. New A/B test means new randomization. You should never expect the same results.",2022-02-21 08:44:04
Comment,1,hxsz0fe,,0,1645425722.0,"Its such a diverse field, some people might actually go far without needing advanced stats, and power to them. To each their own, I want understanding, and dislike black boxes.",2022-02-21 08:42:02
Comment,3,hxsyx9x,,0,1645425665.0,"Hey, don't worry. You'll definitely learn a lot for sure and you'll still have a leg up on 0 experience candidates. It seems like you'll enjoy doing it as well which is actually the most important thing at this point in time.",2022-02-21 08:41:05
Comment,1,hxsxsdi,,0,1645424905.0,"Im an R guy as well, you could try plotnine https://realpython.com/ggplot-python/

Its literally ggplot, in Python, a bit more verbose with the imports but otherwise what you're used to",2022-02-21 08:28:25
Comment,9,hxsxjtn,,0,1645424746.0,"Yeah, close enough",2022-02-21 08:25:46
Comment,1,hxsxe4l,,0,1645424641.0,"It'll benefit you for grad school, for more academic type tasks you could be assigned in your future (trust factor). But don't expect omg wow bonuses for your first real job. Main benefit will be on applying to grad school. Make sure you understand and can explain everything and get hands on as much as possible. Its a cool thing to have on your resume, if it also excites you, do it! You can still work and do coops during or after, if you have nothing landed, get started and enjoy!",2022-02-21 08:24:01
Comment,1,hxsx8hi,,0,1645424538.0,"Erm, you edited your comment it's something completely different now. It used to say if you haven't read PRML yet you don't have a deep understanding of ML which is false and actually what the commenter was referring to.

Most researchers and/or people at the pinnacle of the field definitely have not read PRML. But yeah to be in line with your comment, sure they could if they wanted to.

... But to be completely honest, don't overestimate the value of such books. I've gone through two masters degrees that covered statistical learning and with the benefit of hindsight I can tell you the're a nice to have but really not essential. Big wow, now I know what `dual=False` does in sklearn.  

Do you think anyone in industry cares about VC dimensions and bounding the test error? Or about deep boltzmann machines?

The answer is no.

Again, speaking from experience I spent too much time reading esoteric nonsense. You should not be bothered by sigma algebra, nobody gives a fuck. What matters more is that you have a decent understanding of the internals of the algorithm you're using *and* you use common implementations in Python and/or R to solve problems. Theory that you can't apply doesn't matter unless you become a researcher that does 0 ML and writes proofs all day long.",2022-02-21 08:22:18
Comment,1,hxsx2kx,,0,1645424433.0,"Data Scientists are basically statisticians who can use programming languages like Python and R. I'm a plant process engineer working (primarily focused on optimization, cost savings, etc) and my job is basically like 80% data scientist/analyst, for the past few months Ive been heavily using Excel but I'm currently teaching myself R because I've realized that I'm going to need to do hardcore statistical analysis for my current and future projects. This should give you an idea that I can't just rely on statistics do my work.. I need to also have a solid background in engineering to understand and make sense of the data.",2022-02-21 08:20:33
Comment,0,hxswuyx,,0,1645424297.0,"r/datascience is a huge echo chamber and has a lot of herd mentality. Just ignore them. People who can only code won't go far in ML.

""Data science does not require advanced statistics""

Yep that's all you need to know. I come here to laugh at people's hubris and ignorance.",2022-02-21 08:18:17
Comment,-1,hxsw44q,,0,1645423817.0,"I absolutely believe that the balance was off in your program, but I’m sympathetic to the fact that school’s main purpose is theory that will almost never be learned correctly “on the job.” They have to be pretty conservative in giving up theoretical content.

On the flip side, yes it seems pretty obvious that if there’s not data involved at all there’s been a pretty big oversight.",2022-02-21 08:10:17
Comment,1,hxsvxey,,0,1645423696.0,Cool to hear- nice! Consulting was indeed the other area i've been looking into as I think it could be quite a nice change of pace to gain exposure to a number of different topics via consulting projects.,2022-02-21 08:08:16
Comment,1,hxsvuqg,,0,1645423649.0,Any tips on identifying well balanced programs?,2022-02-21 08:07:29
Comment,21,hxsvuhb,,0,1645423644.0,So Newton got Covid from Calculus?,2022-02-21 08:07:24
Comment,1,hxsvm5r,,0,1645423497.0,"The practicum through my grad program is working with companies in the area doing typical DS duties so I'm hopeful that will help. Admittedly, I've currently been struggling greatly in finding internships/full-time employment so the academic route may be my only option for now (I don't go to school near a tech hub at all. So my options are very limited outside of remote).",2022-02-21 08:04:57
Comment,1,hxsviv6,,0,1645423439.0,"Agreed. No judgement, but that theory is relevant when you actually want rigorous methods and there are fields where we really do want the rigor.",2022-02-21 08:03:59
Comment,11,hxsve1p,,0,1645423354.0,"The question is not:

“Did Newton rigorously prove his calculus correct — presumably meaning rigorous in the sense of modern analysis which didn’t exist yet”

But

“Could Newton, if he was instructed on the epsilon’s and deltas have proven his calculus.”

Your argument is the logical equivalent of saying that “you couldn’t have had COVID, you never got a positive test” when they never took a test at all.",2022-02-21 08:02:34
Comment,1,hxsv7w6,,0,1645423245.0,"Okay, that makes a lot of sense. Im going from 130K base to 154K, and bonus comp from 20K to 25K. No RSUs or options.",2022-02-21 08:00:45
Comment,1,hxsv0pw,,0,1645423121.0,"In Belgium tech related jobs, including data science, are frequently done in consulting companies so whichever my (future) boss sends me to. You can typically have 2 - 4 concurrent projects in various industries. 

Consulting firms that also have an analytics department usually mean that you'll actually be doing data science or at least advanced data engineering. That was the case at my previous place. After the summer I'm moving jobs to a similar but larger consulting firm that does more 'advanced' ML than my previous one.",2022-02-21 07:58:41
Comment,1,hxsuib0,,0,1645422802.0,I’m sometimes terrible at communicating.  I was absolutely intending to give you a compliment for articulating such an important perspective about creating.  I’m so blessed to get to work with a developer who can anticipate what users want before they ask for it and imagine the associated pitfalls.  That is empathy in code.  It’s nothing short of beautiful.,2022-02-21 07:53:22
Comment,5,hxsug8d,,0,1645422768.0,"If I may be brutally honest, it's about as relevant as building an app or website in your spare time. It shows initiative but it's also not really representative of what is done in actual DS jobs.

I cranked out internships and part-time jobs like mad during my studies and that more or less set me apart. After all was said and done it only gave me a 5 % pay raise and one promotion (\~6 months to a year of exp) compared to the other Jr data scientists for my first job. Imo this is the way because I think you could negotiate it upwards (I didn't) and good internship experience, not the summer camp style ones, set you up to grow faster than your peers.",2022-02-21 07:52:48
Comment,1,hxsu7bn,,0,1645422617.0,"**I have a data science interview in a few hours.**

I am 19 years old and have been sending cold emails to companies to get an opportunity to work with them. Somehow one of the CEO's of the companies replied to the email saying he wants to talk to me today. I told him in the email that:  
  
""I learnt a lot of data skills at my last internship, from making dashboards, to automation of reports, to python and mongodb, SQL etc and have real time experience working with it and delivering results which have led to significant data driven decisions.  
  
I know how to maintain data integrity, data governance and security and I love reading numbers.   
  
Since then I have learnt how to implement machine learning algorithms and how to use mathematical and statistical models, and ETL processes in Python. I also know how to use Business Intelligence softwares"",  
  
which is a hundred percent true. What do you think I should keep in mind while giving the interview, also it shouldn't be that complex since this is a newly funded start up so I am not asking for high level advice. What do you think are some questions that I can be asked?  
  
I am afraid that to some of you this might sound amateurish, but please keep in mind that this will be my first internship and I am a beginner right out of high school. Thanks.",2022-02-21 07:50:17
Comment,1,hxstu0p,,0,1645422396.0,"Good point - i think to keep looking and working on side projects to stay sharp is probably the best option for now. Thank you! Out of curiosity, what industry do you levitate more towards?",2022-02-21 07:46:36
Comment,3,hxstn6t,,0,1645422281.0,"When my model does not work, I look at my training data and see if some classes are over/under represented. I also look at the features and try to find the correlations between them and the prediction.",2022-02-21 07:44:41
Comment,3,hxstl33,,0,1645422246.0,"I know you're not complimenting me but your comment makes me feel good vicariously. You get it. You see what the profession can be, what we can do.",2022-02-21 07:44:06
Comment,1,hxst780,,0,1645422011.0,"Hi u/datacringe, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 1 karma.",2022-02-21 07:40:11
Comment,2,hxssjtw,,0,1645421623.0,"If you can tell me what a better route is that allows for you to be educated appropriately in the fields that need it and the hands-on applied practice, let me know. 

I think ""Data Science"" programs are too light on both coding and theory. 

Stats programs may or may not be applied, and traditional stats is the foundation of a lot of data scientist work but not at the forefront of daily work. 

CS would give you the coding skills but none of the real understanding of the theory underlying the foundation of inference.

And stats+CS is still not going to make up for the domain knowledge any job is going to require you to end up using. Business analytics, biomedical fields, making a self-driving car's models... There is no class in a Stats or CS program that will teach you these.

Data science is a very wide field and there are lots of ways in and none are going to be perfect.

Sincerely, someone also in a Stats MS right now.",2022-02-21 07:33:43
Comment,2,hxss0th,,0,1645421310.0,"First off literally all that matters is your compensation. If they're paying you the same or more, even if you have a lower title to start, that's actually a good thing as you have more room to move up to a similar role you had previously and make even more money. I'll use myself as an example I live in a medium cost of living area and was basically the tech lead of my team within a small company making 90k and I got an offer from a large company for 120k as a senior analyst where I was one of many with that title. I have since excelled and was recently promoted to the level between senior analyst and tech lead and am at 160k base and 30k RSUs. I fully expect to be promoted to tech lead next promotion cycle where I'll be at 200 base plus solid equity.

The bottom line is a tech lead at a small company is less responsibility than a tech lead at a large one, but a lot of your experience will transfer and you'll likely advance quicker in your new company given your previous experience, and you'll make a ton more money since your salary goes from a large consideration to a rounding error in your business. My current company's net income is in the 11 figures. There are a lot of employees, but when you're high up in the data science org you're adding a ton of value, and they have the money to compensate you fairly.",2022-02-21 07:28:30
Comment,2,hxsrwop,,0,1645421240.0,"I’m blessed to work with a developer who takes pride in his work these last 15 years.  When he quotes me a job I’m often surprised that the majority of the effort are not on the thing we directly asked for, but often the issues those requests create that users often don’t even know to expect.  It’s an amazing intuition that he possesses on how what he creates effects others…",2022-02-21 07:27:20
Comment,1,hxsrigf,,0,1645421006.0,Not me lurking through what the comments say about us self-taught/on-the-job folk with completely irrelevant degrees…,2022-02-21 07:23:26
Comment,1,hxsqwy2,,0,1645420660.0,"There's no straightforward answer to this. What do you value more, money or job satisfaction? Personally I'd favour the latter but a 35 % pay cut is too much to get better job content.

I'd say: keep interviewing, maybe some place will match your salary down the line. This may just be me but I don't interview at pharma, finance or any highly regulated industry with tons of legacy software. The odds of being in a situation like yours is so much higher there. Obviously there are exceptions so you need to take it on a case by case basis.",2022-02-21 07:17:40
Comment,1,hxsqlx9,,0,1645420483.0,"I think my argument will be that it is only in very rare situation would a MS Stats be preferred over MS CS. Or a bachelors or a PhD. Someone who can code but needs to learn the topic is always preferred over someone who knows the math but can’t code, whether it’s in research or industry.

The best move for getting into deep learning is to do a dual bachelors in math and cs imo, but that is very challenging and requires sacrifices to personal life/health. Speaking from experience",2022-02-21 07:14:43
Comment,1,hxsq53b,,0,1645420214.0,"Isaac Newton never proved calculus “rigorously”, but it would be very difficult to say he didn’t understand it. At some point your intuition is at a “good enough” level.",2022-02-21 07:10:14
Comment,2,hxspyar,,0,1645420106.0,"You’ll also have to be able to code very fluently, and understand pytorch modules, and understand numerical methods. Deepmind researchers only have relative weaknesses, in absolute terms they must be literate on many math/cs/stats areas",2022-02-21 07:08:26
Comment,3,hxspxnu,,0,1645420095.0,"""... big boy data science job ... bomb-ass code...""

Some day if you remain in the field I hope you realize how cringe-worthy these words might sound to a more experienced programmer.

The most common experience, even for the very best work of an elite developer, is that nobody will notice your code or care. Being good means things just seem to magically work whenever you're part of a project, as opposed to what usually happens. Only failure is visible. Nobody will ever compliment you on your code, no matter how good you get. Only, maybe, what it does. Being new, you will hopefully get critiqued and guided, and that's fine. No need to worry about it.

There is one habit for maintainability that will raise you above all others, but you will not do this. Or I should say, the probability is extremely low. Write good documentation and unit tests. Explain in plain English what your code is supposed to do, and why, and use the tests to show that it does these things in finer detail. Then if you get hit by a bus, someone else can pick up where you left off, know exactly what they're looking at, and confidently work with your code because the tests will tell them when something breaks.

As far as learning, there is nothing like having to clean up your own mistakes after a lot of hard work. You suck until you teach yourself. There are no shortcuts. Learn by doing and failing and doing again.

Books might help at first but they get stale real fast. Contrary to others' comments, for resources I would advise you to look at other projects that are in production - ones that have actual people using them - and not books. Use them as examples and compare according to your growing understanding of what's easy and not so easy to maintain.",2022-02-21 07:08:15
Comment,3,hxspnbq,,0,1645419929.0,"That’s a fantastic write-up

And I think your bit about “these aren’t SWE quality tests” is particularly relevant, because they absolutely don’t need to be! But I think that mindset is what holds a lot of people back from writing tests

Tests don’t *need* to be pretty. Or fast. Or optimized. Or any of that crap. Obviously it’s nice if they are, but it’s not necessary. Slow/clunky tests are far better than no tests",2022-02-21 07:05:29
Comment,8,hxspkob,,0,1645419888.0,"You know what? You aren't wrong. In my books there is still a big difference between data scientist, data analyst, statistician and researcher.

Lets say a DS in this case is someone that actually builds predictive models and not just a SQL + dashboard person. Rigorous low level math / stat isn't needed for this because off-the shelf solutions exist for most things. Even if they solve your problem suboptimally the ROI of implementing something from scratch will be lower than just calling it day with Pytorch / Sklearn / statsmodels or their R equivalents.

Data science is second rate in terms of pure statistics because it's simply not statistics. It applies some of stats to a specific problem area. This is essentially the same as statistics being second rate in terms of pure math to mathematics. It isn't a case of better or worse, it's a case of more or less applied. If you want a job that cares about the smallest and most pedantic details of statistics ... get a job as a statistician.

Even for jobs as a statistician, odds are that you'll be stuck in pharma, finance or marketing doing t-tests, AB testing and m-ANOVA 40 hours per week.  Unless you're a researcher reinventing the wheel makes no sense whatsoever, even for a statistician.

Out of curiousity, do you work yet? Somehow you seem like you're still in school and you're in for a whole load of pain when you start working, even as a statistician.",2022-02-21 07:04:48
Comment,3,hxsocsv,,0,1645419190.0,"Yup, my favorite example in this regard is the fact I took a full course on the math behind SVM's. The biggest thing it taught me is when to set `dual=False` if I use it in sklearn...

The vast majority of DS jobs, and I'm only talking about ones that build models, don't require you to be actually good at math / actively use it at work. Most of that stuff is abstracted away. The ROI for making algorithms from scratch is very very low. 

Proofs and convoluted theory only matter *after* you can use it in a real world setting and not vice versa.",2022-02-21 06:53:10
Comment,1,hxso8qr,,0,1645419125.0,"**My job is boring but lucrative. Should i leave it to find something more stimulating?**  


I (25M living in Europe) graduated a couple of years ago with a MS in CS from an elite university and found a very high paying job working in Analytics at an incredible employer in Finance. Lately, I've found myself increasingly dissatisfied as the work content is not stimulating. 

Some of my current points of dissatisfaction:  
\- A lot of work involves simply reporting data, which does not excite me, as I was hired to be a data scientist. I don't feel i'm developing any sophisticated skills as I am having less time to do real ""science"", involving modelling and experimentation. I feel that if I leave eventually, I won't have done any really noteworthy DS projects that will earn me a similar pay check, as my work is now trending more towards that of a data/BI analyst. I basically miss feeling challenged the way i did during my MS, with the fancy math, statistics and novel methods we'd be exposed to, and I feel rusty there.  
\- Management has no clear vision for the team I am working in, and I also have a very unclear idea about my future. I have raised this yet the answer is very vague, as my actual manager has very questionable qualifications to be in his role.  
\- I work in a silo and don't have much opportunity to bounce my ideas off of others and learn through collaboration.  
Some points of satisfaction:  
\- Employer offers great perks and benefits. Compensation is fantastic. I am earning way above average for my experience level, and jobs i've interviewed so far offer around 35% less, which would be a tough pay cut to swallow.  
\- Very nice and respectful company culture.  
\- I am in a position where I can have impact on the business, as my voice is heard at the top management level.  
\- I have learned a lot on the soft-skill side.  
My current dilemma is: should I move on from this company and sacrifice the nice pay check today in order to hopefully gain more useful hands-on technical experience and have better prospects later in my career, or am I being too picky with what I want and should I try to make the most of my current work? I realise that I am very lucky to be at an employer that offers great benefits and working conditions, but I, at the moment, feel like i'm sitting in an uncomfortable comfort zone. I have very little working experience outside this company so I would highly appreciate your opinions.",2022-02-21 06:52:05
Comment,10,hxsnyl2,,0,1645418965.0,"If an industry or job doesn't care about math stats related material then it isn't doing anything rigorous. Which is fine, it may really not be needed. But this is why people say data science is second rate or ez stats and not real stats. Math stats is required in basically every undergrad program for a reason. This is like every high school student in algebra class who complains ""Am I ever gonna use this!?"" and the answer is [""you won't, but one of the smart kids might""](https://www.smbc-comics.com/comic/why-i-couldn39t-be-a-math-teacher)",2022-02-21 06:49:25
Comment,6,hxsnqj9,,0,1645418842.0,"> If your ambition is to work somewhere like deepmind or anywhere more research focussed (basically a place that is really pushing the boundaries of this field)

You are describing a research scientist job, not a data scientist job.",2022-02-21 06:47:22
Comment,3,hxsnnx1,,0,1645418802.0,"Sure but what good is learning about mcmc then? For example. 

Hardly anyone will ask you about sampling methods in interview, you are much more likely to get deep learning or standard cs question.

The statistics masters won’t give you the coding chops to do anything more than call .fit; metropolis Hastings basic implementation is maybe 12 lines of code, but if you want to research more performant methods you simply won’t have the background in numerical methods to do it.

In modern times you simply must need to code if you want to leverage your statistical understanding. And the graduate programs are failing here apart from cs masters",2022-02-21 06:46:42
Comment,3,hxsnlcz,,0,1645418762.0,"> It's just math for math's sake. There is no focus on developing competent practitioners.

I majored in pure math and some of my undergrad electives were mathematical statistics and that's more than enough for 99% of data science jobs. I feel like this sub is conflating data science with academic-level research that uses statistics.",2022-02-21 06:46:02
Comment,1,hxsni3g,,0,1645418710.0,"Hi u/EntertainerKind1981, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 1 karma.",2022-02-21 06:45:10
Comment,5,hxsnclj,,0,1645418624.0,"> I think people underestimate the diminshing returns of extremely advanced stats.

Man, I love seeing replies like this because this has been my experience. For a long time, I used to comment on this sub that most data science jobs aren't *that* mathematical and I would get downvoted.",2022-02-21 06:43:44
Comment,5,hxsn339,,0,1645418480.0,"> Probably an MS in Statistics at a decidedly applied program.

You may have enjoyed a MS in Biostatistics more. Biostats departments tend to have more applied courses. Although depending on the department, they can still be quite theoretical should you want it to be.",2022-02-21 06:41:20
Comment,1,hxsmjc7,,0,1645418176.0,University of Michigan,2022-02-21 06:36:16
Comment,1,hxsme8p,,0,1645418099.0,"I request you estimate how many people in the world have read those books and grokked it, and then also estimate how many people are pushing the world forward in machine learning today. I suspect less than 10% of NIPS presenters have read over 50% of any of those books.

So I mean, you can raise the gates as high as you want, but a lot of people are executing whether you think they have a “deep” understanding or not.",2022-02-21 06:34:59
Comment,28,hxsm1lp,,0,1645417907.0,"This is why I always downvote people who mindlessly say ""Don't get MS in Data Science, get an MS in Stats"". The answer should really be ""figure out what you want in a role and do research on specific master's programs before applying"". I did a MS in Data Science at a stats department that was quite strong in theory, and I thought it was a great balance between applied and theory.",2022-02-21 06:31:47
Comment,1,hxslm5t,,0,1645417669.0,"No, I’m very scared that this person thinks running the same model and getting different results is normal.",2022-02-21 06:27:49
Comment,1,hxslhmo,,0,1645417601.0,Hey can I ask where you did your grad program for Stats?,2022-02-21 06:26:41
Comment,1,hxslcem,,0,1645417523.0,"hey, I'm not sure if you mentioned this somewhere but where are you doing your masters?",2022-02-21 06:25:23
Comment,4,hxskz8c,,0,1645417322.0,"This is by far the best answer here. I think people underestimate the diminshing returns of extremely advanced stats. Like, it doesn't hurt you but you time was probably better spent doing something else unless you're doing it for fun.

The theory versus application split is another thing people underestimate so damn hard. Over my two masters degrees I learnt so many different concepts and ideas but mostly from a highly theoretical pov. That doesn't mean I can use these things in practice whatsoever. I've actually made a list of some of the more exotic/esoteric things we covered and I'm trying to implement them / reteach them because application wasn't a big part of my program. It would have been better if they cut a bit more into the theory and had us apply stuff because that's what pays off the most in the long run.",2022-02-21 06:22:02
Comment,1,hxsj0n2,,0,1645416280.0,"It honestly depends, for example my program at UIUC: BS Statistics and Computer Science, has a lot of data crunching, R, Python, Databases, numerical methods, time series, approximations and a mix of standard statistical methods and newer era machine learning. There are 2-3 non-computational stat requirements but I think they stay towards the useful end of theory.",2022-02-21 06:04:40
Comment,13,hxsj0bs,,0,1645416275.0,"Sounds like my first masters degree then, which was business engineering. I took a wide variety of courses there ranging from combinatorial optimisation in C++, to ML theory to SQL.

But yeah, if you can choose between CS, math and stats I'd think about where you want to land in the next years and pick accordingly.

* A background in (applied) math goes far in DL research but is probably less impactful in industry than CS or stats. I think this option gives you tons of flexibility to change career though because your skillset is applicable in many places.
* Stats is a always good choice but in places like my alma mater they don't get SOTA NLP, computer vision, deep learning etc.
* CS/AI covers the state of the art ML and bayesian algorithms but is light on very advanced statistics like robust statistics or non parametric methods aside from canonical ML algorithms + gaussian processes. Generally these produce the best coders which is the most important skill in industry (sorry not sorry).
* A combination with a lot of electives like my first masters. Sucks a bit that you don't really specialise though, you end up being a jack of all trades.

That's just my 2 cents on this topic.",2022-02-21 06:04:35
Comment,8,hxsiugd,,0,1645416189.0,"Honestly, I disagree. I was mid-way through a PhD program with a heavy emphasis in stats and econometrics before I left it. I finished up a masters in business analytics a month ago and it was WAY more relevant and useful to DS related work.

Sure, I can deep dive into nitty gritty details in ML better than my peers, but if I had not done this Masters program, my peers would be much better well-rounded DS's than myself in terms of coding and actual implementation of models.. you really don't learn much of that in Statistics programs, from what I've seen. Though there has been an uptick and profs using R these days, many old-school profs are still using eViews, minitab, MATLAB, and Stata. There is value in knowing how to derive an OLS estimator from first principles, but there is also a very steep curve in terms of diminishing returns the more and more your training emphasizes theory over application. My PhD program's emphasis on theory to application was probably an 85/15 split. There were students getting As in my stats classes that didn't physically know how to run a regression or design an A/B test.. what's the point? 

In contrast, my masters had about a 30/70 split between theory and application. Learn some content, and then go solve some questions with this dataset we gave you.. or go collect the data yourself and solve this business problem. There are degrees and courses out there now that are geared towards DS and analytics, and I would much more strongly recommend them than Statistics, which are taught by academics for entry into academia.",2022-02-21 06:03:09
Comment,-1,hxsipce,,0,1645416114.0,"Im not 100% that they come up explicitly, but if youre going to carry out a number of the proofs they're going to be involved. Perhaps it was in the dirichlet processes chapter, I recall using properties of borel sets frequently for a few chapters, I've had a whiskey too many atm I'm afraid. But considering the fact its probabilistic ML you're using probability spaces, so you need measure theory if you want to do some of the proofs, and so on up the logic tree (uniform convergence bounds, sigma finite measures for SVM reproducing kernel Hilbert Space, lebesgue measures, all come to mind).",2022-02-21 06:01:54
Comment,0,hxsinj3,,0,1645416087.0,"I currently work as a Data Scientist in India at a Bangalore based company and will complete 1 year this year. I make about 1 lac per month in hand and will soon be getting some salary hike.

1. I wanted to understand what kind of a hike should i be expecting, given the job market. 
2. And what should be the bare minimum, below which I should just resign and look for another job?

Background: IIT graduate, <1 year of work exp",2022-02-21 06:01:27
Comment,1,hxshxwo,,0,1645415721.0,Got you. Is it worth to learn basic and advanced stuffs for data analytics and data science from kaggle and be in the community? Do people collaborate on kaggle for project?,2022-02-21 05:55:21
Comment,2,hxshh3d,,0,1645415483.0,"Can I ask what course or courses in particular you think are ""needlessly complicated and have no real world value""?",2022-02-21 05:51:23
Comment,0,hxshcqe,,0,1645415421.0,State of the art solution: AWS Connect & GPT-3,2022-02-21 05:50:21
Comment,1,hxsgq7b,,0,1645415107.0,"Add comments to your code describing what it does, or why you did certain things.",2022-02-21 05:45:07
Comment,1,hxsgnmj,,0,1645415072.0,"Depends on which company you're asking about.

iirc at Facebook, you are not required to have a master's/PhD for their analytics DS (but many will have a graduate degree anyway). You'll need one for their research-y DS roles. At Amazon, a master's/PhD is required for all their science roles, other than BIE. Same for Google, a master's/PhD is generally required for DS.

Not sure about other companies, but you can check the educational requirements on their job postings.",2022-02-21 05:44:32
Comment,2,hxsfiee,,0,1645414493.0,"Apart from standard time series methods companies would want to think about problem at hand. 

Start with what are you trying to forecast and in how much advance. How many times do you review and update it. 

For example you forecast today for a date in August. and again update that forecast next month because you collected more data in next 30 days. And again in April you update your forecast for August.

Special events and seasonality, how do you plan to handle it? How do you forecast when economy is coming out of COVID.",2022-02-21 05:34:53
Comment,1,hxseppz,,0,1645414101.0,Check out MS in computational and applied mathematics at university of Chicago,2022-02-21 05:28:21
Comment,3,hxse3hg,,0,1645413785.0,"Then you should look at data analyst, analytics engineering and data engineering(the extremes here are SQL and software engineering with a broad spectrum).",2022-02-21 05:23:05
Comment,2,hxse1a9,,0,1645413753.0,"A book I recommend is [Build a Career in Data Science](https://www.manning.com/books/build-a-career-in-data-science). Talks about how to get into data science and what kind of data science jobs there are. 

If by ""business"" you mean not-for-profit, then you could look into government, research centers, or nonprofits. However, money at all these places will still be important in shaping the agenda.",2022-02-21 05:22:33
Comment,1,hxsdqtv,,0,1645413611.0,"Hi u/dumb_cat22, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 1 karma.",2022-02-21 05:20:11
Comment,2,hxscxsi,,0,1645413216.0,"From the same website section 1.6 step 3. It’s usually about what kind of controls you put in to account for the changes/shocks and except maybe seasonality and typical holidays, most others are very problem determined",2022-02-21 05:13:36
Comment,6,hxs9q6a,,0,1645411674.0,Only data engineer at a tech startup.,2022-02-21 04:47:54
Comment,2,hxs8alw,,0,1645410981.0,Probably an MS in Statistics at a decidedly *applied* program. Or a masters in DS at a reputable school that wasn't too expensive. CS probably wouldn't have been an option for me since my undergraduate education was in stats/math.,2022-02-21 04:36:21
Comment,2,hxs7wcd,,0,1645410796.0,"I agree with you. But I feel like my undergraduate education (in stats/math) taught me plenty about how things work inside of scikit, for example. The problem I'm having is that the insanely mathematical and technical treatment of statistics at the *graduate* level seems so useless for practical data science work.",2022-02-21 04:33:16
Comment,3,hxs7o29,,0,1645410688.0,"I was like them when I was in my grad program for Statistics as well. I still think it was all pretty useless, but I thought it back when it was happening too.",2022-02-21 04:31:28
Comment,1,hxs7291,,0,1645410405.0,Great discussion! Going to come back and read more.,2022-02-21 04:26:45
Comment,-1,hxs6px2,,0,1645410242.0,"Most MS and especially BS CS programs don’t get into AI/ML much either, outside of stanford cmu and similar top ranked places. As a PhD student it’s different but even a stat PhD can do research in those topics, even people in bioinformatics PhDs which is not in stat nor CS and covers less of that stuff in the curriculum than either major often do more applied DL/ML. 

Yes coding is important but its a very specific kind of coding-numerical computing that is needed to do well. I actually find that a lot easier than the theory because you can often at least simulate some some data to “check” your answer or intuition.

A CS education that isn’t very specialized as it is in PhD, or MS in those schools, covers topics that are even less directly related to ML than much of stats, such as programming languages and compiler or systems design.  They would still be useful for software/ML eng and but not research.

Most of my CS friends got jobs unrelated to ML",2022-02-21 04:24:02
Comment,2,hxs6lu3,,0,1645410187.0,How long was model used successfully?  What defined success (lift in 1st decile)?  What defined failure?  What was window used for development (only summer/only pandemic)?  What’s PSI for inputs (data drift)?   Arm chair DS manager in me says the model was likely overfit if it just worked well for a few months.  But did you evaluate performance on out of time sample before deployment?  How well did it work?  Did performance suffer compared to original Validation/Test set?,2022-02-21 04:23:07
Comment,1,hxs6j9u,,0,1645410152.0,"Practice. Tons of practice. Oh, and constructive, objective criticism of your code.",2022-02-21 04:22:32
Comment,11,hxs6i9n,,0,1645410139.0,"People might not care if you can prove something, but if you’re not capable of proving something you probably don’t understand the constraints on the problem that may be not appropriate with your data.

Can’t understand finite first and second moment constraint on the central limit theorem if you never learned what a moment is, and I’ve never seen that taught outside math/stats.",2022-02-21 04:22:19
Comment,7,hxs5w9y,,0,1645409852.0,"The moment when both small commits and unit testing completely clicked was when I had to write an evolutionary algorithm from scratch in my masters. 

I was using git but my commits were horrible and covered too much. I was unable to go back and compare different instantations of my algorithm. 

Without unit tests some part of the algorithm would nearly always fail silently after changing another part. With unit tests I'd at least have been aware and could instantly change it.

Finally, there was a freak bug where my initalisation strategy caused my output vector not to have unique integers which was a constraint of the algorithm. This is typically something you assert in a basic unit test and would have saved me so much time. I actually remember submitting the code and being called out by my prof because of the error which I didn't even notice.

After this I started *properly* using version control and also started writing unit tests. I don't write SWE quality tests but at least that and git give me the confidence to experiment and change things in my code iteratively which is the point of (data) **science**.",2022-02-21 04:17:32
Comment,3,hxs5spr,,0,1645409804.0,The research output and the MS program content are two different things.,2022-02-21 04:16:44
Comment,5,hxs3j5z,,0,1645408737.0,"It's far, far, *far* easier to learn the math/stats in college followed by the comp sci skills in your own time/on the job compared to the other way around- some might argue learning that level of math/stats independently is nearly impossible. OP the skills you're missing out on can be covered in a $10 Udemy course or Youtube series but you're in a position to build skills that can only be practically done where you are right now. 

I've been there and yes, it does suck to play catch up and learn so many technologies from nothing (still am in fact). But I don't regret the path I took because knowing about the mathematical bowels of what's actually* going on in scikit is deeply satisfying.",2022-02-21 03:58:57
Comment,2,hxs38pi,,0,1645408597.0,"It CAN be helpful, but only if it’s makes sense in your orgs stack and is resourced appropriately. If not, your assessment is spot on in my experience.

Data scientists should be able to read and write clean, consistent SQL - dbt is a distraction unless it’s already part of the job IMO.",2022-02-21 03:56:37
Comment,0,hxs2z2b,,0,1645408468.0,"That's down to him as an individual and not his CS background then. 

CS based programs cover different algorithms/modelling techniques to stats focussed programs so I expect a CS person to have more finesse with say RBF SVM's, gradient boosting and say neural networks than a stats person. After a year in the workforce they should have learnt proper GLM's (and the stats person should've learnt proper coding).",2022-02-21 03:54:28
Comment,1,hxs2yfg,,0,1645408459.0,"Nice work!! And congratulations!!

Btw what viz program / app is that?",2022-02-21 03:54:19
Comment,4,hxs1j23,,0,1645407792.0,"What career are you in where you read/write SQL every day, if you don't mind my asking? I get to use SQL for some of my projects (CRM with a read-only SQL database), probably 5 hours a week at best but would really love to just write SQL procedures for most of my work week.",2022-02-21 03:43:12
Comment,7,hxs0kkd,,0,1645407341.0,"I think the reluctance is often because people mistakenly view it as “extra work”

But most of these people already write little scripts or scratch files to test out code as they go. Turning those code snippets into formal “unit tests” is trivial, and it ensures future changes won’t break code that was previously working. But for some reason people don’t seem to make that connection. They think unit tests are something entirely different

The only strategy I’ve seen work is to require some reasonable % of code coverage (maybe 60-70 for starters). Being *forced* to write tests typically helps people see how useful they can be",2022-02-21 03:35:41
Comment,1,hxs0bat,,0,1645407222.0,Thanks sounds great,2022-02-21 03:33:42
Comment,0,hxrzfbc,,0,1645406796.0,"I think it depends on where, because in the US a lot of CS MS programs at mediocre schools (aka not Stanford, CMU, et al) cover mostly a bunch of unrelated stuff. If you do an ML/AI MS then of course the general CS is probably lower. Interestingly, even at UCLA, the comp vision stuff actually falls into stats too http://vcla.stat.ucla.edu and their stat curriculum (or even ECE, but not CS) tended to have more AI stuff than pure CS especially at non PhD level which had a lot more focus on systems, compilers, etc which is not directly ML related 

Multi Arm Bandit is RL more so than other ML/DL stuff, I never learned it formally in school but I did implement it in Julia with 0 CS knowledge outside numerical computing.  There were seminars though in stats related to Bandits and experimental design. Numerical computing skills are really the most important. I think with practice you can acquire the ability to translate the math to code.

I would consider optimization as stats as well if you are formulating the likelihood function probabilistically, but I guess not everyone does. Optimization wouldn’t be stats to me if you were just deterministically finding the roots to some equation.",2022-02-21 03:26:36
Comment,1,hxrz6c9,,0,1645406679.0,Maybe start at beginning with clustering and see if your theory pans out before adjusting your model,2022-02-21 03:24:39
Comment,2,hxrywf7,,0,1645406548.0,"Sounds like someone is coming to terms with the realities of graduate school. I thought the same thing about Econometrics.

You'll come appreciate all that stuff you mentioned (math for the sake of math, endless proofs, etc) once you leave the academic world. The two best data scientists I know studied mechanical engineering and bioinformatics, respectively.  The degree doesn't matter, the mind does.",2022-02-21 03:22:28
Comment,11,hxry68s,,0,1645406209.0,"I feel same way about unit tests, but god as my witness in 10 years of trying I haven’t been able to convince another DS to do them. Given workshops on unit tests, add them as best practices, use them liberally in my own code, the whole nine yards, but nada nothing; not sure what the reluctance is (except perhaps the general DS preference for modeling over other activities; or the typical cut edges when rushing for a deadline). I don’t know about you, but I get a serotonin rush every time I get all green lights for unit tests doing a build - makes me feel confident in my code.",2022-02-21 03:16:49
Comment,1,hxry3uy,,0,1645406189.0,"I just grabbed [""Beyond The Basic Stuff With Python""](https://inventwithpython.com/beyond/) By Al Sweigart and figured to read through that over the course of the next month or so. I really enjoyed Al's ""Automate The Boring Stuff With Python"" Udemy Course and figured his book would be a great source for getting further in my coding. Let me know if it sounds interesting to you and we could potentially get through the book together!",2022-02-21 03:16:29
Comment,-6,hxrxzut,,0,1645406122.0,Here give me a password for the db and ill take a look.  👀,2022-02-21 03:15:22
Comment,4,hxrxuvo,,0,1645406057.0,"If you know any Python, you can try a number of things such as various forms of text vectorization: representing text as an array of numeric values. Examples include count vectorization (raw term counts) and term-frequency-inverse-document-frequency vectorization (raw term counts weighted by their inverse document frequency). There are others, too, but these are the most basic.

It sounds like your problem is an unsupervised problem since (I’m assuming) you don’t have labels: you know they belong to “Other,” but am I right to assume you’re wanting to break this category down into smaller subcategories?

You could try things like Latent Dirichlet Analysis to do topic extraction—seems fitting for this scenario, but it’s up to you to interpret and define the topics.

If you have the time and enough data, manually go through a large enough sample and hand-label these. This could open up some supervised modeling capabilities.

Do you think any of the texts in the Other category might actually belong to different, already labeled categories? You could train a supervised model on what you know to be true and see how well it generalizes to the Other category (manual inspection required since you don’t have finer labels in that category).

Edit: I think I initially misread your post. It sounds like many of the Other types should belong to existing non-Other emergency types. Sounds like a classical supervised modeling approach: vectorize your data with the non-Other labels, train some supervised classification model (maybe Naive Bayes?), see how well the model validates and generalizes, then predict on the Other types, then do manual inspection.

Since you’ll end up with false positives and false negatives, make a determination which type of error is more risky, and focus on optimizing for that.

Edit 2: If you can only use SQL, it might be a good start to use regex matching on popular terms?",2022-02-21 03:14:17
Comment,2,hxrxpb8,,0,1645405983.0,"It probably depends on the program but my stats MS basically set me up for more of an ML research scientist role than anything. My web dev background and the CS grad courses helped position me more for a MLE role. I did a DS internship during my MS and apparently I can talk to business folks so I got I hired full time. Now I spend most of my time getting access to data and creating some presentation/deliverables.

Edit: My math program did set me up for my research project on electrical load disaggregation. Basically we use a lot of training data to train a model that can take meter level usage and estimate what the appliance level usage was at the home. The biggest issues are generalization but that means wiring up a bunch of homes with all these sensors.",2022-02-21 03:13:03
Comment,1,hxrxmwr,,0,1645405951.0,"Resources in DS applications, roles for a data scientist? 

I want to know the different things a data scientist can do. I am not interested in solving ""business"" problems, would like more to work on real world, social and enviromental problems.",2022-02-21 03:12:31
Comment,4,hxrx2dl,,0,1645405682.0,"Looking back, what route would you have taken instead?",2022-02-21 03:08:02
Comment,1,hxrurr2,,0,1645404611.0,"Hi u/malambo2, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 1 karma.",2022-02-21 02:50:11
Comment,8,hxrslha,,0,1645403584.0,"Sad part for you guys is that stuff like Bayesian Neural networks and 'exotic' DL architectures are usually only covered in CS/AI programs (at least in my uni). All varieties of multi armed bandit algos were also part of my first masters program and were not covered in stats.

Most of the stats things you covered above are part of any self respecting CS/AI program with a ML major. That being said, stats still has a lot of areas where it obviously shines in comparison to CS/AI programs but I wouldn't call one better than the other per se.

EDIT: The reason for this is that there's some diminishing returns on stats knowledge in 'pure' ML because these algorithms don't do a lot more than convex optimisation. Most of the impact from DL research comes from CS or math related stuff to make training and inference faster.

I think most of the outstanding ML/DL researchers have CS backgrounds and picked up advanced stats and not vice versa.",2022-02-21 02:33:04
Comment,2,hxrrwl4,,0,1645403255.0,"I was like you when I was in my grad program for Statistics. I didn’t understand why we had to dig so deep into the theory. But now, I think it was all worth it.",2022-02-21 02:27:35
Comment,1,hxrrne3,,0,1645403134.0,No clue. They’re both in Europe and I’m in the US. I was hired as a III because I had experience elsewhere. Not sure what kind of pay bump there is between levels. I’m going to guess maybe 10-20%.,2022-02-21 02:25:34
Comment,3,hxrqfdg,,0,1645402561.0,">The number of times I’ve seen models performing poorly because someone didn’t transform the target, did variable selection using p-values only, and performed “causal inference” using observational data is unfathomable.

This is basic stuff I learned in undergrad (and on the job as a DS). My courses now aren't even covering practical modeling because there's no real data involved.",2022-02-21 02:16:01
Comment,3,hxrqc09,,0,1645402517.0,"Learning theory will later help you pick up new models/algos much faster than someone who has no solid stats/math background. In addition, you will notice patterns and math tricks for modeling that a lot of “Data Scientists” miss in the industry. 

The most important thing tho is that you will feel very very confident when tackling new projects that require you to do some research on your own rather than your manager or supervisor telling you what to do.

During school, it’s hard to appreciate that. But, you’ll see when u do an internship or start your first job after grad school",2022-02-21 02:15:17
Comment,1,hxrq25f,,0,1645402389.0,I get an initial cognitive dip by 12 and by 17/5P.M. I can't think at all no matter what I do or don't do. Are you constantly good until 5PM and di you only get it if you work? I could do nothing and still get it.,2022-02-21 02:13:09
Comment,4,hxrpvue,,0,1645402306.0,"You’ll thank your degree and yourself (if you study hard enough) when you’re on a project and you have to learn some new modeling techniques or when your team is stuck on a problem they can’t solve with a one liner from a Python/R package.

The number of times I’ve seen models performing poorly because someone didn’t transform the target, did variable selection using p-values only, and performed “causal inference” using observational data is unfathomable.",2022-02-21 02:11:46
Comment,2,hxrp6gb,,0,1645401976.0,"Econometrics specifically involves a lot of statistics and (pseduo)experimental design, which is a good foundation for becoming a DS. I'm not really sure how well DS programs are received - my company prefers to hire stem PhDs or CS BS/MSs.",2022-02-21 02:06:16
Comment,1,hxroraj,,0,1645401785.0,"Yeah, commercial engines is a good industry to be in, and CAT and Cummins are the frontrunners. 

I'd argue that equipment rentals is an even better industry to be in, even if it's not as well known. The profit margins are huge so everyone gets good pay and benefits. The reason why the workspace isn't croweded is because it's high stress on operations, and requires highly specialized sales reps. That's not really a problem for data workers though.",2022-02-21 02:03:05
Comment,2,hxrodbx,,0,1645401610.0,"Maybe I am biased but I have not seen as much research from statistics department on GAN, multi armed bandit, variational inference as from cs departments. Mcmc and EM, yes primarily from statistics but that is because they are very computationally inefficient so most cs researchers are not interested. Either way, performing research on these topics require you to be pretty fluent with code.",2022-02-21 02:00:10
Comment,3,hxrno0a,,0,1645401291.0,"If their doctorate is in the experimental side, I would very much believe they do have decent knowledge in the use of statistics",2022-02-21 01:54:51
Comment,1,hxrnlmm,,0,1645401262.0,"Anything else is probably going to be less comprehensive.

Raj Chetty + his *many* coauthors at Stanford publish work like this -- it floats up to the NYT occasionally, might be worth punching his name into google and seeing who his team cites.",2022-02-21 01:54:22
Comment,14,hxrnf37,,0,1645401180.0,"ML is statistics, especially the maximum likelihood/optimization/etc stuff at the research level. Things like MCMC, EM algorithm, variational inference in advanced ML (aka probabilistic graphical models) and guarantees/bounds pretty much require solid stats/probability theory. You don’t need any of this stuff if you are just making pipelines like in ML engineering, but to do actual ML research you do. CS covers a lot of stuff that is irrelevant to the ML part of ML if that is truly ones interest-eg im not sure how compilers and programming language theory is going to help one debug a bayesian neural network. Deep generative models and causality is a huge research area thats coming up, and the content is mostly stats Bayesian inference with richly parametrized CPDs. 

Im surprised if OPs MS stats is doing sigma algebras though as that is a PhD measure theoretic topic.

Of course, that said, for most people ML engineering is more realistic as a career though. 

One could say the same thing about CS concepts like distributed computing with the tools too—eg I can just use SparkR in Databricks and make a UDF and gapplyCollect() and ive done “distributed computing” without ever knowing what is going on.",2022-02-21 01:53:00
Comment,1,hxrmcg1,,0,1645400695.0,"Thank you so much-that's because that's pretty much what I've been doing thus far starting-setting up a bunch of meetings with the data team and the clinical folks and understanding everybody's pain points and now trying to figure out what value I can add. I think I have certainly identified some areas and am working on those, but meeting with people can be a little bit overwhelming and confusing at times-like you said, the middle man is problematic when they are conduits for what would have happened anyway-there are some clinical people who know exactly what they want quite well and have a strong rapport with the data team, so in that I feel kind of useless because I don't need to help 'brainstorm' evidence-based measures to relay to the data analytics people. Some people are a little less informed in this area, so that's where I'm taking charge. 

I'm very new and both the clinical and other folks have been here for 5+ years, in fact some of the data folks have been here for 10+ years-a bit different from the last few jobs I worked where people would come and go after 2-3 years or so lol. So I don't feel I'd get to have a chance actually creating machine learning models or even work on dashboards really. I'm trying to focus on small wins but I do feel a bit like I don't know what long term goals I'd accomplish at this place-my hope for my next job when I was applying and got this position was to get a chance to program in Python and deploy models more, but I don't see that being a part of my job at all :(.",2022-02-21 01:44:55
Comment,3,hxrlw6e,,0,1645400494.0,Its a great book for someone not fresh out of a stats degree,2022-02-21 01:41:34
Comment,1,hxrlqpf,,0,1645400427.0,"Thanks for the reference 
It looks interesting.",2022-02-21 01:40:27
Comment,1,hxrlped,,0,1645400411.0,I think you should just try to learn through practice like some of the programs in Datacamp and Dataquest,2022-02-21 01:40:11
Comment,1,hxrkxgx,,0,1645400063.0,"Like i said, you have a great point about that and im not arguing stats ms is often failing students _for industry_. But if they've already begun, the trick is gonna self study",2022-02-21 01:34:23
Comment,5,hxrkp2a,,0,1645399957.0,"Yeah I respect your take and if it was r/statistics or statistics PhD I would not comment. It is r/datascience though where people prefer application and industry over theory and academia. Ms statistics today are not letting students get their hands dirty in the way Ms cs will, and I think that’s not optimal.",2022-02-21 01:32:37
Comment,0,hxrkb36,,0,1645399782.0,"Talking to a dozen friends in cs trying to learn ML Maths, and tutoring a few of them, i disagree. The breadth and depth of a math degree != real analysis",2022-02-21 01:29:42
Comment,1,hxrk4s8,,0,1645399701.0,"Well. Not saying i understood 100% that'd be pretty arrogant lol. And yeah, the new version is much better, helps to cross reference. And you're not wrong, my point has been he is building up his theoretical tooling in a program he's already started, it gives him/her an edge in understanding this stuff, groking it much quicker, and generally having intuitions ""in the field"". Training to the most rigorous standard and applying to the least necessary standard is one hell of a recipe for success. And it would 100% be a benefit in research, because a ton of those people doing research likely struggle with these areas mid-research when they need the material, giving OP and those like OP a speed boost or leg up by doing these hard things in advance. But to each their own, also sounds like they just wanted to vent.",2022-02-21 01:28:21
Comment,6,hxrk2fp,,0,1645399672.0,Yep this. Clearly an observable difference between summer and winter campaigns. Should be fine to encode binary.,2022-02-21 01:27:52
Comment,0,hxrjzf9,,0,1645399635.0,"He made me doubt my self a lot 
I had to review everything about hypothesis testing 

Then I found a YouTube video hinting at my thoughts 

In conclusion yes, your sample statistics will be their in your null hypothesis 
but it will be in the extremes in a position that will allow you to reject the null

https://youtu.be/wiKAtEJp4ys",2022-02-21 01:27:15
Comment,0,hxrjxxf,,0,1645399616.0,Not to toot your horn. But if you found self teaching coding easy with advanced math background it will also be easy to self learn math from cs background + real analysis class.,2022-02-21 01:26:56
Comment,5,hxrjity,,0,1645399427.0,"Sure, for probability theory research you absolutely must understand measures… but how many people are doing that, let alone read MLAPP or similar level text? I have only read maybe 4.5 chapters, you are 1 in several million if you both read and grok the whole thing. The astounding number of typos in that particular book also doesn’t help lol.

even for the most cutting edge machine learning research it doesn’t seem necessary to know more than undergraduate level convex optimization, multi variable calculus, probability theory and grad level linear algebra. Someone who wants to contribute meaningful applied research or industry data science does not need to wade into any advanced statistics.",2022-02-21 01:23:47
Comment,6,hxrjci6,,0,1645399347.0,"Someone explain to me the benefit of dbt. I've looked into it a little and it seems like a quick way to write shitty SQL.

Edit: This is a genuine question. Don't get all worked up.",2022-02-21 01:22:27
Comment,3,hxrj7lf,,0,1645399288.0,I mean... Wikipedia literally has an entry called null distribution lol. Maybe you should have flunked?,2022-02-21 01:21:28
Comment,1,hxrj613,,0,1645399269.0,"is it better to get an undergraduate degree in economics and a graduate degree in data science or both the degrees in data science? since quite a lot of data scientists or analysts are economics graduates, does economics help in any way during the course of study or do companies prefer economics graduates?",2022-02-21 01:21:09
Comment,1,hxrj2ci,,0,1645399225.0,"Ya fuck that guy. You are finding a sample mean and variance. You could bootstrap samples to get robust estimators of the population mean and variance but, dont worry about that yet. Go look at the shared resources. If you want a good book. Lookup Statistical Rethinking by Richard Mcelreath, Libgen.is for a free copy, get the 2nd edition, work through the easy and medium problems at a minimum, lots of programming language translations for the book (python R scala julia go etc)

Edit: also, i think you're trying to learn about the p-value. Tons of resources about there, stats 101 stuff, good luck",2022-02-21 01:20:25
Comment,29,hxriloe,,0,1645399018.0,"This. You can study ""mathematical statistics"" as it was called at my uni, which is the pure math approach to stats. Proving everything. OP's program sounds more pure than applied. There are tons of new programs popping up that are specific to data science (and mathematical finance - think Brownian motion). It seems to depend on the program. I love the pure side, and I have a hard time understanding anything if I can't prove it, but when it comes to industry nobody GAF.",2022-02-21 01:16:58
Comment,3,hxrifv6,,0,1645398948.0,"For me, these resources were very helpful to improve my code.

* Clean code by Robert C Martin
* The Pragmatic programmer by Dave Thomas & Andy Hunt
* Code complete (2nd ed) by Steve McConnell

They may not be specifically targeted for Python or SQL per se and more geared toward traditional languages like Java and C++ but they have great food for thoughts on how to structure and format program.",2022-02-21 01:15:48
Comment,1,hxri6jt,,0,1645398831.0,Do you have ambition to create/ design new data science algorithms rather than just applying the existing ones? Advanced understanding in statistics help in this case.,2022-02-21 01:13:51
Comment,5,hxri4a7,,0,1645398803.0,"And it seems it is you who needs to review basic stats. There is such a thing as a null distribution. For someone who claims to teach stats, it is odd that you are not aware of this basic concept",2022-02-21 01:13:23
Comment,0,hxri3l7,,0,1645398794.0,"Also i had no problem learning clean code after learning maths, it was a breeze. Learning advanced math and stats after learning to write clean code? Good luck..

My senior year of math, i did 100 replicates of 10-fold CV for 12 models in parallel on a distributed cluster woth modularized R code. Without ever having taken a CS class. In 3 weeks. Got 99% AUC and A+ the ML course top 3 students. Idk if that helps or hinders your argument about CS first",2022-02-21 01:13:14
Comment,1,hxri0eg,,0,1645398754.0,Use the weekly thread.,2022-02-21 01:12:34
Comment,1,hxrhw8z,,0,1645398702.0,"Ya coding in stats is poor. And sure, he could have. But he didnt. So might as well make the most. And idk, i use math and stats every single day in my DS job. Sigma algebras were the foundation to understanding more complex probability theory, allowing me to read Kevin Murphy's MLAPP (2012) and now his 2021 book, and soon his coming 2023 book, which are absolutely industry bibles. How about readin SOTA articles? CS isnt going to be much help ascertaining the value of a paper that dives into and relies of advanced statistical and probability theory, of which...most do. If youre not doing these things ya sure. Maybe its a waste. Hindsights a bitch eh. If its what _you think_ you're passionate about and would like to pursue, these are the hoops to jump through.",2022-02-21 01:11:42
Comment,1,hxrhvwo,,0,1645398699.0,I think we need to explain the model better before we start talking about what algorithms to throw the data into.,2022-02-21 01:11:39
Comment,3,hxrhl89,,0,1645398566.0,Why be so mean?,2022-02-21 01:09:26
Comment,17,hxrhd9u,,0,1645398467.0,"You can learn all kafka pytorch kubernetes on your own time but if your goal is to do industry data science or machine learning, OP is much more correct to pursue CS bachelors or CS masters where they will learn first principles of machine learning and distributed computing and how to write clean code, instead of sigma algebras which I have yet to encounter anyone talk about in industry. The coding education given by MS Statistics is atrocious, cannot be denied!

I regret focusing so much on mathematics instead of optimizing for cs personally. Even modern neural network research is primarily performed by CS PhD with no conception of extreme value theory.",2022-02-21 01:07:47
Comment,1,hxrgokt,,0,1645398167.0,"You are conflating quite a few things. If the null hypothesis is false, then p values asymptotically approach 0, if the null hypothesis is true, they are uniformly distributed. 
Small samples have a tougher time to correctly reject a null hypothesis (so, if it is false), due to lower power. But small samples are not more likely to incorrectly reject a null hypothesis (type 1 error), as compared to large samples, which is one common fallacy, and if the null hypothesis is true small and large samples are equally likely to give below or above threshold p values. Equally. Yes, with a larger sample the estimation (being a coefficient or effect size or mean difference or whatever we’re talking about) is likely to be more accurate. But it’s really quite important to understand how things change, in terms of what happens to p values and how they can be interpreted (or not), in the scenario that the null hypothesis is true versus the scenario that the alternative hypothesis is true. People make so many mistakes there. Actually, recently saw a new study again demonstrating that the vast vast majority of statistics professors and active scientists get this stuff wrong. So we’re all in good company. It’s partly for these nuances ans how easily one can get things wrong that conventional inference tests are increasingly replaced with more meaningful Bayesian alternatives",2022-02-21 01:02:47
Comment,1,hxrfrvh,,0,1645397761.0, Think something else is going on here and it’s unclear from the question. Let’s say you repeat the test and as such double the sample size. Now you have twice as many samples. The p-value across all samples should improve  significantly (~sqrt n) while being similar for each set separately. He gave you weird p-values probably because to steer you away from religiously believing in the 0.05 cutoff. If the p-value didn’t change for the total sample size then there might be something going on with normality but thinking about it seems the emphasis was more cutoff definition.,2022-02-21 00:56:01
Comment,7,hxrfdvd,,0,1645397591.0,"Acting school actually helps me more than my two degrees tbh. 

Learning to communicate and create a good environment to work has been much more important.",2022-02-21 00:53:11
Comment,2,hxreznx,,0,1645397418.0,"Not sure if this will be helpful, but [goodresearch.dev](https://goodresearch.dev/) is what I was recommended to write better python code, at least in academia.",2022-02-21 00:50:18
Comment,2,hxrek44,,0,1645397230.0,"Rather than think you have to read all tweets by everyone you follow, maybe take a more casual approach and just see what useful things bubble up? 

I've found Twitter to be helpful for highlighting Python/R tips for example. Oftentimes, these tweets are written by people who have had a lot more experience coding than me. So the fact that they just learned something new/obvious tells me, if anything, that it's fine to not know everything all the time. That's just not possible to do.",2022-02-21 00:47:10
Comment,-7,hxre9b6,,0,1645397100.0,You can do this in most any office job as long as you’re at a computer.,2022-02-21 00:45:00
Comment,13,hxrdhtw,,0,1645396775.0,"I understand why you feel this way.

1. Yeap. Not all stats degrees are 100% theorems. Even within the degree, I'd say apart from mathematical statistics and statistical inference subjects others will take a 50:50 or 70:30 theory to coding with data balance.

2. Tech stuff is so easy that you don't need a degree in it. Excel, SQL, bash, git, pandas, numpy, scipy, statsmodels, scikit-learn, keras, tensorflow, pytorch, seaborn, plotly, tidyverse, tidymodels, shiny, spark, airflow, kafka, fastapi, docker. That's it in the current scene - you don't even need to know half of it, just need to pick it up as you go.

3. The opposite is true for many existing practitioners and DS ""managers"", who often have no clue what is going on or what needs to be done. Don't be that guy.

4. Sure, statistics isn't the only good way to get into DS. Remember the diagram with computer science + statistics + domain expertise? Start with any one, add another to begin in DS. Eventually pick up the third.",2022-02-21 00:39:35
Comment,1,hxrd8hn,,0,1645396664.0,The coordinates to every particle of Covid over the last 3 years.,2022-02-21 00:37:44
Comment,1,hxrcqgj,,0,1645396456.0,3M? :),2022-02-21 00:34:16
Comment,3,hxrckz5,,0,1645396391.0,"I can't speak to the specifics of your classes, but I went the cs route and I can tell you many of the things I thought were useless at the time I ended up using. We were required to take an assembly class, and I promise I've never coded in assembly since. But it gave me an understanding of how higher level programming languages are structured and it has indirectly helped me understand how languages work which I'm relatively new to and has helped me with regards to optimizations in my career. Maybe the proofs you're doing are too low level, but there is some benefit to understanding the low level theory of what you're doing.",2022-02-21 00:33:11
Comment,1,hxrcetz,,0,1645396317.0,"Is there a difference in skill/knowledge expectations between contractor roles and permanent roles that have similar job specifications? (UK)  
  
I am strongly considering transitioning from FTE to contracting. Aside from differences between the two types of employment that come with any field of work (rights, pay, tax, so on), is there a difference in the typical experience level expectation between the two?  
  
Based on a generic job spec I have pulled (pasted below), the listed requirements/tasks seem equally as basic as an intermediate FTE role. Based on this alone, I as an example, would easily meet the criteria. However, I still have the feeling that to start contracting, I must have a greater level of expertise than I would if I were to consider applying for a permanent role with the exact same job description.  
  
example job specification:  
  
The Job  
experience in CRM • applying data mining techniques • Statistical analysis • Building high-quality prediction systems. • Conduct research and development activities, data exploration and discovery, develop prototypes, algorithms and proof of concepts, using leading data science and innovative Big Data solutions.  
  
You  
• Experience with CRM • Experience with SQL, Python, Spark • Available immediately • At least 3 years in a similar position.",2022-02-21 00:31:57
Comment,5,hxrca28,,0,1645396262.0,"Take a step back, and try to find the reasons why what you're learning is relevant.",2022-02-21 00:31:02
Comment,2,hxrc8kj,,0,1645396244.0,"That's fair but as you say, it still doesn't change the argument I made either.",2022-02-21 00:30:44
Comment,7,hxrc6zc,,0,1645396225.0,Good luck getting the job though lol,2022-02-21 00:30:25
Comment,3,hxrc6wz,,0,1645396224.0,"Hey, have you been looking at my work directory.

P.s. I'm up to v4 now :)",2022-02-21 00:30:24
Comment,1,hxrc5qq,,0,1645396210.0,"Hi u/icecoldfeedback, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 17 karma.",2022-02-21 00:30:10
Comment,6,hxrc16t,,0,1645396157.0,"Doing the hardest version of whatever you're trying to do is never a waste of time. You'll be able to learn new things with ease. If you're reading SOTA ML articles for work, and need to find algorithms to apply, how are you going to verify the work is actually any good? Because it's peer reviewed? HA! No you'll have to do the proofs, work through exercises left to the reader, and so on. Which you'll be able to breeze through, as opposed to taking an applied program, and just implementing what might turn out to be a bad algo, and costing your company, and looking unprofessional",2022-02-21 00:29:17
Comment,7,hxrbgo8,,0,1645395915.0,"Youre in an academic program. It's academics for academics sake. I'm not sure what you expected, but statistics masters is really a step on the way to a phd, which is a step on the way to doing stats for stats sake. They're training those people, not for industry specific roles.

The proofs are going to give you rigour. Which _you will_ apply at work, rigour in applying the/calling libraries, choosing models, verifying data integrity, ensuring pipeline flow, so on.",2022-02-21 00:25:15
Comment,3,hxrbfd2,,0,1645395899.0,"> Pretty sure some of the are students in a BSc in stats and want to gatekeep you, someone with a PhD that is actually working, from DS work.

This implicitly uses the argument from authority that you are describing as gatekeeping.

Notice I hadnt mentioned whether I have a PhD or not . (Hint: it’s because it wouldn’t change the argument by authority dynamics)",2022-02-21 00:24:59
Comment,-3,hxrbem0,,0,1645395890.0,Most physics is just applied stats.,2022-02-21 00:24:50
Comment,0,hxrb4yo,,0,1645395776.0,"> Mathematicians thinks math is most important, statiticians thinks statistics is the most important thing, computer scientists thinks CS is the most important thing. 

**Good point but it has minimally to do with the point in contention.** The point was that DS folks aren’t typically strong enough to assess “strong” in stats. For example there are typically Software Engs in staff at most companies so you typically can find someone who can assess “strong” that even if it isn’t necessarily someone in the DS org",2022-02-21 00:22:56
Comment,2,hxr8ktz,,0,1645394691.0,You should test it against  a control to see if its actually failing or just not performing as good as summer but better than baseline,2022-02-21 00:04:51
Comment,2,hxr734i,,0,1645394059.0,"Definitions of a Data Scientist can change at the department level, let alone company and industry level.",2022-02-20 23:54:19
Comment,1,hxr6qg3,,0,1645393909.0,Follow interesting people. Comment on posts getting lots of attention.,2022-02-20 23:51:49
Comment,22,hxr6ig8,,0,1645393814.0,"DS can be a lot of things to different people. In my experience, an MS in stats with no work experience won’t guarantee that you’ll shine in DS, which is an “applied” field. 
MS in stats places you in a unique position to qualify for for higher-level positions that undergrads or transfers from other industries may struggle to reach. It also opens doors to DS roles where they really want a mathematician/statistician.",2022-02-20 23:50:14
Comment,1,hxr68uw,,0,1645393703.0,Un delete your last one or ask it in r/learnmachinelearning,2022-02-20 23:48:23
Comment,1,hxr66nw,,0,1645393677.0,Why did you delete and repost after you got answers,2022-02-20 23:47:57
Comment,2,hxr58bx,,0,1645393270.0,"I did last semester as a capstone project. 21 seasons, trained on 18 and tested on last 3 (or something like that). Had some bonehead teammates but even with that and minimal feature engineering (W/L streak, which team won last time these two played, etc), I think with a tuned SVM we achieved ~66% accuracy which was higher than a baseline of just predicting home team wins (~45% accuracy). At a team level I think we managed as high as 88% accurate (I think it was Middlesbrough FC that the SVM predicted quite well for).",2022-02-20 23:41:10
Comment,1,hxr51g9,,0,1645393190.0,"Ok, I will. Thanks for engaging.",2022-02-20 23:39:50
Comment,2,hxr512x,,0,1645393185.0,"Depending on how you generate features and split you need to be careful of leakage using cross validation with “time series” problems. 

Also, % correct is a metric that isn’t grounded in anything.  Is that a good result?  If you just predict “win” based on whichever team currently has the best record what’s the result?

I don’t have any doubt if you put in the work you can out predict the odds makers in some subset of games. However, what’s the edge they build into the price, 5%? On top of that they can refuse you action whenever they please. 

If it’s 100% for fun then sure, have a ball.",2022-02-20 23:39:45
Comment,1,hxr4qis,,0,1645393061.0,*Please* go read Clean Code. The way you're thinking code should be descriptive is not a best practice.,2022-02-20 23:37:41
Comment,1,hxr48jv,,0,1645392851.0,">Commenting won't help seniors with his code. Better code practices overall will do so.

I don't understand this. Comments are to inform his seniors what he intends with the code, they will then spot any mismatches.",2022-02-20 23:34:11
Comment,1,hxr3xbx,,0,1645392721.0,Using pandas? Seems like a combo of loc and isin should deal with it.,2022-02-20 23:32:01
Comment,3,hxr3vdc,,0,1645392699.0,"Yeah. Add in a variable for the number of the month, and train on a whole year of data. It's fundamental to have a representative sample. OP should read more about this.",2022-02-20 23:31:39
Comment,2,hxr3sh8,,0,1645392665.0,"100% agree on regex.

Commenting won't help seniors with his code. Better code practices overall will do so.

And comments can 100% be detrimental. Code ages, and when it gets updated, comments are often ignored, leading to incorrectness that's missed by PRs. That's a major point in Clean Code (and all over the place - you should read up on this). I really would read Clean Code at a minimum, were I you.",2022-02-20 23:31:05
Comment,1,hxr3b7y,,0,1645392463.0,"Ok, but the assumption is that he isn't good at coding right now. Commenting his code so that the more experienced devs can understand what he is trying to do will make it easier for them to teach him better ways. Additionally, while it isn't always necessary, I've yet to encounter a situation where it was detrimental. So I treat comments like the oxford comma.

Moreover, personally I use regex a lot. It is just professional courtesy to comment your regex because it can be such a PITA to read",2022-02-20 23:27:43
Comment,26,hxr35pm,,0,1645392399.0,"This, if it was completely applied just group_by(), filter(), model.fit() imagine how boring that would be. 

I don’t like pure theory either but I miss the applied-theoretical aspects like for example seeing the equations derived for algorithms like GMMs, doing them from scratch on a dataset. Plus if you ever want to go for researchy positions or a PhD the theory will come into play. 

Additionally, newer topics like eg causal inference, are easier to pick up with a foundation. That small % of the time something interesting comes up also it comes into play.

The tools are easy to get on ones own but the theory isn’t.",2022-02-20 23:26:39
Comment,1,hxr318t,,0,1645392346.0,"Let us say I have a table that looks like this

    index,longitude,latitude,housing_median_age,total_rooms,total_bedrooms,population,households,median_income,median_house_value
    0,-114.31,34.19,15.0,5612.0,1283.0,1015.0,472.0,1.4936,66900.0
    1,-114.47,34.4,19.0,7650.0,1901.0,1129.0,463.0,1.82,80100.0
    2,-114.56,33.69,17.0,720.0,174.0,333.0,117.0,1.6509,85700.0
    3,-114.57,33.64,14.0,1501.0,337.0,515.0,226.0,3.1917,73400.0
    4,-114.57,33.57,20.0,1454.0,326.0,624.0,262.0,1.925,65500.0


I want to know if a specific row contains a value? For example, I want to know if the last row contains ""65500.0"", regardless of column name.

What is the best way to do that?",2022-02-20 23:25:46
Comment,20,hxr2p4o,,0,1645392204.0,"I disagree with this take.

It might not matter if you want to be an average data scientist. If your ambition is to work somewhere like deepmind or anywhere more research focussed (basically a place that is really pushing the boundaries of this field), you will need to have more theoretical/academical understanding aka clever math tricks, and complicated textbook theory.

imo even if you wont use it at your daytime job, learning this stuff will have an indirect benefit to your career",2022-02-20 23:23:24
Comment,2,hxr2l4m,,0,1645392157.0,"Well, there is the distribution of the test statistic given the null hypothesis, which is likely what OP is asking about (since they are learning about hypothesis testing).",2022-02-20 23:22:37
Comment,22,hxr29lt,,0,1645392022.0,Just a binary variable for summer vs. winter. Think of it as encoding summer and winter as having different intercepts.,2022-02-20 23:20:22
Comment,1,hxr20rh,,0,1645391917.0,"> Comments! The number 1 factor in making your code comprehensible to others is having comments.

Respectfully, that's not true. When you're new to code, it seems like comments are the best way to make code easier to understand. Once you get better at coding, you realize that well-written code needs very few comments, aside from docstrings of course.

You should read Clean Code - it will disabuse you of some of your ideas but will make you a much stronger developer.",2022-02-20 23:18:37
Comment,-4,hxr208l,,0,1645391911.0,"Ok, if you are just trying to learn and not trying to get us to do your homework; then two things.

1) statsquest on YouTube with Josh Starter is a great resource. He has a bunch of short videos explaining single topics.

2) there is no null distribution. You have a null and alternative hypothesis, but you do not have a null distribution. You have a population distribution and a sample distribution.",2022-02-20 23:18:31
Comment,68,hxr1tva,,0,1645391836.0,"OP take this mans advice.

You are learning fundamental principles and if you actually understand them, then it doesnt matter what tool you use to solve your e.g. optimisation problem, as the math stays the same.

Having fundamental understanding of the theory together with practical knowledge will separate you from nost of other candidates. You don’t want to go down the route of just learning the tools and understand them at high level. Sure you can solve real world problems, but you will lack the understanding if you end up in a conpany that wants to use more novel algorithms as you would be expected to understand the actual math before you can inplement it.

Trust the process OP and learn all those integrals and theorems as it will sharpen your brain and you will be able to comprehend more analytically challenging topics at work conpared to someone who hadn’t gone through that.",2022-02-20 23:17:16
Comment,6,hxr1p9u,,0,1645391782.0,">You don't need to learn all these clever math tricks to understand the theory underlying applied statistical theory. Page-long derivations generally have no pedagogical value. It's just math for math's sake. 

Yeah, you're mostly on the money there.

But unless you take a pure math class or a pure applied class, that's unfortunately how it tends to be regardless of discipline. I'd love to just set up the problem and write the answer in terms of symbols too.

I think part of this is because some PhD's go through the classes too, and they need to learn how to do these calculations in case they run into them in their research. Kind of sucks, but there's mostly two extremes: those who only want to learn what they need to get a quick job, and those who want to go into academia. There's no middle ground.

Just stick it out if you can, it's still worth it.",2022-02-20 23:16:22
Comment,0,hxr0loj,,0,1645391316.0,The problem is there are too many nonobservable variables that effect the outcome,2022-02-20 23:08:36
Comment,8,hxr0lbl,,0,1645391312.0,"Everyone knows this except the statsbro's of the subreddit which in my opinion are the most toxic and gatekeepey people here. 

Pretty sure some of the are students in a BSc in stats and want to gatekeep you, someone with a PhD that is actually working, from DS work.",2022-02-20 23:08:32
Comment,-2,hxr0bz9,,0,1645391200.0,"First: ouch that hurts

Second I am actually trying to learn not to do homework

Thanks for the reference

And can you tell me the right way to calculate
A standard error for my null distribution, please",2022-02-20 23:06:40
Comment,1,hxr046i,,0,1645391108.0,"Most Kaggle notebooks and code I've seen are very far from clean code or prodiction ready. Which is fine for Kaggle, code quality is not one of the metrics they judge solutions by, and most of the kaggle competions are one-offs, so reusability is not very important either.

But when you want to learn how to write production ready code, Kaggle isn't the right place.",2022-02-20 23:05:08
Comment,3,hxr03q0,,0,1645391103.0,"Considering my BS is in stats, I wouldn't say I'm bad at stats. What I'm bad at is wasting my time on needlessly complicated things that have no real world value.",2022-02-20 23:05:03
Comment,11,hxqzvns,,0,1645391008.0,This is why data scientists are bad at stats,2022-02-20 23:03:28
Comment,1,hxqzuyn,,0,1645391000.0,"There's actually a Clean Code in Python book written by someone named Anaya (no idea who he is, but his blog is pretty reasonable as well). I'd strongly suggest reading Martin first, but CCiP is a really well done book overall.",2022-02-20 23:03:20
Comment,1,hxqzksd,,0,1645390881.0,Sounds like an interesting project. Good luck with it.,2022-02-20 23:01:21
Comment,1,hxqzkmr,,0,1645390879.0,"Yeah, they have great notes online. I've used them a lot, mostly before grad school. I wish I was in that program.

Their notes are at much lower mathematical level than the stuff I'm learning, even for similar topics. They actually teach practically.",2022-02-20 23:01:19
Comment,-1,hxqz95q,,0,1645390744.0,"Not quite sure what your asking. It sounds like you are hoping someone will tutor you in intro stats and do your homework. This isn't the sub for that.

From your rambling post I can tell you should be flunking the course unless your college has grade inflation or you study more. It's obvious you don't understand and it doesn't seem like you have even tried reviewing the basics.

I always recommended that my students read Larry Goonick's, ""A cartoon guide to statistics"". It's quick and easy to read, they explain the concepts well and make it easier to remember.

Good luck",2022-02-20 22:59:04
Comment,9,hxqxytx,,0,1645390196.0,"How many semesters in are you? It could be that your current courses are the core classes and you get to the applied classes later on. 

That or your program is mathematical statistics and not applied.

One program I really like is the Penn State MS in Applied Stats. I regularly go through their notes to re-learn topics or to fill gaps in my knowledge.",2022-02-20 22:49:56
Comment,4,hxqxvvw,,0,1645390161.0,">There aren’t enough interviewers in DS to assess “strong in stats”

It's crazy how the interviewers are often less trained in stats and math than the candidates, it really is the blind leading the blind in DS hiring.",2022-02-20 22:49:21
Comment,0,hxqxrqk,,0,1645390113.0,"Math yes but a phd in physics has little bearing on statistics knowledge. I know there is some overlap in coursework but it's minimal, the focus is physics, not statistics. Especially when they come to DS 5 years after their phd was completed. I've regularly seen very poor quality modeling from physics phds, they really have nothing special to offer.",2022-02-20 22:48:33
Comment,4,hxqxkui,,0,1645390032.0,"Thank you for sharing this.
I always wondered if there are best practices for SQL. resources seems limited compared to OOP programming languages.

CTEs seemed intuitive to me. At my first job as a data analyst I noticed everyone used subqueries instead of CTEs. I still have nightmares of me trying to understand multiple level subqueries with no comments. 
I felt really stupid for not understanding my team mates sql code. But in reality it was hard to understand and badly written",2022-02-20 22:47:12
Comment,1,hxqxal5,,0,1645389911.0,"Hi u/Variousity221, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 1 karma.",2022-02-20 22:45:11
Comment,2,hxqxa7d,,0,1645389907.0,"Has anyone tried... Of course. If you can gamble on it, people have tried to model it and get an edge. As most people know from Moneyball, they did it with baseball and it had been done in basketball as well as soccer/futbol",2022-02-20 22:45:07
Comment,12,hxqx3rt,,0,1645389828.0,"Mathematicians thinks math is most important, statiticians thinks statistics is the most important thing, computer scientists thinks CS is the most important thing. The truth is, you have to be good enough on this three fields to add value to your company, but not the best.",2022-02-20 22:43:48
Comment,3,hxqvyem,,0,1645389341.0,"A classmate some ml modeling for basket ball and made 20k before starting a company, unfortunately i dont know the name or I'd point you in that direction",2022-02-20 22:35:41
Comment,3,hxqvv5y,,0,1645389303.0,"Wouldn’t you know it, the key to getting a high level but in demand role is to get experience and work your way up.",2022-02-20 22:35:03
Comment,-1,hxqvuxp,,0,1645389300.0,">50% of candidates are strongs in statistics and mathematics.

This is way overstated, DS are generally poor in stats and math. I'd wager 99% of people called data scientists have never taken one expected value by hand in their life. The field is known for 2nd rate solo-studying methods, reliance on youtube videos and bootcamps, and mid-life career changers. All of these have no real credentials for passing or failing. It's been mitigated somewhat by the arrival of masters programs but the absolute flood of unqualified people has already been mentioned fairly often:

*> but since data science caught on I feel like the position has actually become filled with less and less competent people, to the point that people in these positions do not even know very basic stats or even just some common sense empiricism.*  
[https://www.reddit.com/r/statistics/comments/j0zqs7/i\_hate\_data\_science\_a\_rant\_c/](https://www.reddit.com/r/statistics/comments/j0zqs7/i_hate_data_science_a_rant_c/)  
  
*> My impression is that the current crop of data scientists is just a bunch of IT guys pretending they understand statistics and/or econometrics.*  
[https://www.reddit.com/r/statistics/comments/j0zqs7/comment/g6wt3mh](https://www.reddit.com/r/statistics/comments/j0zqs7/comment/g6wt3mh)  
  
*> I'm starting to worry that the field is just inundated with unqualified candidates*  
https://www.reddit.com/r/statistics/comments/j0zqs7/comment/g6wrjdt",2022-02-20 22:35:00
Comment,6,hxqvl4i,,0,1645389187.0,">It's intellectually easy to clean data and call libraries. It's much, much harder to decide which models are appropriate when, which you only get from an understanding of the theory.

I agree with this. This is basically how I used to justify my prior belief that stats > cs/ds.

But learning theory does not require the level of detail being taught in this program. You don't need to learn every proof in detail to understand applied statistical theory. You don't need to learn all these clever math tricks to understand the theory underlying applied statistical theory. Page-long derivations generally have no pedagogical value. It's just math for math's sake. There is no focus on developing competent practitioners.",2022-02-20 22:33:07
Comment,10,hxquwzl,,0,1645388901.0,I am not sure having a PhD in physics necessarily means you have a deep understanding of statistics.,2022-02-20 22:28:21
Comment,118,hxquswf,,0,1645388853.0,"The grass is always greener on the other side, sometimes I wish I had a MS in stats but sometimes I realise that I'm probably better off with what I have. Most quantitative programs are equivalent to a certain degree because they all have their pros and cons.",2022-02-20 22:27:33
Comment,1,hxquh9d,,0,1645388713.0,Dont worry. Genereral Equalibrium models or matching models are even more usless.,2022-02-20 22:25:13
Comment,325,hxqubj5,,0,1645388645.0,"Math and Stats in Academia isnt industry training. It's first principles. Foundations. Learn hadoop, spark, dagster, airflow, prefect, trino, hive, tensorflow, keras, mlFlow, guild.ai, rabbitmq, kafka, kubernetes, etc etc on your own time. Read the tutorials, browse the docs, choose a tool, spend 2 months implementing a small project/portfolio on toy data, push it to public github. Repeat. You've got what 1-2 years left? Thats 5-6 projects potentially. Then if you want to get into SOTA ML you'll have thr foundation for understanding some of the papers.

Get some nonlinear programming and optimization under your belt. Get some heavy probability theory (sigma algebras, measure theory). Ya you wont use 99% of it unless you're in research, but you'll blow other people away on understanding tooling, where it goes wrong, quickly understanding best models to use, where design went wrong, why experiments fail, what data you need to collect at beginning of a corporate project. 

You're blessed to learn this stuff, have faith, buckle down, enjoy it while it lasts, enjoy college life while it lasts. Try to appreciate every morsel you can, because its building out your foundational toolset, your problem solving, your intuition. Working with data is simple, especially when youve done something 10-100x harder such as 1-2 page Integral proofs. You'll be bored by basic data work in a year, enjoy this stimulation while you can, you're so lucky to be in such a program even at lesser schools. This is literally forming the foundation of your brain. Dont ask what is the real world applicability, there very well might not be one for you, instead ask how is this shaping my mental tooling!? And ask that _before_ you take a class, best not wait for during or after. 

Google for connections, make connections between what you're learning this week and the field as a whole, maybe you will discover some sort of connections and applications. Maybe you'll never use them, eh so what. Use google scholar to browse articles on this weeks topics, read a few abstracts, check out wikipedia and follow rabbit holes, put it all together in your brain. You'll be glad you did this, and the MS shows you're capable of this level work, its what shows companies they can trust you with important data integrity tasks, however mundane they really are in comparison at the technical level.",2022-02-20 22:24:05
Comment,4,hxqu9fp,,0,1645388620.0,As in add personal data to help differentiate between summer and winter campaign individuals? Or literary have a binary summer or winter variable?,2022-02-20 22:23:40
Comment,25,hxqsyut,,0,1645388073.0,"Does your program not have an applied class, capstone, etc.?

I disagree with your assessment. It's intellectually easy to clean data and call libraries. It's much, much harder to decide which models are appropriate when, which you only get from an understanding of the *theory*.",2022-02-20 22:14:33
Comment,-9,hxqsx9y,,0,1645388054.0,Yep. Masters degrees aren’t super valuable in data careers. You can learn everything on the job.,2022-02-20 22:14:14
Comment,1,hxqrm12,,0,1645387496.0,"Yes, to me it sounded like he was trying to get at researcher degrees of freedom. Which btw is covered in an entertaining podcast episode here https://podcasts.apple.com/us/podcast/hi-phi-nation/id1190204515?i=1000382296859.",2022-02-20 22:04:56
Comment,96,hxqrazo,,0,1645387369.0,"There's so much variability between stats programs, which is unfortunate. Some are so applied that students will never even see a proof; other's are so theoretical that students will only see proofs and never see data.

My Statistics MS has not been relevant for any of the work I've done since getting it, with the exception of a course or two. It was very similar in style to what you've described. I really struggled to get by. I almost failed out and contemplated dropping out many times. I do wish I would've done a more applied program, because I feel like my program was kinda useless. But, at the same time, the degree is definitely nice to have employment-wise, so at least there's that.",2022-02-20 22:02:49
Comment,4,hxqr68e,,0,1645387313.0,"So we have our predicted list (predicted from the model) and we have our hedge list (created with some basic data analysis). This past summer, the hedge list outperformed the hedge list by a long shot. This winter, it's the opposite.

Since this is the first time we've run this campaign during the winter, we aren't shocked because we didn't have data from a winter campaign to use.

I'm just more interested in what people do when models fail, even if it wouldn't apply here. 

Thank you for your thoughts.",2022-02-20 22:01:53
Comment,15,hxqr2if,,0,1645387270.0,"Data science is a large bucket, and not only does statistics fit in it, it's an integral part of it.

I think you chose the best field for DS honestly.

While you may feel you are studying stats in too much depth, what you are learning is going to be useful as it will forever be part of your toolset.",2022-02-20 22:01:10
Comment,1,hxqqs6b,,0,1645387149.0,"Right, and I plan on it. I guess I was curious what others do when a model fails, not specifically what to do in this case. So even if it wouldn't apply to this scenario, I'm always curious what different types of tasks people do in certain situations.

&#x200B;

Thank you for your response.",2022-02-20 21:59:09
Comment,1,hxqqbki,,0,1645386955.0,Makes sense that's the pitch I was given too. What pay are they getting with that jump,2022-02-20 21:55:55
Comment,4,hxqps52,,0,1645386726.0,"I mean, looks like your data is all summer campaign data and there’s a strong seasonality. The best way is just to start collecting winter campaign data and update your model later",2022-02-20 21:52:06
Comment,2,hxqpb0v,,0,1645386525.0,"Demand over time. In detail: I want to predict the demand for a given location. I guess the simplest approach would be to train a model for every location cluster, however than I loose the possible information in their interconnection. 
So far I guess is a combination of CNN and LSTM like in the second paper I mentioned.",2022-02-20 21:48:45
Comment,1,hxqpaue,,0,1645386523.0,Queueing Theory,2022-02-20 21:48:43
Comment,1,hxqnvom,,0,1645385923.0,Wow. Thanks,2022-02-20 21:38:43
Comment,58,hxqn384,,0,1645385594.0,"I mean, add seasonal variable…",2022-02-20 21:33:14
Comment,27,hxqmnvs,,0,1645385419.0,"""_final_feb20_revision3_forrealthistime_2.ipnyb""",2022-02-20 21:30:19
Comment,2,hxqmnqd,,0,1645385417.0,This fear of tech debt is overrated which is why nonsense like tech evangelists get large followings despite not coding anymore.,2022-02-20 21:30:17
Comment,2,hxqmjq4,,0,1645385370.0,"Realistically you would have asked those questions first, but since it's an interview it's too late for that.

But you bring up another valid point.",2022-02-20 21:29:30
Comment,47,hxqmewi,,0,1645385315.0,If you're not versioning your code by calling your notebooks things like 'working_notebook_new_newer_v3_use_this_version.ipynb' are you even a data scientist?,2022-02-20 21:28:35
Comment,2,hxqls3q,,0,1645385048.0,"> I have a PhD in physics , maybe is not enough to understand who is strong enough and who is not

It isnt. There are tons of PhDs in DS. There is a reason stats is a specialized field and it takes a bit more of a deep dive post PhD to get a grasp on it. Similarly for CS skills. Having the attitude that a PhD is somehow a pass on the above has led to a bunch of “no” to interviews for postdoc candidates at job interviews. In industry “potential to learn X” isnt a substitute to learning X",2022-02-20 21:24:08
Comment,3,hxqlm1k,,0,1645384977.0,"> Statistics and strong mathematical foundations are much more important IMO for data scientists.

The industry produces a lot of bad models with no good measurements of performance and when analytic performance doesn’t matter as much, whitespace and discussions on how to lint (not if)  takes a backseat to stats and math",2022-02-20 21:22:57
Comment,1,hxqlkek,,0,1645384959.0,"Hey guyss! :) I've made a package to do enrichment analysis in Pyhton using the EnrichR and OpenTargets API! Check it out if you work in health data science or bioinformatics! 

[https://github.com/saramasarone/enrich\_omics](https://github.com/saramasarone/enrich_omics)",2022-02-20 21:22:39
Comment,1,hxqlehh,,0,1645384890.0,Going to need to grow that biz elsewhere.,2022-02-20 21:21:30
Comment,1,hxqkhkm,,0,1645384511.0,"Hi u/New-Seaworthiness816, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 1 karma.",2022-02-20 21:15:11
Comment,1,hxqjwp4,,0,1645384266.0,"Not quite! It's not the probability of the result -- often the result is probability 0 (e.g., having a normal distribution equal 0). Keep in mind that it's the probability of anything **at least as extreme** as what was observed.

You could totally apply Bayes' rule to get:  
p = P( result++ | null ) = P( null | result++ ) \* P( result++ ) / P( null )

If you were to apply Bayes' to P( null | results++ ) that could be useful, but subjective because you have to bring your own priors.",2022-02-20 21:11:06
Comment,4,hxqjtgs,,0,1645384228.0,I mean it is very likely that the loan acceptance rate is highly seasonal. Whatever that means. But I would start by checking how this average acceptance rate changes throughout the year.,2022-02-20 21:10:28
Comment,2,hxqjf2m,,0,1645384061.0,"> A lot of times in smaller companies you have code written by data scientists that were never trained to write good code. This just means later down the road your technical debt increases and at some point a better coder will get hired and have to clean it all up.

Exactly! This is the norm, not that every incoming DS is just trying to introduce some fancy tool because they saw a youtube video.",2022-02-20 21:07:41
Comment,1,hxqj5um,,0,1645383952.0,If there is another commenter in this thread!,2022-02-20 21:05:52
Comment,4,hxqj55n,,0,1645383944.0,"Lot of DS don't come from software traditional engineering background and are used to writing just scripts or working with juypter notebook. It's some messy code - no tests, no linting, no formatting. Huge functions doing ton of things at once. I have met more such type of DS than those who had some different kind of coding style. So OP should definitely challenge if things are messy and not just accept the way it is.",2022-02-20 21:05:44
Comment,0,hxqj4un,,0,1645383940.0,"Why call it ""a small university in New Jersey"" and not just identify the school if the size or state of the school mattered?

Edit: in your other posts you claim to be attending universities in India and the UK at the same time as a school in New Jersey. I think you're just lying.",2022-02-20 21:05:40
Comment,11,hxqisj8,,0,1645383801.0,"Like you said, comparing feature distributions is a good start.

When you say it failed, what do you mean exactly? Failed in terms of error metrics, actual dollars, etc?",2022-02-20 21:03:21
Comment,1,hxqhtkx,,0,1645383397.0,Read some good quality open source project source code. Maybe contribute as well.,2022-02-20 20:56:37
Comment,1,hxqhfla,,0,1645383238.0,"Thanks for your feedback u/the75th

I deeply believe that the value you get from it is at least 10x bigger than $149 -- especially comparing to other SQL courses and given that there's plenty of real-life context/exercises you don't normally see in content about SQL.

And if someone doesn't agree with that after going through the whole thing, that's why there's money-back guarantee :)

Oh, and there are free chapters to try it out.",2022-02-20 20:53:58
Comment,18,hxqh1rp,,0,1645383082.0,"\+1000 on unit tests, once I started doing them for statistical assumptions against algorithms my ML system development became bullet proof.",2022-02-20 20:51:22
Comment,1,hxqgs6z,,0,1645382975.0,"Writing effective and clean code is pretty awesome, but sometimes I can't understand the purpose of that function made by a previous data scientist who is not in the company anymore.
So I like to  follow google docstring style and, if possible, I create a CRISP DM notebook just to explain in details what I was thinking when I worked on that project. If someday I leave this company, at least the new data scientist won't spend hours trying to understand why I choose that model, features, metrics, etc",2022-02-20 20:49:35
Comment,1,hxqgesa,,0,1645382823.0,Check out Arjan Codes on YouTube,2022-02-20 20:47:03
Comment,1,hxqgb3x,,0,1645382780.0,Machine Learning Engineer is the most SWE applicable job in the data world.,2022-02-20 20:46:20
Comment,5,hxqfeze,,0,1645382416.0,Right. A SQL course that is $ 149. Good luck!,2022-02-20 20:40:16
Comment,1,hxqetrz,,0,1645382175.0,"Read the modules of popular libraries i.e. scikit learn, literally open the .py file and try to imitate them.",2022-02-20 20:36:15
Comment,4,hxqe9sa,,0,1645381947.0,"I don't know, I have a PhD in physics, maybe is not enough to understand who is strong enough and who is not",2022-02-20 20:32:27
Comment,1,hxqdt23,,0,1645381758.0,Data Engineering,2022-02-20 20:29:18
Comment,2,hxqd36r,,0,1645381469.0,"Not necessarily fishy, but I’ve felt that over the years, the car has increasingly become the final prize almost as much as the base prize of 30-40k (depending on season). Even further, it feels that the car is won more often than the base prize AND it rarely comes up as the prize when someone loses. As in, when someone wins, it’s often the car, but if they get the final puzzle wrong, Pat will rarely reveal it was the car they could’ve won. This is all pure intuition and could be completely incorrect. That’s why I want the data! It’d be extremely interesting


I’d also be interested in seeing the general distribution of prizes relative to the letter the contestant lands on in the final spin. I’d like to know if the prizes are randomly assigned to a letter on the wheel, or, if they are intentionally placed with respect to where the average spin lands on. Like, the show runners could see that contestants rarely land on, say, the asterisk, so that’s where they place the $100,000 prize. Along with this l, I’d love to know the distribution of the prizes on the wheel over time. Perhaps it is the case that 50% of the final wheel has the $30k prize, 30% of the wheel had the car, and so on


EVEN FURTHER, I’ve always been curious to know if the final puzzle scales in difficulty relative to the potential final prize. If the contestant landed on the $100k prize, is the difficulty of the puzzle higher than if they were to land on the $30k? Would the puzzles be the same?",2022-02-20 20:24:29
Comment,1,hxqc9fz,,0,1645381134.0,thank you for the tips,2022-02-20 20:18:54
Comment,7,hxqc8mt,,0,1645381126.0,"Your second point is more nuanced. If the code base is messy, doesn't conform to best practices, or is inefficient or sloppy, you should write better code. I know in a lot of cases it's best to use a similar style so the code is consistent, but if you read a book or learn how to write better code... Call people out on their shitty code and write better code. If you can support ""that's how it's supposed to be"" then by all means elevate your code base and teach your team how to do better.

A lot of times in smaller companies you have code written by data scientists that were never trained to write good code. This just means later down the road your technical debt increases and at some point a better coder will get hired and have to clean it all up. 

But to your point, if you just watch a 5 minute video and come in trying to write code in a different style because YouTube person said so and you have no idea if or why that might be true...I agree you shouldn't do that.",2022-02-20 20:18:46
Comment,14,hxqc1h7,,0,1645381048.0,"> 50% of candidates are strongs in statistics and mathematics.

No they aren’t. The industry just has so many people mediocre at stats and thats the bar. There aren’t enough interviewers in DS to assess “strong in stats”

Edit: For example basic A/B testing is very simple undergrad stats and I am not sure if 50% of working DS folks would pass an interview focusing on that aspect much less 50% of candidates. That isn’t to say it isn’t something you can read up , brush up on and get good at given a reasonable STEM foundation but “potential” is different than realized mastery",2022-02-20 20:17:28
Comment,1,hxqb8fl,,0,1645380721.0,"to be fair, I didn't read this until I was about 7 years into my career so I may be over-estimating its user friendliness",2022-02-20 20:12:01
Comment,1,hxqb2wi,,0,1645380659.0,"Tomorrow will be the first day of my first data
science internship, which will be my first data
science professional experience. I will be working
within a big wholesale company on multiple
algorithms to accelerate and optimize the process
of generating offers for the different invitations to
tender addressed to the company. I want to make
the most of this internship. Any advices? Thanks in
advance.",2022-02-20 20:10:59
Comment,8,hxqavmx,,0,1645380578.0,"Some tips from a Sr engineer who works with Python and SQL often:

- where you physically put your code will depend on the project but it should be pretty obvious. If you’re writing queries then there will probably be a standard place to put it. If you’re building a new Class or Controller, same thing. If it’s not obvious, ask.

- run an auto formatter on your code. Black is the most popular but I also like yapf. Use whatever the rest of your team uses.

- check for mistakes or oddness with flake8

- type hint your code and check it with mypy

Above all else, just chatting with someone who’s been around awhile is better than getting a PR rejected. I’d rather a new guy ask me where/what/how before he writes the code than to look over a PR and he have to rewrite it",2022-02-20 20:09:38
Comment,1,hxqai5s,,0,1645380425.0,"Hi Nick! Awesome to see you comment on my post. I used your book to prepare for the interview so it's kind of fun to see you in the wild. I think the conversion rate probably would've been higher as I got better at interviewing. Once I accepted an offer, I had to turn down 4 others I had done the final round for, 3 of which I was confident I would receive an offer from.

Honestly, it's to remember that it's a conversation, not an interrogation. I was well prepared from a technical and behavioral perspective, but the psychological stress of interviewing kind of sucked. Once I had gotten through the first few, it went away.",2022-02-20 20:07:05
Comment,2,hxqa82v,,0,1645380311.0,"Wasn’t getting any feedback or leading questions. The guy really didn’t want to help. As if I was supposed to nail what he was looking for on the first try . Don’t think it was anything else, because all other questions were basic and I’m fairly confident I answered them correctly.",2022-02-20 20:05:11
Comment,1,hxqa7zm,,0,1645380311.0,"Hi u/Difficult_Number4688, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 1 karma.",2022-02-20 20:05:11
Comment,1,hxqa2kr,,0,1645380251.0,"There were a couple of folks on my team who were interns during summer 2020 and then brought on fulltime as I in the fall, and were promoted to II about a year later.",2022-02-20 20:04:11
Comment,2,hxq9pgf,,0,1645380104.0,Pomegranate.,2022-02-20 20:01:44
Comment,2,hxq9muz,,0,1645380075.0,I came here to post the Bob Martin books. I feel they are good for all languages. I have to write code in numerous languages and those books help for all of it.,2022-02-20 20:01:15
Comment,2,hxq9ffp,,0,1645379994.0,"I worked on something very similar at a prior startup. We first log transformed the data to understand percentage impact instead of unit impact.

We were also using Databricks with PySpark. We aggregated to daily sales (sum) and prices (median or mean) for each product across thousands of stores (convenience stores and supermarkets).

The seasonality aspect was challenging because different products have different seasonalities, but (1) we had over two years worth of this data that lead us to assume we’d capture seasonality cycles, and (2) since we were looking at percentage changes and not unit changes, we assumed elasticities would be more or less constant across any time interval.

This simple approach worked fairly well for us.",2022-02-20 19:59:54
Comment,1,hxq96e5,,0,1645379890.0,Yes. What are you trying to optimize for?,2022-02-20 19:58:10
Comment,5,hxq8skz,,0,1645379730.0,"I mean if their code is bad, someone should be talking to them about it. Though, in a more tactful manner and not quoting a youtuber.",2022-02-20 19:55:30
Comment,2,hxq8nnd,,0,1645379674.0,"Isn't it dangerous to be asking these questions post hoc though?  If it turns out you'll p-hack any test that gets within a certain margin of your alpha, you've actually been running at a lower alpha this whole time.",2022-02-20 19:54:34
Comment,1,hxq8mkz,,0,1645379661.0,What packages/language were u using for the HMMs?,2022-02-20 19:54:21
Comment,1,hxq89uu,,0,1645379518.0,Sort of an off based question. And probably differs a lot. But how fast do you see level 1's moving up to 2?,2022-02-20 19:51:58
Comment,0,hxq6to8,,0,1645378930.0,"Congrats! That's a pretty great conversion rate! Curious, if you had to go back to the start of the job hunt (but you know what you know now), what advice would you give yourself to prepare?",2022-02-20 19:42:10
Comment,23,hxq5zkk,,0,1645378588.0,50% of candidates are strongs in statistics and mathematics. If you want differentiate yourself  you need be a good software engineer too.,2022-02-20 19:36:28
Comment,0,hxq5yyj,,0,1645378581.0,"Comments! The number 1 factor in making your code comprehensible to others is having comments.

Also, a good practice I've adopted is to write the comments out first before I write the code. Thinking through the process and writing it down helps keep your code focused and will also help code reviewers understand what your objectives for your code are and provide more helpful feedback",2022-02-20 19:36:21
Comment,7,hxq56wh,,0,1645378266.0,Statistics and strong mathematical foundations are much more important IMO for data scientists. Maybe ML Engineers need more SW development knowledge.,2022-02-20 19:31:06
Comment,38,hxq5324,,0,1645378223.0,"There are lots of strong opinions about formatting SQL, and your best bet is to conform to existing standards at your company.  It might be worthwhile to write a short style guide that makes those standards explicit.

I really like [this SQL style guide](https://github.com/mattm/sql-style-guide), and if you use dbt, the [dbt style guide](https://github.com/dbt-labs/corp/blob/master/dbt_style_guide.md).

As someone that writes and reads SQL every day at work, my strongest SQL opinions are:
 - use CTEs instead of sub queries whenever possible
 - add a comment for (pretty much) every CTE that explains what it does.  Unlike python, even well-written SQL is often not self explanatory at a glance.
 - use consistent indentation
 - join clauses should always have the left table on the left side of the equals sign and the right table on the right
 - when joining, put filtering conditions on the right hand table in the join clause, not in the where clause.  I’ve seen so many bugs caused by the where clause turning a left join into an inner join
 - never use right join. Instead rearrange the order of the from clause and make it a left join
 - don’t use left join when an inner join will do.

I’m probably forgetting stuff but those are what come to mind.",2022-02-20 19:30:23
Comment,1,hxq4c4s,,0,1645377919.0,"Very well said, just a question. Apologies in advance if this is a dumb question. 

If we returned a p-value of .049 and subsequently .051 — why are we arguing for normality here? Aren’t the numbers close enough to assume the data did not change very much? I guess it depends on sample size, but relatively?",2022-02-20 19:25:19
Comment,1,hxq3g0d,,0,1645377557.0,Do this course . https://www.datacamp.com/courses/software-engineering-for-data-scientists-in-python,2022-02-20 19:19:17
Comment,0,hxq3ezn,,0,1645377545.0,"I’m not too worried about haters for myself haha, it’s more for those who may get turned off from applying to one because they see all the push back here. There is a path into this field that involves getting an MS, and it’s not as bad as it’s made out to be. 

I do fully believe you need to go to the right program. Some of them are just milking students without much value add.",2022-02-20 19:19:05
Comment,1,hxq387b,,0,1645377470.0,"Pretty much. We collected all aspects of the supply and demand data, so our models were more or less inventory optimization by forecasting demand to ensure enough supply, minimizing both surplus events and out of stock events.",2022-02-20 19:17:50
Comment,2,hxq2ryv,,0,1645377286.0,We were a team of 5 data scientists. Two of which had their PhDs with 5+ years of experience and the rest had their MS with roughly 1 or 2 years experience.,2022-02-20 19:14:46
Comment,0,hxq2fsv,,0,1645377149.0,"Don't worry about the haters, I have a MS in data science and pull home 6 digits. You don't even need college in the first place to learn statistics and computer science. Honestly I thought this 'elitism' was something that only took place amongst little kids.",2022-02-20 19:12:29
Comment,13,hxq24sw,,0,1645377025.0,"From the comment section of your pullrequest :D

Edit: clean code … in my experience all my peers  have read it and it’s regarded as fundamentals",2022-02-20 19:10:25
Comment,9,hxq1s0n,,0,1645376883.0,it is always great to tell some senior that his code looks wrong because a youtube vid says it should look different.,2022-02-20 19:08:03
Comment,13,hxq1jgw,,0,1645376787.0,"Agree that data scientists shouldn’t obsess with writing code same as software engineers. data scientists aren’t software engineers.

Unit tests definitely help. Data Scientists don’t need to follow test driven development philosophy, but understanding what unit tests are, and their purpose, will help think more carefully about writing code.
once you start writing tests you realise obvious code smells. If you find that writing unit tests requires you to mock many dependencies, write a lot of code before you make your assertion, it is a pretty good indication that you have made poor choices in your development and there is something seriously wrong with your code (e.g. your function does way too many things aka breaks single responsibility principle).",2022-02-20 19:06:27
Comment,2,hxq0f9l,,0,1645376338.0,More basic stuff is in SQL but I use Python/Pyspark for most of my work now. We have a lot of templated code/ code to steal from that we’ve built up over time. I’ve maybe used sklearn once or twice but most of what we’re doing is just analytics.,2022-02-20 18:58:58
Comment,1,hxpzp8m,,0,1645376049.0,"Phd physicist here: We really never use the p-value for anything and it is well known that other fields perform “p hacking” to prop up their papers. First and foremost is to understand that the p-value is based on a lot of assumptions around normality of your data and in a lot of cases normality is not given. In those cases the p-value is pretty much meaningless and you have to invest time making your data normal (see QQ plot, variable transform, box-cox transform). 2nd, as others pointed out, 0.05 is arbitrary, so if you reject at 0.049 or 0.0501 is the same as flipping a coin. 

Coming to your answers: I think you did good on question 1. On question 2 it sounds a lot to me they were after you explaining why and why not a p value has meaning and can change. Assuming you made your case for normality, most straight forward answer is lack of sample size at this effect size. Most easiest test, t-test, scales with delta of your means and sample size, assuming variances are similar. So either The delta is too small (small effect size) or your sample size. 

In A/B test you typically ramp up and you might just be in the 2% percent phase meaning the effect you after is too small at this sample size. I would have probably said something along the lines that we need to enter the next ramped stage (7%) to get more significant results as our results are too close to our self-imposed cutoff and hence not defendable to business stakeholders.

Edit: seems like you did suggest that and a subsequent test also resulted in ambiguous p-values. So I’d probably have argued for normality not being fulfilled. Cheers",2022-02-20 18:54:09
Comment,0,hxpzaan,,0,1645375880.0,"He's good at data engineering tasks, but whenever he does some modeling my internal alarm bells go off.",2022-02-20 18:51:20
Comment,-1,hxpz25d,,0,1645375790.0,"Figured I'd share my experience. MS in data science programs get a decent amount of flak in here, but going to a good reputable program can open a lot of doors. This is kind of outcome is not unique to me (in fact some of my classmates have done even better than I have) and most of the people coming out of my program have had very succesful careers.

If someone's looking to break in, DM me, I'm happy to chat.",2022-02-20 18:49:50
Comment,1,hxpytvb,,0,1645375698.0,"Pep 8 boiiii, and pep 484",2022-02-20 18:48:18
Comment,42,hxpyogy,,0,1645375639.0,+++++++++ for git. Dont skip that shit.,2022-02-20 18:47:19
Comment,10,hxpygfq,,0,1645375548.0,"Also, PEP 8, PEP 484, tidyverse style guide if you use R. Great start. Otherwise, following company styleguides, burn that shit into your brain. Read other people's codebases, learn the conventions and when to break them. Learn when to hack stuff together and when to spend the time. Best practices are really just norms, some people use 2 spaces, some 4, god forbid 8, i know a guy who uses 3. Get stylers, i use prettifier for alot of code in vsc. Most ides have a shortcut for auto-formatting to convention. Rstusio for example will auto format (base rstudio or tidyverse - styler). But that wont fix bad naming conventions. Dont get wrapped up in convention wars, pick something and make it your standard.",2022-02-20 18:45:48
Comment,1,hxpyfop,,0,1645375540.0,I see. Do you guys do a lot of the coding and analysis from scratch? Any specific packages/language?,2022-02-20 18:45:40
Comment,58,hxpy7il,,0,1645375450.0,"According to my experience (I recruit ml engineers and ds) ""design patterns"" and ""unit tests"" are the most important subject to master if you want differentiate yourself from the 99% of candidates",2022-02-20 18:44:10
Comment,1,hxpy6k8,,0,1645375440.0,R is not real programming anyway lulw.,2022-02-20 18:44:00
Comment,4,hxpxjf4,,0,1645375183.0,"I was a software engineer for almost 10 years before returning to academia and eventually transitioning into a career in DS. In this capacity I was an individual contributor (IC) for 5 years before moving into people management where I’ve been 5 years as well. I think it is extremely important to for DS to be able to write clean, coherent, production-quality code. This skill is just as important as (some would argue more so) model fitting, data wrangling, and business/domain knowledge — especially in companies that lack specializations in adjacent disciplines and roles (DE, MLE, etc) and/or are relatively early in their DS maturation process. There are a number of good general resources (as others have pointed out) that can be applied to DS (Clean Code is a good one, as is Martin Fowler’s work on refactoring). The Design Patterns book by Gang of Four is a classic, and although it focuses on OO patterns, many can be leveraged in projects that make use of DS/AI/ML. In my personal journey towards writing high quality code, I have a preference for getting down to the nuts and bolts of the language by reading the actual language specification - great way to really understand the details and implications and shortcomings of a language.",2022-02-20 18:39:43
Comment,2,hxpwgot,,0,1645374746.0,"I don’t write any production code, we just do adhoc analyses on my team. But I created a template to be able to run it with different specs.",2022-02-20 18:32:26
Comment,2,hxpwef5,,0,1645374719.0,"So like the one I described where they have been using a CNN and a LSTM?  
What I am struggling with atm is to understand if there is a basic difference between a approach where you have a mainly graph related problem, such as traffic predictions and a mainly time related problem such as taxi demand.",2022-02-20 18:31:59
Comment,1,hxpw9bl,,0,1645374661.0,What makes you think it’s fishy?,2022-02-20 18:31:01
Comment,1,hxpw4yu,,0,1645374611.0,"Hi u/Coder2j, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 23 karma.",2022-02-20 18:30:11
Comment,2,hxpw4q5,,0,1645374607.0,">I can't remotely understand the philosophy behind using some sort of NHST cutoff value to evaluate a real-world A/B test. Especially some generic alpha pulled from an undergrad social sciences textbook. That company is probably making a lot of stupid decisions.

Hate to break it to you, but this is a very common approach.",2022-02-20 18:30:07
Comment,1,hxpw32o,,0,1645374589.0,"Thank you for that very detailed response!

As to your questions:
1) The way the data is stored I can group it by day, week, month, quarter, year etc. (Could even do time period - that’s how detailed I can access although ofc that would break the server). I may have undersold how many products I need to model due to restrictions on what I can say.

But basically it’s a lot of supermarkets. (2,3)

(4) I don’t have clicks but (5) I do have regions. Whether they matter I don’t know yet I’ll have to look into that.


I think I’ll have to look into ARIMAX models but what I was wondering was mainly is there a way to get sales by period of the year and also pricing and make it simple enough. 

I do agree that maybe a linear model is the best I can do but was hoping to see if someone has a better suggestion to automating the modeling process while making some sort of useful model.",2022-02-20 18:29:49
Comment,-1,hxpvuad,,0,1645374488.0,How about kaggle? It's a community,2022-02-20 18:28:08
Comment,2,hxpvpq1,,0,1645374437.0,">choosing appropriate prior

Vaguely informative is plenty fine - unless you have very little data to work with, the data will overwhelm it anyways.",2022-02-20 18:27:17
Comment,1,hxpvcfj,,0,1645374284.0,"I'd check out the book the Pragmatic Programmer. It really goes into great depth about writing good code that can be easily modified in the future and will not create too much technical debt.

I'm in a similar situation to you and found it very, very helpful.

I'll also second the recommendation of Arjancodes on YouTube for his code refactoring videos",2022-02-20 18:24:44
Comment,1,hxpuvl9,,0,1645374094.0,It definitely could! I would personably try this first before any other model.,2022-02-20 18:21:34
Comment,1,hxpukmx,,0,1645373972.0,Can you share some resources on design patterns and style guides from major tech companies please?,2022-02-20 18:19:32
Comment,0,hxptwf6,,0,1645373698.0,"By GLM, are you referring to Generalized Linear Model? You mind telling us resources like books etc for GLM? Thanks in advance 🙏",2022-02-20 18:14:58
Comment,-1,hxpt8jm,,0,1645373427.0,"u/the75th wrote ‘a feed forward NN with 1 or 2 hidden layers’ and my reply was to that!

I have no energy to argue with random strangers for a trivial thing. 

So whatever you say is right my lord!!",2022-02-20 18:10:27
Comment,2,hxpt77k,,0,1645373412.0,"I have done quite a bit of price elasticity modeling in industry.  It is very challenging, and very context-specific.  The questions I would have is  
(1) what are the volume sales per unit period?  This will determine how much you can discretize time.  
(2) what kind of products are they?  We had some products where the price swings were based on raw material costs, and the elasticity due to raw material costs was much lower than for price changes in other contexts.  
(3) do you have repeat customers?  Tracking repeat customer behavior works much better for elasticity  
(4) do you have click data (so you can see customers which viewed the product but chose not to buy  
(5) Is there geographical segmentation that is relevant?  


Some other thoughts:  
(1) With modeling, you likely do not have enough data for each product to have a complex model, so regression may have to do.    
(2) Time series with regressors might work here (ARIMAX) to capture the elasticity.    
(3) If you don't do straight time series, you will want to look at whether you want to model levels or changes.    
(4) Sometimes it helps to log-transform the data.    
(5) One difficult feature that I saw sometimes was that price elasticity was often asymmetrical, in that the elasticity coefficient for price increases was very different than for price decreases.  I have talked with others who have seen this in their data, but the literature contains virtually nothing about this.",2022-02-20 18:10:12
Comment,2,hxpsvma,,0,1645373280.0,"Read clean code, read up on design patterns and style guides from major tech companies

Most importantly find sr engineers and have them review your code",2022-02-20 18:08:00
Comment,20,hxpstop,,0,1645373257.0,"If you work somewhere that has a decent sized code base...just read code other people in your work are writing.

DO NOT be the person who reads some book or article and starts pushing code that looks differently because ""that's how it's supposed to be"".",2022-02-20 18:07:37
Comment,122,hxpsqxa,,0,1645373227.0,"I didn't do a CS degree either but what helped me immensely was unironically watching a bunch of [YouTubers like this](https://www.youtube.com/c/ArjanCodes) and [also like this](https://www.youtube.com/c/mCodingWithJamesMurphy). They also cover things such as unit tests etc which you should be doing if you're putting anything in production. Unit tests and version control make your life so so much easier, even for a data scientist.

I also think it's important to understand that ""production-quality code"" means very different things for data science than software engineering. The links above cover stuff from a very SWE-heavy angle but you should definitely not try to replicate all of it for data science, it makes no sense. What you should really focus on learning first is idiomatic Python, using the right naming conventions, potentially using a formatter/linter etc.

I also agree with u/dataguy24 the bits you're doing in SQL can and should be handled with DBT. It gives you all of the nice stuff, version control and tests for a SQL heavy workflow.",2022-02-20 18:07:07
Comment,12,hxpsiph,,0,1645373133.0,"For Python I used ""Clean Code"" by Robert Martin. His examples are in Java, but the topics he covers are really good. Things like naming conventions, when to use comments, etc. 

&#x200B;

For Python specifics... I like talks by Raymond Hettinger. He is a great teacher and his examples are very good. His talks have definitely shaped my 'strategy' for writing production code. 

[https://www.youtube.com/watch?v=OSGv2VnC0go](https://www.youtube.com/watch?v=OSGv2VnC0go)

[https://www.youtube.com/watch?v=wf-BqAjZb8M](https://www.youtube.com/watch?v=wf-BqAjZb8M)

[https://www.youtube.com/watch?v=UANN2Eu6ZnM&t=273s](https://www.youtube.com/watch?v=UANN2Eu6ZnM&t=273s) (This one is my favorite IMO)

&#x200B;

On top of that, try and find a github repo that is in a similar field as what you are doing. Figure out if they are writing good production code and copy their style or figure out what you would do differently.",2022-02-20 18:05:33
Comment,1,hxpsi73,,0,1645373127.0,"For this one interview, it became abundantly obvious 5 minutes into the interview that this was not a company you want to work for. It was a remote position, but they were claiming you had to live in the city and come in to work every day…but still pushed it being remote. They had zero idea what types of things the position would be working on. There were a bunch of other things, but anyways, I decided to answer it as “a weakness I have is not wanting to be misled about expectations, if an employer says one thing will take them at their word for it. I don’t like when they say one thing then say another thing the next time we meet. For example, role in a company, if I’m hired to do something I should be doing that. I’m not being hired to do a different job.”

I obviously said this a bit more eloquently, but this was the brunt of it. She did not get the message, as I had to repeatedly decline to do the next interview.",2022-02-20 18:05:27
Comment,3,hxpsd7a,,0,1645373072.0,"Dl just means more than 1 hidden layers, you dont know what you're talking about lmao",2022-02-20 18:04:32
Comment,14,hxpsckb,,0,1645373065.0,"https://effectivepython.com/

https://www.python.org/dev/peps/pep-0008/",2022-02-20 18:04:25
Comment,2,hxps43x,,0,1645372968.0,How does one get into doing research analytics for NASA or other space related research areas? Currently I'm partway through an BA (then an MS) in statistics with two minors- in data analysis and physics. What can I do to get a better chance for that area? Research? Internships?,2022-02-20 18:02:48
Comment,1,hxprzaf,,0,1645372914.0,I don’t know if it’s truly health tech - it’s more like the primary coding software used in hospitals and CMS uses our products . There is a lot of research . Your hospital probably uses one of the products,2022-02-20 18:01:54
Comment,7,hxprm9s,,0,1645372765.0,I can’t speak to Python as that’s far more broad. But for SQL style guides I’ve always enjoyed dbt’s take [found here](https://github.com/dbt-labs/corp/blob/master/dbt_style_guide.md).,2022-02-20 17:59:25
Comment,1,hxpre65,,0,1645372671.0,"The stat masters at my alma mater has offers tons of electives, I can just not pick all of the ANOVA courses and go straight for all the advanced / nonparametrics courses of which are a thing in the program. I can also wiggle my way out of some BS based on the quant business + AI masters. If I can't hit research scientist in 2 years I think I'll just bite the bullet go for a PhD and do an MS stats at the same time.

About the interpretability bits - I actually think people overestimate that stuff. Unless you're working in a regulatory environment you should be able to sell SHAP as much as say logit. Explaining the odds ratio and shap to someone that understands 0 stats is probably as cursed.",2022-02-20 17:57:51
Comment,-2,hxpr15n,,0,1645372526.0,Deep learn *does* mean the network is deep- and so in this case a NN with 2-3 layers is not ‘Deep Neural Network’,2022-02-20 17:55:26
Comment,1,hxpqzv7,,0,1645372511.0,"Hi u/Background_Stress_7, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 1 karma.",2022-02-20 17:55:11
Comment,3,hxpqm9x,,0,1645372354.0,Thats what i woukd have said. In the second case its a different problem but run twice means twice the sample size. If repeating the same tests you now have 2x the sample size which should mean the results much more likely to be significant than each set coming in at approx 5 pct.,2022-02-20 17:52:34
Comment,2,hxpqbtz,,0,1645372234.0,I would love both SQL and Python. It's what most of my next role is going to be.,2022-02-20 17:50:34
Comment,5,hxpq95y,,0,1645372203.0,Are you talking about SQL code or Python code? Or other?,2022-02-20 17:50:03
Comment,1,hxpq6kn,,0,1645372173.0,"I’m not sure about finance, but for DS/analytics roles: 1) entry level roles are saturated and it’s hard to get your foot in the door somewhere and 2) many jobs require/prefer a masters degree. 

So while longterm analytics/DS can pay very well, it might be harder to enter this career. Although I have no idea what it’s like for finance, especially in EU.",2022-02-20 17:49:33
Comment,1,hxppvib,,0,1645372044.0,"It varies by company (and boss), but I am a data scientist (analytics) and have what you’re looking for - WFH, good work/life balance, no issues taking time off, no one bugs me in the evenings or weekends, and I could probably do a 4/10 schedule if I asked. But I’m in the US and most of my team is in Europe, so that might help significantly (the time difference and also their approach to work/life balance). 

I will say, due to the demand for experienced analytics/DS folks, we have the upper hand in terms of demanding WFH and also I would guess getting less pushback if we adhere to a strict schedule. From what I’ve read online, at least in tech, companies that aren’t remote or at least hybrid are having a really hard time getting people to even interview let alone accept jobs.",2022-02-20 17:47:24
Comment,1,hxpp64h,,0,1645371742.0,"No, because at most, their DS roles are actually more analytics/data analyst roles. A masters will help you stand out though. 

I think they have something like “research scientist” and that requires/prefers a PhD.",2022-02-20 17:42:22
Comment,2,hxpp4i2,,0,1645371723.0,"Agreed but try and adjust based on your inference of their interest. State a few high level answers in this case about the math, about A/B testing, and about business context/the company you’re interviewing for. Then, ask if there’s any they want you to go deeper on.

This also highlights your multi-dimensionality (not just good at stats, or whatever the Q was), and communication.",2022-02-20 17:42:03
Comment,2,hxpp478,,0,1645371719.0,"This is correct answer, they were just fishing for excuse not to hire someone who they kept on standby for few weeks.



Most interviews that want to hire me were justca way to find limits of my knowledge and those were not eliminating. But very big difference with highly imprecise technical questions when they clearly don't want me.",2022-02-20 17:41:59
Comment,2,hxporu4,,0,1645371574.0,"I work at a large company and we have 6 levels for analysts/data scientists, and I think Principal is our highest level (or maybe it’s 5 and Distinguished is highest). So I wouldn’t consider you having a lower title. We only use manager/director titles for people who manage teams. “Principal” carries a lot of weight and out of a team of 40 (with probably 30 ICs), only one person on our team had that title. Most were at level 2-4. 

Anyone at a big tech company should recognize that this is a good title.

Edit, checked the levels for ICs on my team (advanced data analyst / analytics DS):

- I = entry level, 0-1 YOE
- II = 1-2 YOE or entry for masters/PhD 
- III = 4 YOE, 3 with masters, entry for “exceptional” PhD 
- Senior (IV) = 7 YOE, 5 masters, 4 PhD
- Principal (V) = 12 YOE, 10 masters, 8 PhD
- Distinguished (VI) = 16 YOE, 14 masters, 12 PhD",2022-02-20 17:39:34
Comment,1,hxpopye,,0,1645371551.0,Cross a geo-spatial model with a time series model.,2022-02-20 17:39:11
Comment,2,hxpnon3,,0,1645371124.0,Then study the one you're better at / is most interesting to you. Your aptitude and interest in either field is what determines how much money you will make.,2022-02-20 17:32:04
Comment,2,hxpnm05,,0,1645371092.0,"Data jobs and finance jobs are solid positions to have, though at least in the US, data jobs are more highly paid. Finance teams typically don’t use the latest tools and therefore don’t scale their abilities very well. 

Not sure the advice for the EU though since I hear data isn’t paid very well over there compared to the US. 

Regardless of pay, managers want to see experience. If you can do the job, that speaks to your candidacy more than education. Try to do what almost all of us did to break into data: work an office job and start taking on data tasks without anyone asking you to.",2022-02-20 17:31:32
Comment,1,hxpnean,,0,1645371000.0,"Haha, though all this new nonlinear and causal inference stat stuff is often not covered at all in an avg stat program either lol. Some are becoming more modern and following the top ones.When I did my degree we had DOE covered by an old prof who worked in clinical trials. Most boring shit ever. Literally did m-factor ANOVAs by hand for weeks and I think this was the class I got the least out of. The year after that they got a younger prof from UW stat who started covering more modern causal inf stuff. 

I picked up this stuff because of working in omics where I was bored doing standard regressions for millions of p values and wanted to at least spice it up a bit lol. 

This stuff is why imo, in 2022 the lines between pure prediction and pure stat inference are blurring, but its going to take more time before such methods are used more widely in industry. Right now, we still have the issue that while a statistician can learn to interpret the nonlinear stuff, communicating it to a business person is another problem entirely. That really is the issue with causal inf methods as well as SHAP and ML interpretability in general. The theory is there but non-technical communication of the result is hard.",2022-02-20 17:30:00
Comment,1,hxpmwit,,0,1645370782.0,"Project management tools exist for the very purpose of being the go to place to get progress on tasks. Remember, the people doing the task have many different people waiting on them and don't have time to keep sending personalized updates to everyone.",2022-02-20 17:26:22
Comment,1,hxpm7pp,,0,1645370485.0,"Just dont. 

Use xgboost.

If you need to extrapolate mix it with linear regression.

Only the think about neural networks.",2022-02-20 17:21:25
Comment,0,hxplslv,,0,1645370306.0,Main goal is to escape from poverty so as much money as possible,2022-02-20 17:18:26
Comment,2,hxplih1,,0,1645370186.0,Ok makes sense thanks,2022-02-20 17:16:26
Comment,3,hxpl5al,,0,1645370020.0,"What's your end goal? If you want to do finance, study finance. If you want to break into  data science, you might as well enroll in a masters of statistics.",2022-02-20 17:13:40
Comment,2,hxpkufi,,0,1645369884.0,"Interesting, so was this something you used as an analysis tool or did you productionize?",2022-02-20 17:11:24
Comment,1,hxpkpwa,,0,1645369827.0,Oh wow,2022-02-20 17:10:27
Comment,1,hxpkmw2,,0,1645369790.0,"I’m fine with the principal of it but in my company the processes around it are extremely slow. In my company new datasets need to go through an onboarding process through DG and when a scientist wants to access it for some new purpose, they need to submit a request and wait potentially weeks for it to get through the DG check. I’ve recently had cases where our work was just halted for days or weeks due to DG processes. Things used to be a lot looser and it was way easier to quickly check/analyse things.",2022-02-20 17:09:50
Comment,1,hxpkjpq,,0,1645369750.0,DS. I was in health tech for 10 years.  I'll never go back.  Much prefer working for the healthcare systems.  Little less money but 1. I think we're in a bit of a health tech bubble and 2. I'm tired of seeing mediocre products bleed non profits dry,2022-02-20 17:09:10
Comment,1,hxpkitu,,0,1645369739.0,Should I stick to finance in my master's or would I benefit from transitioning to data science and economics? (EU coming from a finance bachelor and 0 programming experience),2022-02-20 17:08:59
Comment,2,hxpkc3x,,0,1645369653.0,"No. Much like most data jobs, FAANG require experience. 

Also, I interviewed for a “DS” position from Facebook. That means Data Analyst to them and the role was analytics. If you want to get into algorithms the title is Machine Learning Engineer.",2022-02-20 17:07:33
Comment,1,hxpjym3,,0,1645369481.0,What did you end up answering?,2022-02-20 17:04:41
Comment,2,hxpjx7u,,0,1645369464.0,"From someone who doesn’t know much, can I ask why multiple linear regression wouldn’t suit this example? 

Thanks :)

Best of luck",2022-02-20 17:04:24
Comment,12,hxpjeyb,,0,1645369233.0,"You can read [https://www.evanmiller.org/bayesian-ab-testing.html](https://www.evanmiller.org/bayesian-ab-testing.html)

or watch [https://pyvideo.org/pycon-india-2018/bayesian-ab-testing-using-python-by-vaibhav-pawar.html](https://pyvideo.org/pycon-india-2018/bayesian-ab-testing-using-python-by-vaibhav-pawar.html)",2022-02-20 17:00:33
Comment,3,hxpio4l,,0,1645368883.0,Not only does this vary by company and industry it also varies by boss. However it sounds like work for home would fit most of your needs,2022-02-20 16:54:43
Comment,1,hxpilvd,,0,1645368853.0,All of the stuff on DoubleML is new to me! Guess I need to consider getting a 3rd masters degree in stats after all ;),2022-02-20 16:54:13
Comment,2,hxphp4b,,0,1645368431.0,"It’s actually used for basically any kind of risk forecasting. Insurance risk adjustment, credit cards and other loans, cyber risk quantification (FAIR), and others",2022-02-20 16:47:11
Comment,2,hxph6iy,,0,1645368181.0,"No problem !

Prior to that you can do some outlier detection for time series to make sure your coefficient are un-biased for specific variables.",2022-02-20 16:43:01
Comment,6,hxpfvve,,0,1645367566.0,"The title is a little confusing (I’m not sure how to interpret principal data analyst), but I wouldn’t be too concerned with titling if you’re in the early stage of your career. Focus on compensation trajectory and skill development/experience",2022-02-20 16:32:46
Comment,1,hxpfv4p,,0,1645367556.0,"Once you get to a certain scale of data, dl starts beating gbms as well. Thats why uber switched to dl from xgboost for their eta predictions and got significant improvements",2022-02-20 16:32:36
Comment,2,hxpflf8,,0,1645367423.0,"""he has a CS background, not statistics"" - you must be a fun colleague to work with",2022-02-20 16:30:23
Comment,2,hxpfd5u,,0,1645367305.0,Deep learning doesnt mean you need 100s if layers,2022-02-20 16:28:25
Comment,1,hxpf7r4,,0,1645367227.0,Well I'd really like to be able to predict who survived the titanic instead of just looking it up. Real answer is the event horizon telescope data,2022-02-20 16:27:07
Comment,1,hxpf00r,,0,1645367118.0,"I’m seriously considering training to switch careers and break into data science. However, I really want a good life balance in my next career (why I’m considering leaving this one).

Ideally, I’d love a job that might have some weeks that are harder or easier, but I’m generally not expected to stay after, can get days off when I want them, can work remotely, maybe even can flex my hours and work 4 10-hour shifts and have Fridays off. Is this something possible or way off the mark for data science?

Lastly, I am considering having children and would be interested in working part time while my children are young (ex: 2, 10-hour days). Is this a realistic option for data science, or is it really full time options only?

Thanks!",2022-02-20 16:25:18
Comment,1,hxpeha1,,0,1645366848.0,"Markov decision processes are an extension of Markov chains; the difference is the addition of actions (allowing choice) and rewards (giving motivation). Conversely, if only one action exists for each state (e.g. ""wait"") and all rewards are the same (e.g. ""zero""), a Markov decision process reduces to a Markov chain.",2022-02-20 16:20:48
Comment,1,hxpebw9,,0,1645366773.0,"If the interviewer worried too much about FDR, then just lower alpha to 0.01. Then, all rejected",2022-02-20 16:19:33
Comment,3,hxpe199,,0,1645366621.0,"Google machinelearningmastery a gente introduction to markov chain monte carlo.
That website gives a brief introduction and has links to books to read.",2022-02-20 16:17:01
Comment,2,hxpddz2,,0,1645366284.0,Write access? The credit reporting agencies datasets.,2022-02-20 16:11:24
Comment,3,hxpctu4,,0,1645365987.0,"The value is larger numbers is accuracy/precision in estimating the test statistics. It doesn’t really matter if all p-values are theoretically equally likely even if that’s true. And I’d have to think harder than I’m willing to on a Sunday morning. 

But I do think that it’s fair to attach more or less legitimacy to results (correctly interpreted) with larger sample sizes than smaller. There’s certainly a point if diminishing returns but still. 

With smaller sample sizes it’s harder to detect smaller but important effect sizes. This is the entire purpose of a power analysis to determine the N with which we can rely on a p-value at a particular level. 

I’m not claiming you’re more likely to get false positives, I’m saying the p-value asymptotically approaches zero. Which diminishes its value in large samples. A p-value is a probability estimate. It should be interpreted as such, including the incorporation of how sample size impacts probability estimates.",2022-02-20 16:06:27
Comment,1,hxpc2cj,,0,1645365582.0,"I was just going off of memory, I always have to look it up to get it exactly right. I’d never expect a candidate to recite the conditional probability, but just knowing that it exists and causes nuance.",2022-02-20 15:59:42
Comment,-2,hxpbo8y,,0,1645365370.0,"There was recently some small drama regarding claims of using DL on tabular data giving 'similar' results to RF. In short, leave DL+tabular to the quacks(academics)",2022-02-20 15:56:10
Comment,2,hxpax4n,,0,1645364955.0,"Hi everyone,

Does anyone have recommendations for online masters programs focused more on the Big Data Engineering/Data Wrangling aspects of Data Science? Or E-learning?

I have 14 years of experience in analytics, with the first 6 years as a hands on statistician, while the last 8 years have been less hands on and more management of analytics/insights projects and data visualization/dashboard design. 

I'm fairly good with some traditional machine learning techniques (regression, clustering, classification, association, dimension reduction etc). The Data Engineering/Wrangling aspects have always interested me since they tend to take up a majority of the time on DS projects, but I've never gained a proficiency in it (I've generally always had datasets cleaned and delivered to me, but having these data skills is necessary for most modern data science roles I see).",2022-02-20 15:49:15
Comment,2,hxp9gfl,,0,1645364138.0,"Yeah, i don't think the technical answers were the reason. More something like a vibe thing or just that a different candidate was a better fit.",2022-02-20 15:35:38
Comment,2,hxp99vi,,0,1645364035.0,"Residual plots by eye may not be sensitive enough to that. You would know there was a nonlinear association if you fit an RF and linear model—only on the right variables, aka dont include colliders in the graph—and looked at predictive accuracy. If the RF/xgb performed much better then there is evidence of nonlinearity and the difference is quantifies how much. The problem with this approach is by examining the predictive accuracy unless you do the actual inferential stats on another held out dataset you end up biasing the inference.

There are new methods in econ/stats that account for nonlinearity to do inference though. One is called orthogonal Double ML. It works only for continuous Y and is actually related to residuals—you basically fit an ML model with MSE loss of Y against confounders and an ML model of X against confounders (even if X is binary, use MSE loss) and then regress the Y residuals against X residuals in just a univariate linear regression. Throw on a sandwich estimator and then the coefficient and p value of the final univariate linear model are the causal effect of interest provided you had the right confounders. If your treatment is nonlinear then the final model can include splines too. 

Basically it amounts to isolating out the variable of interest and modeling the others nonlinearly. Its in Python too https://docs.doubleml.org/stable/guide/basics.html",2022-02-20 15:33:55
Comment,2,hxp99v7,,0,1645364035.0,Were the models applied primarily to demand forecasts?,2022-02-20 15:33:55
Comment,1,hxp90k4,,0,1645363888.0,Ah that sounds like exactly what I am looking for!,2022-02-20 15:31:28
Comment,1,hxp8vuu,,0,1645363810.0,"Hi u/civil4991, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 10 karma.",2022-02-20 15:30:10
Comment,1,hxp89ns,,0,1645363439.0,It’s Markov decision process used in reinforcement learning which is an extension of Markov chain. The difference is that Markov decision process is continuous time while Markov chain is discrete time for future behavior.,2022-02-20 15:23:59
Comment,1,hxp87l4,,0,1645363405.0,Thanks!!,2022-02-20 15:23:25
Comment,1,hxp7yle,,0,1645363258.0,[sklearn documentation is a really good an easy to understand read.](https://scikit-learn.org/stable/modules/grid_search.html),2022-02-20 15:20:58
Comment,1,hxp7u4k,,0,1645363187.0,Do you have any good articles on how to do a grid search? I was trying to follow a couple and failed miserably.,2022-02-20 15:19:47
Comment,0,hxp7u14,,0,1645363185.0,"I know GAM's are capable of assigning a level of importance to features. I'm sadly constrained to Python (for now) so I never use them, I do use `scipy.interpolate.Rbf` or `sklearn.preprocessing.SplineTransformer` to achieve similar effect. 

The interactions make sense, even for a medium sized data set, so long as there's no insane amount of knots (e.g. splines for daily seasonality instead of fourier terms). 

I think you can use the [Nystrom method](https://boostedml.com/2020/08/the-nystrom-method-for-finding-eigenpairs-of-a-kernel-function.html) yourself to consider interaction and not have it be terribly slow, it's essentially a low rank representation of the kernel (Gram) matrix. This is what I usually do if I'm going that route. Reason why I'm mentioning this in this post is by this point I seriously think I should've done xgb or a 2-4 layer MLP.

Although I've more or less been a soc sci researcher for the past months I actually read none of their papers. If there's a nonlinear association can't you just see that in the distribution of the residuals? Is this not commonplace to do even for them even though it's econometrics 101?",2022-02-20 15:19:45
Comment,2,hxp7cwe,,0,1645362895.0,"Stop being a condescending jerk. If you can’t help, just don’t comment.",2022-02-20 15:14:55
Comment,1,hxp6w8m,,0,1645362611.0,"Hi u/BroRo01, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 15 karma.",2022-02-20 15:10:11
Comment,2,hxp6l0g,,0,1645362413.0,I’m completing a masters and would be interested in sharing ideas.  I’m a relative beginner in NLP tho.  And my main interest is in natural lang understanding and hybrid rule based + ML systems…because i am working on a project where the answer isn’t as important as the why…,2022-02-20 15:06:53
Comment,0,hxp6gtp,,0,1645362340.0,"Its trickier to interpret it but its doable, just needs some advanced stat. GAMs in R with te() in mgcv do consider nonlinear interactions. They are slow to fit though on large datasets for sure. 

What bothers me though is the reams of social sci and biomedical papers that just throw linear additive features into a model and “control” for features by just putting them into a regression without any feature eng. Controlling for variables linear-additively doesn’t necessarily actually control for them if there is nonlinear association to those variables. And I never see it justified domain-wise lol as a statistician DS most domain experts don’t really know the true function—they help with variable selection. Somehow everyone knows/thinks that “normality” is important and just forget about linearity being critical to inference too.",2022-02-20 15:05:40
Comment,1,hxp6eqy,,0,1645362304.0,Do FAANG companies in general require a Masters/PhD candidate for a Data Scientist position?,2022-02-20 15:05:04
Comment,1,hxp667o,,0,1645362158.0,If it’s to scale then there will be a huge and empty 50 yr blank space with a bit of action on either end…,2022-02-20 15:02:38
Comment,1,hxp5uwr,,0,1645361959.0,google bara.bet guys they're doing that,2022-02-20 14:59:19
Comment,2,hxp5nsb,,0,1645361831.0,"I got an MS from one of the better known universities in this field and it was the best decision I ever made. I ended up with multiple offers and ultimately took one at a bank for $135k base and $30k incentive comp. I have a PhD in a science field and I still ended up adding over $50k to my previous salary. Many of my classmates have gotten salaries between $90k-$120k. If you can handle the opportunity cost of going to the program, I would definitely recommend it. I think more than the initial foot in the door itself, the alumni network is what really gives the program value. Moving jobs in the future is pretty easy. 

If you want more details about the program, feel free to dm me. This program serves you best if you come in with job experience in a different field.",2022-02-20 14:57:11
Comment,1,hxp4jtl,,0,1645361093.0,"https://towardsdatascience.com/applying-a-clustering-algorithm-to-feature-contribution-3c649ab0ca17

https://docs.datarobot.com/en/docs/tutorials/using-the-api/pe-cluster.html",2022-02-20 14:44:53
Comment,4,hxp4765,,0,1645360855.0,"Splines can add a lot of dimensionality and don't even consider feature interaction. I guess you could add them with ""domain knowledge"" but if you're unsure about what interaction terms are interesting you could throw on a kernel (approximation) and consider all of them. At this point the logistic regression is more or less an RBF SVM lol.

OP only has 32 features so this doesn't matter. But tbh, if you're adding splines and other transformations you lose most of the interpretability anyway and you might as well consider things that are non-linear out of the box. Personally I always start with something like logit just to get some baseline(s) though, don't get me wrong.",2022-02-20 14:40:55
Comment,1,hxp3yza,,0,1645360705.0,those are all my favourite subjects lol (i mean astronomy isnt really a subject we study here but you get the idea),2022-02-20 14:38:25
Comment,1,hxp3i9n,,0,1645360388.0,"I use them for understanding consumer behavior, what they do before and after an action",2022-02-20 14:33:08
Comment,2,hxp2ihq,,0,1645359682.0,"Yeah you are correct. Even if the pay would be good, working in such a fragmented IT landscape would be a nightmare. Where I’m from, our tax and welfare agencies cannot exchange information freely, which makes tracking down welfare fraud incredibly difficult…",2022-02-20 14:21:22
Comment,2,hxp27y6,,0,1645359472.0,"Clearly you've never honestly answered ""what is your biggest weakness"" /s",2022-02-20 14:17:52
Comment,2,hxp22yi,,0,1645359370.0,"People also tend to forget theres splines, transformations, etc that can improve the performance of logistic",2022-02-20 14:16:10
Comment,1,hxp1zhi,,0,1645359301.0,I think I've been trolling myself this entire time. I think I'm also very sleep deprived because my toddler isn't sleeping correctly.,2022-02-20 14:15:01
Comment,11,hxp17f5,,0,1645358722.0,"Lol, what an degrading unfriendly comment of yours",2022-02-20 14:05:22
Comment,1,hxp0tmz,,0,1645358437.0,"Hi u/the_real_Strobus, I created a [new Entering & Transitioning thread](/r/datascience/comments/swzsmx/weekly_entering_transitioning_thread_20_feb_2022/). Since you haven't received any replies yet, please feel free to resubmit your comment in the new thread.",2022-02-20 14:00:37
Comment,1,hxp0tm8,,0,1645358437.0,"Hi u/IAMHideoKojimaAMA, I created a [new Entering & Transitioning thread](/r/datascience/comments/swzsmx/weekly_entering_transitioning_thread_20_feb_2022/). Since you haven't received any replies yet, please feel free to resubmit your comment in the new thread.",2022-02-20 14:00:37
Comment,1,hxp0tlo,,0,1645358437.0,"Hi u/_darpann_, I created a [new Entering & Transitioning thread](/r/datascience/comments/swzsmx/weekly_entering_transitioning_thread_20_feb_2022/). Since you haven't received any replies yet, please feel free to resubmit your comment in the new thread.",2022-02-20 14:00:37
Comment,1,hxp0tl3,,0,1645358436.0,"Hi u/JournalistCritical32, I created a [new Entering & Transitioning thread](/r/datascience/comments/swzsmx/weekly_entering_transitioning_thread_20_feb_2022/). Since you haven't received any replies yet, please feel free to resubmit your comment in the new thread.",2022-02-20 14:00:36
Comment,1,hxp0tkf,,0,1645358436.0,"Hi u/Relevant-Rhubarb-849, I created a [new Entering & Transitioning thread](/r/datascience/comments/swzsmx/weekly_entering_transitioning_thread_20_feb_2022/). Since you haven't received any replies yet, please feel free to resubmit your comment in the new thread.",2022-02-20 14:00:36
Comment,2,hxp0tjm,,0,1645358435.0,"Hi u/jarena009, I created a [new Entering & Transitioning thread](/r/datascience/comments/swzsmx/weekly_entering_transitioning_thread_20_feb_2022/). Since you haven't received any replies yet, please feel free to resubmit your comment in the new thread.",2022-02-20 14:00:35
Comment,1,hxp0th3,,0,1645358434.0,"Hi u/Daaaarling02, I created a [new Entering & Transitioning thread](/r/datascience/comments/swzsmx/weekly_entering_transitioning_thread_20_feb_2022/). Since you haven't received any replies yet, please feel free to resubmit your comment in the new thread.",2022-02-20 14:00:34
Comment,1,hxp0tgl,,0,1645358434.0,"Hi u/Citizenofhudoor, I created a [new Entering & Transitioning thread](/r/datascience/comments/swzsmx/weekly_entering_transitioning_thread_20_feb_2022/). Since you haven't received any replies yet, please feel free to resubmit your comment in the new thread.",2022-02-20 14:00:34
Comment,1,hxp0tfq,,0,1645358433.0,"Hi u/Weekly_Atmosphere604, I created a [new Entering & Transitioning thread](/r/datascience/comments/swzsmx/weekly_entering_transitioning_thread_20_feb_2022/). Since you haven't received any replies yet, please feel free to resubmit your comment in the new thread.",2022-02-20 14:00:33
Comment,1,hxp0tez,,0,1645358433.0,"Hi u/INeedMoreShoes, I created a [new Entering & Transitioning thread](/r/datascience/comments/swzsmx/weekly_entering_transitioning_thread_20_feb_2022/). Since you haven't received any replies yet, please feel free to resubmit your comment in the new thread.",2022-02-20 14:00:33
Comment,-16,hxp0rve,,0,1645358401.0,"Your **3 forms of linear regression** are standard, ridge and lasso? Lol such a noob",2022-02-20 14:00:01
Comment,1,hxozrxo,,0,1645357631.0,"Bayesian filtering and smoothing methods are also based on the Markov property (similar to HMMs) and are used for various state estimation applications in robotics (position, orientation, velocity etc.).",2022-02-20 13:47:11
Comment,1,hxoymfn,,0,1645356725.0,"If you plan on using tensorflow, this here looks decent: https://www.tensorflow.org/tutorials/keras/regression",2022-02-20 13:32:05
Comment,0,hxoyd9z,,0,1645356515.0,Nope. Incorrect for some statements/intuitions there,2022-02-20 13:28:35
Comment,2,hxoy7id,,0,1645356384.0,"Literally been in that position last friday. Colleague tried to do a prediction task using a complicated NN for 3 weeks without even trying a logistig regression or xgboost (he has a CS background, not statistics).

I get annoyed with his approach, match his best model with a simple logistic regression and completely surpass it with a small but of feature engineering and an xgboost model with 1 hour, increasing F1 from 0.5 to almost 0.9.

Please people, don't use a hammer (NN in this case) for everything.",2022-02-20 13:26:24
Comment,2,hxoxxzo,,0,1645356168.0,"This illustrates the problem with many of these vague, contextless interview questions when there seems to be only one 'right' answer. It is impossible to really know why the question was asked.",2022-02-20 13:22:48
Comment,1,hxoxxq2,,0,1645356162.0,"If the null is true, all p values are equally likely (uniformly distributed). There is no validity in differentiating how meaningful a p value is above significance threshold.

Also, you’re not more likely to get false positives for small samples than for large samples. So… some fallacies here.",2022-02-20 13:22:42
Comment,2,hxox6jl,,0,1645355538.0,"I agree. I have used something similar in a real world project. 

I guess OP is not looking for Shallow NNs though",2022-02-20 13:12:18
Comment,1,hxox4do,,0,1645355488.0,Did they tell you they didn’t like that answer specifically? Could be something else.,2022-02-20 13:11:28
Comment,1,hxowf4o,,0,1645354916.0,Maybe they wanted to hear that the effect size of whatever you were measuring was just so that little variations would land you over/under 0.05? Basically you'd have to decide then if the effect size is meaningful to you without religiously relying on the cutoff?,2022-02-20 13:01:56
Comment,1,hxowefq,,0,1645354899.0,"so uh... regression using deep learning is kinda saying ""building a motor using a car""

a neural net with a single neuron and a single layer is in fact nothing else than multinomial linear regression.
(in a NN you would additionally normaloze the output with a sigmoid )

there is basically 3 forms of linear regression:
- standard regression (no regularization)
- ridge regression (you have a regularization hyperparameter)
- LASSO regression: you have regularization where basically your weights have a threshold and are either 0 or 1. this makes it in many cases easier to determine important variables",2022-02-20 13:01:39
Comment,1,hxovmvp,,0,1645354264.0,"Best Live feed data possible from a satellite , tracking anyone, anywhere at anytime would be pretty benefitial and everyone would pay you for your services.",2022-02-20 12:51:04
Comment,7,hxov8sg,,0,1645353936.0,"I don't think you can say that a priori to doing it. A feedforward NN with 1 or two hidden layers is probably suitable for this task and will not overfit if done correctly. Still not worth the effort to do it, OP should just use gradient boosting or a GLM.

EDIT: no free lunch theorem.",2022-02-20 12:45:36
Comment,18,hxouvcl,,0,1645353629.0,"In my experience, Random Forest, XGBoost or LightGBM models will probably outperform any neural network with minimal effort. NN’s usually tend to overfit and take absolutely forever to tune. You can probably run a grid search on tree based models, use permutation importance to prune features and call it a day.",2022-02-20 12:40:29
Comment,1,hxouaif,,0,1645353154.0,"p-value = p(result|null) = p(null|result) * p(result) / sum_i(p(null|result_i))

(Is that a helpful equation? Sort of interesting as a consistency check maybe, but probably not)",2022-02-20 12:32:34
Comment,5,hxotxhh,,0,1645352855.0,I'm sorry I'm not going to walk you through that. There's a gazillion guides on neural networks nowadays. [This is an example.](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras),2022-02-20 12:27:35
Comment,3,hxotjd1,,0,1645352533.0,"You can use a simple feedforward neural network, you would probably not even need that many layers. 

If this is for learning, definitely go ahead. Also compare it to xgboost, linear regression etc.",2022-02-20 12:22:13
Comment,1,hxosnx7,,0,1645351811.0,"Hi u/Daninon_, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 9 karma.",2022-02-20 12:10:11
Comment,1,hxor5kb,,0,1645350580.0,I'll have to ask my sibling about that. They're a physical chemist not a particle physicist but their research has them working with people who accelerate particles.,2022-02-20 11:49:40
Comment,1,hxoqqnz,,0,1645350245.0,Furthermore my understanding of GNN was that it's focus is on the spatial component in form of the edges and time is more like a side effect that can be included. However this problem is more time related than space related I would say.,2022-02-20 11:44:05
Comment,3,hxoqcc4,,0,1645349927.0,"""Big dolla dolla bills yo"" - best answer every time!",2022-02-20 11:38:47
Comment,1,hxoprfb,,0,1645349468.0,"Netflix streaming data. It pains me that this amazingly data-driven company is not sharing any real insights at all.

Also: WHY ARE MY FAVORITE SHOWS BEING CANCELLED???",2022-02-20 11:31:08
Comment,3,hxopn9x,,0,1645349375.0,"Well, I believe the classic way would be to use a Multiple Linear Regression in the Econometrics way under continuous timeframes (OLS) or à GLM if asked for specific periods where you’d create new timeframes (Summer, quarters or such).

After that, check the coefficients (Making sure your pValue are close to zero)… if your coefficient are high, the price sensitivity is significant & vice versa.",2022-02-20 11:29:35
Comment,1,hxop094,,0,1645348860.0,"Reading this thread and it's like It's another language - clearly I need to go learn me some stats, this isn't good enough.

Thanks everyone",2022-02-20 11:21:00
Comment,11,hxooscv,,0,1645348693.0,"I recommend to start with Bayesian statistics first to understand the concept. After that, you can apply to many use cases.

Gelman books are good start, including various practical examples",2022-02-20 11:18:13
Comment,1,hxoogdd,,0,1645348424.0,"It’s not only more transparent to interpret but also more practical to use in real life decision making, which always contains uncertainty. 

It’s more difficult to understand at the first step with choosing appropriate prior, compare to frequentist approach but the following process is much more transparent.",2022-02-20 11:13:44
Comment,1,hxoo8x4,,0,1645348260.0,"Don’t worry bro, it happens. Just consider it not being your day, I hope you will do well in the next interview.

Few days back I also fuck up in a very basic question, I kind of knew the answer but choked.

Basically I was told the interview will be verbal and out of no where the interviewer asked me to open an IDE and write the code for IOU of two images.

My stupid brain got froze but after few minutes I started writing the code and followed the very basic instinct of iterating through things. As the image was binary I iterated through width and height and ised nested for loop. Now at that moment interview ler asked me do I know numpy, I straight away knew I fucked up. But then he went for another question, Whole interview regarding basic of deep learning and python went so went, but that one question got the better of me and I haven’t got any response from them.
I prepared so hard for that interview because I so liked that startup, but sometimes it just not your day. So better luck next time. To me and to you as well.",2022-02-20 11:11:00
Comment,1,hxoo4kn,,0,1645348161.0,"In theory, writing tests is not difficult. But if all you've ever needed was some data crunching scripts for data analysis, why should you ever have bothered to even learn about it?

And as long as people stay in data analysis tasks, whether the involved machine learning or not, that is fine. 

The issues start when the same people are tasked, without adequate training or oversight, with integrating that code with a software product. 

You end up with good practices being unknown, misunderstood, or deliberately skirted. ""It is not a global variable if it is in a namespace."" Um what? `#define ZERO 0.0` Someone misunderstood ""no magic numbers"" and made the situation worse.

A complete lack of testing is likely among the worst consequence of such a development, because of its knock-on effects. Having to write comprehensive tests would force thinking about clean interfaces and separation of code units, including the avoidance of hidden inputs and outputs through (mutable) global state. It would also allow rewriting code later to account for new requirements, without almost certainly breaking production code.",2022-02-20 11:09:21
Comment,1,hxona0z,,0,1645347510.0,I’m glad I was of help. Keep it up!,2022-02-20 10:58:30
Comment,3,hxomsq5,,0,1645347127.0,"In marketing. Given the different stats I’d consider a p-value much lower as significant in circumstances. 

Marketing stats is a bitch. Far more practical than scientific if you want to separate you’re value from others. 

If you don’t have marketing experience, or prefer things to be right and accurate, pursue something else. Marketing is an ugly bitch that will leave you scratching your head how to communicate at times. 

Always remember your audience and what they want to hear. Then be as honest as you can while providing value to the decision making process",2022-02-20 10:52:07
Comment,2,hxomqcl,,0,1645347074.0,"Wanted to sat a huge thankyou! I'm presented my recommendations on Tuesday. Your input was a big help.

&#x200B;

Also that [Guru99.com](https://Guru99.com) website looks fantastic, seems to be much more detailed than most sites from the articles I've seen",2022-02-20 10:51:14
Comment,5,hxolgxj,,0,1645346068.0,">p-value is strictly a conditional probability that the null is true given the observed relationship

I think you have that backwards. The p value is a probability of data at least as extreme as observed, conditioned on the null hypothesis being true.",2022-02-20 10:34:28
Comment,1,hxol054,,0,1645345692.0,"Hi yeah sounds great the idea of discretizing time. 

Would you say the idea of just using a linear model be good enough or is there another statistical method which would be more appropriate.",2022-02-20 10:28:12
Comment,5,hxoks6x,,0,1645345512.0,I think this is what they were looking for. That's what I would hope the interviewee would take the conversation.,2022-02-20 10:25:12
Comment,1,hxok6yb,,0,1645345049.0,"Interesting....have you got some blogs, links about more of this strategy",2022-02-20 10:17:29
Comment,16,hxok2pm,,0,1645344959.0,"""had a question google couldnt answer"" usually (99.999%) means you're confused and dont know the right question. Start with definitions and making sure you're clear on them, their combinations, and you'll probably be 80% of the way yo answering your own question. Just fyi. (0.001% of the time youre the first to face some new esoteric bug). Im not saying this to be rude, googling is a tier 1 skill worth cultivating. Learn wildcards, using """" and -. 

This might set you in a good direction: https://www.kdnuggets.com/2020/04/data-transformation-standardization-normalization.html

Im not sure what you mean by preserving the mean, but your conclusions are more or less on track yes. Youre just describing standardization... 

Hopefully this link clears things up for you, its a good website for beginners. Analytics vidhya also has some great info. Otherwise medium and towards data science. Best would be pdfs of textbooks, libgen.is for free copies of classic books (ISL/ESL by tibshirani/hastie, statistical rethinking by mcElreath, hands on ML by aurelien geron, PRML by christopher bishop, kevin P. Murphy 2021)",2022-02-20 10:15:59
Comment,3,hxojzjl,,0,1645344887.0,"Bingo. I want to hire data scientists who are strategic about test planning, not just robots that say significant if P<0.05. The kind of thinking above is exactly what I look for when I hire.",2022-02-20 10:14:47
Comment,1,hxojx4v,,0,1645344833.0,"Awww this sucks man. But personally if the pvalue was that close to alpha, I would’ve rounded up & retained the null. Guy definitely pulled a trap card for someone not to involved with stats😭",2022-02-20 10:13:53
Comment,1,hxojwpj,,0,1645344823.0,"Let's not assume, please. We've only heard one side of the story.",2022-02-20 10:13:43
Comment,2,hxoju6q,,0,1645344766.0,Yep. Bingo.,2022-02-20 10:12:46
Comment,1,hxojc2v,,0,1645344363.0,"I'm a data scientist. I've given similar interviews. Here's what I perceive as your mistake: you ended at the 'reject the null hypothesis.' In an ideal world, this is where your answer begins. There's so much more texture to real-world decisions than null hypothesis testing. E.g.,  


What is the cost of more testing? If it's cheap, get more data.

What's the trade off of being wrong in either direction? If rolling out means huge amount of cost and no rollout means no cost, then be extra conservative in rollout decisions.

What's the actual thing being tested? Do you have some product sense that gives you a prior belief on whether it would be successful? That too should influence your interpretation of the p-value.   


What's the magnitude of the effect? If it's tiny, then who cares if it's significant.  


Was this test one of a gazillion? Then maybe should worry about multiple hypothesis testing more carefully.

&#x200B;

Et cetera. Good luck mate!",2022-02-20 10:06:03
Comment,2,hxoja2d,,0,1645344320.0,"If you’re going to stay in Env work, I might suggest also learning geographical coding to generate spatial data output. Eg wind farms (and most marine developments) need EIA and detailed analysis of the predicted impact of such work to go ahead. It is in theory a boom time for such work.",2022-02-20 10:05:20
Comment,3,hxoiyuk,,0,1645344085.0,"At the average small bank or credit union, stats means ELI5’ing the difference between median and average to executives and making sure the charts match brand guidelines.

I’d imagine ecology stats are a bit more rigorous.",2022-02-20 10:01:25
Comment,4,hxoitzj,,0,1645343981.0,"Make a huge assumption and discretize time.

Even if you had a perfectly smooth prediction of elasticity to the microsecond, there’s a few problems:

1. You can’t predict the future, therefore predictions will be out of independent variable range along the time dimension. Not good in a regression.

2. Not like sales can actually act on these predictions at that near inviting frequency anyways. Maybe if y’all were a global retailer processing millions of transactions per second it would be appropriate. Given the nature of humans, you’d probably be fine with either 12 or 52 bins.",2022-02-20 09:59:41
Comment,3,hxoimb7,,0,1645343813.0,"Job hop 🤷‍♂️ youll guaranteed get over 100k, maybe over 110. Could go in so so so many directions, start researching the field for what you'd be interested in. Start upskilling while you're employed!!! Easier to find a job when you have a job.

Read ISL and ESL by tibshirani/hastie. Read statistical rethinking by McElreath if you need it. Read PRML by christopher bishop. Read Kevin P Murphy 2021. Read Hands on ML by Aurelien Geron. Do a course. Do a few portfolio projects. Then with your title and experience and demonstrable new skills and passion, go get literally most any job you want in DS. And maybe a few you are interested in, MLOps, MLE, Data Engineer, Analytics Engineer like another poster said.

Fate is in your own hands, best of luck in these exciting times!!",2022-02-20 09:56:53
Comment,1,hxoiiii,,0,1645343728.0,"Can you elaborate? 

I’m open to exploring other avenues outside of biological sciences. I’ll most likely stay involved in ecology even if it’s just through volunteer roles, but I’ve realized early on in my career that I enjoy the mental challenges involved in data analysis and coding regardless of what topic they’re about.",2022-02-20 09:55:28
Comment,5,hxoibhy,,0,1645343575.0,"I imagine it depends if they are making a claim in their marketing ""improved your efficiency by 10%* (a survey of 15 people)"", or assessing the results of a campaign.",2022-02-20 09:52:55
Comment,13,hxoi5e6,,0,1645343446.0,But then OP's answer already indicated scepticism at repeated testing until the hypothesis could be accepted. If anything it feels the interviewer wanted someone who is comfortable with that kind of manipulation.,2022-02-20 09:50:46
Comment,1,hxohunr,,0,1645343219.0,"Are you staying in ecology or thinking of moving to corporate life?

The stats required are very different between industries/fields.",2022-02-20 09:46:59
Comment,1,hxohbw2,,0,1645342810.0,Connect with this guy on LinkedIn and politely ask him for a feedback.,2022-02-20 09:40:10
Comment,6,hxoh9p8,,0,1645342763.0,"I have a similar back history as you. I’ve been on the periphery of DS for about 2 decades performing data analysis and delivery of data products to end users but also to data scientists who generate the greater statistical products that are more bespoke. 
I’ve fairly recent shifted gear to do that aspect of work also. I have found the below to have been key in being able to get up and running to win and complete some projects as a new income.

1. Python. 
I used to use FORTRAN, VB and MATLAB for data processing, but decided to shift to a new language mainly to avoid the licence fee with MATLAB. I have found Python very adaptable and easy to pick up. It’s been simple to generate Report level products such as 150 coloured tables along with over 300 rose plots to as well as great tools to wrangle data with a degree of automatic QA. Frankly I wish I’d learnt it years ago!

2. Mathematics
I’ve spent almost half my time learning new statistics and mathematical revision to be able to produce meaningful reports with clarity. 

3. An underlying understanding of what is being investigated. I’m luckily I’ve worked in my field for 2 decades and understand data sources, typical processing issues and critically, end user expectations. I would therefore suggest looking party as where you want to go with the shift as it may align with your background better? Eg I’m not doing any marine biology work any longer, but I’m still often involved with oceanographic data set computation.

4. Other skillsI
I have not used SQL in like 10 years, but want to build that skill up over the next year or so.
I have also studied project management and am looking as data flow management to optimise process and improve QA/QC for future projects.
I do use R from time to time to validate what I have setup in Python.
I’ve also had to learn CDO in unix to manipulate particular formats.",2022-02-20 09:39:23
Comment,5,hxogy7p,,0,1645342516.0,".05 might have been chosen by academics of the past but many top journals in stats and econ won't accept this threshold approach to reporting significance anymore, requiring the actual p-values to be reported instead. This gives the reader more information to decide for themselves whether to take the results seriously, but doesn't stop the author just saying ""significant at conventional levels"".",2022-02-20 09:35:16
Comment,1,hxoga6d,,0,1645342010.0,"Sounds like you got in trouble with the p-value police. Wow that’s hilarious probably best to not work there since it sounds like your boss still lives in the 1970s and hasn’t caught on to Bayesian methods. This does make for a great case study though for how stupid selecting an arbitrary value for ‘alpha’ is lmao, literally the least robust thing you can imagine",2022-02-20 09:26:50
Comment,1,hxofaqv,,0,1645341276.0,"I don't know if this is what the interviewer was looking for, but ds is as much art as science. I would answer that I would weigh my knowledge of the data and the problem much more highly than a p-value delta of .0002. If it's a variable that one would expect to be significant, or in your experience makes predictions better, or can be removed without model instability etc., any of those softer factors can tip the scales on a close p-value. 

As data scientists, we need to do more than set up automated step-wise regressions. There's a human touch to quality ds that can't be automated away by turning our roles over to computers that reject nulls when p < alpha.",2022-02-20 09:14:36
Comment,1,hxoetjv,,0,1645340916.0,"Thank you, I found this very interesting.",2022-02-20 09:08:36
Comment,2,hxocc2a,,0,1645339091.0,Yeah it was on the tip of my tongue I kept forgetting the exact name tho haha,2022-02-20 08:38:11
Comment,1,hxoc8qw,,0,1645339028.0,Yep I should have read more closely. While you could have talked about Bonferroni correction or something i think it's just a dumb question in that case.,2022-02-20 08:37:08
Comment,3,hxoc442,,0,1645338939.0,Analytics engineer?,2022-02-20 08:35:39
Comment,4,hxobxhe,,0,1645338812.0,"Please, feel free to let me know if you think my logic is off. 

If we know p-values asymptotically approach zero. Then we have a ttest or something with 1M observations in each group, and the p-value is still something like 0.1 then that would be STRONGER evidence in favor of the null than if I had only 10k or 1k observations. 

Granted, it’s safe to assume that if you have a large p-value in a large sample that’s likely because the difference/coefficient is near zero. In which case it doesn’t really matter anyway since substantively even if it were significant it’s moot.",2022-02-20 08:33:32
Comment,1,hxobpus,,0,1645338660.0,Questions 1 and 2 were for two different tests/problems completely.,2022-02-20 08:31:00
Comment,5,hxobo3c,,0,1645338628.0,"Absolutely! I've used [MCMC Sampling](https://towardsdatascience.com/monte-carlo-markov-chain-mcmc-explained-94e3a6c8de11) to determine fit parameters for variable flux stars. Although not industry, the idea that you can explore parameter space with a random walk and maximize some sort of likelihood function is powerful.",2022-02-20 08:30:28
Comment,1,hxobkve,,0,1645338568.0,"""Whereas a large p-value in a large sample would be quite damning potentially.""

Wait what?  Could you please explain this?  Why would a _large_ p value be damning?",2022-02-20 08:29:28
Comment,1,hxob6u0,,0,1645338293.0,More or less the exact wording. They were for two different problems.,2022-02-20 08:24:53
Comment,1,hxoasb6,,0,1645338020.0,What was the position title?,2022-02-20 08:20:20
Comment,10,hxoaezu,,0,1645337770.0,"""OP didn't have enough information to put those p-values in context with each other in any meaningful way.""

Which may have been the entire point.  My thought was that they should've asked for more information before making any conclusion and that's probably what the interviewer wanted.",2022-02-20 08:16:10
Comment,1,hxoa4fq,,0,1645337567.0,I read a lot about it. Still not sure since I thought a GSTNet would be state of the art.,2022-02-20 08:12:47
Comment,0,hxoa1ix,,0,1645337510.0,"Is this the exact wording?

>Ok... what if you run another test for another problem, alpha = .05 and you get a p-value = .04999 and subsequently you run it once more and get a p-value of .05001 ?

If so, I'd assume he would have meant that you were running the same test on the same exact data. In which case discrepancies would be caused by some sort of computational error. Start checking your code and your data.",2022-02-20 08:11:50
Comment,3,hxo9n6q,,0,1645337232.0,I have used it to predict different stages of credit card delinquency,2022-02-20 08:07:12
Comment,1,hxo9las,,0,1645337196.0,I use Tableau for visualising after processing with Python. I love it!,2022-02-20 08:06:36
Comment,1,hxo9cte,,0,1645337036.0,Man I'm getting stats. knowledge FOMO I need to open a text so I feel like I can contribute to this discussion,2022-02-20 08:03:56
Comment,3,hxo9agx,,0,1645336992.0,"With the first question he was probably hoping you'd ask for more information about the context instead of just making a decision based on a single number.  P-values in particular have kind of a bad rep because of how they've been over-relied on and seen as the be-all-and-end-all of whether some result is meaningful.  

The problem isn't p-values themselves, but the tendency to use a single value as a measure of whether results are meaningful.  Among other problems, it leads to p-hacking, which is just an example of how ""if a measure becomes the goal, it ceases to be a useful measure.""  

In particular, to me, his second question was clearly an attempt to test if you'd recognize the problem with making a decision based on whether a single probability is below some arbitrary alpha value.  Even if we assume that everything else in the study was solid - large sample size, potential confounding variables controlled for, etc., a p value _that_ close the alpha value is clearly not very strong evidence, _especially_ if a subsequent p value was just slightly above alpha.  

I obviously don't know what exactly this particular interviewer was looking for, but he may have had an issue with your wording that you'd simply reject H₀, rather than the more nuanced conclusion that, _assuming no confounding variables, large sample size, etc._, a p value significantly less than alpha is good evidence against the null hypothesis.  While it's unfortunately quite common in introductory statistics courses to teach students to simply reject/accept H₀ based on whether p is greater than or less than alpha, this is, _at best,_ simplistic.  

I'm a statistics tutor and data science minor, not a job recruiter or data scientist, so take this with however much salt you choose, but I imagine the point of this type of question was for you to demonstrate you know how to _think_ about how to interpret test results, not merely to give the simplistic textbook answer on how to interpret a hypothesis test.  You did do that somewhat at the end when you stated you'd need more information, but my guess is that you took too long to do that, and that he was expecting that to be your response to the first question.",2022-02-20 08:03:12
Comment,-1,hxo8had,,0,1645336446.0,I would like to see how HMM are used with Google’s PageRank algorithm.,2022-02-20 07:54:06
Comment,2,hxo3vzg,,0,1645333569.0,In marketing they consider a p-value of .15 statistically significant?,2022-02-20 07:06:09
Comment,14,hxo3eml,,0,1645333288.0,"I can't remotely understand the philosophy behind using some sort of NHST cutoff value to evaluate a real-world A/B test. Especially some generic alpha pulled from an undergrad social sciences textbook. That company is probably making a lot of stupid decisions.  


Editing to additionally say: where I would start with that interview question is to point out that the null hypothesis is ALWAYS wrong and the only question an NHST answers is whether the clustering in the data is clear enough that one rejects it with confidence. If that is not the question being asked then NHST is not the technique that should be used.",2022-02-20 07:01:28
Comment,1,hxo2sr8,,0,1645332933.0,Damn,2022-02-20 06:55:33
Comment,1,hxo199w,,0,1645332047.0,This correction is known to be pretty conservative.  So YMMV,2022-02-20 06:40:47
Comment,5,hxnxxge,,0,1645330182.0,That’s so cool. So was this role more for phds or were new grads doing this work too?,2022-02-20 06:09:42
Comment,4,hxnxrqa,,0,1645330095.0,"But that's a correction for multiple tests on the same sample.

Perhaps they were looking for an answer on how to combine analyses; e.g. meta-analysis, meta-analysis, or updating the null hypthosis from H0 = 0 to a null hypothesis that tests against the mean difference from A/B test one (like an overly simplified implementation of priors)",2022-02-20 06:08:15
Comment,1,hxnxcs5,,0,1645329872.0,don't copy paste - look at the %%writefile magic method.,2022-02-20 06:04:32
Comment,1,hxnx2ch,,0,1645329717.0,"You clearly really, really want to hate Python, to the extent that you are diving into obscure aspects of its internal C code that mentioned almost nowhere in an attempt to confuse yourself. Maybe you should consider that if you have to search that hard to find something to get upset over, it probably really isn't that bad.

I am getting the impression you have been trolling me this entire time. You never mentioned one thing about C or static typing, ever. And the idea that you could look at the documentation for Python vs C and conclude that the C documentation is the clear, consistent, and easy to understand one is, frankly, insane. It is a [literal joke](https://www.gnu.org/fun/jokes/unix-hoax.html) how cryptic C is.",2022-02-20 06:01:57
Comment,23,hxnwrok,,0,1645329565.0,When I worked at a startup in the logistics industry we used hidden Markov models for inventory stock forecasting.,2022-02-20 05:59:25
Comment,1,hxnwnrf,,0,1645329509.0,"I don't know what to tell you then. It is literally just ""the numpy ones, plus this table of others, click the links if you want more info on any of these."" I mean, ""categorical"" has categories. MATLAB has that, too. ""sparse"" is sparse, matlab has that too. If you consider a table with links ""impenetable"" then I don't know how you deal with [MATLAB's types](https://www.mathworks.com/help/matlab/numeric-types.html), which is literally just a table with links.",2022-02-20 05:58:29
Comment,3,hxnvlzt,,0,1645328969.0,"Thanks for the info. Sorry I was unclear, I actually meant a function that could be called once which would basically auto-wrap all plotlyexpress plotting functions in a FigureResampler, so that one doesn't have to manually do it. Something like the below (haven't tested it but just to convey the idea)

    def register_express():
        import plotly.express
        from functools import wraps
        from plotly_resampler import FigureResampler
        
        px_funcnames = ['line', 'scatter', ...]
        for funcname in px_funcnames:
            @wraps(getattr(plotly.express, funcname)
            def resampled_func(*args, **kwargs):
                return FigureResampler(func(*args, **kwargs))
            
            setattr(plotly.express, func, resampled_func)

So that one could just do

    import plotly_resampler
    
    plotly_resampler.register_express() 

And everything will automatically be wrapped in FigureResampler",2022-02-20 05:49:29
Comment,12,hxnuqpx,,0,1645328522.0,Definitely. I did a technical interview recently and bombed most of the coding/ stats questions. I got the job because of my work experience & answers to behavioural questions.,2022-02-20 05:42:02
Comment,1,hxnugp6,,0,1645328376.0,"Those docs are fucking impenetrable. I read that exact part and still came away utterly confused about how many actual numeric types pandas supports. Now maybe it sounds like ""all the numpy ones, plus extra that are almost the same but we PUT SOME MORE PYTHON IN IT.",2022-02-20 05:39:36
Comment,1,hxnsfvx,,0,1645327331.0,"I think... I think maybe what I really want deep down is just SQL and C. Maybe dynamically typed languages just aren't for me.

Or maybe you've just convinced me I don't actually like programming. No, that's not it. I think you've convinced me I don't like any programming LANGUAGES.",2022-02-20 05:22:11
Comment,2,hxns9ch,,0,1645327241.0,"I wasn’t the author of the reply, which is now deleted and makes it difficult",2022-02-20 05:20:41
Comment,7,hxns7x8,,0,1645327220.0,"Perhaps they wanted you to think past just the math. Like how expensive would the change this test is designed to measure be? Was the average impact positive for the business, even if questionably measurable? What would the potential drawback of implementing it be? 

If it’s a potentially multi-million dollar effect (even if small) and there’s no huge cost to the test, perhaps try again with new groups. Etc etc. 

Basically, not really mattering what you said (as long as it’s not stupid) but caring that you think beyond what it shows in the stats textbook because that’s what they’re looking for.

All speculation of course, and I have no doubt you would do all this consideration in practice, and that’s what you were getting at with “I’d need to know more about the test etc.”. However, they may well have wanted you to state some assumptions (reasonable ones, perhaps a few key archetypes) and explain what you’d have done.",2022-02-20 05:20:20
Comment,1,hxns79z,,0,1645327211.0,"Based on how you worded it, it sounds like they were going after multiple testing. Once you do multiple tests, you are no longer comparing with 0.5. Look up multiple testing corrections / Bonferroni.",2022-02-20 05:20:11
Comment,1,hxnquxi,,0,1645326516.0,"Prototype on your 3080Ti machine and then farm off to a massive AWS EC2 instance.

This keeps your workstations free to tweak models and allows you to spin off a ton of instances to train and validate in parallel. Also prevents issues with overworking consumer grade hardware and risking failure during training or something.",2022-02-20 05:08:36
Comment,1,hxnqg5u,,0,1645326302.0,"Every time I try to meet with people (not your program, just in general) everyone is too busy to get a minute in. It’s so frustrating trying to find a mentor when it’s just a game of phone and e-mail tag until you give up trying to find an hour when neither of you are railed from work stress and actually free enough to commit to a conversation.

How is your program handling this?",2022-02-20 05:05:02
Comment,1,hxnppns,,0,1645325934.0,"Some other users brought up some good points to this that I also agree with. Working long and hard hours and not knowing when your paycheck will be your last one at the company isn’t great feeling to have long term. 

I’d rather put in the work, grow in my career and enjoy my life outside work as much as possible.",2022-02-20 04:58:54
Comment,5,hxnpb0i,,0,1645325725.0,Thanks! Is there any concise resource that covers these in slightly more detail?,2022-02-20 04:55:25
Comment,28,hxnoire,,0,1645325326.0,"You might be close to the answer.

The response should have been, ""Why is it 0.005? Which team is this analysis for? What/how much $ does this impact?""

I wonder if they want to figure out if someone can make judgments on how far to take an analysis/how high the standard should be to reject the null.

Idk, just bullshitting. I hate these sorts of questions. But a lot of the better roles want you to ask questions more than give answers.",2022-02-20 04:48:46
Comment,1,hxnnp9y,,0,1645324906.0,"Wouldn't the context be the actual job you're interviewing for and the company you're interviewing at? When someone argues over semantics and minor technicalities during an interview, it's an automatic fail for me. I see this candidate as someone will most likely delay everything due to being too stuck on theory rather than focusing on real world application.

Edit: OP answered the second question incorrectly. Usually when someone starts to argue semantics in that way, they're talking out of their ass.",2022-02-20 04:41:46
Comment,4,hxnnp69,,0,1645324905.0,I developed and generalized GLMs to detect engine failures across multiple engine manufacturers installed on the largest oil rig in the Gulf of Mexico in 2018. I give all the true positives credit to YouTube.,2022-02-20 04:41:45
Comment,12,hxnnm3t,,0,1645324863.0,"This is my new favourite stats joke!  


Would you believe that I have yet to make single person laugh with a stats joke? This comment means that you have me beat by at least one!",2022-02-20 04:41:03
Comment,3,hxnng12,,0,1645324778.0,"Practical significance is as important as statistical significance. Try reading about Cohen's d , effect size and power. 

I feel that the recruiter was rather expecting you to talk about Bonferroni correction which comes up quite often in multiple testing frameworks. You divide alpha by the number of tests you do. That's your new alpha.",2022-02-20 04:39:38
Comment,23,hxnmgiw,,0,1645324279.0,"It could be as low as 0.0000003 if we're talking about a new discovery in particle physics.

I think the hiring manager was aiming to stir up some debate about the 0.05 value.",2022-02-20 04:31:19
Comment,1,hxnly8u,,0,1645324023.0,I always tend to think reject the null is too technical an answer. Maybe he wanted you to explain what that actually means?,2022-02-20 04:27:03
Comment,1,hxnlm47,,0,1645323847.0,"Certificates aren’t worth it. They won’t get you a job. 

You need to gain experience with data work at your current job, even when people don’t ask you to.",2022-02-20 04:24:07
Comment,1,hxnlj6i,,0,1645323805.0,Seems like an unusually scenario and set of questions.  Couldnt you combine the three studies into one larger experiment with random effects for the individual trials (three of them) and use this to get a single p-value.,2022-02-20 04:23:25
Comment,1,hxnlf49,,0,1645323748.0,If you want a data job you need to get more specific on what you want to do. And then go apply that at an office job even if you don’t get a data specific job.,2022-02-20 04:22:28
Comment,5,hxnkmpx,,0,1645323351.0,This guy youtubes logistic regressions using python 😎,2022-02-20 04:15:51
Comment,1,hxnkmgw,,0,1645323348.0,"This is assuming that the samples are independent, which may not be true.",2022-02-20 04:15:48
Comment,1,hxnk5xh,,0,1645323116.0,Nice! This is pretty similar to what I do!,2022-02-20 04:11:56
Comment,2,hxnjxdv,,0,1645323000.0,When I look back on my life I don't want it to be what I was doing at work lmao,2022-02-20 04:10:00
Comment,1,hxnjma6,,0,1645322847.0,A dataset that contains data on how government officials make their trading decisions,2022-02-20 04:07:27
Comment,1,hxnjezi,,0,1645322752.0,I think I've decided on the same. Good title with a Fortune 500 but nearly a lateral pay. But truth be told I've got to get my feet wet more before I interview with the big fellas,2022-02-20 04:05:52
Comment,1,hxnj0yq,,0,1645322571.0,"As I said, you need to read the [Essential Basic Functionality](https://pandas.pydata.org/docs/user_guide/basics.html) section of the docs. It is all explained there, with tons of links to more information if you want more details. You aren't going to get anywhere with any programming tool, MATLAB included, if you won't read the basic introduction. The it only looks like a conflict because you haven't learned the basics yet.",2022-02-20 04:02:51
Comment,1,hxnixwz,,0,1645322529.0,"Correct we did so much modeling it was crazy. Some of the modeling was slow even on ""average"" sized data sets and I'm like there's no way this is used in corporate.",2022-02-20 04:02:09
Comment,1,hxnis00,,0,1645322448.0,"> First I read that Python has 3 basic numeric types: integers, floating point numbers, and complex numbers. What KIND of integers are we talking about? Many sources say ""unlimited precision"", so.. variable number of bytes? Another source says python integers are 32 bit signed integers, but that there's also ""long_int"" which is variable length.

Python integers are unlimited precision. That is all users need to care about. Internally, in the default Python implementation, it is a variable-length custom C data type, and there is a behind-the-scenes fast code path for math on integers of a certain size, but users don't need to care about that, normally won't know about it, never see it, and have no control over it.

I am having trouble actually finding anything that mentions `long_int` (less than 2,000 google hits, most of which are python's C source code, vs more than 165,000,000 for just `int`), so how did you even find that? It certainly isn't something someone trying to learn about Python would normally encounter.

If you want high-performance numeric processing and packed data then you want to use numpy. Again, lists are like cell arrays. The overhead of storing all the object information is going to be more than couple of bytes, in python or MATLAB.

> so I Google numpy data types, and there's 4 different names for each data type

You see that in MATLAB too, such as with `fwrite`. These names are IEEE standards.  

The big difference is that numpy fully supports integers as primary data types, while MATLAB has poor support for integer types. For example you can't construct an integer array directly in MATLAB, you need to convert a float array, while you can in numpy. You also can't add together two different integer types in MATLAB,  like `uint8` and `uint16`, but you can in numpy.

> So I Google Pandas data types, and I find a result on pandas.pydata.org, which has a list of data types.. 

If you look at the ""Essential Basic Functionality"" section of the docs, which should be the first thing you read when learning any new tool, it explains that all [here](https://pandas.pydata.org/docs/user_guide/basics.html#basics-dtypes)

> For the most part, pandas uses NumPy arrays and dtypes for Series or individual columns of a DataFrame.

And then later:

> pandas and third-party libraries extend NumPy’s type system in a few places. This section describes the extensions pandas has made internally. See Extension types for how to write your own extension that works with pandas. See Extension data types for a list of third-party libraries that have implemented an extension.

So it uses numpy types, but it has some additional types numpy lacks. So you would have encountered this if you had read the basic beginners intro to the tool.

If someone came to you complaining that MATLAB tables where hard to use, and you found out they didn't read the basic introduction to tables, would you consider that MATLAB's fault?

> And the corresponding array type for floating point numbers, ""pandas.arrays.FloatingArray"" is a dead link. 

`FloatingArray` is mentioned in exactly [one place](https://pandas.pydata.org/docs/reference/api/pandas.array.html?highlight=floatingarray) in the entire pandas docs, in a table that says:

> Currently, pandas will infer an extension dtype for sequences of

So those are extension types. As the documentation I linked to before, which again should be the first thing you read when trying to learn a new tool, extensions are additional types not part of numpy, and aren't used by default. This is explained again just a few lines up from that table:

> The dtype to use for the array. This may be **a NumPy dtype or an extension type** registered with pandas using pandas.api.extensions.register_extension_dtype().

(emphasis added)

Pandas arrays are used when making extensions, as the docs I linked to explain. You don't need to deal with them directly.

So overall it is pretty straightforward, but you have to read the documentation on the basics before using something.

> And the integer array type apparently forces the use of a separate mask array, so I can't store 8bit values without using 16 bits of memory per value?

Again, as the basic documentation explains, that is an extension type, not the default integer type. You need to specifically choose to use it. There is also a link right there in the basic documentation for more information about what it is, why you would want it, and how to use it. The experimental API isn't an issue in normal usage because you don't need to interact with the API.",2022-02-20 04:00:48
Comment,1,hxnim8n,,0,1645322368.0,Not familiar with pytest at all. Need to get up on this,2022-02-20 03:59:28
Comment,1,hxnidyt,,0,1645322255.0,"For half a second I was going to redo my example, because it kinda feels counter factual to use the Navy as an example of an aircraft parts purchasers - but fuck it, the Navy is the second largest Air Force in the world right after the actual Air Force. God bless you guys and keep blowing up shit",2022-02-20 03:57:35
Comment,1,hxni5ad,,0,1645322135.0,"This is so helpful, thank you!",2022-02-20 03:55:35
Comment,3,hxnht25,,0,1645321969.0,"same, as soon as I read it I thought of that xkcd example: https://www.explainxkcd.com/wiki/index.php/882:\_Significant",2022-02-20 03:52:49
Comment,1,hxnhddg,,0,1645321756.0,I would have discussed the significant digits of the inputs. SD of the output can not be more than the lowest SD of all inputs. Very few things in life are accurate to 5 significant digits.,2022-02-20 03:49:16
Comment,52,hxnhbzt,,0,1645321737.0,"So many - nearly impossible to list them all. I'll give you a few to think about:

Hidden markov models (HMM) for time series predictions in many domains such as quant finance, NLP and bio-informatics.

You can reformulate some algorithms such as Naive Bayes to a HMM.

Google's PageRank algorithm is essentially a Markov Chain.

Tons of ML algorithms such as latent dirichlet allocation (LDA).

Markov Random fields in computer vision / image processing.

... And tons more of applications. I did a full course on markov chains (directed, undirected and their combinations) and covered a bunch of places that they were used.

They also propped up in so many graduate level ML courses I had, most prominently in NLP, Computer vision and their child: Information Retrieval.  They might've been superceded by neural networks in all 3 domains but they are a very elegant and **interpretable** solution (looking at you LDA) for common problems.

EDIT: I've mixed in markov models in general, not just markov chains but they're closely related. Chains are 1-D and networks are N-D.",2022-02-20 03:48:57
Comment,3,hxngxwn,,0,1645321545.0,"As an avid US election/fivethirtyeight watcher, I'd love a full list of who everyone voted for at every election. How many people change their minds vs how many just stop voting?  How does it vary per state? Did they answer any polling questions? If so did they change their minds? 

You could do a lot with that information, but unfortunately, so could a lot of other nefarious people..",2022-02-20 03:45:45
Comment,8,hxngv9p,,0,1645321508.0,I work for NAVSEA doing Analytics and you're 100% spot.,2022-02-20 03:45:08
Comment,1,hxngi2i,,0,1645321327.0,"Hey guys, I'm currently studying my UG in computer applications and I am interested in learning python and other fields related to AI, data analysis and data scientist, but I kinda dk what to study after this , so anyone can help me choosing up what should I do or study , help guys🙂",2022-02-20 03:42:07
Comment,1,hxnggkz,,0,1645321306.0,Right cause most things would be continuous time,2022-02-20 03:41:46
Comment,1,hxng2id,,0,1645321107.0,"I set up my flows for prefect while in a Jupiter notebook, usually to give conspicuous notes about what’s going on in a specific flow",2022-02-20 03:38:27
Comment,1,hxng2e6,,0,1645321106.0,Just use PyCharm or any other proper IDE instead,2022-02-20 03:38:26
Comment,1,hxnfuok,,0,1645321000.0,"How do you filter out people who are serious about working with a mentor?

Just spent 3 months mentoring someone who wasn't willing to do any of the work and had to drop them. If I'd do it again, I would have been more upfront about expectations with work that needs to be completed (it was only about 4 hours of work per week).",2022-02-20 03:36:40
Comment,3,hxnevph,,0,1645320520.0,"Okay general tips:

&#x200B;

* Keep your CV under one page. They get hundreds of these, they won't read multiple pages.
* Make sure HR can understand your CV and/or cover letter. They just won't understand overly technical stuff.
* Write a killer cover letter. What I always do is: How I found you. What's interesting about the job and finally why I'm the right person for the job.
* Slightly change the content of your CV to fit the job you're applying for. If you have multiple pages of content, consider swapping in and out stuff based on the job you're applying for.
* Network! This is the most important one. Job fairs are so much easier to get interviews at than LinkedIn.",2022-02-20 03:28:40
Comment,2,hxndnkh,,0,1645319918.0,Great question. I've wondered how much stochastic processes in general are used in data science. That's probably closest to my research. Though far more Brownian motion than Markov chains.,2022-02-20 03:18:38
Comment,3,hxndini,,0,1645319850.0,"I ask almost this exact question. And I’m probing for a nuanced understanding of a p-value. Specifically, I want the understanding to be that p-values are useless outside the context of the coefficient/difference. P-values asymptotically approach zero, so in large samples they are worthless. And also the difference between 0.049 and 0.051 is literally nothing meaningful to me outside the context of the effect size. 

Also, it’s critical to understand that a p-value is strictly a conditional probability that the null is true given the observed relationship. So if it’s just a probability, and not a hard stop heuristic, how does that change your perspective of its utility?

Edit for clarification: small p-values in large samples are not very indicative of anything special on their own. Whereas a large p-value in a large sample would be quite damning potentially.",2022-02-20 03:17:30
Comment,4,hxnbyo3,,0,1645319081.0,"Exactly. Who runs the same inferential model and gets a different p-value twice? I've worked in SAS, SPSS, Mplus, and R for 7+ years and have never had that happen. Something's up.",2022-02-20 03:04:41
Comment,42,hxnbslm,,0,1645318999.0,"Bayesian testing is not really a thing unless you mean Bayes Factors, and that doesn't really improve on the fundamental problem of statistical testing (which is, the dichotomization). Really just model and estimate - the value of Bayesian statistics is that you get a distribution of possible parameters, which is easier to interpret than p values and confidence intervals.",2022-02-20 03:03:19
Comment,1,hxna55j,,0,1645318196.0,They were probably looking for you to expand further and show some knowledge beyond understanding how p-values work.,2022-02-20 02:49:56
Comment,7,hxn9pyr,,0,1645317993.0,"This may sound dumb, but I’ve been telling my dad for years that’s there’s something fishy with the final prizes in Wheel of Fortune. I’d love a complete dataset of every single puzzle outcome within every game across all games ever played, along with the final outcome and prize",2022-02-20 02:46:33
Comment,1,hxn9d4r,,0,1645317819.0,"Yeah, I started a few weeks ago but mass applied with a very general cv and realized that approach is not effective for getting interviews that are useful. Am still crafting the cv for specific positions, definitely needed work going from a multi - page academic style to just highlighting the specifics. Your comment lit a fire under me to wrap it up though 😆",2022-02-20 02:43:39
Comment,1,hxn91bw,,0,1645317657.0,Don't worry! There were other cool positions that were still open at that point but the  key part of my argument is: the sooner you start the better and leverage your network. Definitely better than spamming your CV and hoping for the best.,2022-02-20 02:40:57
Comment,1,hxn8xuy,,0,1645317610.0,"Hi u/BoundtoLincoln, I removed your submission for the following removal reasons:

* **Videos are not allowed.** Submissions from youtube.com are not allowed on r/datascience.",2022-02-20 02:40:10
Comment,11,hxn8k1d,,0,1645317424.0,"Generally agree, with the exception of ""What are your income expectations for the position?""

I've been rejected a few times after answering that one.",2022-02-20 02:37:04
Comment,1,hxn80jr,,0,1645317169.0,Im just now starting to apply  and now im freaked out haha. Appreciate this info!,2022-02-20 02:32:49
Comment,2,hxn69su,,0,1645316338.0,Multiple comparison corrections aren't that big of an effect with two trials. If you were close to .05 it would be easily significant.,2022-02-20 02:18:58
Comment,1,hxn62yx,,0,1645316249.0,"I'm reading a lot of conflicting stuff now about what you can and can't store in a pandas dataframe. If I can't have e.g. a column of structs/dicts/whatever, a column of video reader objects, a column of geometric transformation objects, etcetera, that's 100% a dealbreaker, that's a live-or-die feature for me.",2022-02-20 02:17:29
Comment,2,hxn5oub,,0,1645316064.0,"Yeah, but you still need to correct for multiple comparisons, so it's not clear that you'd reach corrected significance.",2022-02-20 02:14:24
Comment,3,hxn55ts,,0,1645315814.0,Welcome to the “real world” (corporate America) 😂😂😂,2022-02-20 02:10:14
Comment,2,hxn4vhj,,0,1645315678.0,"What about asking if it's a two tailed t-test? Then the alpha value would be .05/2 = .025, so you would fail to reject the null hypothesis on both follow up tests.",2022-02-20 02:07:58
Comment,3,hxn4oml,,0,1645315590.0,"I kinda disagree. It’s all in the context of the problem. Academically sure, practically I’m not going to treat it like that",2022-02-20 02:06:30
Comment,2,hxn3ohj,,0,1645315120.0,"If you're running the same test over and over again, your true alpha isn't 0.05 because of multiplicity. 

Read about the Bonferroni correction.",2022-02-20 01:58:40
Comment,2,hxn2ofs,,0,1645314652.0,"As others have said, the premise you should only input correlated features is false. PCA will be more efficient the more correlated the columns are, but that's about it. Touching upon this slightly, you're interested in visualization, so by all means select the columns that you're interested in. If a column with large variance is inside leg length, and it's uncorrelated with any other feature, and you don't really care how tall people are, I'd drop that column first.

Bear in mind PCA will essentially derive new features that are linear combinations of the originals, so if you want to interpret any patterns you see, think about how you would interpret the coefficients. If it's meaningful to your problem to say ""ah, here's a distinct group of high earners who are young but have had several different employers already and are short arses"" then knock yourself out, but you'd probably want to omit that height column. Probably.

So my top tips for your stated aim are

1. Consider what input variables are of interest to you, given that you'll be looking at weighted combinations of them.

2. Scale them! This can be skipped if they're all the same units. Maybe. Eg I've often applied PCA to high dimensional spectra where each column is counts for a different wavelength. I don't scale each column. I do scale for overall intensity (probably). But there's units and units. You'd still want to scale the features if one column was ""money in wallet"" (of the order of a few tens) and another was ""annual income"" (of the order of hundred thousand).

3. Check the amount of variance explained by these two features you're plotting. If you input 20 financial columns and your 2D scatter plot explains just 10% of the variance, you're potentially missing a lot of structure; if they explain 85% and the remaining components account for sod all, then you've got a very effective reduced dimension representation of those original features.

4. Consider homogeneity/imbalances in your data. I nearly didn't include this, but it can be important. Bear in mind PCA will faithfully explain variance. If 5% of your sample is women and 95% men, any visualisation will be driven by what's going on with the men. You may want to look at each subpopulation separately, or balance them before running PCA.",2022-02-20 01:50:52
Comment,3,hxn27xp,,0,1645314439.0,If they were using the Neyman-Pearson framework then I can see why they didn’t like p values.,2022-02-20 01:47:19
Comment,1,hxn1yb4,,0,1645314312.0,It's a coding environment. You can use it anywhere you want to write code.,2022-02-20 01:45:12
Comment,1,hxn1mv2,,0,1645314163.0,Good luck! Hope the talk goes well.,2022-02-20 01:42:43
Comment,1,hxn16mk,,0,1645313948.0,"Speaking in general as someone at a large and high profile org in my area who gets contacted a lot- its fine, just don't ask them to put in a word for you with the hiring manager. They don't know you or your work and won't be able to do that after emailing you once or having one phone call.",2022-02-20 01:39:08
Comment,27,hxmztfm,,0,1645313307.0,Any good resources on Bayesian A/B test you could share/point to?,2022-02-20 01:28:27
Comment,10,hxmyhkz,,0,1645312689.0,"I think you are right, this is the correct answer or in other words applying Bonferroni's Correction.",2022-02-20 01:18:09
Comment,5,hxmxinb,,0,1645312242.0,"Ha ha. Yeah, those datasets owned by different sections, powered by systems created by various IT contractors that don't want to talk to each other, assuming the government teams could put aside their turf wars for five minutes. Oh, you were serious.",2022-02-20 01:10:42
Comment,3,hxmxicf,,0,1645312239.0,"I believe this is called the Bonferroni correction, just so you know for the future (and the rest of the thread.)",2022-02-20 01:10:39
Comment,5,hxmwk6l,,0,1645311804.0,"you dont do hypothesis testing until you get the result you like. You design your hypothesis, you test it once and you conclude. In stat, if you conduct enough experiments, eventually you will reach statistically significant result even if your result is 90% statistically insignificant. Even before the hypothesis, you should have already had a wild guess of the outcomes and the hypothesis testing is just a rigorous way to verify your wild guess.",2022-02-20 01:03:24
Comment,6,hxmuoub,,0,1645310950.0,"I mean, you can do more with your life than just constantly progress at work. Job security means you can take a real vacation or ignore your boss's texts while you're out on a first date without having to worry about being fired.",2022-02-20 00:49:10
Comment,6,hxmumhw,,0,1645310922.0,Basing my companies profitably on a p-value. If op said that the guy would've blown him right then and there lol. I think that's the best response because it can strike a nerve in virtually every manager,2022-02-20 00:48:42
Comment,5,hxmuhrv,,0,1645310864.0,Sounds like you weren’t getting the job regardless of how you answered it. This is a stupid hypothetical that would never happen in real life. Does this guy really have unlimited time and budget to keep running tests over a difference of one hundred thousandth?,2022-02-20 00:47:44
Comment,3,hxmu7gx,,0,1645310736.0,I had to answer stats questions for an analyst interview. Talk about title dilution,2022-02-20 00:45:36
Comment,7,hxmtvr1,,0,1645310592.0,China’s Social Credit System database... translated into English:),2022-02-20 00:43:12
Comment,5,hxmtfo5,,0,1645310389.0,"I think this comment would actually be a pretty good response, wouldn't it? Like in a more ""interview response"" form it'd be like ""there are ways to aggregate these results, like how they do in meta analyses, I'd have to look into it more because I don't think you can just {multiply, add, combine} them directly.""",2022-02-20 00:39:49
Comment,0,hxmsy4b,,0,1645310169.0,"6%, or 6% merit + 7.5% inflation?",2022-02-20 00:36:09
Comment,1,hxmspgn,,0,1645310062.0,"> The companies in the midwest can't offer their salaries to anyone outside of the midwest, though, which is going to be a big problem for them.

If Midwest companies want Bay Area talent then they'll have to offer Bay Area pay (or at least what a Bay Area company is willing to pay someone working remotely from the Midwest). If they can't compete then they will lose top talent and die, and I'm not sure that's a bad thing.",2022-02-20 00:34:22
Comment,1,hxmso7j,,0,1645310047.0,"This. I didn’t realize prior to the real world how something too easy or worse just mundane could actually make you feel burned out too lol. Its the worst though when you are also required to be in-person for work most days (even though everything could be done remotely
via cloud) because if you are remote then you could at least do other hobbies after just turning in the deliverables and check out",2022-02-20 00:34:07
Comment,5,hxmsjjq,,0,1645309988.0,"Yes, that's more or less what I was thinking, except that I felt (?), from the 2nd-hand report of what the interviewer said, that he was dragging OP in a different direction.",2022-02-20 00:33:08
Comment,2,hxmrgdj,,0,1645309495.0,"Not at all, I remember I started applying for jobs in october when I'd be graduating in July and signed my first contract in December for my first real DS job. All Jr positions were actually filled and gone by january.

Biggest piece of advice I can give you is go to job fairs, go to local meet-ups, apply through your unis job portal - in short, network a lot. The way I got my first job was attending a workshop on deep learning + model deployment organised by a company. After interacting with the people they offered me a position.",2022-02-20 00:24:55
Comment,6,hxmqz3f,,0,1645309282.0,"I've read some of this, but I admit all my training has very much been from the Neyman-Pearson perspective... by professors who thought p-values were a very bad idea.",2022-02-20 00:21:22
Comment,4,hxmpt8e,,0,1645308758.0,"I think it just depends on ones personality. For the businessy-type, or hell just average person thats probably a good thing. For a stat or ML nerd type though who has passion for models lol (of which I consider myself a part of) it is kinda disappointing to come out of school to do this. The shock is pretty high after just coming out of college+grad school, especially if one did grad school directly after in ones’ 20s. 

However, even for non-nerds I think the realization is also part of a larger psych/social issue in 20s-you are coming out of an environment where you had not much “real life” responsibility to worry about, social life is also much better and easier to have in college and even grad school too. Then afterwards all that kind of goes away and then on top of that you realize your job/DS is way more mundane and less intellectually stimulating model building than expected",2022-02-20 00:12:38
Comment,7,hxmpsrx,,0,1645308753.0,"Maybe the interviewer wanted to learn about a Bonferroni correction. This article gives a good explanation:

https://www.statisticshowto.com/familywise-error-rate/",2022-02-20 00:12:33
Comment,-1,hxmpnrg,,0,1645308691.0,">I’ll be happy when “data science” is only used as an academic topic like “computer science” and no longer used as a job title -u/ColinRobinsonEnergy

\-u/Mobile\_Busy",2022-02-20 00:11:31
Comment,1,hxmpklf,,0,1645308652.0,To each their own I suppose!,2022-02-20 00:10:52
Comment,51,hxmphgk,,0,1645308613.0,The pea value is whatever green giant decide to set their frozen greens at 😰🥵🤤,2022-02-20 00:10:13
Comment,0,hxmpeoa,,0,1645308579.0,"Define fundamental understanding though?

Things like meta analysis etc. are usually not covered at all in DS curriculums that aren't statistics. Personally I always avoid doing hypothesis tests because they're too easy to completely mess up if you're not someone with an actual statistics background. However, I don't think that makes me any less of a data scientist.

Fwiw reading the comments in this thread have been enlightening.",2022-02-20 00:09:39
Comment,6,hxmp7ai,,0,1645308486.0,I’m going to balk at both statements you made. They both are just untrue.,2022-02-20 00:08:06
Comment,56,hxmp732,,0,1645308483.0,"The p-value is a number between .03 and .15, depending on whether you're talking to someone from compliance or marketing.",2022-02-20 00:08:03
Comment,1,hxmp1xv,,0,1645308418.0,You're not wrong. It's a poorly-formulated question and they're rejecting you on the basis of hypothetical toy problem edge cases.,2022-02-20 00:06:58
Comment,1,hxmotlo,,0,1645308312.0,"I'll be getting my MS in DS in May - is it too early to start applying to jobs? 

Also I'd love to hear any advice anyone has about what I can do to make up for not having any experience in DS. I have a small  but solid amount of work experience and an engineering degree (plus math and technical communication minors). During Covid, I transitioned into DS because I know I will enjoy if I can just get my foot in the door.  Any advice would be very much appreciated!",2022-02-20 00:05:12
Comment,1,hxmopdd,,0,1645308259.0,In Chicago and this aligns with my research as well,2022-02-20 00:04:19
Comment,3,hxmohyj,,0,1645308169.0,"Agreed - there's so much more you can do with data than just build models, always go for the low hanging fruit but you obviously know this.

Imo the end goal is (nearly) always automating or improving some business process. If your EDA shows you that a handful of if-then rules are sufficient that's what you should do.

... that being said a lot of people are in this game to solve ""non-trivial"" problems hence why model building is brought up so much I guess.",2022-02-20 00:02:49
Comment,1,hxmodbu,,0,1645308112.0,"I assume you are using laptop. Right? Thats why sentence transformers will be better (easier to iterate). And you dont need lots of examples. Although not sure how they will perform on non English data.

The more the better but there wont be much difference between 10k and 1k.",2022-02-20 00:01:52
Comment,1,hxmoczh,,0,1645308108.0,ADS can link with your git 😉,2022-02-20 00:01:48
Comment,1,hxmnz7k,,0,1645307937.0,I think the key thing the interviewer wanted to see is that you wouldn’t draw different conclusions from the two experiments.,2022-02-19 23:58:57
Comment,16,hxmnagt,,0,1645307630.0,"That’s the Neyman-Pearson view which currently is very much a minority view among statisticians today. Fisher saw it very differently and argued you could use a p value to asses the strength of evidence against the null hypothesis (of course he didn’t mean the probability the null hypothesis is true). That’s one reason exact p values are presented, not the old school p<.",2022-02-19 23:53:50
Comment,1,hxmmvx7,,0,1645307449.0,"Right. I was just confused bc you had said:

>> Did we choose the appropriate risk (alpha/beta)

>That's the question that the interviewer is asking you.",2022-02-19 23:50:49
Comment,51,hxmmazu,,0,1645307196.0,Iris dataset so I could really understand the pedal length distribution of the virginica.,2022-02-19 23:46:36
Comment,1,hxmlqyf,,0,1645306949.0,"I am half done with their online master's in data science program. It is a mess and I cannot recommend it. Very little of the skills needed for completing assignments are in the text or videos, so we are essentially Googling most of our degree. HUGE waste of time.",2022-02-19 23:42:29
Comment,2,hxmln61,,0,1645306904.0,"Hi everyone,

Does anyone have recommendations for online masters programs focused more on the Big Data Engineering/Data Wrangling aspects of Data Science? Or E-learning?

I have 14 years of experience in analytics, with the first 6 years as a hands on statistician, while the last 8 years have been less hands on and more management of analytics/insights projects and data visualization/dashboard design. 

I'm fairly good with some machine learning techniques (regression, clustering, classification, association, dimension reduction etc). The Data Engineering/Wrangling aspects have always interested me since they tend to take up a majority of the time on Data Science, but I've never gained a proficiency in it (I've generally always had datasets cleaned and delivered to me, but having these data skills is necessary for most modern data science roles I see).",2022-02-19 23:41:44
Comment,2,hxmlmtj,,0,1645306900.0,"I am half done with their online master's in data science program. It is also a mess and I cannot recommend it. Very little of the skills needed for completing assignments are in the text or videos, so we are essentially Googling most of our degree. HUGE waste of time.",2022-02-19 23:41:40
Comment,3,hxmljfm,,0,1645306860.0,"Thanks for sharing! Gave it a quick read, pretty interesting.",2022-02-19 23:41:00
Comment,1,hxmlfbm,,0,1645306810.0,"Hi u/valdsw, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 41 karma.",2022-02-19 23:40:10
Comment,1,hxmlahe,,0,1645306751.0,"It’s not the question asked though. There is a chosen alpha, you use that to decide if you accept reject. 

You’re answering “how would I choose alpha, what considerations would there be?”",2022-02-19 23:39:11
Comment,11,hxmlaaz,,0,1645306749.0,"I think that’s a good thing. You can do so much more with data than just model building. Models are great and provide a lot of value but it’s not the only way to get value from data, and it’s not the only thing someone with an advanced understanding of stats + programming + business can/should do. 

I’ve said this before and I’ll keep saying it … I’ll be happy when “data science” is only used as an academic topic like “computer science” and no longer used as a job title.",2022-02-19 23:39:09
Comment,1,hxmkfpk,,0,1645306378.0,Irs,2022-02-19 23:32:58
Comment,1,hxmkc7n,,0,1645306337.0,Left for another job paying $40k more and helped my friend do the same thing,2022-02-19 23:32:17
Comment,9,hxmk9wa,,0,1645306309.0,If anything it seems more and more that DS is moving away from model building day by day….,2022-02-19 23:31:49
Comment,1,hxmjzko,,0,1645306182.0,"IMO, this is one of the biggest issues with DS now. At the end of the day a DS is not coding; they are solving a business problem. That might require coding, it might require designing an experiment, it might require applying stats methods correctly... And most likely it will require talking stakeholders into trusting you and listening to your recommendations.

Being a DS is so much more than just being a CS/SWE/ good coder.",2022-02-19 23:29:42
Comment,10,hxmjeh5,,0,1645305923.0,"The way I read the question, I think they were specifically trying to test knowledge of what p-hacking is in order to avoid it!",2022-02-19 23:25:23
Comment,1,hxmj4r3,,0,1645305806.0,Yes I have computed stats without spark in *checks notes* 2001. Spark is just one of many tools.,2022-02-19 23:23:26
Comment,25,hxmiz3v,,0,1645305738.0,Job titles are meaningless. “Data Scientist” at one company is a “Data Analyst” at another. Not every DS role is building ML models.,2022-02-19 23:22:18
Comment,3,hxmiuk5,,0,1645305684.0,Of course R has the right statistical package.,2022-02-19 23:21:24
Comment,1,hxmilwe,,0,1645305580.0,I know it's a bit late but here are a bunch of certification options. Some you can finish in 2 months or less. Hope this helps out. https://gisgeography.com/best-data-science-courses-certification/,2022-02-19 23:19:40
Comment,9,hxmieye,,0,1645305498.0,"Having a fundamental understanding of statistics is very important to being a good data scientist, even if you aren't running statistical tests in your everyday work.",2022-02-19 23:18:18
Comment,3,hxmias2,,0,1645305448.0,"I think if you were to combine the data that way you may have to use sequential testing corrections but im not sure.

The more standard thing to do is a random effects meta analysis in that case to combine the results. If they were sufficiently similar then you could get away with fixed effects but usually thats not assumed by default. 

R meta package can do this and give 1 p value overall.",2022-02-19 23:17:28
Comment,19,hxmhyhc,,0,1645305301.0,"I mean, yes, but if you run a one-way trial twice and you get p=.05001 both times, it's trivially easy to do a meta-analysis that would have p far less than .05.",2022-02-19 23:15:01
Comment,1,hxmhl0n,,0,1645305137.0,"Facilitating reproducibility of research.

As a computational biologist, it's pretty key to sharing results efficiently.",2022-02-19 23:12:17
Comment,9,hxmhbgw,,0,1645305022.0,"I know a common practice to avoid data snooping is that you divide the alpha threshold by the number of tests you conduct. So say I conduct 5 tests with an alpha of 0.05, I would test for an individual alpha of 0.01 to try and curtail any random significance. This is jsut a heuristic I read is used by many statisticians, but maybe its the answer he was looking for?",2022-02-19 23:10:22
Comment,1,hxmh7dn,,0,1645304972.0,Could the data from the two experiments not be combined and the hypothesis be retested? (Assuming experimental conditions are sufficiently similar that an SME wouldn't expect results to be affected and that samples from two experiments are independent of each other.),2022-02-19 23:09:32
Comment,2,hxmfzys,,0,1645304445.0,I was watching week 1 of How to Win Data Science Competitions on coursera,2022-02-19 23:00:45
Comment,1,hxmfnir,,0,1645304294.0,"I like having an IDE window open next to a notebook. I implement methods in the IDE and often write unit test for them. In the notebook I simply sys.path.append the local repo that I’ve been developing and import it.

My notebook is just for storybuilding in Markdown and for inline plotting. Everything that is actual logic stays in the repo, written in IDE, and checked into version control.

This works very well for me, and am pretty happy with this hybrid IDE/notebook setup.

It also makes sure that when I actually want to bring something to production, my code is already in the repo and already unit tested.",2022-02-19 22:58:14
Comment,2,hxme51n,,0,1645303642.0," Nielsen marketing data on consumer habits, or potentially College Board data on testing",2022-02-19 22:47:22
Comment,13,hxme4jh,,0,1645303636.0,"They didn't say they used the same data, they said they repeated the experiment (generated new data testing the same hypothesis). Early stopping does inflate type I error rate, yes, but that's not happening here. 

This question also has nothing to do with multiple comparisons - the question is about how to combine information from two experiments. Bonferroni (and, frankly, all FWER control methods) is overly conservative when looking at correlated tests (and these tests should be highly correlated, because they're testing the same hypothesis!)",2022-02-19 22:47:16
Comment,3,hxmdin2,,0,1645303366.0,Have u tried bayesian inference? With that you could quantity whether you have absence of evidence (ie bad data) or whether you have actually data in favour of the null hypothesis,2022-02-19 22:42:46
Comment,-3,hxmd8vq,,0,1645303247.0,"I think you are missing the point of multiple comparison here. Whenever you run multiple tests on the same set of data the probability of a false positive result actually accumulates over time. So with more tests you would actually loose confidence in there being a true effect.
Thus if one were to adjust the p value to prevent this (for example simple Bonferoni where the p value becomes 0.25) both tests would be non significant.
The multiple comparisons problem is one of the reasons why a lot of scientific fields face a replication crisis.",2022-02-19 22:40:47
Comment,2,hxmd7oq,,0,1645303233.0,"Thank you, this comment made my day better.",2022-02-19 22:40:33
Comment,0,hxmcw7x,,0,1645303093.0,"> Can they be used in ETL processes?

Omg. Please don't.",2022-02-19 22:38:13
Comment,1,hxmcw0i,,0,1645303090.0,"You are not alone. There are a lot of senior data scientist that come from a stats, social science, actuarial, econ, etc background rather than CS. I'm not a SWE, and I never will be; but I am a domain expert in my space.",2022-02-19 22:38:10
Comment,22,hxmco5e,,0,1645302995.0,"Definitely. Unless that question uncovers some deep flaw in the candidate's moral character I can't image a single question was the reason they ""failed"" the interview. The final straw maybe, but not the only reason. Doesn't work like that.",2022-02-19 22:36:35
Comment,1,hxmcj5s,,0,1645302933.0,"I am going to have a talk with SAC team to understand why/how are they missclassifiying the messages. If we can get them to properly classify future messages I can wait a few weeks and start using them.

I cant think in a way to remove misslabelled data right now and only use the correct ones as my dataset is pretty Big (~600k) and seems to have a Lot of bad data.",2022-02-19 22:35:33
Comment,161,hxmcfpj,,0,1645302891.0,"To add onto that, .05 is an arbitrary number used as a standard in academia. It depends on what you’re testing. If you’re a parts manufacturer building an aircraft component for the Navy, and the contract requires six sigma confidence in parts specification, then yeh an entire batch of parts may have to be dumped at a confidence of .0501 because the contract literally specified that. Granted, I would do more testing (and refer the matter to our legal team), but if it’s what the government requires, you can’t avoid that. On the other hand, if your researching stats for a marketing company, and you get a confidence that you’ll do X sales with Y changes at a .0501 confidence, I would make a quick notation of that, remind the client that .05 is an arbitrary number chosen by academia, and move on",2022-02-19 22:34:51
Comment,17,hxmcf96,,0,1645302886.0,"It's not very common to fail a candidate because of a single question during an interview. If so, they are taking in too many random candidates. Usually, it is the final drop, some composition of evidence indicating there is to much of a risk you're not the right person for the job. He might even think it is more than likely that you'd do well, but that is usually still too high of a risk. You say you don't have a background in stats. That might be it. The interview itself might have been giving you the benefit of the doubt, and you might have been judged by a higher standard because the paperwork wasn't there.",2022-02-19 22:34:46
Comment,1,hxmc920,,0,1645302810.0,What is it with DS influencers on LinkedIn man? It’s like they’re trying to be get-rich-quick-scheme life coaches,2022-02-19 22:33:30
Comment,11,hxmbzh3,,0,1645302694.0,"Sorry if it's a stupid question, but why do they even need a data scientist to run statistical tests? A statistician would cost them way less...",2022-02-19 22:31:34
Comment,52,hxmbx87,,0,1645302666.0,"I agree, having been on both sides of the hiring selection process many many times. I would not be losing sleep if i were OP.",2022-02-19 22:31:06
Comment,4,hxmbvjl,,0,1645302647.0,That was an inexperienced interviewer.,2022-02-19 22:30:47
Comment,94,hxmbszj,,0,1645302616.0,"Exactly. I’m so bored at frequentist hypothesis testing for A/B testing. In one interview, I straightly told the interviewer that I have implemented Bayesian A/B testing which is better.",2022-02-19 22:30:16
Comment,3,hxmbsst,,0,1645302614.0,"I'm with the others that don't think you would have passed/failed based on this one answer. So don't beat yourself up.

But as I read this, what jumps out at me is that there is likely a reason to run multiple tests like this. Not knowing anything else, if you ran the test once and got 0.049 and then again and got 0.051, I'm seeing that the data is changing. It might represent drift of the variables (or may just be due to incomplete data you're testing on).

The other option is that if you're changing a thing and testing in the same dataset, the significance (standard significance levels) are cut in half so your new level is 0.025 rather than 0.5 because of the duplicate testing. In that scenario (two different tests, same dataset), then you would not reject the null in either case.

But again, I think there is more going on here than it sounds.",2022-02-19 22:30:14
Comment,1,hxmbpvt,,0,1645302578.0,"I have tried using bert but It was estimating more than 100h for the training ( maybe because I have to use the multilanguage model due to my portuguese text).

Its quite hard to remove the misslabelled data since I cant find ALL of them ;/",2022-02-19 22:29:38
Comment,1,hxmbmer,,0,1645302535.0,Hasn’t everything gotten more since then? Man i miss 2016,2022-02-19 22:28:55
Comment,1,hxmbln0,,0,1645302526.0,https://github.com/edatk/edatk,2022-02-19 22:28:46
Comment,1,hxmb3d9,,0,1645302305.0,"Well, if you think about de cdf of the null hypothesis region for both alphas the difference is negligible (unless you are dealing with a strange distribution?), I wouldn't mind the difference.

Even on research, although not statistically significant, I would still present the findings, and if they corroborate to other findings (more robust) then it is fine. 

The significance chosen is arbitrary, not a reason to throw it all away.",2022-02-19 22:25:05
Comment,4,hxma9jd,,0,1645301944.0,It'd be non-significant at a 5%. Saying it without the last part would be flat out wrong.,2022-02-19 22:19:04
Comment,1,hxm9ku3,,0,1645301646.0,I’ve had problems projecting seaborn and cufflinks plots on spyder,2022-02-19 22:14:06
Comment,10,hxm9bos,,0,1645301535.0,"There's probably something I'm missing, but I'm pretty much in agreement with you. We accumulate research results on independent samples with things like meta-analyses, not simple probability calculations. OP didn't have enough information to put those p-values in context with each other in any meaningful way.",2022-02-19 22:12:15
Comment,4,hxm996t,,0,1645301505.0,The question does not say the observations are dependent.,2022-02-19 22:11:45
Comment,1,hxm97tj,,0,1645301490.0,"I can add my experience, though I'm only tangentially related to data science if that's ok.   

Was in healthcare for nearly 20 years in the laboratory. The pandemic was/is a particular type of hell that I wouldn't wish on anyone. Left for a consultant position at  one of the largest companies in medical devices, they more than doubled my pay and I WFH next to my cat all day.   

Fuck every healthcare corporation, they nearly killed me.",2022-02-19 22:11:30
Comment,17,hxm92jr,,0,1645301429.0,"Hm. Maybe that's where the interviewer was going. It's not clear that he was, but it would be an interesting question for an interviewee, if you could ask it effectively.",2022-02-19 22:10:29
Comment,15,hxm90tj,,0,1645301408.0,"I think that the question in itself is dumb. I would just said that significance is idiotic and go on that (even ASA says this and they have guidelines on this). I personally would have said that because I'm not taking a job that asks me to do p-values or p-hacking or any of that shit.

Also, if you calculate marginal effects/first differences, for some values of X there could be a significant effect on Y.

Your answers were not technically wrong. I think the whole set-up was just wrong and if they were trying to check something else, they should have asked different questions.",2022-02-19 22:10:08
Comment,65,hxm8zga,,0,1645301391.0,"If you're going to lean on statistical significance, .05001 isn't margincally significant; it's non-significant. The whole enterprise is a rigid, zero-excuses binary system. It's not a great system, but if you're going to use it, I think you have to *use it*. 

That's more or less semantics, sometimes, though; there are better ways to estimate your effect and its likely existence in the population versus only the sample.",2022-02-19 22:09:51
Comment,22,hxm8rk0,,0,1645301296.0,"The interviewer gave you very little information to generate a ""correct"" answer. If all you know is the basic research design and a sequence of p-values, there are lots of factors that could be involved. I guess he was asking why did that specific sequence happen. I might say ""First, I'd stop basing my company's profitability on a p-value difference of .0001. If we get these results, we should think about a more robust approach, or multiple approaches, to deciding how effective our advertising (or whatever) is."" I think your answers were in some good directions; without contextual information it's really hard to know what he considered the ""correct"" answer.",2022-02-19 22:08:16
Comment,1,hxm8ms2,,0,1645301241.0,"This is a problem I face too--for example, we have a group of customers and we randomly assign them to a test/control each week.  Sometimes, the results are Stat Sig, sometimes they aren't'.

I always felt like there was a better way to handle this but never knew what to search.",2022-02-19 22:07:21
Comment,3,hxm81li,,0,1645300996.0,Guess you are right. Didn't see that he explicitly said that it's for another problem.,2022-02-19 22:03:16
Comment,1,hxm817t,,0,1645300991.0,"Like other people in this thread, I was working in a city in the midwest that didn’t have a TON of ds jobs, but once remote work went permanent offers from the west coast started coming in. 

Its pretty insane, I can take a salary halfway between midwest and SF levels, but continue to live in my much cheaper home city.",2022-02-19 22:03:11
Comment,1,hxm7vr8,,0,1645300926.0,"From interviewing college students, schools mostly focus on machine learning algorithms and modeling. Typically, students have been taught that data science is just running data through a bunch of models and tuning parameters. Corporate data science is often done in a way where the models must be maintainable and scalable. This is where the computer science aspect comes into play heavily. Often a model/methodology will be chosen because it is good enough to accomplish a business objective with a healthy backlog to also work through. 

You can also get into the Rick and Morty issue of your purpose not being to pass butter but to sell advertising.",2022-02-19 22:02:06
Comment,48,hxm7qpz,,0,1645300869.0,It's unlikely you can attribute a 'failure' in an interview to a single question.,2022-02-19 22:01:09
Comment,1,hxm7bpo,,0,1645300688.0,"Work life balance was not great, we were expected to be online 9 am to 7 pm and keep an eye on our emails at all times. Culture was typical corporate finance middle office, with plenty of bureaucracy like a time-gated promotion structure. Our team manager was excellent though, and everyone who was on the team pre-remote work were good friends outside of work too. I'm just surprised that the team culture managed to outweigh everything else.",2022-02-19 21:58:08
Comment,3,hxm7b36,,0,1645300682.0,There is so much that was important back in grad school. Now it usually comes down to what is the best decision I can make with current information.,2022-02-19 21:58:02
Comment,3,hxm72x6,,0,1645300585.0,"We built https://iko.ai which offers real-time collaborative notebooks to train, track, package, deploy, and monitor machine learning models.

You start with a live notebook to explore data and play with it. You can collaborate with others in real-time, see their cursors and selections and edits, troubleshoot code with them, etc.

You can connect private or public S3 buckets and interact with the data as if it were a file system. The compute power is provided by your own Kubernetes cluster: you can hook up your clusters from AWS, GCP, Azure, DigitalOcean, etc. And you can run any notebook on any of your clusters.

Then you can schedule the notebook in a job. iko.ai allows you to execute long-running training notebooks in the background while streaming their output to you. That solves the horrible problem of disconnected kernels or closed browsers that cause normal notebooks to lose output.

These runs are tracked. iko.ai automatically tracks your parameters, automatically detects your models and metrics. It saves all that in buckets.

Once you compare your runs and like a model with good metrics, iko.ai allows you either to click a button that builds a Docker image around the model and pushes it to your registry (DockerHub, GitLab Image registry, etc) or click another button that will deploy your model.

The deployment gives you a REST API / endpoint to which you can send data to your model and get inference results. Yiu also get a Web page for the model where you can upload a CSV file and get predictions for the CSV data/instances.

You also get a live dashboard that shows your model performances: successful and failed requests, latency, and other performance measures. You can send feedback when your model gets something right or wrong, and this allows you to visualize deteriorating performances when the data distribution changes for example and your model isn't predicting as well as it did.

So, the notebooks _produce_ the models which are then _deployed_ so that your product or application or people can invoke them.

iko.ai also allows you to deploy Streamlit applications right from the platform in case you want to let your clients to interact with a model or some data. It also offers AppBooks, which are automatically parametrized notebooks to allow non-technical people to run notebooks by changing parameters without being overwhelmed by the code or mutating a notebook. These runs are also tracked (models, params, metrics, the whole thing is saved).",2022-02-19 21:56:25
Comment,13,hxm6z00,,0,1645300538.0,">Off topic.

So, what was the right answer?",2022-02-19 21:55:38
Comment,10,hxm6usm,,0,1645300489.0,"It's marginally insignificant when the p value is 0.05001.
Probably test with a large sample or check with domain expert to employ means to confirm and form the next sequence of events.",2022-02-19 21:54:49
Comment,1,hxm6lqf,,0,1645300382.0,(just for the sake of argument) don't you need to answer if the chosen alpha is appropriate before you can reject NH?,2022-02-19 21:53:02
Comment,1,hxm63jp,,0,1645300173.0,"I also shared a very personal story to me while high in the ""mentor-request"" channel and have also ""doxxed"" myself because I know everything I've said is my personal truth and don't care about the repercussions because I have everything in writing and could sue a company and possibly make a lot of money if I wanted. I choose not to because I know the aggressor in the situation is living a very sad life and the pettiness in me likes watching him suffer. But that's how I cope. Keep an eye and watch them spiral out of control for all their shitty things coming back to haunt them.",2022-02-19 21:49:33
Comment,3,hxm5pbd,,0,1645300011.0,"I think people will learn they don't have to worry about as much as they think. It doesn't matter if you learn r vs python. It doesn't matter what interview style a FAANG company does or what format your resume is.

People really overthink things and all that it takes to find a position is willingness to learn, patience to learn, and ability to pivot if things don't go according to plan.

I thought I'd be a Walgreens store manager 12 years ago.  I thought I'd be an FCAS Actuary 7 years ago. Now I'm a data scientist and learned I can use my experiences to help others and I have a lot of like minded friends and contacts. 

I don't give everyone access to my close contacts, but I am certain I can help people land a job if they are willing to learn. I will eventually grow the space into a full collaborative environment where we have a bitbucket to share code, a confluence to share knowledge, and host workshops to learn new tech. 

For instance, I know a DevOPs guy that spent 15 years running devops for a large company. He's willing to do a 101 on Kubernetes and give free resources for people to test out Kubernetes on a local machine. It's a top tier skillset right now and this one workshop would get you enough experience to list it on your resume confidently.",2022-02-19 21:46:51
Comment,198,hxm5iib,,0,1645299931.0,"It might also be that you are attributing a perfectly fine answer to them deciding not to hire you, when they already knew who they wanted to hire and were simply looking for anything to tell you no.

I tend to think that generally most roles they know who they want to hire after the first interview and baring some huge red flag they are going to hire that person. Could be a referral, an excellent resume, went to the same college as hiring manager etc etc. 

More often than not it is the human element of interviewing that gets people roles, not the objective technical interviews in my experience.

If I were you I wouldn’t beat myself up too hard, I’ve gone through many interviews where I thought I did fine and didn’t get into the next round and have done not well and gotten into the next round of interviews.

Interviews are way more social science than people want to admit.",2022-02-19 21:45:31
Comment,1,hxm4tta,,0,1645299643.0,"I think this spurs my curiosity even more. How do you deal with not having many mentors available willing to do this altruistically, compared to the hordes of folks interested in data mentors?",2022-02-19 21:40:43
Comment,36,hxm4llf,,0,1645299549.0,"Its debatable though because its separate tests on different problems done after another. Its not sequential tests unless its the same data being collected online where you do multiple interim data-looks. Nor is it doing many tests at once on related outcomes or contrasts.

Else philosophically its like do we correct sequentially for every test we perform ever?

I think this question was pretty BS and basically looking for ways to confuse the candidate",2022-02-19 21:39:09
Comment,36,hxm4gxc,,0,1645299495.0,Those are the sort of details that OP could have asked about to show they understood both the experimental design concerns as well as the math underlying how p-values work.,2022-02-19 21:38:15
Comment,1,hxm4ds9,,0,1645299460.0,So I can only speak for my experience but many good employers started expanding around this time. I ended up hopping over to a great employer that I absolutely love working for and the reason why my role was open was because they were building out a few new and existing departments. I know a few other people with the same story. So yeah some just got opportunities to work for great employers that treat their workers well because those employers were/are growing.,2022-02-19 21:37:40
Comment,3,hxm49km,,0,1645299412.0,"Probably some google service data, google maps would be an intresting one",2022-02-19 21:36:52
Comment,42,hxm3w4j,,0,1645299263.0,"It sounds like your assuming the two tests of the same thing are independent, which doesn’t at all hold if the samples are overlapping or influenced by the same grouping or biases",2022-02-19 21:34:23
Comment,4,hxm3p7l,,0,1645299183.0,"It’s not just the correlated components but the rank of each of the components in terms of how distinctive  (in terms of being orthogonal in n-D space) it is … which can be used to decide which, or how many, components to use in training.",2022-02-19 21:33:03
Comment,2,hxm3kuw,,0,1645299134.0,maybe want to adjust for multiple comparisons in the second case,2022-02-19 21:32:14
Comment,4,hxm36b6,,0,1645298974.0,I was under the impression that data science had a more Bayesian approach to statistics. Perhaps he was expecting you to push back on this approach?,2022-02-19 21:29:34
Comment,44,hxm2nil,,0,1645298767.0,"Your answer to the first question is fine. The second question is what seems to have gotten you. 

Assuming the null hypothesis is true, you have a 1/20 chance of getting a p-value below 0.05. If you test the same hypothesis twice and a p-value around 0.05 both times with an effect size in the same direction, you just witnessed a ~1/400 event assuming the null is true! Therefore, you should reject the null. There's some wiggle room here about early stopping, etc., but I don't think the interviewer was going for that. 

If you want to learn more about the logic here, read about the math underlying meta-analysis. Specifically, read about Stouffer's method for combining p-values.",2022-02-19 21:26:07
Comment,4,hxm2d34,,0,1645298654.0,"Posting link. Not sure if it gets auto-banned. 

If this sounds like something you're interested in, anyone is free to join. It's not very active right now because I don't think a lot of people are comfortable sharing their stories yet. That's ok. Anyone can feel free to DM me for personal advice or anyone who is listed as a mentor. Years of experience isn't a factor. Where you went to school and what career you're going for doesn't matter at the end of the day. I was cleaning shit out of toilets at Walgreens 13 years ago. 

&#x200B;

https://discord.gg/h96G5Qq2",2022-02-19 21:24:14
Comment,1,hxm24h4,,0,1645298562.0,"> All right, I'm surprised. I really didn't expect that to be that easy to do in Python. I was wrong. If this were /r/cmv, I'd give you the delta.

Great, let's see if I am also wrong. Again, please show me how you would do my example in MATLAB.

> I can Google it, and find some Stackoverflow posts and reproduce the solutions they offer, but then LATER I find out there was a much better way to do it.

I searched for ""python find files by extension recursively"" and my suggestion was the accepted answer on the first result. 

The thing about `pathlib` is that it is new. Not everyone keeps up with the latest developments in any language. The number of people I have worked with who use MATLAB but aren't aware of tables or strings is staggering, and advice relying on structs or char arrays that would be better off as strings or tables are everywhere.

> Obviously, with any language there's multiple ways to peel an egg, but with MatLab there is often one specific function that is the obvious way to do something, and if you don't find it right away upon searching the matlab docs, you'll find it in the ""see also"" links on one of the pages you do find.

That is generally the case with Python, too. In fact it is literally one of the [design goals of Python](https://www.python.org/dev/peps/pep-0020/): ""There should be one-- and preferably only one --obvious way to do it.""

And there is. `os.walk` *can* do the same thing as `glob`, but it is overkill. `os.walk` is extremely flexible, but that flexibility isn't usually needed.  Similar to how MATLAB structs are generally overkill when you want to use something like a map, if MATLAB's maps weren't such a slow pain in the ass that nobody uses them.

MATLAB has nothing like `os.walk`, and if you need it you will need to write your own solution from scratch using a recursive function, so it is hard to explain in terms you would immediately understand.

> But if you encounter a problem that you DON'T already know the best solution for, how do you find out efficiently? 

Searching online generally gives a good solution. Again, Python is designed that way. You ended up with a special case here because: (1) there is a newer, innovative solution that not everyone is up to speed on yet, and (2) directory trees are a mess, so Python gives a simple, dumb way and slightly more complicated but infinitely more powerful way, but even then the first result is the same solution I would use.

But generally, with any programming language, I would learn the basic groups of tools available. So for Python I would look through the standard library so I at least know what the basic components are. I wouldn't know what every function is, but I would know where to look. I did the same with MATLAB. If I am learning a new tool, again I would go through the basic firsts, and get some feel for where to look for specific types of tools.

> My whole thing about list comprehensions springs from the last time I seriously tried to implement something in Python, wanted to select a subset from a list of strings, and none of the search results that I (or the person who was assisting me) found mentioned the fact that you could just use a numpy string array.

Honestly I probably would use a list comprehension, too. You *can* use a numpy array, but when working with something like a string where you probably want to look at specific aspects of the string, like slices with case matching or something, and numpy (and MATLAB strings) start becoming overly complicated to work with. List comprehensions are brilliant and extremely powerful, don't shy away from them just because they seem unfamiliar.",2022-02-19 21:22:42
Comment,2,hxm200d,,0,1645298513.0,"Nothing is in it for anyone. If that's how you approach mentorship, then you're looking at it incorrectly and defeats the purpose of the community. You're more than welcome to join and lurk. Just don't be a dick to anyone.

Edit: Not targeting that statement at you dataguy24, just generally to anyone interested",2022-02-19 21:21:53
Comment,1,hxm1eq2,,0,1645298273.0,Yep only for aggregated charts not big data sets,2022-02-19 21:17:53
Comment,3,hxm1do4,,0,1645298261.0,How do you deal with the fact that there are orders of magnitude more people who want mentorship than mentors? What’s in it for the mentors?,2022-02-19 21:17:41
Comment,2,hxm1c5p,,0,1645298244.0,Spyder ?,2022-02-19 21:17:24
Comment,1,hxm15bz,,0,1645298166.0,"As your data set size goes up G sheet becomes the worst way to get your data into BI. Honestly at our workplace we detest G sheets because of the numerous compatibility issues, especially with Tableau. CSV -> Extract -> Publish data source into tableau server works best, physical file dependency is also erased this way",2022-02-19 21:16:06
Comment,367,hxm0yd5,,0,1645298087.0,"Reminds me of this classic paper from Andrew Gelman: [The Difference Between “Significant” and “Not Significant” is not Itself Statistically Significant](http://www.stat.columbia.edu/~gelman/research/published/signif4.pdf)

You might find it enlightening.",2022-02-19 21:14:47
Comment,1,hxm0x0f,,0,1645298070.0,"I'd like an invite as well, if that's okay. I'm still aspiring to get into the field; college fucked me up and I'll need therapy before I can go back.",2022-02-19 21:14:30
Comment,2,hxm0pyq,,0,1645297991.0,"My point is that even someone with just one year of experience is far more valuable than a new grad, especially if they got that experience at your company. That experience has value has to be paid for if you want them to stay. Otherwise your company will be doomed to train new grads for 1-2 years and then have them leave before they can deliver any significant return on investment.

A rough pay scheme:

* new grad X
* 5 YoE at least 2X
* 10 YoE at least 3X

15% annual raises every year takes a new grad from X to 2X in 5 years. 8% annual raises every years takes a 5 YoE from 2X to 3X in 5 years. Also these raises don’t account for COLA, so add that on top of these numbers.",2022-02-19 21:13:11
Comment,2,hxm0fde,,0,1645297872.0,"What is the work life balance like? Good culture? Good management and colleagues? If you tick three of those boxes, a lot of people would take 5 figure pay cuts for such a job",2022-02-19 21:11:12
Comment,230,hxm02dj,,0,1645297724.0,"A lot of companies look for practical significance as well, maybe he was going for that. There are cases where you can reject the null but the alternate hypothesis does not lead to any real world impact.

So in this case I wouldve brought up practical significance and if it was large I would reject the null regardless of whether it was 0.0499 or 0.05001",2022-02-19 21:08:44
Comment,77,hxlzvj7,,0,1645297648.0,Maybe he wanted to hear something about the alpha error cumulation if you test multiple times.,2022-02-19 21:07:28
Comment,1,hxlzhji,,0,1645297487.0,"Nope, just making myself more useful in terns of the bigger picture.",2022-02-19 21:04:47
Comment,1,hxlzgba,,0,1645297474.0,"Postscript:

Now I'm swinging back towards ""take it out back and shoot it."" I wanted to know more about Python's numeric types, so I started Googling, and that familiar feeling of wanting to set my computer on fire is creeping up my neck again.

First I read that Python has 3 basic numeric types: integers, floating point numbers, and complex numbers. What KIND of integers are we talking about? Many sources say ""unlimited precision"", so.. variable number of bytes? Another source says python integers are 32 bit signed integers, but that there's also ""long_int"" which is variable length. So there's actually FOUR numeric data types? At this point I'm thinking ""so if I have an array of 8 bit integers, that's going to have to be stored as 32 bit integers? What if it's a BIG array of 8 bit integers, I'm going to run out of memory! But then I remember that of course there's numpy, which will have its own set of data types, so I Google numpy data types, and there's 4 different names for each data type, but OK, I find that you can specify 8, 16, 32, or 64 bit integers, signed or unsigned, and the normal floating point types. But NOW I realize ""hey, but if I want to use those types in tabular data, which I do ALL THE TIME?"" So I Google Pandas data types, and I find a result on pandas.pydata.org, which has a list of data types.. All the usual flavors of integer are present, but I can't find any floating point formats on the list, but there's some reference to them under ""pandas.array"", so they must exist, but maybe only doubles? And the corresponding array type for floating point numbers, ""pandas.arrays.FloatingArray"" is a dead link. Can I not have arrays of floating point numbers in Pandas? And the integer array type apparently forces the use of a separate mask array, so I can't store 8bit values without using 16 bits of memory per value? And ""integerArray is currently experimental, and its API or internal implementation may change without warning""? 

You almost had me sold, but I don't know if I want to touch this mess.",2022-02-19 21:04:34
Comment,4,hxlzf0i,,0,1645297459.0,"Who was aware of what disinformation campaign and when regarding US imperial actions.

Not that anyone would do anything about it but at some point someone needs to be held to account.",2022-02-19 21:04:19
Comment,10,hxlzadw,,0,1645297407.0,"Not saying this is what they were looking for, but if three different tests are finding it sig or close to sig, then it's easy to group the tests together and say it is the right business decision. Depends if you are talking academic research or helping the company make the correct business decisions.


Edit: on first read I thought you said you were testing the same attribute every time.",2022-02-19 21:03:27
Comment,1,hxlz2j3,,0,1645297322.0,Thanks for posting it. Do you mind sharing the discord? I’m a student in college pursuing Data Science.,2022-02-19 21:02:02
Comment,1,hxlye7k,,0,1645297047.0,"Senior data scientist here and also interested in moving toward MLE. What types of companies on west coast are hiring fully remote while not adjusting pay for your location? FAANG? How were technical interviews for MLE? More on the data science side, leetcode side or some combo?

Thanks",2022-02-19 20:57:27
Comment,6,hxlxw3b,,0,1645296840.0,"The other novel way is using graph neural network

https://deepmind.com/blog/article/traffic-prediction-with-advanced-graph-neural-networks",2022-02-19 20:54:00
Comment,4,hxlxul3,,0,1645296823.0,Like all the data Epic ehr has across ALLL organizations they have,2022-02-19 20:53:43
Comment,1,hxlwpba,,0,1645296358.0,"I've run into the sane issue I live in the Philly area but work remotely for a Midwest company with Midwest salaries, I have colleagues looking for work but the pay is 30-40% below what other companies are offering from the West  Cost or Boston",2022-02-19 20:45:58
Comment,1,hxlwn78,,0,1645296334.0,"I usually use jupyter notebooks for initial testing, then I move everything into a regular python file for more testing, then I restructure as needed to clean everything up.

Jupyter is great in testing and programs that will only be used a few times, but thats about it.",2022-02-19 20:45:34
Comment,2,hxlw1ot,,0,1645296085.0,"Yeah I’ve been there… I found these guys to be pretty good at explaining stuff! They have some training for free, and maybe you can get your company to pay for the rest https://www.sqlbi.com/training/",2022-02-19 20:41:25
Comment,3,hxlviza,,0,1645295867.0,"Code meant to run unsupervised in an official capacity for the business (i.e. interacting with real world stakeholders, processes, and objects).

Of course, not every bit of data science code needs to run unsupervised...",2022-02-19 20:37:47
Comment,12,hxluzxs,,0,1645295648.0,All the dataset soccer teams keep on their players and other teams. Or all betting companies datasets,2022-02-19 20:34:08
Comment,8,hxlukvg,,0,1645295476.0,"I have often thought that the datasets that the police / intelligence services work with must be pretty interesting. Who is part of what criminal network, where are their money and assets stashed etc. If it weren’t for the terrible pay, I’d probably join the police",2022-02-19 20:31:16
Comment,1,hxlu25s,,0,1645295262.0,"I'm literally using notebooks to everything (etl, web apps, scheduling). I would recommend two packages:

- https://github.com/mwouts/jupytext for converting `ipynb` file to plain python files. Additionally you can pair `ipynb` with `py` file - changes are mutual. Greatly simplifies code changes tracking in git. 

- https://github.com/mljar/mercury for converting Jupyter notebooks into web applications. By adding YAML header the widgets are added to notebook. User can change the input and execute the notebook. Greatly simplifies the process of notebook sharing with non-coders. (*disclaimer: I'm the author*)",2022-02-19 20:27:42
Comment,1,hxlu08o,,0,1645295241.0,I’ve heard it referred to as ‘The Great Renegotiation’ and that and the posts here answer the question.,2022-02-19 20:27:21
Comment,1,hxltrqb,,0,1645295142.0,"I don’t see how new grads can generate the biggest rev because first they lack of industry experience, team work experience, and if a new graduate put on a project without senior or lead, they will definitely leave  before you can count to 3. The reason new graduate is attractive hiring option is they are a cheaper choice to get the most benefits being if they are bad but they cheap, if they r good then best business decision. However for senior or lead the situation are different, they are expensive decision",2022-02-19 20:25:42
Comment,1,hxltjnz,,0,1645295049.0,scam,2022-02-19 20:24:09
Comment,1,hxltidg,,0,1645295034.0,Absolutely.,2022-02-19 20:23:54
Comment,2,hxltcg7,,0,1645294966.0,Son and nephews :),2022-02-19 20:22:46
Comment,2,hxlrvz8,,0,1645294371.0,"Also, SHAP! It's so important for everyone to know ""why"" the model does what it does. I have been using it to identify and visualize interactions in data. Call it state of the art in model explanability/interpretability.",2022-02-19 20:12:51
Comment,2,hxlrod8,,0,1645294283.0,"> Workers are just better negotiators now.

I'm debating myself if this is the case. I think companies are mainly doing it for us and transparency is better. My pay on levels.fyi is pretty damn accurate. 

I can simply point to that and say 'that's my absolute minimum.' Does that mean I'm a better negotiator now? Idk. Maybe.",2022-02-19 20:11:23
Comment,1,hxlr7j9,,0,1645294088.0,"Get a coop or internship (most are paid) that way you'll get to see what industry is about. 

Data science means everything from data analyst to developing novel algorithms and implementations, so if you're an undergrad, you will probably be leaning towards data analyst type jobs, on average.",2022-02-19 20:08:08
Comment,1,hxlpjv7,,0,1645293411.0,Hey would you mind elaborating on what the reality of corporate data science is please? I'm a colleges student and I have 'data science' on my list of possible future jobs/careers so would appreciate your perspective!,2022-02-19 19:56:51
Comment,1,hxlpj1t,,0,1645293402.0,"We have had zero people leave during the supposed ""great resignation"".",2022-02-19 19:56:42
Comment,1,hxloxt3,,0,1645293160.0,"All right, I'm surprised. I really didn't expect that to be that easy to do in Python. I was wrong. If this were /r/cmv, I'd give you the delta. 

Here's what still frustrates me, and maybe you can offer some useful advice. Out of curiosity, I DID try to figure out how to do the first step in Python, but I did NOT arrive at as elegant a solution. I did some googling, clicked through the first 3 or 4 results that looked promising, and wound up trying to use os.Path, which was messier. I think I remember seeing ""glob"" mentioned in passing in one of the Google results, as well as a few other methods. This is a general theme with my attempts to figure out how to do things in Python: I can Google it, and find some Stackoverflow posts and reproduce the solutions they offer, but then LATER I find out there was a much better way to do it.

Obviously, with any language there's multiple ways to peel an egg, but with MatLab there is often one specific function that is the obvious way to do something, and if you don't find it right away upon searching the matlab docs, you'll find it in the ""see also"" links on one of the pages you do find. The point being, it's usually not THAT hard to find the best way to do something. 

With Python, as I mentioned, there's usually many ways to do something with different packages, and as a Python novice encountering a problem for the first time, it's really hard to figure out which of the different solutions being suggested is the best, or even be sure you've found all the options. You, I'm sure, have the benefit of experience and know right off the bat that ""rglob"" is the right tool for the job. But if you encounter a problem that you DON'T already know the best solution for, how do you find out efficiently? Do you rely on a trusted source for tips on the best ways to solve various problems in Python? Do you actually try every suggested solution you can find and evaluate which is best for yourself? Do you rely on heuristics like ""I know that THIS package usually contains elegant and performant solutions, whereas THIS package usually requires more fidgeting to bring things together""? Reading entrails? 

You've raised my estimation of Python's capabilites enough that I'd seriously consider trying to develop some of the processing and analysis pipelines I have on my road map in Python (and make more of an effort to use Python in code intended for publication) IF I felt more confident that I wouldn't spend all my time chasing down false leads for solutions to simple problems like ""getting a list of folders"". My whole thing about list comprehensions springs from the last time I seriously tried to implement something in Python, wanted to select a subset from a list of strings, and none of the search results that I (or the person who was assisting me) found mentioned the fact that you could just use a numpy string array.",2022-02-19 19:52:40
Comment,2,hxlovdc,,0,1645293132.0,"I doubled my pay after moving into an MLE role from a tech consulting background, fully remote west coast pay while living in FL. Your statement is absolutely correct that there are ""good"" employers snatching all the talent, my last position became a high stress, toxic work environment. The wake up call for us is that we no longer have to acquiesce to that kind of workplace for the sake of paying your bills.",2022-02-19 19:52:12
Comment,1,hxloufg,,0,1645293122.0,"İ did the soul search part as well and since I started applying again, I can't explain why I quit to recruiters",2022-02-19 19:52:02
Comment,2,hxlon0y,,0,1645293038.0,That's an excellent explanation.,2022-02-19 19:50:38
Comment,1,hxloigh,,0,1645292987.0,"It deeply depends on what you are trying to do with your model and what type of data is in those tables.

Transforming data from a large database into a usable dataset for a model is like 90% of DS work.  The two suggestions I have is to make a documentation page per table (Confluence, Wiki, OneNote, etc.) that lists what it is with a place for usage notes, and work back from what your final dataset should look like.  If you know you need 1 row per user, then find the table(s) to get you a list of all users.  Then if you need last subscribed date, find that table.  Etc.",2022-02-19 19:49:47
Comment,1,hxln89d,,0,1645292459.0,"I’ve been wondering this myself. After I taught for a few years to get out of uni debt, I started looking in 2020 and it’s only gotten bleaker and bleaker while people will tell me “no one wants to work” or whatever. Been in sales/warehousing ever since just throwing my resume everywhere.",2022-02-19 19:40:59
Comment,1,hxlmu0y,,0,1645292296.0,"Yes research shows that companies with unlimited PTO actually have employees that take less time off, but that ain't going to be me. I'm two weeks in and I've already taken two half days for doctors appointments, and I'm taking next Friday off (even though we have Monday off already) so I can play the new Witch Queen expansion for Destiny 2. When I asked my manager he said I don't need approval for single days off, just multiple consecutive ones so we can plan coverage.",2022-02-19 19:38:16
Comment,2,hxlm6p1,,0,1645292036.0,Unlimited PTO is a scam,2022-02-19 19:33:56
Comment,2,hxllxh4,,0,1645291933.0,"Thanks a ton both of you for your inputs, i really appreciate it, really helped me clear my concepts about the topic",2022-02-19 19:32:13
Comment,1,hxlkotx,,0,1645291431.0,"Looks as though my post got removed.. what I get for using a throwaway I guess lol

Thanks a lot for the detailed response, plus the laughs!

I did have an internship at a larger company, but bureaucracy was only a slight inconvenience. The lack of any sort of impedance to actually doing my job is something I've taken for granted, I can't imagine having to jump through hoops to do basic functions.

At the same time - I would rate the culture where I am as a.. B? There are some differences in culture from what I want.

What you say about large companies having more bad than good is definitely what the rule of thumb seems to be for data science. I feel as though I will want to make a transition in the future, if only for more stability/ benefits - what skills are you talking about, ""soft skills"" like communication, or something bureaucracy related?",2022-02-19 19:23:51
Comment,2,hxlkkaf,,0,1645291380.0,Not the women and the children!,2022-02-19 19:23:00
Comment,3,hxlkfv9,,0,1645291331.0,"I’m not sure where the phony thing comes up. If they fit that title, then I’m not sure how they’re doing anything dishonest. 

Plus DS/Data Analyst technical interviews vary widely in requirements and rigor. Grifters can do just fine for the moment",2022-02-19 19:22:11
Comment,1,hxlk9h5,,0,1645291260.0,"Or just write your code in a .py file in VSCODE, right click -> run in Jupyter notebook",2022-02-19 19:21:00
Comment,3,hxljktd,,0,1645290981.0,Data science positions filled up but we're still hiring software engineers: https://boards.greenhouse.io/urbanfootprint,2022-02-19 19:16:21
Comment,5,hxlim7s,,0,1645290587.0,"Either new grads help the company run smoothly and it's something worth complaining about to lose them, or they don't help the company run smoothly and there is no point in complaining about losing them. It's intellectually dishonest to argue that companies don't care about losing new grads when they complain about losing new grads after a couple of years.

And yes, of course everyone is replaceable and companies will continue to exist even without their Y+2 new grads. It just seems strange to me that companies get upset at the idea of losing these employees when they know what to do to retain them, but refuse to do what it takes.",2022-02-19 19:09:47
Comment,2,hxlillg,,0,1645290580.0,Prepare to be unimpressed with pay raises this year.,2022-02-19 19:09:40
Comment,2,hxligle,,0,1645290522.0,Any opportunities you know of? 🤣,2022-02-19 19:08:42
Comment,1,hxliaji,,0,1645290452.0,"Yes, made famous as a method by Enrico Fermi",2022-02-19 19:07:32
Comment,3,hxlhza7,,0,1645290326.0,"Dude you are insanely generous, thanks a lot for taking the time and actually be explaining this to a stranger on the internet, really appreciate it",2022-02-19 19:05:26
Comment,5,hxlhuru,,0,1645290276.0,They're like animals!,2022-02-19 19:04:36
Comment,5,hxlhfoe,,0,1645290106.0,"gonna specify what I mean with etl pipelines.
etl pipelines in my line of work are scheduled scripts that get data from various APIs that got sent to our S3 buckets. then we load parse and transform the data and load it into our database (often in multiple scripts).

we allow data scientists and analysts then carry out analysis for whatever purpose they need.
For our etl pipelines we usually use spark for batch jobs and s3 and redshift for storage and datawarehouse.

my stack is python, sql for ETL/ELT (sql only for T), aws step functions or Airfow for DAGs (job orchestration). For CI/CD we use Azure DevOps.
to deploy required infrastructure we use CloudFormation .yaml scripts. 

Once data is loded into data warehouse or database (e.g. redshift) you can use whatever tool you like for connecting to it. If you want to do a one time job and not scheduled ETL the. jupyter is perfectly fine to extract, transform and load data where you need",2022-02-19 19:01:46
Comment,1,hxlg5jx,,0,1645289586.0,"You would apply it to your entire set of features, generally.",2022-02-19 18:53:06
Comment,7,hxlfnt2,,0,1645289392.0,"IMO, the difference between experimentation and production is blurry.

When you start a new project, you're in 100% experimentation mode, that's why Jupyter is so popular at this stage since it allows you to understand what's going on with your data.

As you make progress, you start to know what kind of stuff you need to build to process the data: ""I need to clean columns A, B, C"", ""I need to join tables A and B to compute C"", so you start to move to maybe 50% experimentation and 50% ""production"".

When you need to deploy your model, you start doing things that are more engineering than data science, so you may go all in 100% production mode.

But as soon as your project (dashboard, model) is deployed, you go back to experimentation mode to some extent. The model may break in production, you may want to explore new features to improve performance, you may need to find why certain subpopulations have worse performance than others. Answering these questions requires a lot of exploration and experimentation so at any time you're moving back and forth between experimentation and production.",2022-02-19 18:49:52
Comment,1,hxlemfc,,0,1645288975.0,"Large enough transformer may refuse to learn badly labeled examples - and that will be visible by comparing ground ""truth"" vs prediction.",2022-02-19 18:42:55
Comment,1,hxlear7,,0,1645288846.0,"Instead of Word2Vec use SBERT models.

Don't use unsupervised method - just train softmax on properly classified feedback.

You can also make use of ZeroShotClassification pipeline but thats slight overkill imo and waste of compute.",2022-02-19 18:40:46
Comment,3,hxldx2a,,0,1645288692.0,"Oh wow. That was the post brought it into my attention. Reddit is small, i guess.",2022-02-19 18:38:12
Comment,17,hxldj2n,,0,1645288535.0,"Ploomber creator here, feel free to ask me anything :)

I agree that the overall sentiment is that notebooks are only good for experimentation, and there are valid reasons to think that. However, it's possible to achieve a good balance between the interactivity and dynamism that Jupyter offers with modular, maintainable code required for production. That's our objective with Ploomber.

If you want to learn more, check out [our blog post.](https://ploomber.io/blog/nbs-production/)",2022-02-19 18:35:35
Comment,3,hxlcf79,,0,1645288079.0,Lost those to Nike 'jobs',2022-02-19 18:27:59
Comment,1,hxlc4wa,,0,1645287962.0,Are you an analyst or a DS At the hospital ? I am in hospital / healthcare too. I just Moved last year to a f100 into a health tech division. Message me if you want to work chat,2022-02-19 18:26:02
Comment,1,hxlc0dx,,0,1645287911.0,"Hi u/TheDefender365, I removed your submission for the following removal reasons:

* **Articles from blog aggregators are not allowed.** Submissions from towardsdatascience.com are not allowed on r/datascience.
* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 27 karma.",2022-02-19 18:25:11
Comment,1,hxlbm3w,,0,1645287751.0,"Writing unit tests are not difficult. If you can write a script in python using something like numpy or pandas, you should be able to figure out how to use pytest. You have a super simple, one off script that you can verify the output quite easily, sure.",2022-02-19 18:22:31
Comment,2,hxlbhi0,,0,1645287699.0,We’re supposedly doing some sort of market rate adjustment in march. I asked for 20% minimum and am definitely leaving if I don’t get that or more.,2022-02-19 18:21:39
Comment,1,hxlb81x,,0,1645287593.0,"You'd think so, but then you start working there and half the people making $150-250K just complain they aren't making $350-450K like the software engineers and product managers. Check out the tech company section of Blind (anonymous work chat app), if you wanna see some truly entitled folks.",2022-02-19 18:19:53
Comment,1,hxlajry,,0,1645287314.0,"I come from an economics background as well, and actually hated using R the first time I tried it. So coming from a non-technical background, and feeling like coding doesn't come naturally is fine. The data world needs people of all types. To figure out if you'd enjoy data science, there are a few things you can do. Note that all of the advice below comes from someone who works as a Data Engineer, not a Dara Scientist, so take it with a grain of salt. 

First, look back on your studies in undergrad. Did you enjoy your econometrics course(s)? Did you find yourself wanting to take a more math-heavy course load? Did you want to go beyond the surface-level content that was being taught in your 201 and 301 econ courses, and figure out the data behind all the graphs? Or, did you look at the MR and MC curves and think about their primary drivers and what questions you'd ask to determine them? If so, then you've already demonstrated the analytical mindset of a data scientist. 

Second, you could try your hand at a few Kaggle challenges. It doesn't have to be one of the active challenges, just any challenge you find interesting. Be sure to pay attention to when your interest piques and wanes. Do you find yourself feeling satisfied once you've found the initial answer? Or does your interest really pique once you've got your model/algorithm in place and now you need to tune it. Are you more interested in assessing the problem from multiple angles to determine the right solution to use, or are your more interested in running queries and getting answers quickly? Do you like building visualizations more? Or models more? This will help determine if you're more of a business analyst archetype, or a machine learning archetype. 

Lastly, observe the world around you, think of some questions you'd like answered, and then go find the data to answer them. Build a solution and again pay attention to the things mentioned in 2. The main value in this approach is assessing your passion for thinking of questions that need to be answered and feeling motivated to answer them. If you don't like doing this, then DS might not be for you.",2022-02-19 18:15:14
Comment,8,hxlajc0,,0,1645287309.0,"Yes I do agree, because [I was actually the OP of that front page](https://www.reddit.com/r/unpopularopinion/comments/sn6c84/250k_is_the_new_six_figures/) r/unpopularopinion post.",2022-02-19 18:15:09
Comment,1,hxla08j,,0,1645287087.0,Agreed.,2022-02-19 18:11:27
Comment,3,hxl9x7i,,0,1645287053.0,"That's not been my experience at all. In FAANG we've got the full scope of data jobs from business analyst, business intelligence engineer, data engineer, data scientist, research scientist, and applied scientist (SDE with AI/ML), with a wide range of salaries to go along with them. We certainly weren't in the business of paying a data science premiums for something a BI Engineer could do. Plus if you want to do quality data science, you need big data, and FAANG has that in spades. I suspect these rumors came from data scientists that might be hired into immature teams with still developing data environments. Too often folks just want perfect clean data to work with and don't want to participate in the process of data cleanup, normalization, and formatting, which I feel is needed at every level mentioned about to ensure you truly understand the data (not that you should do all of it, that's for data engineers, but to some degree you should know the data you're working with).",2022-02-19 18:10:53
Comment,6,hxl8duq,,0,1645286414.0,"This is business. Everyone is a phony in some capacity. Whether it will ruin operation is another thing. 99% of people don’t know how to code, so if someone is lacking technically, but they have the “soft skills” to work the executives and decision makers, I’d probably give them the benefit of the doubt so long as they are a team player.",2022-02-19 18:00:14
Comment,1,hxl7u51,,0,1645286183.0,LOL,2022-02-19 17:56:23
Comment,-2,hxl7opr,,0,1645286120.0,Job security isn’t necessarily a good thing. Some people that get burned by former employers and use it to really take initiative. Some people sit on their ass in the same role and a decade goes by and they ask themselves what in the hell they’ve been doing with their life the whole time.,2022-02-19 17:55:20
Comment,3,hxl7j1s,,0,1645286054.0,Completely pointless and a huge waste of time for any kind of EDA,2022-02-19 17:54:14
Comment,9,hxl77h8,,0,1645285921.0,Businesses only attempt to retain people because it keeps the operation of money making flowing smoothly. No one is ever “serious” about it. I think it’s more that the whole “we are a family” nonsense is being destroyed in front of our very eyes and the business advantage that large corporate outfits held over society is being picked apart. Workers are just better negotiators now.,2022-02-19 17:52:01
Comment,1,hxl6qpb,,0,1645285726.0,"If they are hiring full remote, I’m always looking for more offers!",2022-02-19 17:48:46
Comment,5,hxl694o,,0,1645285518.0,Got some awesome new coworkers from that region. Seriously good talent.,2022-02-19 17:45:18
Comment,16,hxl66fk,,0,1645285485.0,"> The issue is that we are losing these new ~~hires~~ **grads** after a couple of years to SWE jobs.

I changed a word to really make my point. Out of all workers, new grads have the greatest potential to grow their income. If you want to retain new grads offer them a 15-20% raise every year for the first 5 years of their career. If you're not offering this much then you're not serious about trying to retain them.",2022-02-19 17:44:45
Comment,-3,hxl5s6r,,0,1645285315.0,They do require technical interviews so that won't pan out lol. We know there are phonies out there.,2022-02-19 17:41:55
Comment,1,hxl5jc0,,0,1645285210.0,"/u/the75th Heya! Just wanted to thank you for the advice. I just stopped trying to recreate my workflow. I started with R, picked up a basic udemy course and am gradually and slowly making my way through it. I definitely am nowhere near my goal but while doing it this way, I am actually enjoying learning the software and its idiosyncrasies! Probably this will help in actually solving the issue in the long run, plus learning has become a little more enjoyable. Appreciate the solid advice!",2022-02-19 17:40:10
Comment,1,hxl4smi,,0,1645284886.0,Memes only on Monday,2022-02-19 17:34:46
Comment,2,hxl36m4,,0,1645284175.0,"What do you use to load data into the python script and and what does the modelling usually go like, could you elaborate? Like a list of things that you do while usually modelling data and building ETL pipelines? What packages do you use and what databases are used and what result are you usually hoping for? Thanks for your time i know it's a lot...",2022-02-19 17:22:55
Comment,3,hxl2sqn,,0,1645284006.0,"Usually in other places it is a mix of Data Analyst and Stats stuff. Like in a lot of omics biotech startups, data science is just automate tons of regressions and provide p values and visualizations. But yea basically slightly fancier “AB testing” except its omics data. Oh and of course data cleaning too",2022-02-19 17:20:06
Comment,2,hxl1yrp,,0,1645283631.0,"just jupyter notebooks. Python is a solid choice for ETL as it is the most common language for data engineering.

I am a data engineer and most ETL stuff I write is in python.

when you push code to production you usually crrate a CI/CD pipeline in gitlab, github actions, azure devops etc. the code usually goes through automated unit tests, integration tests, end-to-end tests and if everything passes then your code is pushed to production environment.

jupyter notebooks are not meant to be used for such process as they are meant to be as an interactive tool for researchers, data scientists to write their code and collaborate.

There is nothing wrong with using jupyter notebook to connect to databases, fetch some data, analyse it and create a model. just if you want to have an automated etl process, it is not the right tool",2022-02-19 17:13:51
Comment,2,hxl1j55,,0,1645283431.0,"I've done this. You still end up editing the exported Python script a little, but the notebook gets you 90% of the way to a cron-worthy script.",2022-02-19 17:10:31
Comment,3,hxl1dt9,,0,1645283365.0,"I am working as a junior data scientist in fintech. Things that I do on a daily basis are EDA with python, SQL, ad-hoc requests with python, SQL. Sometimes I will be assigned to do changes in some ML model which is in prod, and if the senior is happy with the changes, results, then the model's deployed. I'm learning things like AWS sagemaker for deploying and monitoring ML models as it's the what we use for these purposes.

In general, it's nice but there's tons of domain knowledge to acquire in fintech and you have to acquire this knowledge if you want to progress.",2022-02-19 17:09:25
Comment,1,hxl0nrm,,0,1645283038.0,"Big companies poached small company employees.

It was the perfect storm for that to happen.

Small and medium sized companies had their contracts, projects or supply chain in a very risky position, big corpo had the muscle to ""support"" people through the rough patch and reap the results in the long run, so they seized the opportunity.

Just look at headcount growth for big corpo vs SMC",2022-02-19 17:03:58
Comment,2,hxl0ah8,,0,1645282867.0,"It’s best to use PCA when:
   1) The variables describe the same underlying concept (length, width, and height)
   2) when each of the variables are all correlated with the target variable.",2022-02-19 17:01:07
Comment,7,hxl09xo,,0,1645282861.0,"I've heard that too, but isn't that how it is at most places? At least in FAANG you know you'll be properly compensated and have that name on your resume.",2022-02-19 17:01:01
Comment,1,hxl05g1,,0,1645282807.0,"Hadn’t even considered insights on competition. I like hearing other’s perspectives to help think differently, thank you!",2022-02-19 17:00:07
Comment,-11,hxkzq0j,,0,1645282607.0,You’re so progressive,2022-02-19 16:56:47
Comment,17,hxkzka3,,0,1645282531.0,"Depends on the exact purpose of the code.

From what I understand some of the data science is basically data analytics, where you write throw-away scripts for your own data crunching use. This kind of position won't require any automated testing -- though it helps to produce reusable code even for my own internal use.

But if the people that get hired are not from CS but closer to the data part (e.g. statistics, mathematics, ...), expecting them to also have solid SWE skills is going to narrow the possible employees *a lot.* What I've seen in my own experience (Physics), unless you have extracurricular programming/SWE education, you'll get out of the curriculum being able to ""code"" a bit, but not anything anyone else should ever have to touch. 

To think that I almost took a masters thesis, that would have required me to continue working on a former PhD students data crunching code. I can only guess the horrors that would have put me through.",2022-02-19 16:55:31
Comment,21,hxkz51r,,0,1645282334.0,"Let me know if this helps. The purpose of PCA is to reduce correlated data and find the principal components. PCA works best with lots of correlated data. The principal components are the components, in an abstract sense, of your data that are uncorrelated. You are transforming your data from its current space to an abstract space where the principal components are linear combinations of the original data and each component is orthogonal or uncorrelated from every other component. Looking at the weights (or linear coefficients) you find, you can determine which components of your original dataset make up each principal component. If you take truely uncorrelated data and run PCA you will find that each column of data is its own principal component so then there's no need to run PCA. You don't need to identify which columns are correlated and which are uncorrelated before running PCA it will give that to you.


As an example, say you have 100 variables and 30 of them are highly correlated with each other (we'll call them group 1), 40 others are correlated with themselves (group 2), 
 20 others are correlated with themselves (group 3), 8 others don't fit nicely into any of these groups and are in some sense correlated to all of them but at different times and different ways (group 4), and 2 of them are totally uncorrelated with any of the other variables (group 5). When you run PCA, the groups 1, 2, and 3 will all be represented as distinct principal components. Really this means you have 3 variables representing 90 of the variables. The variables from group 4 will be spread over those three principal components with different parts of them represented in each component. So really 98 of the variables can be represented by just 3 variables. That's pretty fantastic for the data reduction. Then for group 5 they don't belong in any other group on their own they will be represented as 2 additional principal components. Note: With PCA you get 1 prinicpal component per variable so you would have 100 prinicpal components but the magnitude or energy of those principal components can be used to determine how many to keep. So you just reduced 100 variables of data to 5 principal components that you can use to model or to explore the data further with. The group 5 in this example is the columns that are not correlated with anything else in your dataset that you are proposing dropping, PCA will identify these for you.

If your 100 variables were all uncorrelated then PCA would give you back 100 principal components and there was no reason to run PCA in the first place but you can learn that quickly by running PCA analysis.

For your data you would identify the first two principal components and plot them as u/DeathBy1000Words said",2022-02-19 16:52:14
Comment,1,hxkyxu7,,0,1645282242.0,That would be any industry! You could help a compact big time by gathering and analyzing data on their competition. For example when I was at Uber complete teams were tracking investments in and by competition as an input for pricing and incentives decisions.,2022-02-19 16:50:42
Comment,2,hxkywt9,,0,1645282228.0,"That's fair enough! You may want to consider whether there are better ways to do what you're trying to achieve (notebooks can encourage weird code habits) but at the end of the day 1/3 of data science is hacking.  If it works, it works.",2022-02-19 16:50:28
Comment,3,hxkyc95,,0,1645281962.0,IT experience? You are getting away from data science at that point.,2022-02-19 16:46:02
Comment,2,hxkyaxi,,0,1645281945.0,"You will probably be doing all the work yourself, as there is talent shortage there also...",2022-02-19 16:45:45
Comment,13,hxky5bt,,0,1645281869.0,And the children too!,2022-02-19 16:44:29
Comment,1,hxkxizu,,0,1645281571.0,Is that just with jupyter notebooks or python in general? Can we use Python scripts for etl processes using pymongo and sqllite packages? If not what softwares are used for such processes?,2022-02-19 16:39:31
Comment,6,hxkxe3w,,0,1645281503.0,"Jupyter notebooks are mostly used for experimentation. 

But if you are serious about using it in production, check out nbdev, https://github.com/fastai/nbdev

Netflix uses notebooks in production as they are very good at logging the activity. So it's not all bad, you can do a lot with it if you want to. 

You can parameterize a notebook using papermill too.",2022-02-19 16:38:23
Comment,1,hxkwzgc,,0,1645281309.0,What if I just export the notebook into a python script and run it on CronJob? Is that something someone in a data role would do or be responsible for?,2022-02-19 16:35:09
Comment,2,hxkwpmq,,0,1645281181.0,"Jupyter is a *notebook* - clue is in the label. It's a great place to scribble in, or maybe write an essay in. I work in research, and producing a jupyter notebook that combines writing and output is fantastic.  But if you're writing loads of code, refactor that shit elsewhere.",2022-02-19 16:33:01
Comment,2,hxkwn4p,,0,1645281149.0,"Yes, thanks a lot 👍",2022-02-19 16:32:29
Comment,1,hxkwexg,,0,1645281038.0,"Jupyter is a nice tool for experimentation and for research type of work.
It is nocer to collaborate with other scientists as you can add comments and format the notebook using markup language.

in theory you can use jupyter for etl or automated scripts as there are workarounds how to do it. However it is not meant for that and is considered a poor practice",2022-02-19 16:30:38
Comment,3,hxkvouk,,0,1645280672.0,"For me production level work means how easy it is to collaborate and extend what you have developed. Basically how would you go about a piece of code once developed to be reusable, testable, and extendable. 

These things aren't very easy to achieve using a jupyter notebook. It's difficult to make sense out of a version of jupyter notebook. If you want to understand why some piece of code was added or removed, you would find it hard because committing to any versioning system will add lot of meta-data.

What I want to convey is testing or extending your jupyter notebook is cumbersome. It can be achieved but not right out of the box and hence tools like ploomber exist.

There are also performance aspect which can be ignored since here whatever performance you get out of a jupyter notebook would be more or less same as from a stand-alone python script.",2022-02-19 16:24:32
Comment,0,hxkvg56,,0,1645280548.0,"Yeah Plotly is nice and definitely been around longer. I like the 3D stuff even though I never find a use for it. I don’t like all the little buttons in the corner of the graphs with their logo and stuff. Makes it feel less clean to me.

That is why I like Altair more. If you know JavaScript (which most of these interactive data viz libraries are usually built with anyways) then things like Plot.js or D3.js (depending on the use case) make more sense to use for me.",2022-02-19 16:22:28
Comment,21,hxkvd6y,,0,1645280505.0,Men? Really? Some of them were women.,2022-02-19 16:21:45
Comment,1,hxkv3t9,,0,1645280372.0,"Same, lol. Still freelancing to pay for the studies, but I'm happy Of my situation. It's a bit exhausting to do both tho.",2022-02-19 16:19:32
Comment,1,hxkuy0y,,0,1645280290.0,"I left a small startup to a local consulting agency, got paid 50% more and my client seems pretty cool. The PM has actually good technical knowledge and little people skills, which I don't mind. All remote instead of having to wake up before 6AM is a big plus imo.",2022-02-19 16:18:10
Comment,4,hxkunv6,,0,1645280144.0,"Glad to hear that you like this package! 

Actually we recently supported this feature with plotly-resampler! :)  You can now wrap any plotly Figure (e.g., FigureResampler(px.line(...))) and then call .show_dash(). 

So;  
1) The requirement to wrap the constuctor is now removed (we still need to update the docs). However, adding traces with the data in hf_x and hf_y is still significantly faster.  
2) Any plotly Figure can be wrapped (e.g., bar chart, px.line, ..., combionations thereof). But obviously, only high dimensional scatter traces will get resampled.",2022-02-19 16:15:44
Comment,21,hxkuipl,,0,1645280070.0,"Not the guy you replied to, but for me the difference between experimentation and production is:

Experimentation is me trying something out with no idea what's gonna happen and trying to understand the data and see if there's a use for it.

Production is okay yes this data/model/code/whatever has use to the company an we're going to want to run it regularly and not just a once in a blue moon thing I could do adhoc. My code is well written and does it's task efficiently. I've commented my code. I've tested it multiple times and in multiple situations. And if my company/org has a list of requirements like unit testing or whatever I've done them. Then this is ready for production.

It's that what you were looking for?",2022-02-19 16:14:30
Comment,2,hxkucva,,0,1645279984.0,whoa that's a lot of money,2022-02-19 16:13:04
Comment,1,hxkrpcr,,0,1645278596.0,Altair - it has great default themes and is ready to go with minimal code. It is difficult to make more complex charts though,2022-02-19 15:49:56
Comment,2,hxkri47,,0,1645278486.0,"I use them mainly for journaling, experimenting, working through complex functions or ad hoc requests.",2022-02-19 15:48:06
Comment,2,hxkqwpf,,0,1645278162.0,My wife & I quit the same day. She’s def retired. I’m retired until I can find a nontoxic tech org for Prodmgmt work. We saved salaries for 18 months to do so.,2022-02-19 15:42:42
Comment,-29,hxkq4wr,,0,1645277732.0,"Best ask in stack overflow, this isn't really the place for very basic data science",2022-02-19 15:35:32
Comment,1,hxkpt95,,0,1645277547.0,"Best Laptop is one with a nice screen you like looking at, an ergonomic keyboard that feels good to you, size/battery/creature comforts you can live with, and the operating system you like best (or is suggested by your program/company).

Pretty much everything any of us do can be done on any machine. Data or compute intensive stuff is done on the cloud. The laptop is an interface device to you.

To answer your question: my work machine is a Thinkpad with windows. Private machine is a Thinkpad with Linux (I also have a surface, which is a piece of shit)",2022-02-19 15:32:27
Comment,39,hxkppxr,,0,1645277496.0,You don't need to pre-filter the data for correlation. Send everything in and select the 2 eigenvectors with highest eigenvalues.,2022-02-19 15:31:36
Comment,1,hxkpczp,,0,1645277289.0,"Does it have to be a laptop? Do you have the budget to rent space in any of the super computers?

Focus on available ram and gpu dedicated ram over processor, hard drive and especially the fancy lights etc. A desktop will let you stretch your dollar more. If you can afford to rent space for resource intensive tasks but don’t always need that available power, you can save a little.",2022-02-19 15:28:09
Comment,10,hxkp26o,,0,1645277113.0,How would you describe to a beginner what production level work entails? Could you kindly provide some examples?,2022-02-19 15:25:13
Comment,7,hxkoxkr,,0,1645277038.0,"In VS Code using a .ipynb file, you have an option where you can export it as a Python script.",2022-02-19 15:23:58
Comment,10,hxkowt5,,0,1645277025.0,"Took a year off to hike and travel, and decided to hike the Pacific Crest Trail.",2022-02-19 15:23:45
Comment,2,hxkodw7,,0,1645276723.0,In healthcare. Went from hospital system to start up for double salary and equity.,2022-02-19 15:18:43
Comment,2,hxkodn9,,0,1645276719.0,"The remote-work stuff + the increase in money in tech, made the pool of potential employers really big for most tech folks, and it became easier to interview for other roles (no need to travel for on-sites, you can get away with taking minimal PTO, etc.).",2022-02-19 15:18:39
Comment,5,hxko8qj,,0,1645276643.0,"Do you also agree with the new notion of ""250k is the new six figure"" ?",2022-02-19 15:17:23
Comment,6,hxko4p7,,0,1645276578.0,Glass ceiling is much different over here.,2022-02-19 15:16:18
Comment,0,hxko1uu,,0,1645276531.0,Good men. May their memories be a blessing.,2022-02-19 15:15:31
Comment,1,hxko0m1,,0,1645276510.0,"Hi u/Spirited-Order4409, I removed your submission for the following removal reasons:

* **Not enough karma.** You don't have enough karma to start a new thread on r/datascience, but you can post your questions in the [Entering and Transitioning thread](https://www.reddit.com/r/datascience/search/?q=Weekly%20Entering%20%26%20Transitioning%20Thread&restrict_sr=1&sort=new&t=week) until you accumulate at least 50 karma. Right now you only have 26 karma.",2022-02-19 15:15:10
Comment,35,hxko0k1,,0,1645276510.0,I’m assuming it rocks.,2022-02-19 15:15:10
Comment,3,hxknuj1,,0,1645276408.0,seconded. We will see another have in the next couple months pending comp increase. Personally if comp isn't >6% I'm gone by June.,2022-02-19 15:13:28
Comment,1,hxknpa5,,0,1645276320.0,I have an X1 Yoga Thinkpad from work (with a dock and two decent monitors) but in general every mid range laptop will do. As a student all your tasks will easily compute on smaller hardware (e.g. the energy efficient i5s) and if you really needed more your lab/school should have the appropriate hardware. Unless it's deep learning most libraries are very decently optimized so the worst case would be that you just leave it running overnight but even that should be very rare. If you really wanted to train more complex stuff on your own hardware you should opt for a desktop and ignore laptops altogether,2022-02-19 15:12:00
